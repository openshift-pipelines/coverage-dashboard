<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Coverage Report</title>
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/go.min.js"></script>
    <style>
      :root {
  --sidebar-width: 280px;
  --topbar-height: 48px;
  --line-height: 20px;
  --font-mono: ui-monospace, SFMono-Regular, "SF Mono", Menlo, Consolas, "Liberation Mono", monospace;
}

[data-theme="dark"] {
  --bg: #1e1e1e;
  --bg-secondary: #252526;
  --bg-tertiary: #2d2d2d;
  --text: #d4d4d4;
  --text-muted: #808080;
  --border: #3c3c3c;
  --covered: rgba(35, 134, 54, 0.25);
  --covered-gutter: #238636;
  --uncovered: rgba(218, 54, 51, 0.25);
  --uncovered-gutter: #da3633;
  --highlight: #264f78;
  --highlight-match: #613214;
  --accent: #569cd6;
  --hover: #2a2d2e;
}

[data-theme="light"] {
  --bg: #ffffff;
  --bg-secondary: #f3f3f3;
  --bg-tertiary: #e8e8e8;
  --text: #24292f;
  --text-muted: #656d76;
  --border: #d0d7de;
  --covered: rgba(35, 134, 54, 0.15);
  --covered-gutter: #1a7f37;
  --uncovered: rgba(218, 54, 51, 0.15);
  --uncovered-gutter: #cf222e;
  --highlight: #ddf4ff;
  --highlight-match: #fff8c5;
  --accent: #0969da;
  --hover: #f6f8fa;
}

* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

html, body {
  height: 100%;
  overflow: hidden;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
  font-size: 14px;
  background: var(--bg);
  color: var(--text);
}

#app {
  display: grid;
  grid-template-columns: var(--sidebar-width) 1fr;
  height: 100%;
}

/* Sidebar */
#sidebar {
  display: flex;
  flex-direction: column;
  background: var(--bg-secondary);
  border-right: 1px solid var(--border);
  overflow: hidden;
}

#sidebar-header {
  padding: 16px;
  border-bottom: 1px solid var(--border);
}

/* Logo link */
#logo-link {
  text-decoration: none;
  color: inherit;
  display: block;
}

#logo-link:hover #logo-container {
  opacity: 0.8;
}

#logo-container {
  display: flex;
  align-items: center;
  gap: 10px;
  margin-bottom: 12px;
  transition: opacity 0.15s ease;
}

#logo-container .github-icon {
  flex-shrink: 0;
  color: var(--text-muted);
  transition: color 0.15s ease;
}

#logo-link:hover .github-icon {
  color: var(--accent);
}

#logo {
  flex-shrink: 0;
  width: 32px;
  height: 32px;
}

#logo-text {
  flex: 1;
  min-width: 0;
}

#sidebar-header h1 {
  font-size: 16px;
  font-weight: 600;
  margin: 0;
  line-height: 1.2;
}

#tagline {
  font-size: 12px;
  font-weight: 500;
  color: var(--text-muted);
  margin: 2px 0 0 0;
  line-height: 1.3;
}

#summary {
  font-size: 13px;
  color: var(--text-muted);
}

#summary .percent {
  font-weight: 600;
  color: var(--text);
}

#search-box {
  padding: 8px 16px;
  border-bottom: 1px solid var(--border);
}

#search-input {
  width: 100%;
  padding: 6px 10px;
  border: 1px solid var(--border);
  border-radius: 4px;
  background: var(--bg);
  color: var(--text);
  font-size: 13px;
}

#search-input:focus {
  outline: none;
  border-color: var(--accent);
}

/* Sort controls */
#sort-controls {
  display: flex;
  gap: 0;
  margin: 8px 12px;
  border: 1px solid var(--border);
  border-radius: 4px;
  overflow: hidden;
}

.sort-btn {
  flex: 1;
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 4px;
  padding: 6px 8px;
  background: var(--bg-secondary);
  color: var(--text);
  border: none;
  cursor: pointer;
  font-size: 12px;
  transition: background-color 0.2s, color 0.2s;
}

.sort-btn:hover {
  background: var(--hover);
}

.sort-btn.active {
  background: var(--accent);
  color: #fff;
}

.sort-btn .icon {
  font-weight: 600;
}

.sort-btn .label {
  font-size: 11px;
}

/* Coverage badges for directories */
.coverage-badge {
  margin-left: auto;
  padding-left: 8px;
  font-size: 11px;
  color: var(--text-muted);
  font-weight: 500;
  font-family: var(--font-mono);
}

#file-tree {
  flex: 1;
  overflow-y: auto;
  padding: 8px 0;
}

/* Sidebar footer */
#sidebar-footer {
  padding: 12px 16px;
  border-top: 1px solid var(--border);
  font-size: 12px;
  text-align: center;
}

#sidebar-footer a {
  color: var(--text-muted);
  text-decoration: none;
  display: inline-flex;
  align-items: center;
  gap: 6px;
}

#sidebar-footer a:hover {
  color: var(--accent);
  text-decoration: underline;
}

#sidebar-footer .github-icon {
  flex-shrink: 0;
}

.tree-node {
  cursor: pointer;
  user-select: none;
}

.tree-item {
  display: flex;
  align-items: center;
  padding: 4px 16px;
  gap: 6px;
  white-space: nowrap;
}

.tree-item:hover {
  background: var(--hover);
}

.tree-item.selected {
  background: var(--highlight);
}

.tree-item .icon {
  width: 16px;
  text-align: center;
  font-size: 12px;
  color: var(--text-muted);
}

.tree-item .name {
  font-size: 13px;
  overflow: hidden;
  text-overflow: ellipsis;
  flex: 1;
  min-width: 0;
}

.tree-children {
  display: none;
}

.tree-node.expanded > .tree-children {
  display: block;
}

.tree-children .tree-item {
  padding-left: calc(16px + var(--depth, 0) * 16px);
}

.tree-node.hidden {
  display: none;
}

/* Canvas */
#canvas {
  display: flex;
  flex-direction: column;
  overflow: hidden;
}

#topbar {
  display: flex;
  align-items: center;
  justify-content: space-between;
  height: var(--topbar-height);
  padding: 0 16px;
  background: var(--bg-secondary);
  border-bottom: 1px solid var(--border);
  gap: 16px;
}

#file-path {
  font-size: 13px;
  font-family: var(--font-mono);
  color: var(--text-muted);
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

#topbar-actions {
  display: flex;
  align-items: center;
  gap: 12px;
}

#in-file-search {
  display: flex;
  align-items: center;
  gap: 8px;
}

#content-search {
  width: 180px;
  padding: 4px 8px;
  border: 1px solid var(--border);
  border-radius: 4px;
  background: var(--bg);
  color: var(--text);
  font-size: 12px;
}

#content-search:focus {
  outline: none;
  border-color: var(--accent);
}

#match-info {
  font-size: 12px;
  color: var(--text-muted);
  min-width: 60px;
}

#prev-match, #next-match {
  padding: 2px 8px;
  border: 1px solid var(--border);
  border-radius: 4px;
  background: var(--bg);
  color: var(--text);
  cursor: pointer;
  font-size: 10px;
}

#prev-match:hover, #next-match:hover {
  background: var(--hover);
}

#theme-toggle {
  padding: 6px 10px;
  border: 1px solid var(--border);
  border-radius: 4px;
  background: var(--bg);
  color: var(--text);
  cursor: pointer;
  font-size: 16px;
}

#theme-toggle:hover {
  background: var(--hover);
}

#syntax-toggle {
  padding: 6px 10px;
  border: 1px solid var(--border);
  border-radius: 4px;
  background: var(--bg);
  color: var(--text);
  cursor: pointer;
  font-size: 14px;
  font-family: var(--font-mono);
}

#syntax-toggle:hover {
  background: var(--hover);
}

#syntax-toggle.active {
  background: var(--accent);
  color: #fff;
  border-color: var(--accent);
}

#help-toggle {
  padding: 6px 10px;
  border: 1px solid var(--border);
  border-radius: 4px;
  background: var(--bg);
  color: var(--text);
  cursor: pointer;
  font-size: 14px;
  font-weight: 600;
}

#help-toggle:hover {
  background: var(--hover);
}

/* Override highlight.js to use theme-aware colors */
.hljs { background: transparent !important; }

[data-theme="dark"] .hljs-keyword { color: #569cd6; }
[data-theme="dark"] .hljs-type { color: #4ec9b0; }
[data-theme="dark"] .hljs-string { color: #ce9178; }
[data-theme="dark"] .hljs-number { color: #b5cea8; }
[data-theme="dark"] .hljs-comment { color: #6a9955; }
[data-theme="dark"] .hljs-built_in { color: #dcdcaa; }
[data-theme="dark"] .hljs-literal { color: #569cd6; }
[data-theme="dark"] .hljs-function { color: #dcdcaa; }

[data-theme="light"] .hljs-keyword { color: #0000ff; }
[data-theme="light"] .hljs-type { color: #267f99; }
[data-theme="light"] .hljs-string { color: #a31515; }
[data-theme="light"] .hljs-number { color: #098658; }
[data-theme="light"] .hljs-comment { color: #008000; }
[data-theme="light"] .hljs-built_in { color: #795e26; }
[data-theme="light"] .hljs-literal { color: #0000ff; }
[data-theme="light"] .hljs-function { color: #795e26; }

/* Viewport */
#viewport {
  flex: 1;
  overflow: auto;
  background: var(--bg);
  outline: none;
}

#viewport::-webkit-scrollbar {
  width: 14px;
  height: 14px;
}

#viewport::-webkit-scrollbar-track {
  background: var(--bg);
}

#viewport::-webkit-scrollbar-thumb {
  background: var(--border);
  border: 3px solid var(--bg);
  border-radius: 7px;
}

#viewport::-webkit-scrollbar-thumb:hover {
  background: var(--text-muted);
}

.code-container {
  display: table;
  min-width: 100%;
  font-family: var(--font-mono);
  font-size: 13px;
  line-height: var(--line-height);
}

.code-line {
  display: table-row;
}

.code-line:hover {
  background: var(--hover);
}

.code-line.covered {
  background: var(--covered);
}

.code-line.uncovered {
  background: var(--uncovered);
}

.code-line.covered:hover {
  background: var(--covered);
}

.code-line.uncovered:hover {
  background: var(--uncovered);
}

.gutter {
  display: table-cell;
  width: 4px;
  min-width: 4px;
}

.code-line.covered .gutter {
  background: var(--covered-gutter);
}

.code-line.uncovered .gutter {
  background: var(--uncovered-gutter);
}

.line-number {
  display: table-cell;
  width: 50px;
  min-width: 50px;
  padding: 0 12px 0 8px;
  text-align: right;
  color: var(--text-muted);
  user-select: none;
  vertical-align: top;
}

.line-content {
  display: table-cell;
  padding-right: 16px;
  white-space: pre;
  tab-size: 4;
}

.match-highlight {
  background: var(--highlight-match);
  border-radius: 2px;
}

.current-match {
  background: var(--accent);
  color: #fff;
}

/* Empty state */
.empty-state {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  height: 100%;
  color: var(--text-muted);
  gap: 8px;
}

.empty-state .icon {
  font-size: 48px;
  opacity: 0.5;
}

/* Scrollbar for file tree */
#file-tree::-webkit-scrollbar {
  width: 8px;
}

#file-tree::-webkit-scrollbar-track {
  background: transparent;
}

#file-tree::-webkit-scrollbar-thumb {
  background: var(--border);
  border-radius: 4px;
}

#file-tree::-webkit-scrollbar-thumb:hover {
  background: var(--text-muted);
}

/* Help modal */
.modal {
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background: rgba(0, 0, 0, 0.5);
  display: flex;
  align-items: center;
  justify-content: center;
  z-index: 1000;
}

.modal.hidden {
  display: none;
}

.modal-content {
  background: var(--bg-secondary);
  border: 1px solid var(--border);
  border-radius: 8px;
  padding: 24px;
  max-width: 400px;
  width: 90%;
}

.modal-content h2 {
  margin-bottom: 16px;
  font-size: 18px;
}

.modal-content dl {
  display: grid;
  grid-template-columns: auto 1fr;
  gap: 8px 16px;
}

.modal-content dt {
  font-family: var(--font-mono);
  background: var(--bg-tertiary);
  padding: 2px 6px;
  border-radius: 4px;
  font-size: 13px;
}

.modal-content dd {
  color: var(--text-muted);
}

.modal-content button {
  margin-top: 20px;
  padding: 8px 16px;
  border: 1px solid var(--border);
  border-radius: 4px;
  background: var(--accent);
  color: #fff;
  cursor: pointer;
  width: 100%;
}

/* Selected line range (multi-line selection) */
.code-line.selected-line {
  background-color: var(--highlight);
}

.code-line.selected-line.covered {
  background-color: var(--highlight);
}

.code-line.selected-line.uncovered {
  background-color: var(--highlight);
}

/* Line number click indicator */
.line-number {
  cursor: pointer;
}

.line-number:hover {
  color: var(--accent);
}

    </style>
  </head>
  <body data-theme="dark">
    <div id="app">
      <aside id="sidebar">
        <div id="sidebar-header">
          <a
            href="https://github.com/chmouel/go-better-html-coverage"
            id="logo-link"
            target="_blank"
            rel="noopener"
          >
            <div id="logo-container">
              <svg id="logo" viewBox="0 0 32 32" width="32" height="32">
                <defs>
                  <linearGradient
                    id="logoGradient"
                    x1="0%"
                    y1="0%"
                    x2="100%"
                    y2="100%"
                  >
                    <stop
                      offset="0%"
                      style="stop-color: var(--accent); stop-opacity: 1"
                    />
                    <stop
                      offset="100%"
                      style="stop-color: var(--accent); stop-opacity: 0.7"
                    />
                  </linearGradient>
                </defs>
                
                <circle
                  cx="16"
                  cy="16"
                  r="14"
                  fill="none"
                  stroke="url(#logoGradient)"
                  stroke-width="2"
                  opacity="0.3"
                />
                
                <path
                  d="M 10 17 L 14 21 L 22 11"
                  fill="none"
                  stroke="var(--accent)"
                  stroke-width="2.5"
                  stroke-linecap="round"
                  stroke-linejoin="round"
                />
                
                <circle
                  cx="24"
                  cy="10"
                  r="1.5"
                  fill="var(--accent)"
                  opacity="0.6"
                />
                <circle
                  cx="26"
                  cy="12"
                  r="1.5"
                  fill="var(--accent)"
                  opacity="0.6"
                />
              </svg>
              <div id="logo-text">
                <h1>GO Coverage</h1>
                <div id="tagline">A better HTML Go Coverage</div>
              </div>
            </div>
          </a>
          <div id="summary"></div>
        </div>
        <div id="search-box">
          <input type="text" id="search-input" placeholder="Search files..." />
        </div>
        <div id="sort-controls">
          <button
            class="sort-btn active"
            data-sort="name"
            title="Sort alphabetically"
          >
            <span class="icon">Aâ†’Z</span>
            <span class="label">Name</span>
          </button>
          <button
            class="sort-btn"
            data-sort="coverage"
            title="Sort by coverage percentage"
          >
            <span class="icon">%</span>
            <span class="label">Coverage</span>
          </button>
        </div>
        <div id="file-tree"></div>
        <footer id="sidebar-footer">
          <a
            href="https://github.com/chmouel/go-better-html-coverage"
            target="_blank"
            rel="noopener"
          >
            <svg
              class="github-icon"
              viewBox="0 0 16 16"
              width="14"
              height="14"
              fill="currentColor"
            >
              <path
                d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"
              />
            </svg>
            chmouel/go-better-html-coverage
          </a>
        </footer>
      </aside>
      <main id="canvas">
        <header id="topbar">
          <div id="file-path"></div>
          <div id="topbar-actions">
            <div id="in-file-search">
              <input
                type="text"
                id="content-search"
                placeholder="Search in file..."
              />
              <span id="match-info"></span>
              <button id="prev-match" title="Previous match">&#9650;</button>
              <button id="next-match" title="Next match">&#9660;</button>
            </div>
            <button id="syntax-toggle" title="Toggle syntax highlighting">
              &lt;/&gt;
            </button>
            <button id="theme-toggle" title="Toggle theme">&#9788;</button>
            <button id="help-toggle" title="Keyboard shortcuts">?</button>
          </div>
        </header>
        <div id="viewport" tabindex="-1"></div>
      </main>
      <div id="help-modal" class="modal hidden">
        <div class="modal-content">
          <h2>Keyboard Shortcuts</h2>
          <dl>
            <dt>Ctrl+P</dt>
            <dd>Focus file search</dd>
            <dt>Ctrl+F</dt>
            <dd>Search in file</dd>
            <dt>Enter</dt>
            <dd>Next match</dd>
            <dt>Shift+Enter</dt>
            <dd>Previous match</dd>
            <dt>?</dt>
            <dd>Show this help</dd>
            <dt>Esc</dt>
            <dd>Close modal</dd>
          </dl>
          <h2>Permalinks</h2>
          <dl>
            <dt>Click line</dt>
            <dd>Select line, update URL</dd>
            <dt>Shift+Click</dt>
            <dd>Select line range</dd>
          </dl>
          <button id="close-help">Close</button>
        </div>
      </div>
    </div>
    <script>
      window.COVERAGE_DATA = {"files":[{"id":0,"path":"pkg/artifacts/signable.go","lines":["/*","Copyright 2020 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package artifacts","","import (","\t\"context\"","\t_ \"crypto/sha256\" // Recommended by go-digest.","\t_ \"crypto/sha512\" // Recommended by go-digest.","\t\"fmt\"","\t\"regexp\"","\t\"strings\"","","\t\"github.com/google/go-containerregistry/pkg/name\"","\t\"github.com/in-toto/in-toto-golang/in_toto/slsa_provenance/common\"","\t\"github.com/opencontainers/go-digest\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"github.com/tektoncd/chains/pkg/config\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"knative.dev/pkg/logging\"",")","","const (","\tArtifactsInputsResultName  = \"ARTIFACT_INPUTS\"","\tArtifactsOutputsResultName = \"ARTIFACT_OUTPUTS\"","\tOCIScheme                  = \"oci://\"","\tGitSchemePrefix            = \"git+\"","\tisBuildArtifactField       = \"isBuildArtifact\"","\tOCIImageURLResultName      = \"IMAGE_URL\"","\tOCIImageDigestResultName   = \"IMAGE_DIGEST\"","\tOCIImagesResultName        = \"IMAGES\"",")","","var (","\tSha1Regexp *regexp.Regexp = regexp.MustCompile(`^[a-f0-9]{40}$`)",")","","type Signable interface {","\tExtractObjects(ctx context.Context, obj objects.TektonObject) []interface{}","\tStorageBackend(cfg config.Config) sets.Set[string]","\tSigner(cfg config.Config) string","\tPayloadFormat(cfg config.Config) config.PayloadType","\t// FullKey returns the full identifier for a signable artifact.","\t// - For OCI artifact, it is the full representation in the format of `\u003cNAME\u003e@sha256:\u003cDIGEST\u003e`.","\t// - For TaskRun/PipelineRun artifact, it is `\u003cGROUP\u003e-\u003cVERSION\u003e-\u003cKIND\u003e-\u003cUID\u003e`","\tFullKey(interface{}) string","\t// ShortKey returns the short version  of an artifact identifier.","\t// - For OCI artifact, it is first 12 chars of the image digest.","\t// - For TaskRun/PipelineRun artifact, it is `\u003cKIND\u003e-\u003cUID\u003e`.","\tShortKey(interface{}) string","\tType() string","\tEnabled(cfg config.Config) bool","}","","type TaskRunArtifact struct{}","","var _ Signable = \u0026TaskRunArtifact{}","","func (ta *TaskRunArtifact) ShortKey(obj interface{}) string {","\ttro := obj.(*objects.TaskRunObjectV1)","\treturn \"taskrun-\" + string(tro.UID)","}","","func (ta *TaskRunArtifact) FullKey(obj interface{}) string {","\ttro := obj.(*objects.TaskRunObjectV1)","\tgvk := tro.GetGroupVersionKind()","\treturn fmt.Sprintf(\"%s-%s-%s-%s\", gvk.Group, gvk.Version, gvk.Kind, tro.UID)","}","","func (ta *TaskRunArtifact) ExtractObjects(ctx context.Context, obj objects.TektonObject) []interface{} {","\treturn []interface{}{obj}","}","","func (ta *TaskRunArtifact) Type() string {","\treturn \"tekton\"","}","","func (ta *TaskRunArtifact) StorageBackend(cfg config.Config) sets.Set[string] {","\treturn cfg.Artifacts.TaskRuns.StorageBackend","}","","func (ta *TaskRunArtifact) PayloadFormat(cfg config.Config) config.PayloadType {","\treturn config.PayloadType(cfg.Artifacts.TaskRuns.Format)","}","","func (ta *TaskRunArtifact) Signer(cfg config.Config) string {","\treturn cfg.Artifacts.TaskRuns.Signer","}","","func (ta *TaskRunArtifact) Enabled(cfg config.Config) bool {","\treturn cfg.Artifacts.TaskRuns.Enabled()","}","","type PipelineRunArtifact struct{}","","var _ Signable = \u0026PipelineRunArtifact{}","","func (pa *PipelineRunArtifact) ShortKey(obj interface{}) string {","\tpro := obj.(*objects.PipelineRunObjectV1)","\treturn \"pipelinerun-\" + string(pro.UID)","}","","func (pa *PipelineRunArtifact) FullKey(obj interface{}) string {","\tpro := obj.(*objects.PipelineRunObjectV1)","\tgvk := pro.GetGroupVersionKind()","\treturn fmt.Sprintf(\"%s-%s-%s-%s\", gvk.Group, gvk.Version, gvk.Kind, pro.UID)","}","","func (pa *PipelineRunArtifact) ExtractObjects(ctx context.Context, obj objects.TektonObject) []interface{} {","\treturn []interface{}{obj}","}","","func (pa *PipelineRunArtifact) Type() string {","\t// TODO: Is this right?","\treturn \"tekton-pipeline-run\"","}","","func (pa *PipelineRunArtifact) StorageBackend(cfg config.Config) sets.Set[string] {","\treturn cfg.Artifacts.PipelineRuns.StorageBackend","}","","func (pa *PipelineRunArtifact) PayloadFormat(cfg config.Config) config.PayloadType {","\treturn config.PayloadType(cfg.Artifacts.PipelineRuns.Format)","}","","func (pa *PipelineRunArtifact) Signer(cfg config.Config) string {","\treturn cfg.Artifacts.PipelineRuns.Signer","}","","func (pa *PipelineRunArtifact) Enabled(cfg config.Config) bool {","\treturn cfg.Artifacts.PipelineRuns.Enabled()","}","","type OCIArtifact struct{}","","var _ Signable = \u0026OCIArtifact{}","","type image struct {","\turl    string","\tdigest string","}","","func (oa *OCIArtifact) ExtractObjects(ctx context.Context, obj objects.TektonObject) []interface{} {","\tobjs := []interface{}{}","","\t// Now check TaskResults","\tresultImages := ExtractOCIImagesFromResults(ctx, obj.GetResults())","\tobjs = append(objs, resultImages...)","","\treturn objs","}","","// ExtractOCIImagesFromResults returns all the results marked as OCIImage type-hint result.","func ExtractOCIImagesFromResults(ctx context.Context, results []objects.Result) []interface{} {","\tlogger := logging.FromContext(ctx)","\tobjs := []interface{}{}","","\textractor := structuredSignableExtractor{","\t\turiSuffix:    OCIImageURLResultName,","\t\tdigestSuffix: OCIImageDigestResultName,","\t\tisValid:      hasImageRequirements,","\t}","\tfor _, s := range extractor.extract(ctx, results) {","\t\tdgst, err := name.NewDigest(fmt.Sprintf(\"%s@%s\", s.URI, s.Digest))","\t\tif err != nil {","\t\t\tlogger.Errorf(\"error getting digest: %v\", err)","\t\t\tcontinue","\t\t}","\t\tobjs = append(objs, dgst)","\t}","","\t// look for a comma separated list of images","\tfor _, key := range results {","\t\tif key.Name != OCIImagesResultName {","\t\t\tcontinue","\t\t}","\t\timgs := strings.FieldsFunc(key.Value.StringVal, split)","","\t\tfor _, img := range imgs {","\t\t\ttrimmed := strings.TrimSpace(img)","\t\t\tif trimmed == \"\" {","\t\t\t\tcontinue","\t\t\t}","\t\t\tdgst, err := name.NewDigest(trimmed)","\t\t\tif err != nil {","\t\t\t\tlogger.Errorf(\"error getting digest for img %s: %v\", trimmed, err)","\t\t\t\tcontinue","\t\t\t}","\t\t\tobjs = append(objs, dgst)","\t\t}","\t}","","\treturn objs","}","","// ExtractSignableTargetFromResults extracts signable targets that aim to generate intoto provenance as materials within TaskRun results and store them as StructuredSignable.","func ExtractSignableTargetFromResults(ctx context.Context, obj objects.TektonObject) []StructuredSignable {","\tlogger := logging.FromContext(ctx)","\textractor := structuredSignableExtractor{","\t\turiSuffix:    \"ARTIFACT_URI\",","\t\tdigestSuffix: \"ARTIFACT_DIGEST\",","\t\tisValid: func(s StructuredSignable) bool {","\t\t\tif !hasImageRequirements(s) {","\t\t\t\treturn false","\t\t\t}","\t\t\tif _, _, err := ParseDigest(s.Digest); err != nil {","\t\t\t\tlogger.Errorf(\"error getting digest %s: %v\", s.Digest, err)","\t\t\t\treturn false","\t\t\t}","\t\t\treturn true","\t\t},","\t}","\treturn extractor.extract(ctx, obj.GetResults())","}","","// FullRef returns the full reference of the signable artifact in the format of URI@DIGEST","func (s *StructuredSignable) FullRef() string {","\treturn fmt.Sprintf(\"%s@%s\", s.URI, s.Digest)","}","","// RetrieveMaterialsFromStructuredResults retrieves structured results from Object Results, and convert them into materials.","func RetrieveMaterialsFromStructuredResults(ctx context.Context, objResults []objects.Result) []common.ProvenanceMaterial {","\tlogger := logging.FromContext(ctx)","\t// Retrieve structured provenance for inputs.","\tmats := []common.ProvenanceMaterial{}","\tssts := ExtractStructuredTargetFromResults(ctx, objResults, ArtifactsInputsResultName)","\tfor _, s := range ssts {","\t\talg, digest, err := ParseDigest(s.Digest)","\t\tif err != nil {","\t\t\tlogger.Debugf(\"Digest for %s not in the right format: %s, %v\", s.URI, s.Digest, err)","\t\t\tcontinue","\t\t}","\t\tmats = append(mats, common.ProvenanceMaterial{","\t\t\tURI:    s.URI,","\t\t\tDigest: map[string]string{alg: digest},","\t\t})","\t}","\treturn mats","}","","// ExtractStructuredTargetFromResults extracts structured signable targets aim to generate intoto provenance as materials within TaskRun results and store them as StructuredSignable.","// categoryMarker categorizes signable targets into inputs and outputs.","func ExtractStructuredTargetFromResults(ctx context.Context, objResults []objects.Result, categoryMarker string) []*StructuredSignable {","\tlogger := logging.FromContext(ctx)","\tobjs := []*StructuredSignable{}","\tif categoryMarker != ArtifactsInputsResultName \u0026\u0026 categoryMarker != ArtifactsOutputsResultName {","\t\treturn objs","\t}","","\t// TODO(#592): support structured results using Run","\tfor _, res := range objResults {","\t\tif strings.HasSuffix(res.Name, categoryMarker) {","\t\t\tvalid, err := isStructuredResult(res, categoryMarker)","\t\t\tif err != nil {","\t\t\t\tlogger.Debugf(\"ExtractStructuredTargetFromResults: %v\", err)","\t\t\t}","\t\t\tif valid {","\t\t\t\tlogger.Debugf(\"Extracted Structured data from Result %s, %s\", res.Value.ObjectVal[\"uri\"], res.Value.ObjectVal[\"digest\"])","\t\t\t\tobjs = append(objs, \u0026StructuredSignable{URI: res.Value.ObjectVal[\"uri\"], Digest: res.Value.ObjectVal[\"digest\"]})","\t\t\t}","\t\t}","\t}","\treturn objs","}","","// ExtractBuildArtifactsFromResults extracts all the structured signable targets from the given results, only processing the ones marked as build artifacts.","func ExtractBuildArtifactsFromResults(ctx context.Context, results []objects.Result) (objs []*StructuredSignable) {","\tlogger := logging.FromContext(ctx)","","\tfor _, res := range results {","\t\tvalid, err := IsBuildArtifact(res)","\t\tif err != nil {","\t\t\tlogger.Debugf(\"ExtractBuildArtifactsFromResults failed validatin artifact %v, ignoring artifact, err: %v\", res.Name, err)","\t\t\tcontinue","\t\t}","\t\tif valid {","\t\t\tlogger.Debugf(\"Extracted Build artifact data from Result %s, %s\", res.Value.ObjectVal[\"uri\"], res.Value.ObjectVal[\"digest\"])","\t\t\tobjs = append(objs, \u0026StructuredSignable{URI: res.Value.ObjectVal[\"uri\"], Digest: res.Value.ObjectVal[\"digest\"]})","\t\t}","\t}","\treturn","}","","// IsBuildArtifact indicates if a given result was marked as a Build Artifact.","func IsBuildArtifact(res objects.Result) (bool, error) {","\tif !strings.HasSuffix(res.Name, ArtifactsOutputsResultName) {","\t\treturn false, nil","\t}","","\tif res.Value.ObjectVal == nil {","\t\treturn false, fmt.Errorf(\"%s should be an object: %v\", res.Name, res.Value.ObjectVal)","\t}","","\tif res.Value.ObjectVal[isBuildArtifactField] != \"true\" {","\t\treturn false, nil","\t}","","\treturn isValidArtifactOutput(res)","}","","func isStructuredResult(res objects.Result, categoryMarker string) (bool, error) {","\tif !strings.HasSuffix(res.Name, categoryMarker) {","\t\treturn false, nil","\t}","\tif res.Value.ObjectVal == nil {","\t\treturn false, fmt.Errorf(\"%s should be an object: %v\", res.Name, res.Value.ObjectVal)","\t}","\treturn isValidArtifactOutput(res)","}","","func isValidArtifactOutput(res objects.Result) (bool, error) {","\tif res.Value.ObjectVal[\"uri\"] == \"\" {","\t\treturn false, fmt.Errorf(\"%s should have uri field: %v\", res.Name, res.Value.ObjectVal)","\t}","\tif res.Value.ObjectVal[\"digest\"] == \"\" {","\t\treturn false, fmt.Errorf(\"%s should have digest field: %v\", res.Name, res.Value.ObjectVal)","\t}","\tif _, _, err := ParseDigest(res.Value.ObjectVal[\"digest\"]); err != nil {","\t\treturn false, fmt.Errorf(\"error getting digest %s: %v\", res.Value.ObjectVal[\"digest\"], err)","\t}","\treturn true, nil","}","","// ParseDigest parses the digest string and returns the algorithm and hex section of the digest.","func ParseDigest(dig string) (algo_string string, hex string, err error) {","\tparts := strings.Split(dig, \":\")","\tif len(parts) != 2 {","\t\treturn \"\", \"\", fmt.Errorf(\"digest string %s, not in the format of \u003calgorithm\u003e:\u003cdigest\u003e\", dig)","\t}","\talgo_string = strings.ToLower(strings.TrimSpace(parts[0]))","\talgo := digest.Algorithm(algo_string)","\thex = strings.TrimSpace(parts[1])","","\tswitch {","\tcase algo.Available():","\t\tif err := algo.Validate(hex); err != nil {","\t\t\treturn \"\", \"\", err","\t\t}","\tcase algo_string == \"sha1\":","\t\t// Version 1.0.0, which is the released version, of go_digest does not support SHA1,","\t\t// hence this has to be handled differently.","\t\tif !Sha1Regexp.MatchString(hex) {","\t\t\treturn \"\", \"\", fmt.Errorf(\"sha1 digest %s does not match regexp %s\", dig, Sha1Regexp.String())","\t\t}","\tdefault:","\t\treturn \"\", \"\", fmt.Errorf(\"unsupported digest algorithm: %s\", dig)","","\t}","\treturn algo_string, hex, nil","}","","// split allows IMAGES to be separated either by commas (for backwards compatibility)","// or by newlines","func split(r rune) bool {","\treturn r == '\\n' || r == ','","}","","func (oa *OCIArtifact) Type() string {","\treturn \"oci\"","}","","func (oa *OCIArtifact) StorageBackend(cfg config.Config) sets.Set[string] {","\treturn cfg.Artifacts.OCI.StorageBackend","}","","func (oa *OCIArtifact) PayloadFormat(cfg config.Config) config.PayloadType {","\treturn config.PayloadType(cfg.Artifacts.OCI.Format)","}","","func (oa *OCIArtifact) Signer(cfg config.Config) string {","\treturn cfg.Artifacts.OCI.Signer","}","","func (oa *OCIArtifact) ShortKey(obj interface{}) string {","\tv := obj.(name.Digest)","\treturn strings.TrimPrefix(v.DigestStr(), \"sha256:\")[:12]","}","","func (oa *OCIArtifact) FullKey(obj interface{}) string {","\tv := obj.(name.Digest)","\treturn v.Name()","}","","func (oa *OCIArtifact) Enabled(cfg config.Config) bool {","\treturn cfg.Artifacts.OCI.Enabled()","}","","func hasImageRequirements(s StructuredSignable) bool {","\treturn s.URI != \"\" \u0026\u0026 s.Digest != \"\"","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,1,1,1,1,1,0,1,1,1,0,1,1,1,0,1,1,1,0,1,1,1,0,1,1,1,0,1,1,1,0,0,0,0,0,1,1,1,1,0,1,1,1,1,1,0,1,1,1,0,1,1,1,1,0,1,1,1,0,1,1,1,0,1,1,1,0,1,1,1,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,0,0,0,2,2,2,0,2,2,2,2,2,2,0,2,2,1,1,0,2,0,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,1,1,1,0,0,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,0,2,0,0,0,0,2,2,2,2,1,1,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,0,2,0,0,0,2,2,2,2,0,2,2,2,0,2,2,2,0,2,0,0,2,2,2,2,2,1,1,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,2,2,2,0,1,1,1,0,1,1,1,0,1,1,1,0,1,1,1,0,1,1,1,1,0,1,1,1,1,0,1,1,1,0,2,2,2]},{"id":1,"path":"pkg/artifacts/structured.go","lines":["/*","Copyright 2023 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package artifacts","","import (","\t\"context\"","\t\"strings\"","","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"knative.dev/pkg/logging\"",")","","// StructuredSignable contains info for signable targets to become either subjects or materials in","// intoto Statements.","// URI is the resource uri for the target needed iff the target is a material.","// Digest is the target's SHA digest.","type StructuredSignable struct {","\tURI    string","\tDigest string","}","","type structuredSignableExtractor struct {","\turiSuffix    string","\tdigestSuffix string","\tisValid      func(StructuredSignable) bool","}","","func (b *structuredSignableExtractor) extract(ctx context.Context, results []objects.Result) []StructuredSignable {","\tlogger := logging.FromContext(ctx)","\tpartials := map[string]StructuredSignable{}","","\tsuffixes := map[string]func(StructuredSignable, string) StructuredSignable{","\t\tb.uriSuffix: func(s StructuredSignable, value string) StructuredSignable {","\t\t\ts.URI = value","\t\t\treturn s","\t\t},","\t\tb.digestSuffix: func(s StructuredSignable, value string) StructuredSignable {","\t\t\ts.Digest = value","\t\t\treturn s","\t\t},","\t}","","\tfor _, res := range results {","\t\tfor suffix, setFn := range suffixes {","\t\t\tif suffix == \"\" {","\t\t\t\tcontinue","\t\t\t}","\t\t\tif !strings.HasSuffix(res.Name, suffix) {","\t\t\t\tcontinue","\t\t\t}","\t\t\tvalue := strings.TrimSpace(res.Value.StringVal)","\t\t\tif value == \"\" {","\t\t\t\tlogger.Debugf(\"error getting string value for %s\", res.Name)","\t\t\t\tcontinue","\t\t\t}","\t\t\tmarker := strings.TrimSuffix(res.Name, suffix)","\t\t\tif _, ok := partials[marker]; !ok {","\t\t\t\tpartials[marker] = StructuredSignable{}","\t\t\t}","\t\t\tpartials[marker] = setFn(partials[marker], value)","\t\t}","\t}","","\tvar signables []StructuredSignable","\tfor _, s := range partials {","\t\tif !b.isValid(s) {","\t\t\tcontinue","\t\t}","\t\tsignables = append(signables, s)","\t}","","\treturn signables","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,1,0,2,2,0,2,2,2,2,0,2,2,2,2,2,0,0,0,2,2,2,2,0,2,0,0,2,0]},{"id":2,"path":"pkg/chains/annotations/annotations.go","lines":["/*","Copyright 2020 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package annotations","","import (","\t\"context\"","\t\"encoding/json\"","\t\"fmt\"","\t\"strconv\"","\t\"strings\"","","\t\"github.com/pkg/errors\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\tversioned \"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"","\t\"knative.dev/pkg/logging\"",")","","//nolint:revive,exported","const (","\t// ChainsAnnotationPrefix is the prefix for all Chains annotations","\tChainsAnnotationPrefix       = \"chains.tekton.dev/\"","\tChainsAnnotation             = ChainsAnnotationPrefix + \"signed\"","\tRetryAnnotation              = ChainsAnnotationPrefix + \"retries\"","\tChainsTransparencyAnnotation = ChainsAnnotationPrefix + \"transparency\"","\tMaxRetries                   = 3",")","","// Reconciled determines whether a Tekton object has already been reconciled.","// It first inspects the state of the given TektonObject. If that indicates it","// has not been reconciled, then Reconciled fetches the latest version of the","// TektonObject from the cluster and inspects that version as well. This aims","// to avoid creating multiple attestations due to a stale cached TektonObject.","func Reconciled(ctx context.Context, client versioned.Interface, obj objects.TektonObject) bool {","\tif reconciledFromAnnotations(obj.GetAnnotations()) {","\t\treturn true","\t}","","\tlogger := logging.FromContext(ctx)","\tannotations, err := obj.GetLatestAnnotations(ctx, client)","\tif err != nil {","\t\tlogger.Warnf(\"Ignoring error when fetching latest annotations: %s\", err)","\t\treturn false","\t}","\treturn reconciledFromAnnotations(annotations)","}","","func reconciledFromAnnotations(annotations map[string]string) bool {","\tval, ok := annotations[ChainsAnnotation]","\tif !ok {","\t\treturn false","\t}","\treturn val == \"true\" || val == \"failed\"","}","","// mergeAnnotations creates a new map with existing annotations plus a new key-value pair","func mergeAnnotations(annotations map[string]string, key, value string) map[string]string {","\tmerged := make(map[string]string)","\tfor k, v := range annotations {","\t\tmerged[k] = v","\t}","\tmerged[key] = value","\treturn merged","}","","// MarkSigned marks a Tekton object as signed.","func MarkSigned(ctx context.Context, obj objects.TektonObject, ps versioned.Interface, annotations map[string]string) error {","\tif _, ok := obj.GetAnnotations()[ChainsAnnotation]; ok {","\t\t// Object is already signed, but we may still need to apply additional annotations","\t\tif len(annotations) \u003e 0 {","\t\t\treturn AddAnnotations(ctx, obj, ps, mergeAnnotations(annotations, ChainsAnnotation, \"true\"))","\t\t}","\t\treturn nil","\t}","\treturn AddAnnotations(ctx, obj, ps, mergeAnnotations(annotations, ChainsAnnotation, \"true\"))","}","","func MarkFailed(ctx context.Context, obj objects.TektonObject, ps versioned.Interface, annotations map[string]string) error {","\treturn AddAnnotations(ctx, obj, ps, mergeAnnotations(annotations, ChainsAnnotation, \"failed\"))","}","","func RetryAvailable(obj objects.TektonObject) bool {","\tann, ok := obj.GetAnnotations()[RetryAnnotation]","\tif !ok {","\t\treturn true","\t}","\tval, err := strconv.Atoi(ann)","\tif err != nil {","\t\treturn false","\t}","\treturn val \u003c MaxRetries","}","","func AddRetry(ctx context.Context, obj objects.TektonObject, ps versioned.Interface, annotations map[string]string) error {","\tann := obj.GetAnnotations()[RetryAnnotation]","\tif ann == \"\" {","\t\treturn AddAnnotations(ctx, obj, ps, mergeAnnotations(annotations, RetryAnnotation, \"0\"))","\t}","\tval, err := strconv.Atoi(ann)","\tif err != nil {","\t\treturn errors.Wrap(err, \"adding retry\")","\t}","\treturn AddAnnotations(ctx, obj, ps, mergeAnnotations(annotations, RetryAnnotation, fmt.Sprintf(\"%d\", val+1)))","}","","// AddAnnotations adds annotation to the k8s object","func AddAnnotations(ctx context.Context, obj objects.TektonObject, ps versioned.Interface, annotations map[string]string) error {","\t// Get current annotations from API server to ensure we have the latest state","\tcurrentAnnotations, err := obj.GetLatestAnnotations(ctx, ps)","\tif err != nil {","\t\treturn err","\t}","","\t// Start with existing chains annotations, ignore annotations from other controllers,","\t// so we do not take ownership of them.","\tmergedAnnotations := make(map[string]string)","\tfor k, v := range currentAnnotations {","\t\tif strings.HasPrefix(k, ChainsAnnotationPrefix) {","\t\t\tmergedAnnotations[k] = v","\t\t}","\t}","","\t// Add the new chains annotations, they all must be chains annotations","\tfor k, v := range annotations {","\t\tif !strings.HasPrefix(k, ChainsAnnotationPrefix) {","\t\t\treturn fmt.Errorf(\"invalid annotation key %q: all annotations must have prefix %q\", k, ChainsAnnotationPrefix)","\t\t}","\t\tmergedAnnotations[k] = v","\t}","","\tpatchBytes, err := CreateAnnotationsPatch(mergedAnnotations, obj)","\tif err != nil {","\t\treturn err","\t}","\terr = obj.Patch(ctx, ps, patchBytes)","\tif err != nil {","\t\treturn err","\t}","","\t// Note: Ideally here we'll update the in-memory object to keep it consistent through","\t// the reconciliation loop. It hasn't been done to preserve the existing controller behavior","\t// and maintain compatibility with existing tests. This could be revisited in the future.","","\treturn nil","}","","// HandleRetry handles retries managed as annotation on the k8s object","func HandleRetry(ctx context.Context, obj objects.TektonObject, ps versioned.Interface, annotationsMap map[string]string) error {","\tif RetryAvailable(obj) {","\t\treturn AddRetry(ctx, obj, ps, annotationsMap)","\t}","\treturn MarkFailed(ctx, obj, ps, annotationsMap)","}","","// CreateAnnotationsPatch returns patch bytes that can be used with kubectl patch","func CreateAnnotationsPatch(newAnnotations map[string]string, obj objects.TektonObject) ([]byte, error) {","\t// Get GVK using the TektonObject interface method (more reliable than runtime.Object)","\tgvkStr := obj.GetGVK()","\tif gvkStr == \"\" {","\t\treturn nil, fmt.Errorf(\"unable to determine GroupVersionKind for object %s/%s\", obj.GetNamespace(), obj.GetName())","\t}","","\t// Parse the string format \"group/version/kind\"","\tparts := strings.Split(gvkStr, \"/\")","\tif len(parts) != 3 || parts[0] == \"\" || parts[1] == \"\" || parts[2] == \"\" {","\t\treturn nil, fmt.Errorf(\"invalid GVK format: %s\", gvkStr)","\t}","\tapiVersion := parts[0] + \"/\" + parts[1]","\tkind := parts[2]","","\t// For server-side apply, we need to create a structured patch with metadata","\tp := serverSideApplyPatch{","\t\tAPIVersion: apiVersion,","\t\tKind:       kind,","\t\tMetadata: serverSideApplyMetadata{","\t\t\tName:        obj.GetName(),","\t\t\tNamespace:   obj.GetNamespace(),","\t\t\tAnnotations: newAnnotations,","\t\t},","\t}","\treturn json.Marshal(p)","}","","// These are used to get proper json formatting for server-side apply","type serverSideApplyPatch struct {","\tAPIVersion string                  `json:\"apiVersion\"`","\tKind       string                  `json:\"kind\"`","\tMetadata   serverSideApplyMetadata `json:\"metadata\"`","}","","type serverSideApplyMetadata struct {","\tName        string            `json:\"name\"`","\tNamespace   string            `json:\"namespace,omitempty\"`","\tAnnotations map[string]string `json:\"annotations,omitempty\"`","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,2,2,2,1,1,1,2,0,0,2,2,2,1,1,2,0,0,0,2,2,2,2,2,2,2,0,0,0,2,2,1,1,1,1,1,0,2,0,0,2,2,2,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,1,1,2,0,0,0,2,2,2,2,1,1,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,2,2,1,1,2,2,1,1,0,0,0,0,0,2,0,0,0,2,2,1,1,2,0,0,0,2,2,2,2,1,1,0,0,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0]},{"id":3,"path":"pkg/chains/formats/format.go","lines":["/*","Copyright 2020 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package formats","","import (","\t\"context\"","\t\"fmt\"","","\t\"github.com/tektoncd/chains/pkg/config\"",")","","// Payloader is an interface to generate a chains Payload from a TaskRun","type Payloader interface {","\tCreatePayload(ctx context.Context, obj interface{}) (interface{}, error)","\tType() config.PayloadType","\tWrap() bool","\tRetrieveAllArtifactURIs(ctx context.Context, obj interface{}) ([]string, error)","}","","const (","\tPayloadTypeTekton        config.PayloadType = \"tekton\"","\tPayloadTypeSimpleSigning config.PayloadType = \"simplesigning\"","\tPayloadTypeInTotoIte6    config.PayloadType = \"in-toto\"","\tPayloadTypeSlsav1        config.PayloadType = \"slsa/v1\"","\tPayloadTypeSlsav2alpha3  config.PayloadType = \"slsa/v2alpha3\"","\tPayloadTypeSlsav2alpha4  config.PayloadType = \"slsa/v2alpha4\"",")","","var (","\tIntotoAttestationSet = map[config.PayloadType]struct{}{","\t\tPayloadTypeInTotoIte6:   {},","\t\tPayloadTypeSlsav1:       {},","\t\tPayloadTypeSlsav2alpha3: {},","\t\tPayloadTypeSlsav2alpha4: {},","\t}","\tpayloaderMap = map[config.PayloadType]PayloaderInit{}",")","","// PayloaderInit initializes a new Payloader instance for the given config.","type PayloaderInit func(config.Config) (Payloader, error)","","// RegisterPayloader registers the PayloaderInit func for the given type.","// This is suitable to be calling during init() to register Payloader types.","func RegisterPayloader(key config.PayloadType, init PayloaderInit) {","\tpayloaderMap[key] = init","}","","// GetPayloader returns a new Payloader of the given type.","// If no Payloader is registered for the type, an error is returned.","func GetPayloader(key config.PayloadType, cfg config.Config) (Payloader, error) {","\tfn, ok := payloaderMap[key]","\tif !ok {","\t\treturn nil, fmt.Errorf(\"payloader %q not found\", key)","\t}","\treturn fn(cfg)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,1,1,1,1,1,1,0]},{"id":4,"path":"pkg/chains/formats/simple/simple.go","lines":["/*","Copyright 2020 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package simple","","import (","\t\"context\"","\t\"fmt\"","","\t\"github.com/sigstore/sigstore/pkg/signature/payload\"","\t\"github.com/tektoncd/chains/pkg/chains/formats\"","\t\"github.com/tektoncd/chains/pkg/config\"","","\t\"github.com/google/go-containerregistry/pkg/name\"",")","","const (","\tPayloadTypeSimpleSigning = formats.PayloadTypeSimpleSigning",")","","func init() {","\tformats.RegisterPayloader(PayloadTypeSimpleSigning, NewFormatter)","}","","// SimpleSigning is a formatter that uses the RedHat simple signing format","// https://www.redhat.com/en/blog/container-image-signing","type SimpleSigning struct{}","","type SimpleContainerImage payload.SimpleContainerImage","","// CreatePayload implements the Payloader interface.","func (i *SimpleSigning) CreatePayload(ctx context.Context, obj interface{}) (interface{}, error) {","\tswitch v := obj.(type) {","\tcase name.Digest:","\t\tformat := NewSimpleStruct(v)","\t\treturn format, nil","\tdefault:","\t\treturn nil, fmt.Errorf(\"unsupported type %s\", v)","\t}","}","","func (i *SimpleSigning) Wrap() bool {","\treturn false","}","","func NewFormatter(config.Config) (formats.Payloader, error) {","\treturn \u0026SimpleSigning{}, nil","}","","func NewSimpleStruct(img name.Digest) SimpleContainerImage {","\tcosign := payload.Cosign{Image: img}","\treturn SimpleContainerImage(cosign.SimpleContainerImage())","}","","func (i SimpleContainerImage) ImageName() string {","\treturn fmt.Sprintf(\"%s@%s\", i.Critical.Identity.DockerReference, i.Critical.Image.DockerManifestDigest)","}","","func (i *SimpleSigning) Type() config.PayloadType {","\treturn formats.PayloadTypeSimpleSigning","}","","// RetrieveAllArtifactURIs returns always an error, feature not available for simplesigning formatter.","func (i *SimpleSigning) RetrieveAllArtifactURIs(_ context.Context, _ interface{}) ([]string, error) {","\treturn nil, fmt.Errorf(\"RetrieveAllArtifactURIs not supported for simeplesining formatter\")","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,0,0,0,1,1,1,0,1,1,1,0,2,2,2,2,0,2,2,2,0,1,1,1,0,0,1,1,1]},{"id":5,"path":"pkg/chains/formats/slsa/attest/attest.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package attest","","import (","\t\"fmt\"","\t\"strings\"","","\tslsa \"github.com/in-toto/in-toto-golang/in_toto/slsa_provenance/v0.2\"","\t\"github.com/tektoncd/chains/pkg/artifacts\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tcorev1 \"k8s.io/api/core/v1\"",")","","const (","\tCommitParam                  = \"CHAINS-GIT_COMMIT\"","\tURLParam                     = \"CHAINS-GIT_URL\"","\tChainsReproducibleAnnotation = \"chains.tekton.dev/reproducible\"",")","","type StepAttestation struct {","\tEntryPoint  string            `json:\"entryPoint\"`","\tArguments   interface{}       `json:\"arguments,omitempty\"`","\tEnvironment interface{}       `json:\"environment,omitempty\"`","\tAnnotations map[string]string `json:\"annotations\"`","}","","func Step(step *v1.Step, stepState *v1.StepState) StepAttestation {","\tattestation := StepAttestation{}","","\tentrypoint := strings.Join(step.Command, \" \")","\tif step.Script != \"\" {","\t\tentrypoint = step.Script","\t}","\tattestation.EntryPoint = entrypoint","\tattestation.Arguments = step.Args","","\tenv := map[string]interface{}{}","\tenv[\"image\"] = artifacts.OCIScheme + strings.TrimPrefix(stepState.ImageID, \"docker-pullable://\")","\tenv[\"container\"] = stepState.Name","\tattestation.Environment = env","","\treturn attestation","}","","func Invocation(obj objects.TektonObject, params []v1.Param, paramSpecs []v1.ParamSpec) slsa.ProvenanceInvocation {","\tvar source *v1.RefSource","\tif p := obj.GetProvenance(); p != nil {","\t\tsource = p.RefSource","\t}","\ti := slsa.ProvenanceInvocation{","\t\tConfigSource: convertConfigSource(source),","\t}","","\tiParams := make(map[string]v1.ParamValue)","","\t// get implicit parameters from defaults","\tfor _, p := range paramSpecs {","\t\tif p.Default != nil {","\t\t\tiParams[p.Name] = *p.Default","\t\t}","\t}","","\t// get explicit parameters","\tfor _, p := range params {","\t\tiParams[p.Name] = p.Value","\t}","","\ti.Parameters = iParams","\tenvironment := map[string]map[string]string{}","","\tannotations := map[string]string{}","\tfor name, value := range obj.GetAnnotations() {","\t\t// Ignore annotations that are not relevant to provenance information","\t\tif name == corev1.LastAppliedConfigAnnotation || strings.HasPrefix(name, \"chains.tekton.dev/\") {","\t\t\tcontinue","\t\t}","\t\tannotations[name] = value","\t}","\tif len(annotations) \u003e 0 {","\t\tenvironment[\"annotations\"] = annotations","\t}","","\tlabels := obj.GetLabels()","\tif len(labels) \u003e 0 {","\t\tenvironment[\"labels\"] = labels","\t}","","\tif len(environment) \u003e 0 {","\t\ti.Environment = environment","\t}","","\treturn i","}","","func convertConfigSource(source *v1.RefSource) slsa.ConfigSource {","\tif source == nil {","\t\treturn slsa.ConfigSource{}","\t}","\treturn slsa.ConfigSource{","\t\tURI:        source.URI,","\t\tDigest:     source.Digest,","\t\tEntryPoint: source.EntryPoint,","\t}","}","","// supports the SPDX format which is recommended by in-toto","// ref: https://spdx.github.io/spdx-spec/v2-draft/package-information/#773-examples","// ref: https://github.com/in-toto/attestation/blob/849867bee97e33678f61cc6bd5da293097f84c25/spec/field_types.md","func SPDXGit(url, revision string) string {","\tif !strings.HasPrefix(url, artifacts.GitSchemePrefix) {","\t\turl = artifacts.GitSchemePrefix + url","\t}","\tif !strings.HasSuffix(url, \".git\") {","\t\turl = url + \".git\"","\t}","\tif revision == \"\" {","\t\treturn url","\t}","\treturn url + fmt.Sprintf(\"@%s\", revision)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,1,0,1,0,1,1,1,0,1,1,1,1,0,1,1,1,0,1,0,0,1,1,1,1,1,1,1,1,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0]},{"id":6,"path":"pkg/chains/formats/slsa/extract/extract.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package extract","","import (","\t\"context\"","\t\"fmt\"","\t\"strings\"","","\t\"github.com/google/go-containerregistry/pkg/name\"","\tintoto \"github.com/in-toto/attestation/go/v1\"","\t\"github.com/in-toto/in-toto-golang/in_toto/slsa_provenance/common\"","\t\"github.com/tektoncd/chains/pkg/artifacts\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/artifact\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/slsaconfig\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"knative.dev/pkg/logging\"",")","","// SubjectDigests returns software artifacts produced from the TaskRun/PipelineRun object","// in the form of standard subject field of intoto statement.","// The type hinting fields expected in results help identify the generated software artifacts.","// Valid type hinting fields must:","//   - have suffix `IMAGE_URL` \u0026 `IMAGE_DIGEST` or `ARTIFACT_URI` \u0026 `ARTIFACT_DIGEST` pair.","//   - the `*_DIGEST` field must be in the format of \"\u003calgorithm\u003e:\u003cactual-sha\u003e\" where the algorithm must be \"sha256\" and actual sha must be valid per https://github.com/opencontainers/image-spec/blob/main/descriptor.md#sha-256.","//   - the `*_URL` or `*_URI` fields cannot be empty.","//","//nolint:all","func SubjectDigests(ctx context.Context, obj objects.TektonObject, slsaconfig *slsaconfig.SlsaConfig) []*intoto.ResourceDescriptor {","\tvar subjects []*intoto.ResourceDescriptor","","\tswitch obj.GetObject().(type) {","\tcase *v1.PipelineRun:","\t\tsubjects = subjectsFromPipelineRun(ctx, obj, slsaconfig)","\tcase *v1.TaskRun:","\t\tsubjects = subjectsFromTektonObject(ctx, obj)","\tdefault:","\t\tlogger := logging.FromContext(ctx)","\t\tlogger.Warnf(\"object type %T not supported\", obj.GetObject())","\t}","","\treturn subjects","}","","func subjectsFromPipelineRun(ctx context.Context, obj objects.TektonObject, slsaconfig *slsaconfig.SlsaConfig) []*intoto.ResourceDescriptor {","\tprSubjects := subjectsFromTektonObject(ctx, obj)","","\t// If deep inspection is not enabled, just return subjects observed on the pipelinerun level","\tif !slsaconfig.DeepInspectionEnabled {","\t\treturn prSubjects","\t}","","\tlogger := logging.FromContext(ctx)","\t// If deep inspection is enabled, collect subjects from child taskruns","\tvar result []*intoto.ResourceDescriptor","","\tpro := obj.(*objects.PipelineRunObjectV1)","","\tpSpec := pro.Status.PipelineSpec","\tif pSpec != nil {","\t\tpipelineTasks := pSpec.Tasks","\t\tpipelineTasks = append(pipelineTasks, pSpec.Finally...)","\t\tfor _, t := range pipelineTasks {","\t\t\ttaskRuns := pro.GetTaskRunsFromTask(t.Name)","\t\t\tif len(taskRuns) == 0 {","\t\t\t\tlogger.Infof(\"no taskruns found for task %s\", t.Name)","\t\t\t\tcontinue","\t\t\t}","\t\t\tfor _, tr := range taskRuns {","\t\t\t\t// Ignore Tasks that did not execute during the PipelineRun.","\t\t\t\tif tr == nil || tr.Status.CompletionTime == nil {","\t\t\t\t\tlogger.Infof(\"taskrun status not found for task %s\", t.Name)","\t\t\t\t\tcontinue","\t\t\t\t}","\t\t\t\ttrSubjects := subjectsFromTektonObject(ctx, tr)","\t\t\t\tresult = artifact.AppendSubjects(result, trSubjects...)","\t\t\t}","\t\t}","\t}","","\t// also add subjects observed from pipelinerun level with duplication removed","\tresult = artifact.AppendSubjects(result, prSubjects...)","","\treturn result","}","","func subjectsFromTektonObject(ctx context.Context, obj objects.TektonObject) []*intoto.ResourceDescriptor {","\tlogger := logging.FromContext(ctx)","\tvar subjects []*intoto.ResourceDescriptor","","\timgs := artifacts.ExtractOCIImagesFromResults(ctx, obj.GetResults())","\tfor _, i := range imgs {","\t\tif d, ok := i.(name.Digest); ok {","\t\t\tsubjects = artifact.AppendSubjects(subjects, \u0026intoto.ResourceDescriptor{","\t\t\t\tName: d.Repository.Name(),","\t\t\t\tDigest: common.DigestSet{","\t\t\t\t\t\"sha256\": strings.TrimPrefix(d.DigestStr(), \"sha256:\"),","\t\t\t\t},","\t\t\t})","\t\t}","\t}","","\tsts := artifacts.ExtractSignableTargetFromResults(ctx, obj)","\tfor _, obj := range sts {","\t\tsplits := strings.Split(obj.Digest, \":\")","\t\tif len(splits) != 2 {","\t\t\tlogger.Errorf(\"Digest %s should be in the format of: algorthm:abc\", obj.Digest)","\t\t\tcontinue","\t\t}","\t\tsubjects = artifact.AppendSubjects(subjects, \u0026intoto.ResourceDescriptor{","\t\t\tName: obj.URI,","\t\t\tDigest: common.DigestSet{","\t\t\t\tsplits[0]: splits[1],","\t\t\t},","\t\t})","\t}","","\tssts := artifacts.ExtractStructuredTargetFromResults(ctx, obj.GetResults(), artifacts.ArtifactsOutputsResultName)","\tfor _, s := range ssts {","\t\tsplits := strings.Split(s.Digest, \":\")","\t\talg := splits[0]","\t\tdigest := splits[1]","\t\tsubjects = artifact.AppendSubjects(subjects, \u0026intoto.ResourceDescriptor{","\t\t\tName: s.URI,","\t\t\tDigest: common.DigestSet{","\t\t\t\talg: digest,","\t\t\t},","\t\t})","\t}","","\treturn subjects","}","","// RetrieveAllArtifactURIs returns all the URIs of the software artifacts produced from the run object.","// - It first extracts intoto subjects from run object results and converts the subjects","// to a slice of string URIs in the format of \"NAME\" + \"@\" + \"ALGORITHM\" + \":\" + \"DIGEST\".","// - If no subjects could be extracted from results, then an empty slice is returned.","func RetrieveAllArtifactURIs(ctx context.Context, obj objects.TektonObject, deepInspectionEnabled bool) []string {","\tresult := []string{}","\tsubjects := SubjectDigests(ctx, obj, \u0026slsaconfig.SlsaConfig{DeepInspectionEnabled: deepInspectionEnabled})","","\tfor _, s := range subjects {","\t\tfor algo, digest := range s.Digest {","\t\t\tresult = append(result, fmt.Sprintf(\"%s@%s:%s\", s.Name, algo, digest))","\t\t}","\t}","\treturn result","}","","// SubjectsFromBuildArtifact returns the software artifacts/images produced by the TaskRun/PipelineRun in the form of standard","// subject field of intoto statement. The detection is based on type hinting. To be read as a software artifact the","// type hintint should:","// - use one of the following type-hints:","//   - Use the *ARTIFACT_OUTPUTS object type-hinting suffix. The value associated with the result should be an object","//     with the fields `uri`, `digest`, and `isBuildArtifact` set to true.","//   - Use the IMAGES type-hint","//   - Use the *IMAGE_URL / *IMAGE_DIGEST type-hint suffix","func SubjectsFromBuildArtifact(ctx context.Context, results []objects.Result) []*intoto.ResourceDescriptor {","\tvar subjects []*intoto.ResourceDescriptor","\tlogger := logging.FromContext(ctx)","\tbuildArtifacts := artifacts.ExtractBuildArtifactsFromResults(ctx, results)","\tfor _, ba := range buildArtifacts {","\t\tsplits := strings.Split(ba.Digest, \":\")","\t\tif len(splits) != 2 {","\t\t\tlogger.Errorf(\"Error procesing build artifact %v, digest %v malformed. Build artifact skipped\", ba.FullRef(), ba.Digest)","\t\t\tcontinue","\t\t}","","\t\talg := splits[0]","\t\tdigest := splits[1]","\t\tsubjects = artifact.AppendSubjects(subjects, \u0026intoto.ResourceDescriptor{","\t\t\tName: ba.URI,","\t\t\tDigest: common.DigestSet{","\t\t\t\talg: digest,","\t\t\t},","\t\t})","\t}","","\timgs := artifacts.ExtractOCIImagesFromResults(ctx, results)","\tfor _, i := range imgs {","\t\tif d, ok := i.(name.Digest); ok {","\t\t\tsubjects = artifact.AppendSubjects(subjects, \u0026intoto.ResourceDescriptor{","\t\t\t\tName: d.Repository.Name(),","\t\t\t\tDigest: common.DigestSet{","\t\t\t\t\t\"sha256\": strings.TrimPrefix(d.DigestStr(), \"sha256:\"),","\t\t\t\t},","\t\t\t})","\t\t}","\t}","","\treturn subjects","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,1,1,1,0,0,2,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,1,1,0,2,2,0,0,0,0,0,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,1,1,1,1,0,1,1,1,1,1,1,0,0,2,2,1,1,1,1,1,1,1,1,1,1,0,2,0,0,0,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,1,1,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,0]},{"id":7,"path":"pkg/chains/formats/slsa/internal/artifact/append.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","package artifact","","import (","\tintoto \"github.com/in-toto/attestation/go/v1\"","\t\"github.com/in-toto/in-toto-golang/in_toto/slsa_provenance/common\"",")","","// AppendSubjects adds new subject(s) to the original slice.","// It merges the new item with an existing entry if they are duplicate instead of append.","func AppendSubjects(original []*intoto.ResourceDescriptor, items ...*intoto.ResourceDescriptor) []*intoto.ResourceDescriptor {","\tvar artifacts []artifact","\tfor _, s := range original {","\t\tartifacts = append(artifacts, subjectToArtifact(s))","\t}","","\tfor _, s := range items {","\t\tartifacts = addArtifact(artifacts, subjectToArtifact(s))","\t}","","\tvar result []*intoto.ResourceDescriptor","\tfor _, a := range artifacts {","\t\tresult = append(result, artifactToSubject(a))","\t}","\treturn result","}","","// AppendMaterials adds new material(s) to the original slice.","// It merges the new item with an existing entry if they are duplicate instead of append.","func AppendMaterials(original []common.ProvenanceMaterial, items ...common.ProvenanceMaterial) []common.ProvenanceMaterial {","\tvar artifacts []artifact","\tfor _, m := range original {","\t\tartifacts = append(artifacts, materialToArtifact(m))","\t}","","\tfor _, m := range items {","\t\tartifacts = addArtifact(artifacts, materialToArtifact(m))","\t}","","\tvar result []common.ProvenanceMaterial","\tfor _, a := range artifacts {","\t\tresult = append(result, artifactToMaterial(a))","\t}","\treturn result","}","","type artifact struct {","\tname      string","\tdigestSet map[string]string","}","","// AddArtifact adds a new artifact item to the original slice.","func addArtifact(original []artifact, item artifact) []artifact {","","\tfor i, a := range original {","\t\t// if there is an equivalent entry in the original slice, merge the","\t\t// artifact's DigestSet into the existing entry's DigestSet.","\t\tif artifactEqual(a, item) {","\t\t\tmergeMaps(original[i].digestSet, item.digestSet)","\t\t\treturn original","\t\t}","\t}","","\toriginal = append(original, item)","\treturn original","}","","// two artifacts are equal if and only if they have same name and have at least","// one common algorithm and hex value.","func artifactEqual(x, y artifact) bool {","\tif x.name != y.name {","\t\treturn false","\t}","\tfor algo, hex := range x.digestSet {","\t\tif y.digestSet[algo] == hex {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","func mergeMaps(m1 map[string]string, m2 map[string]string) {","\tfor k, v := range m2 {","\t\tm1[k] = v","\t}","}","","func subjectToArtifact(s *intoto.ResourceDescriptor) artifact {","\treturn artifact{","\t\tname:      s.Name,","\t\tdigestSet: s.Digest,","\t}","}","","func artifactToSubject(a artifact) *intoto.ResourceDescriptor {","\treturn \u0026intoto.ResourceDescriptor{","\t\tName:   a.name,","\t\tDigest: a.digestSet,","\t}","}","","func materialToArtifact(m common.ProvenanceMaterial) artifact {","\treturn artifact{","\t\tname:      m.URI,","\t\tdigestSet: m.Digest,","\t}","}","","func artifactToMaterial(a artifact) common.ProvenanceMaterial {","\treturn common.ProvenanceMaterial{","\t\tURI:    a.name,","\t\tDigest: a.digestSet,","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,2,2,2,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,0,2,2,2,0,2,2,2,2,2,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,0,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,0,0,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2]},{"id":8,"path":"pkg/chains/formats/slsa/internal/build_definition/build_definition.go","lines":["/*","Copyright 2024 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package builddefinition","","import (","\t\"context\"","\t\"encoding/json\"","","\tslsa \"github.com/in-toto/attestation/go/predicates/provenance/v1\"","\tbuildtypes \"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/build_types\"","\texternalparameters \"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/external_parameters\"","\tinternalparameters \"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/internal_parameters\"","\tresolveddependencies \"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/resolved_dependencies\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/slsaconfig\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"google.golang.org/protobuf/encoding/protojson\"","\t\"google.golang.org/protobuf/types/known/structpb\"",")","","// GetTaskRunBuildDefinition returns the buildDefinition for the given TaskRun based on the configured buildType. This will default to the slsa buildType","func GetTaskRunBuildDefinition(ctx context.Context, tro *objects.TaskRunObjectV1, buildType string, resolveOpts resolveddependencies.ResolveOptions) (slsa.BuildDefinition, error) {","\trd, err := resolveddependencies.TaskRun(ctx, resolveOpts, tro)","\tif err != nil {","\t\treturn slsa.BuildDefinition{}, err","\t}","","\texternalParams := externalparameters.TaskRun(tro)","\tstructExternalParams, err := getStruct(externalParams)","\tif err != nil {","\t\treturn slsa.BuildDefinition{}, err","\t}","","\tbuildDefinitionType := buildType","\tif buildDefinitionType == \"\" {","\t\tbuildDefinitionType = buildtypes.SlsaBuildType","\t}","","\tinternalParams, err := internalparameters.GetInternalParamters(tro, buildDefinitionType)","\tif err != nil {","\t\treturn slsa.BuildDefinition{}, err","\t}","\tstructInternalParams, err := getStruct(internalParams)","\tif err != nil {","\t\treturn slsa.BuildDefinition{}, err","\t}","","\treturn slsa.BuildDefinition{","\t\tBuildType:            buildDefinitionType,","\t\tExternalParameters:   structExternalParams,","\t\tInternalParameters:   structInternalParams,","\t\tResolvedDependencies: rd,","\t}, nil","}","","// GetPipelineRunBuildDefinition returns the buildDefinition for the given PipelineRun based on the configured buildType. This will default to the slsa buildType","func GetPipelineRunBuildDefinition(ctx context.Context, pro *objects.PipelineRunObjectV1, slsaconfig *slsaconfig.SlsaConfig, resolveOpts resolveddependencies.ResolveOptions) (slsa.BuildDefinition, error) {","\tbuildDefinitionType := slsaconfig.BuildType","\tif slsaconfig.BuildType == \"\" {","\t\tbuildDefinitionType = buildtypes.SlsaBuildType","\t}","","\ttd, err := resolveddependencies.GetTaskDescriptor(buildDefinitionType)","\tif err != nil {","\t\treturn slsa.BuildDefinition{}, err","\t}","","\trd, err := resolveddependencies.PipelineRun(ctx, pro, slsaconfig, resolveOpts, td)","\tif err != nil {","\t\treturn slsa.BuildDefinition{}, err","\t}","","\texternalParams := externalparameters.PipelineRun(pro)","\tstructExternalParams, err := getStruct(externalParams)","\tif err != nil {","\t\treturn slsa.BuildDefinition{}, err","\t}","","\tinternalParams, err := internalparameters.GetInternalParamters(pro, buildDefinitionType)","\tif err != nil {","\t\treturn slsa.BuildDefinition{}, err","\t}","\tstructInternalParams, err := getStruct(internalParams)","\tif err != nil {","\t\treturn slsa.BuildDefinition{}, err","\t}","","\treturn slsa.BuildDefinition{","\t\tBuildType:            buildDefinitionType,","\t\tExternalParameters:   structExternalParams,","\t\tInternalParameters:   structInternalParams,","\t\tResolvedDependencies: rd,","\t}, nil","}","","func getStruct(data map[string]any) (*structpb.Struct, error) {","\tbytes, err := json.Marshal(data)","\tif err != nil {","\t\treturn nil, err","\t}","","\tprotoStruct := \u0026structpb.Struct{}","\terr = protojson.Unmarshal(bytes, protoStruct)","\tif err != nil {","\t\treturn nil, err","\t}","","\treturn protoStruct, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,1,1,0,2,2,2,1,1,0,2,2,2,2,0,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,0,0,0,2,2,2,1,1,0,2,2,2,2,0,2,2,1,1,0,2,2,2,1,1,0,2,2,1,1,2,2,1,1,0,2,2,2,2,2,2,0,0,2,2,2,1,1,0,2,2,2,1,1,0,2,0]},{"id":9,"path":"pkg/chains/formats/slsa/internal/compare/slsacompare.go","lines":["/*","Copyright 2023 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","package compare","","import (","\t\"github.com/google/go-cmp/cmp\"","\t\"github.com/google/go-cmp/cmp/cmpopts\"","\tintoto \"github.com/in-toto/attestation/go/v1\"","\t\"github.com/in-toto/in-toto-golang/in_toto/slsa_provenance/common\"",")","","// SLSAV1CompareOptions returns the comparison options for sorting some slice fields in","// SLSA v1 statement including ResourceDescriptor and Subject.","func SLSAV1CompareOptions() []cmp.Option {","\t// checking content + uri + digest should be sufficient here based on the fact that","\t// a ResourceDescriptor MUST specify one of uri, digest or content at a minimum.","\t// Source: https://github.com/in-toto/attestation/blob/main/spec/v1/resource_descriptor.md#fields","\tresourceDescriptorSort := func(x, y *intoto.ResourceDescriptor) bool {","\t\tif string(x.Content) != string(y.Content) {","\t\t\treturn string(x.Content) \u003c string(y.Content)","\t\t}","\t\tif x.Uri != y.Uri {","\t\t\treturn x.Uri \u003c y.Uri","\t\t}","\t\treturn lessDigestSet(x.Digest, y.Digest)","\t}","","\treturn []cmp.Option{","\t\tcmpopts.SortSlices(resourceDescriptorSort),","\t\tSubjectCompareOption(),","\t}","}","","// SubjectCompareOption returns the comparison option to sort and compare a","// list of Subjects.","func SubjectCompareOption() cmp.Option {","\tsubjectSort := func(x, y *intoto.ResourceDescriptor) bool {","\t\tif x.Name != y.Name {","\t\t\treturn x.Name \u003c y.Name","\t\t}","\t\treturn lessDigestSet(x.Digest, y.Digest)","\t}","\treturn cmpopts.SortSlices(subjectSort)","}","","// MaterialsCompareOption returns the comparison option to sort and compare a","// list of Materials.","func MaterialsCompareOption() cmp.Option {","\tmaterialsSort := func(x, y common.ProvenanceMaterial) bool {","\t\tif x.URI != y.URI {","\t\t\treturn x.URI \u003c y.URI","\t\t}","\t\treturn lessDigestSet(x.Digest, y.Digest)","\t}","\treturn cmpopts.SortSlices(materialsSort)","}","","func lessDigestSet(x, y common.DigestSet) bool {","\tfor algo, digestX := range x {","\t\tdigestY, ok := y[algo]","\t\tif !ok {","\t\t\t// Algorithm not present in y, x is considered greater.","\t\t\treturn false","\t\t}","\t\t// Compare the digests lexicographically.","\t\tif digestX != digestY {","\t\t\treturn digestX \u003c digestY","\t\t}","\t\t// The digests are equal, check the next algorithm.","\t}","","\t// All algorithms in x have corresponding entries in y, so check if y has more algorithms.","\treturn len(x) \u003c len(y)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,0,0,0,0,1,1,1,1,1,1,0,1,0,0,0,0,1,1,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,0,1,1,1,0,0,0,0,1,0]},{"id":10,"path":"pkg/chains/formats/slsa/internal/external_parameters/external_parameters.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package externalparameters","","import (","\t\"fmt\"","","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"",")","","func BuildConfigSource(provenance *v1.Provenance) map[string]string {","\tref := \"\"","\tfor alg, hex := range provenance.RefSource.Digest {","\t\tref = fmt.Sprintf(\"%s:%s\", alg, hex)","\t\tbreak","\t}","\tbuildConfigSource := map[string]string{","\t\t\"ref\":        ref,","\t\t\"repository\": provenance.RefSource.URI,","\t\t\"path\":       provenance.RefSource.EntryPoint,","\t}","\treturn buildConfigSource","}","","// PipelineRun adds the pipeline run spec and provenance if available","func PipelineRun(pro *objects.PipelineRunObjectV1) map[string]any {","\texternalParams := make(map[string]any)","","\tif provenance := pro.GetRemoteProvenance(); provenance != nil {","\t\texternalParams[\"buildConfigSource\"] = BuildConfigSource(provenance)","\t}","\texternalParams[\"runSpec\"] = pro.Spec","\treturn externalParams","}","","// TaskRun adds the task run spec and provenance if available","func TaskRun(tro *objects.TaskRunObjectV1) map[string]any {","\texternalParams := make(map[string]any)","","\tif provenance := tro.GetRemoteProvenance(); provenance != nil {","\t\texternalParams[\"buildConfigSource\"] = BuildConfigSource(provenance)","\t}","\texternalParams[\"runSpec\"] = tro.Spec","\treturn externalParams","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0]},{"id":11,"path":"pkg/chains/formats/slsa/internal/internal_parameters/internal_parameters.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package internalparameters","","import (","\t\"fmt\"","","\tbuildtypes \"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/build_types\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"",")","","// SLSAInternalParameters provides the chains config as internalparameters","func SLSAInternalParameters(tko objects.TektonObject) map[string]any {","\tinternalParams := make(map[string]any)","\tif provenance := tko.GetProvenance(); provenance != (*v1.Provenance)(nil) \u0026\u0026 provenance.FeatureFlags != nil {","\t\tinternalParams[\"tekton-pipelines-feature-flags\"] = *provenance.FeatureFlags","\t}","\treturn internalParams","}","","// TektonInternalParameters provides the chains config as well as annotations and labels","func TektonInternalParameters(tko objects.TektonObject) map[string]any {","\tinternalParams := make(map[string]any)","\tif provenance := tko.GetProvenance(); provenance != (*v1.Provenance)(nil) \u0026\u0026 provenance.FeatureFlags != nil {","\t\tinternalParams[\"tekton-pipelines-feature-flags\"] = *provenance.FeatureFlags","\t}","\tinternalParams[\"labels\"] = tko.GetLabels()","\tinternalParams[\"annotations\"] = tko.GetAnnotations()","\treturn internalParams","}","","// GetInternalParamters returns the internal parameters for the given tekton object based on the build type.","func GetInternalParamters(obj objects.TektonObject, buildDefinitionType string) (map[string]any, error) {","\tvar internalParameters map[string]any","","\tswitch buildDefinitionType {","\tcase buildtypes.SlsaBuildType:","\t\tinternalParameters = SLSAInternalParameters(obj)","\tcase buildtypes.TektonBuildType:","\t\tinternalParameters = TektonInternalParameters(obj)","\tdefault:","\t\treturn nil, fmt.Errorf(\"unsupported buildType %v\", buildDefinitionType)","\t}","","\treturn internalParameters, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,0]},{"id":12,"path":"pkg/chains/formats/slsa/internal/material/material.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package material","","import (","\t\"context\"","\t\"fmt\"","\t\"strings\"","","\t\"github.com/in-toto/in-toto-golang/in_toto/slsa_provenance/common\"","\t\"github.com/tektoncd/chains/pkg/artifacts\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/attest\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/artifact\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/slsaconfig\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"knative.dev/pkg/logging\"",")","","const (","\turiSeparator    = \"@\"","\tdigestSeparator = \":\"",")","","// TaskMaterials constructs `predicate.materials` section by collecting all the artifacts that influence a taskrun such as source code repo and step\u0026sidecar base images.","func TaskMaterials(ctx context.Context, tro *objects.TaskRunObjectV1) ([]common.ProvenanceMaterial, error) {","\tvar mats []common.ProvenanceMaterial","","\t// add step images","\tstepMaterials, err := FromStepImages(tro)","\tif err != nil {","\t\treturn nil, err","\t}","\tmats = artifact.AppendMaterials(mats, stepMaterials...)","","\t// add sidecar images","\tsidecarMaterials, err := FromSidecarImages(tro)","\tif err != nil {","\t\treturn nil, err","\t}","\tmats = artifact.AppendMaterials(mats, sidecarMaterials...)","","\tmats = artifact.AppendMaterials(mats, FromTaskParamsAndResults(ctx, tro)...)","","\treturn mats, nil","}","","func PipelineMaterials(ctx context.Context, pro *objects.PipelineRunObjectV1, slsaconfig *slsaconfig.SlsaConfig) ([]common.ProvenanceMaterial, error) {","\tlogger := logging.FromContext(ctx)","\tvar mats []common.ProvenanceMaterial","\tif p := pro.Status.Provenance; p != nil \u0026\u0026 p.RefSource != nil {","\t\tm := common.ProvenanceMaterial{","\t\t\tURI:    p.RefSource.URI,","\t\t\tDigest: p.RefSource.Digest,","\t\t}","\t\tmats = artifact.AppendMaterials(mats, m)","\t}","\tpSpec := pro.Status.PipelineSpec","\tif pSpec != nil {","\t\tpipelineTasks := append(pSpec.Tasks, pSpec.Finally...)","\t\tfor _, t := range pipelineTasks {","\t\t\ttaskRuns := pro.GetTaskRunsFromTask(t.Name)","\t\t\tif len(taskRuns) == 0 {","\t\t\t\tlogger.Infof(\"no taskruns found for task %s\", t.Name)","\t\t\t\tcontinue","\t\t\t}","\t\t\tfor _, tr := range taskRuns {","\t\t\t\t// Ignore Tasks that did not execute during the PipelineRun.","\t\t\t\tif tr == nil || tr.Status.CompletionTime == nil {","\t\t\t\t\tlogger.Infof(\"taskrun status not found for task %s\", t.Name)","\t\t\t\t\tcontinue","\t\t\t\t}","\t\t\t\tstepMaterials, err := FromStepImages(tr)","\t\t\t\tif err != nil {","\t\t\t\t\treturn mats, err","\t\t\t\t}","\t\t\t\tmats = artifact.AppendMaterials(mats, stepMaterials...)","\t\t\t\t// add sidecar images","\t\t\t\tsidecarMaterials, err := FromSidecarImages(tr)","\t\t\t\tif err != nil {","\t\t\t\t\treturn nil, err","\t\t\t\t}","\t\t\t\tmats = artifact.AppendMaterials(mats, sidecarMaterials...)","","\t\t\t\t// add remote task configsource information in materials","\t\t\t\tif tr.Status.Provenance != nil \u0026\u0026 tr.Status.Provenance.RefSource != nil {","\t\t\t\t\tm := common.ProvenanceMaterial{","\t\t\t\t\t\tURI:    tr.Status.Provenance.RefSource.URI,","\t\t\t\t\t\tDigest: tr.Status.Provenance.RefSource.Digest,","\t\t\t\t\t}","\t\t\t\t\tmats = artifact.AppendMaterials(mats, m)","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\tmats = artifact.AppendMaterials(mats, FromPipelineParamsAndResults(ctx, pro, slsaconfig)...)","","\treturn mats, nil","}","","// FromStepImages gets predicate.materials from step images","func FromStepImages(tro *objects.TaskRunObjectV1) ([]common.ProvenanceMaterial, error) {","\tmats := []common.ProvenanceMaterial{}","\tfor _, image := range tro.GetStepImages() {","\t\tm, err := fromImageID(image)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tmats = artifact.AppendMaterials(mats, m)","\t}","\treturn mats, nil","}","","// FromSidecarImages gets predicate.materials from sidecar images","func FromSidecarImages(tro *objects.TaskRunObjectV1) ([]common.ProvenanceMaterial, error) {","\tmats := []common.ProvenanceMaterial{}","\tfor _, image := range tro.GetSidecarImages() {","\t\tm, err := fromImageID(image)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tmats = artifact.AppendMaterials(mats, m)","\t}","\treturn mats, nil","}","","// fromImageID converts an imageId with format \u003curi\u003e@sha256:\u003cdigest\u003e and generates a provenance materials.","func fromImageID(imageID string) (common.ProvenanceMaterial, error) {","\turiDigest := strings.Split(imageID, uriSeparator)","\tif len(uriDigest) != 2 {","\t\treturn common.ProvenanceMaterial{}, fmt.Errorf(\"expected imageID %s to be separable by @\", imageID)","\t}","\tdigest := strings.Split(uriDigest[1], digestSeparator)","\tif len(digest) != 2 {","\t\treturn common.ProvenanceMaterial{}, fmt.Errorf(\"expected imageID %s to be separable by @ and :\", imageID)","\t}","\turi := strings.TrimPrefix(uriDigest[0], \"docker-pullable://\")","\tm := common.ProvenanceMaterial{","\t\tDigest: common.DigestSet{},","\t}","\tm.URI = artifacts.OCIScheme + uri","\tm.Digest[digest[0]] = digest[1]","\treturn m, nil","}","","// FromTaskParamsAndResults scans over the taskrun, taskspec params and taskrun results","// and looks for unstructured type hinted names matching CHAINS-GIT_COMMIT and CHAINS-GIT_URL","// to extract the commit and url value for input artifact materials.","func FromTaskParamsAndResults(ctx context.Context, tro *objects.TaskRunObjectV1) []common.ProvenanceMaterial {","\tvar commit, url string","\t// Scan for git params to use for materials","\tif tro.Status.TaskSpec != nil {","\t\tfor _, p := range tro.Status.TaskSpec.Params {","\t\t\tif p.Default == nil {","\t\t\t\tcontinue","\t\t\t}","\t\t\tif p.Name == attest.CommitParam {","\t\t\t\tcommit = p.Default.StringVal","\t\t\t\tcontinue","\t\t\t}","\t\t\tif p.Name == attest.URLParam {","\t\t\t\turl = p.Default.StringVal","\t\t\t}","\t\t}","\t}","","\tfor _, p := range tro.Spec.Params {","\t\tif p.Name == attest.CommitParam {","\t\t\tcommit = p.Value.StringVal","\t\t\tcontinue","\t\t}","\t\tif p.Name == attest.URLParam {","\t\t\turl = p.Value.StringVal","\t\t}","\t}","","\tfor _, r := range tro.Status.Results {","\t\tif r.Name == attest.CommitParam {","\t\t\tcommit = r.Value.StringVal","\t\t}","\t\tif r.Name == attest.URLParam {","\t\t\turl = r.Value.StringVal","\t\t}","\t}","","\turl = attest.SPDXGit(url, \"\")","","\tvar mats []common.ProvenanceMaterial","\tif commit != \"\" \u0026\u0026 url != \"\" {","\t\tmats = artifact.AppendMaterials(mats, common.ProvenanceMaterial{","\t\t\tURI: url,","\t\t\t// TODO. this could be sha256 as well. Fix in another PR.","\t\t\tDigest: map[string]string{\"sha1\": commit},","\t\t})","\t}","","\tsms := artifacts.RetrieveMaterialsFromStructuredResults(ctx, tro.GetResults())","\tmats = artifact.AppendMaterials(mats, sms...)","","\treturn mats","}","","// FromStepActionsResults extracts type hinted results from StepActions associated with the TaskRun and adds the url and digest to materials.","func FromStepActionsResults(ctx context.Context, tro *objects.TaskRunObjectV1) (mats []common.ProvenanceMaterial) {","\tfor _, s := range tro.Status.Steps {","\t\tvar sCommit, sURL string","\t\tfor _, r := range s.Results {","\t\t\tif r.Name == attest.CommitParam {","\t\t\t\tsCommit = r.Value.StringVal","\t\t\t\tcontinue","\t\t\t}","","\t\t\tif r.Name == attest.URLParam {","\t\t\t\tsURL = r.Value.StringVal","\t\t\t}","\t\t}","","\t\tsURL = attest.SPDXGit(sURL, \"\")","\t\tif sCommit != \"\" \u0026\u0026 sURL != \"\" {","\t\t\tmats = artifact.AppendMaterials(mats, common.ProvenanceMaterial{","\t\t\t\tURI:    sURL,","\t\t\t\tDigest: map[string]string{\"sha1\": sCommit},","\t\t\t})","\t\t}","\t}","\tsms := artifacts.RetrieveMaterialsFromStructuredResults(ctx, tro.GetStepResults())","\tmats = artifact.AppendMaterials(mats, sms...)","\treturn","}","","// FromPipelineParamsAndResults extracts type hinted params and results and adds the url and digest to materials.","func FromPipelineParamsAndResults(ctx context.Context, pro *objects.PipelineRunObjectV1, slsaconfig *slsaconfig.SlsaConfig) []common.ProvenanceMaterial {","\tmats := []common.ProvenanceMaterial{}","\tsms := artifacts.RetrieveMaterialsFromStructuredResults(ctx, pro.GetResults())","\tmats = artifact.AppendMaterials(mats, sms...)","","\tvar commit, url string","","\tpSpec := pro.Status.PipelineSpec","\tif pSpec != nil {","\t\t// search type hinting param/results from each individual taskruns","\t\tif slsaconfig.DeepInspectionEnabled {","\t\t\tlogger := logging.FromContext(ctx)","\t\t\tpipelineTasks := append(pSpec.Tasks, pSpec.Finally...)","\t\t\tfor _, t := range pipelineTasks {","\t\t\t\ttaskRuns := pro.GetTaskRunsFromTask(t.Name)","\t\t\t\tif len(taskRuns) == 0 {","\t\t\t\t\tlogger.Infof(\"no taskruns found for task %s\", t.Name)","\t\t\t\t\tcontinue","\t\t\t\t}","\t\t\t\tfor _, tr := range taskRuns {","\t\t\t\t\t// Ignore Tasks that did not execute during the PipelineRun.","\t\t\t\t\tif tr == nil || tr.Status.CompletionTime == nil {","\t\t\t\t\t\tlogger.Infof(\"taskrun is not found or not completed for the task %s\", t.Name)","\t\t\t\t\t\tcontinue","\t\t\t\t\t}","\t\t\t\t\tmaterialsFromTasks := FromTaskParamsAndResults(ctx, tr)","\t\t\t\t\tmats = artifact.AppendMaterials(mats, materialsFromTasks...)","\t\t\t\t}","\t\t\t}","\t\t}","","\t\t// search status.PipelineSpec.params","\t\tfor _, p := range pSpec.Params {","\t\t\tif p.Default == nil {","\t\t\t\tcontinue","\t\t\t}","\t\t\tif p.Name == attest.CommitParam {","\t\t\t\tcommit = p.Default.StringVal","\t\t\t\tcontinue","\t\t\t}","\t\t\tif p.Name == attest.URLParam {","\t\t\t\turl = p.Default.StringVal","\t\t\t}","\t\t}","\t}","","\t// search pipelineRunSpec.params","\tfor _, p := range pro.Spec.Params {","\t\tif p.Name == attest.CommitParam {","\t\t\tcommit = p.Value.StringVal","\t\t\tcontinue","\t\t}","\t\tif p.Name == attest.URLParam {","\t\t\turl = p.Value.StringVal","\t\t}","\t}","","\t// search status.Results","\tfor _, r := range pro.Status.Results {","\t\tif r.Name == attest.CommitParam {","\t\t\tcommit = r.Value.StringVal","\t\t}","\t\tif r.Name == attest.URLParam {","\t\t\turl = r.Value.StringVal","\t\t}","\t}","\tif len(commit) \u003e 0 \u0026\u0026 len(url) \u003e 0 {","\t\turl = attest.SPDXGit(url, \"\")","\t\tmats = artifact.AppendMaterials(mats, common.ProvenanceMaterial{","\t\t\tURI:    url,","\t\t\tDigest: map[string]string{\"sha1\": commit},","\t\t})","\t}","\treturn mats","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,1,1,2,2,2,2,2,1,1,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,1,1,0,2,2,1,1,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,0,0,0,2,2,2,2,2,1,1,2,0,2,0,0,0,2,2,2,2,2,1,1,2,0,2,0,0,0,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,0,0,0,2,2,2,2,0,2,2,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,2,2,0,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,1,1,0,2,2,0,0,0,0,0,2,2,2,0,2,2,2,0,2,2,2,0,0,0,0,2,2,2,2,0,2,2,2,0,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,0]},{"id":13,"path":"pkg/chains/formats/slsa/internal/metadata/metadata.go","lines":["/*","Copyright 2024 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package metadata","","import (","\tslsa \"github.com/in-toto/attestation/go/predicates/provenance/v1\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"google.golang.org/protobuf/types/known/timestamppb\"",")","","// GetBuildMetadata returns SLSA metadata.","func GetBuildMetadata(obj objects.TektonObject) *slsa.BuildMetadata {","\tvar startedOn *timestamppb.Timestamp","\tvar finishedOn *timestamppb.Timestamp","\tobjStartTime := obj.GetStartTime()","\tobjCompletitionTime := obj.GetCompletitionTime()","","\tif objStartTime != nil {","\t\tstartedOn = timestamppb.New(*objStartTime)","\t}","","\tif objCompletitionTime != nil {","\t\tfinishedOn = timestamppb.New(*objCompletitionTime)","\t}","","\treturn \u0026slsa.BuildMetadata{","\t\tInvocationId: string(obj.GetUID()),","\t\tStartedOn:    startedOn,","\t\tFinishedOn:   finishedOn,","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,2,2,0]},{"id":14,"path":"pkg/chains/formats/slsa/internal/provenance/provenance.go","lines":["/*","Copyright 2024 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package provenance","","import (","\tslsa \"github.com/in-toto/attestation/go/predicates/provenance/v1\"","\tintoto \"github.com/in-toto/attestation/go/v1\"","\tslsaprov \"github.com/in-toto/in-toto-golang/in_toto/slsa_provenance/v1\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/metadata\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/slsaconfig\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"google.golang.org/protobuf/encoding/protojson\"","\t\"google.golang.org/protobuf/types/known/structpb\"",")","","// GetSLSA1Statement returns a predicate in SLSA v1.0 format using the given data.","func GetSLSA1Statement(obj objects.TektonObject, sub []*intoto.ResourceDescriptor, bd *slsa.BuildDefinition, bp []*intoto.ResourceDescriptor, slsaConfig *slsaconfig.SlsaConfig) (intoto.Statement, error) {","\tpredicate := slsa.Provenance{","\t\tBuildDefinition: bd,","\t\tRunDetails: \u0026slsa.RunDetails{","\t\t\tBuilder: \u0026slsa.Builder{","\t\t\t\tId: slsaConfig.BuilderID,","\t\t\t},","\t\t\tMetadata:   metadata.GetBuildMetadata(obj),","\t\t\tByproducts: bp,","\t\t},","\t}","","\tpredicateStruct, err := getProtoStruct(\u0026predicate)","\tif err != nil {","\t\treturn intoto.Statement{}, err","\t}","","\treturn intoto.Statement{","\t\tType:          intoto.StatementTypeUri,","\t\tPredicateType: slsaprov.PredicateSLSAProvenance,","\t\tSubject:       sub,","\t\tPredicate:     predicateStruct,","\t}, nil","}","","func getProtoStruct(predicate *slsa.Provenance) (*structpb.Struct, error) {","\tprotoStruct := \u0026structpb.Struct{}","\tpredicateJSON, err := protojson.Marshal(predicate)","\tif err != nil {","\t\treturn nil, err","\t}","","\terr = protojson.Unmarshal(predicateJSON, protoStruct)","\tif err != nil {","\t\treturn nil, err","\t}","","\treturn protoStruct, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,0,1,1,1,1,1,1,0,1,1,1,1,0,1,0]},{"id":15,"path":"pkg/chains/formats/slsa/internal/resolved_dependencies/resolved_dependencies.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resolveddependencies","","import (","\t\"context\"","\t\"encoding/json\"","\t\"fmt\"","","\tintoto \"github.com/in-toto/attestation/go/v1\"","\t\"github.com/in-toto/in-toto-golang/in_toto/slsa_provenance/common\"","\tbuildtypes \"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/build_types\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/material\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/slsaconfig\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"go.uber.org/zap\"","\t\"google.golang.org/protobuf/encoding/protojson\"","\t\"knative.dev/pkg/logging\"",")","","const (","\t// PipelineConfigName is the name of the resolved dependency of the pipelineRef.","\tPipelineConfigName = \"pipeline\"","\t// TaskConfigName is the name of the resolved dependency of the top level taskRef.","\tTaskConfigName = \"task\"","\t// PipelineTaskConfigName is the name of the resolved dependency of the pipeline task.","\tPipelineTaskConfigName = \"pipelineTask\"","\t// InputResultName is the name of the resolved dependency generated from Type hinted parameters or results.","\tInputResultName = \"inputs/result\"","\t// PipelineResourceName is the name of the resolved dependency of pipeline resource.","\tPipelineResourceName = \"pipelineResource\"",")","","// AddTaskDescriptorContent is used to toggle the fields in  see AddTektonTaskDescriptor and AddSLSATaskDescriptor","type AddTaskDescriptorContent func(*objects.TaskRunObjectV1) (*intoto.ResourceDescriptor, error)","","// ResolveOptions represents the configuration to be use to resolve dependencies.","type ResolveOptions struct {","\t// Indicates if StepActions type-hinted results should be read to resolve dependecies.","\tWithStepActionsResults bool","}","","// ConvertMaterialsToResolvedDependencies converts a SLSAv0.2 Material to a resolved dependency","func ConvertMaterialsToResolvedDependencies(mats []common.ProvenanceMaterial, name string) []*intoto.ResourceDescriptor {","\trds := []*intoto.ResourceDescriptor{}","\tfor _, mat := range mats {","\t\trd := intoto.ResourceDescriptor{}","\t\trd.Uri = mat.URI","\t\trd.Digest = mat.Digest","\t\tif len(name) \u003e 0 {","\t\t\trd.Name = name","\t\t}","\t\trds = append(rds, \u0026rd)","\t}","\treturn rds","}","","// RemoveDuplicateResolvedDependencies removes duplicate resolved dependencies from the slice of resolved dependencies.","// Original order of resolved dependencies is retained.","func RemoveDuplicateResolvedDependencies(resolvedDependencies []*intoto.ResourceDescriptor) ([]*intoto.ResourceDescriptor, error) {","\tout := make([]*intoto.ResourceDescriptor, 0, len(resolvedDependencies))","","\t// make map to store seen resolved dependencies","\tseen := map[string]bool{}","\tfor _, resolvedDependency := range resolvedDependencies {","\t\t// Since resolvedDependencies contain names, we want to ignore those while checking for duplicates.","\t\t// Therefore, make a copy of the resolved dependency that only contains the uri and digest fields.","\t\trDep := intoto.ResourceDescriptor{}","\t\trDep.Uri = resolvedDependency.Uri","\t\trDep.Digest = resolvedDependency.Digest","\t\t// pipelinTasks store content with the slsa-tekton buildType","\t\trDep.Content = resolvedDependency.Content","\t\t// This allows us to ignore dependencies that have the same uri and digest.","\t\trd, err := protojson.Marshal(\u0026rDep)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tif seen[string(rd)] {","\t\t\t// We dont want to remove the top level pipeline/task config from the resolved dependencies","\t\t\t// because its critical to provide that information in the provenance. In SLSAv0.2 spec,","\t\t\t// we would put this in invocation.ConfigSource. In order to ensure that it is present in","\t\t\t// the resolved dependencies, we dont want to skip it if another resolved dependency from the same","\t\t\t// uri+digest pair was already included before.","\t\t\tif !(resolvedDependency.Name == TaskConfigName || resolvedDependency.Name == PipelineConfigName) {","\t\t\t\tcontinue","\t\t\t}","\t\t}","\t\tseen[string(rd)] = true","\t\tout = append(out, resolvedDependency)","\t}","\treturn out, nil","}","","// AddTektonTaskDescriptor returns the more verbose resolved dependency content. this adds the name, uri, digest","// and content if possible.","func AddTektonTaskDescriptor(tr *objects.TaskRunObjectV1) (*intoto.ResourceDescriptor, error) {","\trd := intoto.ResourceDescriptor{}","\tstoredTr, err := json.Marshal(tr)","\tif err != nil {","\t\treturn nil, err","\t}","","\trd.Name = PipelineTaskConfigName","\trd.Content = storedTr","\tif tr.Status.Provenance != nil \u0026\u0026 tr.Status.Provenance.RefSource != nil {","\t\trd.Uri = tr.Status.Provenance.RefSource.URI","\t\trd.Digest = tr.Status.Provenance.RefSource.Digest","\t}","","\treturn \u0026rd, nil","}","","// AddSLSATaskDescriptor resolves dependency content for the more generic slsa verifiers. just logs","// the name, uri and digest.","func AddSLSATaskDescriptor(tr *objects.TaskRunObjectV1) (*intoto.ResourceDescriptor, error) {","\tif tr.Status.Provenance != nil \u0026\u0026 tr.Status.Provenance.RefSource != nil {","\t\treturn \u0026intoto.ResourceDescriptor{","\t\t\tName:   PipelineTaskConfigName,","\t\t\tUri:    tr.Status.Provenance.RefSource.URI,","\t\t\tDigest: tr.Status.Provenance.RefSource.Digest,","\t\t}, nil","\t}","\treturn nil, nil","}","","// fromPipelineTask adds the resolved dependencies from pipeline tasks","// such as pipeline task uri/digest for remote pipeline tasks and step and sidecar images.","func fromPipelineTask(logger *zap.SugaredLogger, pro *objects.PipelineRunObjectV1, addTasks AddTaskDescriptorContent) ([]*intoto.ResourceDescriptor, error) {","\tpSpec := pro.Status.PipelineSpec","\tresolvedDependencies := []*intoto.ResourceDescriptor{}","\tif pSpec != nil {","\t\tpipelineTasks := pSpec.Tasks","\t\tpipelineTasks = append(pipelineTasks, pSpec.Finally...)","\t\tfor _, t := range pipelineTasks {","\t\t\ttaskRuns := pro.GetTaskRunsFromTask(t.Name)","\t\t\tif len(taskRuns) == 0 {","\t\t\t\tlogger.Infof(\"no taskruns found for task %s\", t.Name)","\t\t\t\tcontinue","\t\t\t}","\t\t\tfor _, tr := range taskRuns {","\t\t\t\t// Ignore Tasks that did not execute during the PipelineRun.","\t\t\t\tif tr == nil || tr.Status.CompletionTime == nil {","\t\t\t\t\tlogger.Infof(\"taskrun status not found for task %s\", t.Name)","\t\t\t\t\tcontinue","\t\t\t\t}","\t\t\t\trd, err := addTasks(tr)","\t\t\t\tif err != nil {","\t\t\t\t\tlogger.Errorf(\"error storing taskRun %s, error: %s\", t.Name, err)","\t\t\t\t\tcontinue","\t\t\t\t}","\t\t\t\tif rd != nil {","\t\t\t\t\tresolvedDependencies = append(resolvedDependencies, rd)","\t\t\t\t}","","\t\t\t\tmats := []common.ProvenanceMaterial{}","","\t\t\t\t// add step images","\t\t\t\tstepMaterials, err := material.FromStepImages(tr)","\t\t\t\tif err != nil {","\t\t\t\t\treturn nil, err","\t\t\t\t}","\t\t\t\tmats = append(mats, stepMaterials...)","","\t\t\t\t// add sidecar images","\t\t\t\tsidecarMaterials, err := material.FromSidecarImages(tr)","\t\t\t\tif err != nil {","\t\t\t\t\treturn nil, err","\t\t\t\t}","\t\t\t\tmats = append(mats, sidecarMaterials...)","","\t\t\t\t// convert materials to resolved dependencies","\t\t\t\tresolvedDependencies = append(resolvedDependencies, ConvertMaterialsToResolvedDependencies(mats, \"\")...)","","\t\t\t}","\t\t}","\t}","\treturn resolvedDependencies, nil","}","","// taskDependencies gather all dependencies in a task and adds them to resolvedDependencies","func taskDependencies(ctx context.Context, opts ResolveOptions, tro *objects.TaskRunObjectV1) ([]*intoto.ResourceDescriptor, error) {","\tvar resolvedDependencies []*intoto.ResourceDescriptor","\tvar err error","\tmats := []common.ProvenanceMaterial{}","","\t// add step and sidecar images","\tstepMaterials, err := material.FromStepImages(tro)","\tif err != nil {","\t\treturn nil, err","\t}","\tmats = append(mats, stepMaterials...)","","\tsidecarMaterials, err := material.FromSidecarImages(tro)","\tif err != nil {","\t\treturn nil, err","\t}","\tmats = append(mats, sidecarMaterials...)","\tresolvedDependencies = append(resolvedDependencies, ConvertMaterialsToResolvedDependencies(mats, \"\")...)","","\tif opts.WithStepActionsResults {","\t\tmats = material.FromStepActionsResults(ctx, tro)","\t\tresolvedDependencies = append(resolvedDependencies, ConvertMaterialsToResolvedDependencies(mats, InputResultName)...)","\t}","","\tmats = material.FromTaskParamsAndResults(ctx, tro)","\t// convert materials to resolved dependencies","\tresolvedDependencies = append(resolvedDependencies, ConvertMaterialsToResolvedDependencies(mats, InputResultName)...)","","\t// convert materials to resolved dependencies","\tresolvedDependencies = append(resolvedDependencies,","\t\tConvertMaterialsToResolvedDependencies(mats, PipelineResourceName)...)","","\t// remove duplicate resolved dependencies","\tresolvedDependencies, err = RemoveDuplicateResolvedDependencies(resolvedDependencies)","\tif err != nil {","\t\treturn nil, err","\t}","","\treturn resolvedDependencies, nil","}","","// TaskRun constructs `predicate.resolvedDependencies` section by collecting all the artifacts that influence a taskrun such as source code repo and step\u0026sidecar base images.","func TaskRun(ctx context.Context, opts ResolveOptions, tro *objects.TaskRunObjectV1) ([]*intoto.ResourceDescriptor, error) {","\tvar resolvedDependencies []*intoto.ResourceDescriptor","\tvar err error","","\t// add top level task config","\tif p := tro.Status.Provenance; p != nil \u0026\u0026 p.RefSource != nil {","\t\trd := intoto.ResourceDescriptor{","\t\t\tName:   TaskConfigName,","\t\t\tUri:    p.RefSource.URI,","\t\t\tDigest: p.RefSource.Digest,","\t\t}","\t\tresolvedDependencies = append(resolvedDependencies, \u0026rd)","\t}","","\trds, err := taskDependencies(ctx, opts, tro)","\tif err != nil {","\t\treturn nil, err","\t}","\tresolvedDependencies = append(resolvedDependencies, rds...)","","\treturn resolvedDependencies, nil","}","","// PipelineRun constructs `predicate.resolvedDependencies` section by collecting all the artifacts that influence a pipeline run such as source code repo and step\u0026sidecar base images.","func PipelineRun(ctx context.Context, pro *objects.PipelineRunObjectV1, slsaconfig *slsaconfig.SlsaConfig, opts ResolveOptions, addTasks AddTaskDescriptorContent) ([]*intoto.ResourceDescriptor, error) {","\tvar err error","\tvar resolvedDependencies []*intoto.ResourceDescriptor","\tlogger := logging.FromContext(ctx)","","\t// add pipeline config to resolved dependencies","\tif p := pro.Status.Provenance; p != nil \u0026\u0026 p.RefSource != nil {","\t\trd := intoto.ResourceDescriptor{","\t\t\tName:   PipelineConfigName,","\t\t\tUri:    p.RefSource.URI,","\t\t\tDigest: p.RefSource.Digest,","\t\t}","\t\tresolvedDependencies = append(resolvedDependencies, \u0026rd)","\t}","","\t// add resolved dependencies from pipeline tasks","\trds, err := fromPipelineTask(logger, pro, addTasks)","\tif err != nil {","\t\treturn nil, err","\t}","\tresolvedDependencies = append(resolvedDependencies, rds...)","","\tif slsaconfig.DeepInspectionEnabled \u0026\u0026 opts.WithStepActionsResults {","\t\texecTasks := pro.GetExecutedTasks()","\t\tfor _, task := range execTasks {","\t\t\tstepActionMat := material.FromStepActionsResults(ctx, task)","\t\t\tresolvedDependencies = append(resolvedDependencies, ConvertMaterialsToResolvedDependencies(stepActionMat, InputResultName)...)","\t\t}","\t}","","\t// add resolved dependencies from pipeline results","\tmats := material.FromPipelineParamsAndResults(ctx, pro, slsaconfig)","\t// convert materials to resolved dependencies","\tresolvedDependencies = append(resolvedDependencies, ConvertMaterialsToResolvedDependencies(mats, InputResultName)...)","","\t// remove duplicate resolved dependencies","\tresolvedDependencies, err = RemoveDuplicateResolvedDependencies(resolvedDependencies)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn resolvedDependencies, nil","}","","// GetTaskDescriptor returns the conrresponding addTaskDescriptor function according to the given build type.","func GetTaskDescriptor(buildDefinition string) (AddTaskDescriptorContent, error) {","\tswitch buildDefinition {","\tcase buildtypes.SlsaBuildType:","\t\treturn AddSLSATaskDescriptor, nil","\tcase buildtypes.TektonBuildType:","\t\treturn AddTektonTaskDescriptor, nil","\tdefault:","\t\treturn nil, fmt.Errorf(\"unsupported buildType %v\", buildDefinition)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,0,0,2,2,0,2,0,0,0,0,2,2,2,2,1,1,0,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,1,0,0,0,0,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,1,1,0,2,2,1,1,0,2,2,2,0,2,2,2,2,2,1,1,2,2,2,2,2,1,1,2,2,2,2,0,0,0,0,2,0,0,0,2,2,2,2,2,2,2,2,1,1,2,2,2,2,1,1,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,1,1,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,1,1,2,2,2,1,1,1,1,1,0,0,0,2,2,2,2,2,2,2,1,1,2,0,0,0,2,2,2,2,2,2,2,2,0,0]},{"id":16,"path":"pkg/chains/formats/slsa/internal/results/results.go","lines":["/*","Copyright 2024 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package results","","import (","\t\"encoding/json\"","\t\"fmt\"","\t\"strings\"","","\t\"github.com/tektoncd/chains/pkg/artifacts\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","","\tslsa \"github.com/in-toto/attestation/go/v1\"",")","","var imageResultsNamesSuffixs = []string{","\tartifacts.OCIImageURLResultName,","\tartifacts.OCIImageDigestResultName,","}","","// GetResultsWithoutBuildArtifacts returns all the results without those that are build artifacts.","func GetResultsWithoutBuildArtifacts(objName string, results []objects.Result, resultTypePrefix string) ([]*slsa.ResourceDescriptor, error) {","\tbyProd := []*slsa.ResourceDescriptor{}","\tfor _, r := range results {","\t\tif isBuildArtifact, err := artifacts.IsBuildArtifact(r); err != nil || isBuildArtifact {","\t\t\tcontinue","\t\t}","","\t\tif isOCIImage(r.Name) {","\t\t\tcontinue","\t\t}","","\t\tcontent, err := json.Marshal(r.Value)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","","\t\tbyProd = append(byProd, \u0026slsa.ResourceDescriptor{","\t\t\tName:      fmt.Sprintf(resultTypePrefix, objName, r.Name),","\t\t\tContent:   content,","\t\t\tMediaType: \"application/json\",","\t\t})","\t}","","\treturn byProd, nil","}","","func isOCIImage(resName string) bool {","\tfor _, suffix := range imageResultsNamesSuffixs {","\t\tif strings.HasSuffix(resName, suffix) {","\t\t\treturn true","\t\t}","\t}","","\treturn resName == artifacts.OCIImagesResultName","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,2,1,0,0,2,2,1,1,0,2,2,2,2,2,0,0,2,0,0,2,2,2,1,1,0,0,2,0]},{"id":17,"path":"pkg/chains/formats/slsa/v1/internal/protos/protos.go","lines":["package protos","","import (","\t\"encoding/json\"","","\tslsa \"github.com/in-toto/in-toto-golang/in_toto/slsa_provenance/v0.2\"","\t\"google.golang.org/protobuf/encoding/protojson\"","\t\"google.golang.org/protobuf/types/known/structpb\"",")","","// GetPredicateStruct returns a protobuf struct from the given SLSAv0.2 predicate.","func GetPredicateStruct(predicate *slsa.ProvenancePredicate) (*structpb.Struct, error) {","\tpredicateJSON, err := json.Marshal(predicate)","\tif err != nil {","\t\treturn nil, err","\t}","","\tpredicateStruct := \u0026structpb.Struct{}","\terr = protojson.Unmarshal(predicateJSON, predicateStruct)","\tif err != nil {","\t\treturn nil, err","\t}","","\treturn predicateStruct, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,1,1,1,1,1,0,1,0]},{"id":18,"path":"pkg/chains/formats/slsa/v1/intotoite6.go","lines":["/*","Copyright 2021 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","\t\"fmt\"","","\t\"github.com/tektoncd/chains/pkg/chains/formats\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/extract\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/slsaconfig\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/v1/pipelinerun\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/v1/taskrun\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"github.com/tektoncd/chains/pkg/config\"",")","","const (","\tPayloadTypeInTotoIte6 = formats.PayloadTypeInTotoIte6","\tPayloadTypeSlsav1     = formats.PayloadTypeSlsav1",")","","func init() {","\tformats.RegisterPayloader(PayloadTypeInTotoIte6, NewFormatter)","\tformats.RegisterPayloader(PayloadTypeSlsav1, NewFormatter)","}","","type InTotoIte6 struct {","\tslsaConfig *slsaconfig.SlsaConfig","}","","func NewFormatter(cfg config.Config) (formats.Payloader, error) {","\treturn \u0026InTotoIte6{","\t\tslsaConfig: \u0026slsaconfig.SlsaConfig{","\t\t\tBuilderID:             cfg.Builder.ID,","\t\t\tDeepInspectionEnabled: cfg.Artifacts.PipelineRuns.DeepInspectionEnabled,","\t\t},","\t}, nil","}","","func (i *InTotoIte6) Wrap() bool {","\treturn true","}","","func (i *InTotoIte6) CreatePayload(ctx context.Context, obj interface{}) (interface{}, error) {","\tswitch v := obj.(type) {","\tcase *objects.TaskRunObjectV1:","\t\treturn taskrun.GenerateAttestation(ctx, v, i.slsaConfig)","\tcase *objects.PipelineRunObjectV1:","\t\treturn pipelinerun.GenerateAttestation(ctx, v, i.slsaConfig)","\tdefault:","\t\treturn nil, fmt.Errorf(\"intoto does not support type: %s\", v)","\t}","}","","func (i *InTotoIte6) Type() config.PayloadType {","\treturn formats.PayloadTypeSlsav1","}","","// RetrieveAllArtifactURIs returns the full URI of all artifacts detected as subjects.","func (i *InTotoIte6) RetrieveAllArtifactURIs(ctx context.Context, obj interface{}) ([]string, error) {","\ttkObj, ok := obj.(objects.TektonObject)","\tif !ok {","\t\treturn nil, fmt.Errorf(\"intoto does not support type\")","\t}","\treturn extract.RetrieveAllArtifactURIs(ctx, tkObj, i.slsaConfig.DeepInspectionEnabled), nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,0,1,1,1,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,0,0,1,1,1,1,1,1,0]},{"id":19,"path":"pkg/chains/formats/slsa/v1/pipelinerun/pipelinerun.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pipelinerun","","import (","\t\"context\"","\t\"strings\"","\t\"time\"","","\tintoto \"github.com/in-toto/attestation/go/v1\"","\t\"github.com/in-toto/in-toto-golang/in_toto/slsa_provenance/common\"","\tslsa \"github.com/in-toto/in-toto-golang/in_toto/slsa_provenance/v0.2\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/attest\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/extract\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/material\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/slsaconfig\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/v1/internal/protos\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/logging\"",")","","type BuildConfig struct {","\tTasks []TaskAttestation `json:\"tasks\"`","}","","type TaskAttestation struct {","\tName               string                    `json:\"name,omitempty\"`","\tAfter              []string                  `json:\"after,omitempty\"`","\tRef                v1.TaskRef                `json:\"ref,omitempty\"`","\tStartedOn          time.Time                 `json:\"startedOn,omitempty\"`","\tFinishedOn         time.Time                 `json:\"finishedOn,omitempty\"`","\tServiceAccountName string                    `json:\"serviceAccountName,omitempty\"`","\tStatus             string                    `json:\"status,omitempty\"`","\tSteps              []attest.StepAttestation  `json:\"steps,omitempty\"`","\tInvocation         slsa.ProvenanceInvocation `json:\"invocation,omitempty\"`","\tResults            []v1.TaskRunResult        `json:\"results,omitempty\"`","}","","const statementInTotoV01 = \"https://in-toto.io/Statement/v0.1\"","","func GenerateAttestation(ctx context.Context, pro *objects.PipelineRunObjectV1, slsaConfig *slsaconfig.SlsaConfig) (interface{}, error) {","\tsubjects := extract.SubjectDigests(ctx, pro, slsaConfig)","","\tmat, err := material.PipelineMaterials(ctx, pro, slsaConfig)","\tif err != nil {","\t\treturn nil, err","\t}","","\tpredicate := \u0026slsa.ProvenancePredicate{","\t\tBuilder: common.ProvenanceBuilder{","\t\t\tID: slsaConfig.BuilderID,","\t\t},","\t\tBuildType:   pro.GetGVK(),","\t\tInvocation:  invocation(pro),","\t\tBuildConfig: buildConfig(ctx, pro),","\t\tMetadata:    metadata(pro),","\t\tMaterials:   mat,","\t}","","\tpredicateStruct, err := protos.GetPredicateStruct(predicate)","\tif err != nil {","\t\treturn nil, err","\t}","","\tatt := \u0026intoto.Statement{","\t\tType:          statementInTotoV01,","\t\tPredicateType: slsa.PredicateSLSAProvenance,","\t\tSubject:       subjects,","\t\tPredicate:     predicateStruct,","\t}","\treturn att, nil","}","","func invocation(pro *objects.PipelineRunObjectV1) slsa.ProvenanceInvocation {","\tvar paramSpecs []v1.ParamSpec","\tif ps := pro.Status.PipelineSpec; ps != nil {","\t\tparamSpecs = ps.Params","\t}","\treturn attest.Invocation(pro, pro.Spec.Params, paramSpecs)","}","","func buildConfig(ctx context.Context, pro *objects.PipelineRunObjectV1) BuildConfig {","\tlogger := logging.FromContext(ctx)","\ttasks := []TaskAttestation{}","","\tpSpec := pro.Status.PipelineSpec","\tif pSpec == nil {","\t\treturn BuildConfig{}","\t}","\tpipelineTasks := append(pSpec.Tasks, pSpec.Finally...)","","\tvar last string","\tfor i, t := range pipelineTasks {","\t\ttaskRuns := pro.GetTaskRunsFromTask(t.Name)","\t\tif len(taskRuns) == 0 {","\t\t\tlogger.Infof(\"no taskruns found for task %s\", t.Name)","\t\t\tcontinue","\t\t}","\t\tfor _, tr := range taskRuns {","\t\t\t// Ignore Tasks that did not execute during the PipelineRun.","\t\t\tif tr.Status.CompletionTime == nil {","\t\t\t\tlogger.Warnf(\"taskrun status not complete for task %s\", tr.Name)","\t\t\t\tcontinue","\t\t\t}","","\t\t\tsteps := []attest.StepAttestation{}","\t\t\t// tr.Status.TaskSpec.Steps and tr.Status.Steps should be sime size","\t\t\tif tr.Status.TaskSpec == nil {","\t\t\t\tlogger.Errorf(\"TaskSpec is nil for task run %s. Skipping this task run.\", tr.Name)","\t\t\t\tcontinue","\t\t\t}","","\t\t\tif len(tr.Status.TaskSpec.Steps) != len(tr.Status.Steps) {","\t\t\t\tlogger.Errorf(\"Mismatch in number of steps for task run %s. TaskSpec steps: %d, Status steps: %d\",","\t\t\t\t\ttr.Name, len(tr.Status.TaskSpec.Steps), len(tr.Status.Steps))","\t\t\t\tcontinue","\t\t\t}","\t\t\t// Validate and process steps","\t\t\tvalid := true","\t\t\tfor i, step := range tr.Status.TaskSpec.Steps {","\t\t\t\tstepState := tr.Status.Steps[i]","","\t\t\t\t// Check if unnamed step matches empty name in the other list","\t\t\t\tif strings.HasPrefix(stepState.Name, \"unnamed-\") \u0026\u0026 step.Name != \"\" {","\t\t\t\t\tlogger.Errorf(\"Mismatch in step names for task run %s. Step %d: %s, StepState %d: %s\",","\t\t\t\t\t\ttr.Name, i, step.Name, i, stepState.Name)","\t\t\t\t\tvalid = false","\t\t\t\t\tbreak","\t\t\t\t}","","\t\t\t\tif valid {","\t\t\t\t\tsteps = append(steps, attest.Step(\u0026step, \u0026stepState))","\t\t\t\t}","\t\t\t}","","\t\t\tif !valid {","\t\t\t\tlogger.Errorf(\"Skipping task run %s due to step name mismatch\", tr.Name)","\t\t\t\tcontinue","\t\t\t}","","\t\t\tafter := t.RunAfter","\t\t\t// Establish task order by retrieving all task's referenced","\t\t\t// in the \"when\" and \"params\" fields","\t\t\trefs := v1.PipelineTaskResultRefs(\u0026t)","\t\t\tfor _, ref := range refs {","\t\t\t\t// Ensure task doesn't already exist in after","\t\t\t\tfound := false","\t\t\t\tfor _, at := range after {","\t\t\t\t\tif at == ref.PipelineTask {","\t\t\t\t\t\tfound = true","\t\t\t\t\t}","\t\t\t\t}","\t\t\t\tif !found {","\t\t\t\t\tafter = append(after, ref.PipelineTask)","\t\t\t\t}","\t\t\t}","","\t\t\t// tr is a finally task without an explicit runAfter value. It must have executed","\t\t\t// after the last non-finally task, if any non-finally tasks were executed.","\t\t\tif len(after) == 0 \u0026\u0026 i \u003e= len(pSpec.Tasks) \u0026\u0026 last != \"\" {","\t\t\t\tafter = append(after, last)","\t\t\t}","","\t\t\tparams := tr.Spec.Params","\t\t\tvar paramSpecs []v1.ParamSpec","\t\t\tif tr.Status.TaskSpec != nil {","\t\t\t\tparamSpecs = tr.Status.TaskSpec.Params","\t\t\t} else {","\t\t\t\tparamSpecs = []v1.ParamSpec{}","\t\t\t}","","\t\t\ttask := TaskAttestation{","\t\t\t\tName:               t.Name,","\t\t\t\tAfter:              after,","\t\t\t\tStartedOn:          tr.Status.StartTime.Time.UTC(),","\t\t\t\tFinishedOn:         tr.Status.CompletionTime.Time.UTC(),","\t\t\t\tServiceAccountName: pro.Spec.TaskRunTemplate.ServiceAccountName,","\t\t\t\tStatus:             getStatus(tr.Status.Conditions),","\t\t\t\tSteps:              steps,","\t\t\t\tInvocation:         attest.Invocation(tr, params, paramSpecs),","\t\t\t\tResults:            tr.Status.Results,","\t\t\t}","\t\t\tif t.TaskRef != nil {","\t\t\t\ttask.Ref = *t.TaskRef","\t\t\t}","\t\t\ttasks = append(tasks, task)","\t\t}","","\t\tif i \u003c len(pSpec.Tasks) {","\t\t\tlast = t.Name","\t\t}","\t}","\treturn BuildConfig{Tasks: tasks}","}","","func metadata(pro *objects.PipelineRunObjectV1) *slsa.ProvenanceMetadata {","\tm := \u0026slsa.ProvenanceMetadata{}","\tif pro.Status.StartTime != nil {","\t\tutc := pro.Status.StartTime.Time.UTC()","\t\tm.BuildStartedOn = \u0026utc","\t}","\tif pro.Status.CompletionTime != nil {","\t\tutc := pro.Status.CompletionTime.Time.UTC()","\t\tm.BuildFinishedOn = \u0026utc","\t}","\tfor label, value := range pro.Labels {","\t\tif label == attest.ChainsReproducibleAnnotation \u0026\u0026 value == \"true\" {","\t\t\tm.Reproducible = true","\t\t}","\t}","\treturn m","}","","// Following tkn cli's behavior","// https://github.com/tektoncd/cli/blob/6afbb0f0dbc7186898568f0d4a0436b8b2994d99/pkg/formatted/k8s.go#L55","func getStatus(conditions []apis.Condition) string {","\tvar status string","\tif len(conditions) \u003e 0 {","\t\tswitch conditions[0].Status {","\t\tcase corev1.ConditionFalse:","\t\t\tstatus = \"Failed\"","\t\tcase corev1.ConditionTrue:","\t\t\tstatus = \"Succeeded\"","\t\tcase corev1.ConditionUnknown:","\t\t\tstatus = \"Running\" // Should never happen","\t\t}","\t}","\treturn status","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,1,1,2,2,2,2,2,2,1,1,0,2,2,2,1,1,0,0,2,2,2,1,1,0,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,0,0,0,0,2,1,1,0,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,1,1,1,0,2,0,0,0,0,2,2,2,2,1,1,2,2,1,1,0,0,2,0]},{"id":20,"path":"pkg/chains/formats/slsa/v1/taskrun/buildconfig.go","lines":["/*","Copyright 2021 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package taskrun","","import (","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/attest\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"",")","","// BuildConfig is the custom Chains format to fill out the","// \"buildConfig\" section of the slsa-provenance predicate","type BuildConfig struct {","\tSteps []attest.StepAttestation `json:\"steps\"`","}","","// Step corresponds to one step in the TaskRun","type Step struct {","\tEntryPoint  string            `json:\"entryPoint\"`","\tArguments   interface{}       `json:\"arguments,omitempty\"`","\tEnvironment interface{}       `json:\"environment,omitempty\"`","\tAnnotations map[string]string `json:\"annotations\"`","}","","func buildConfig(tro *objects.TaskRunObjectV1) BuildConfig {","\tattestations := []attest.StepAttestation{}","\tfor _, stepState := range tro.Status.Steps {","\t\tstep := stepFromTaskRun(stepState.Name, tro)","\t\tattestations = append(attestations, attest.Step(step, \u0026stepState))","\t}","\treturn BuildConfig{Steps: attestations}","}","","func stepFromTaskRun(name string, tro *objects.TaskRunObjectV1) *v1.Step {","\tif tro.Status.TaskSpec != nil {","\t\tfor _, s := range tro.Status.TaskSpec.Steps {","\t\t\tif s.Name == name {","\t\t\t\treturn \u0026s","\t\t\t}","\t\t}","\t}","\treturn \u0026v1.Step{}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,2,0]},{"id":21,"path":"pkg/chains/formats/slsa/v1/taskrun/taskrun.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package taskrun","","import (","\t\"context\"","","\tintoto \"github.com/in-toto/attestation/go/v1\"","\t\"github.com/in-toto/in-toto-golang/in_toto/slsa_provenance/common\"","\tslsa \"github.com/in-toto/in-toto-golang/in_toto/slsa_provenance/v0.2\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/attest\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/extract\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/material\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/slsaconfig\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/v1/internal/protos\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"",")","","const statementInTotoV01 = \"https://in-toto.io/Statement/v0.1\"","","func GenerateAttestation(ctx context.Context, tro *objects.TaskRunObjectV1, slsaConfig *slsaconfig.SlsaConfig) (interface{}, error) {","\tsubjects := extract.SubjectDigests(ctx, tro, slsaConfig)","","\tmat, err := material.TaskMaterials(ctx, tro)","\tif err != nil {","\t\treturn nil, err","\t}","","\tpredicate := \u0026slsa.ProvenancePredicate{","\t\tBuilder: common.ProvenanceBuilder{","\t\t\tID: slsaConfig.BuilderID,","\t\t},","\t\tBuildType:   tro.GetGVK(),","\t\tInvocation:  invocation(tro),","\t\tBuildConfig: buildConfig(tro),","\t\tMetadata:    Metadata(tro),","\t\tMaterials:   mat,","\t}","","\tpredicateStruct, err := protos.GetPredicateStruct(predicate)","\tif err != nil {","\t\treturn nil, err","\t}","","\treturn \u0026intoto.Statement{","\t\tType:          statementInTotoV01,","\t\tPredicateType: slsa.PredicateSLSAProvenance,","\t\tSubject:       subjects,","\t\tPredicate:     predicateStruct,","\t}, nil","}","","// invocation describes the event that kicked off the build","// we currently don't set ConfigSource because we don't know","// which material the Task definition came from","func invocation(tro *objects.TaskRunObjectV1) slsa.ProvenanceInvocation {","\tvar paramSpecs []v1.ParamSpec","\tif ts := tro.Status.TaskSpec; ts != nil {","\t\tparamSpecs = ts.Params","\t}","\treturn attest.Invocation(tro, tro.Spec.Params, paramSpecs)","}","","// Metadata adds taskrun's start time, completion time and reproducibility labels","// to the metadata section of the generated provenance.","func Metadata(tro *objects.TaskRunObjectV1) *slsa.ProvenanceMetadata {","\tm := \u0026slsa.ProvenanceMetadata{}","\tif tro.Status.StartTime != nil {","\t\tutc := tro.Status.StartTime.Time.UTC()","\t\tm.BuildStartedOn = \u0026utc","\t}","\tif tro.Status.CompletionTime != nil {","\t\tutc := tro.Status.CompletionTime.Time.UTC()","\t\tm.BuildFinishedOn = \u0026utc","\t}","\tfor label, value := range tro.Labels {","\t\tif label == attest.ChainsReproducibleAnnotation \u0026\u0026 value == \"true\" {","\t\t\tm.Reproducible = true","\t\t}","\t}","\treturn m","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,0,0,0,0,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,1,1,1,0,2,0]},{"id":22,"path":"pkg/chains/formats/slsa/v2alpha3/internal/pipelinerun/pipelinerun.go","lines":["/*","Copyright 2023 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pipelinerun","","import (","\t\"context\"","\t\"encoding/json\"","\t\"fmt\"","","\tintoto \"github.com/in-toto/attestation/go/v1\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/extract\"","\tbuilddefinition \"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/build_definition\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/provenance\"","\tresolveddependencies \"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/resolved_dependencies\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/slsaconfig\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"",")","","const (","\tpipelineRunResults = \"pipelineRunResults/%s\"","\t// JsonMediaType is the media type of json encoded content used in resource descriptors","\tJsonMediaType = \"application/json\"",")","","// GenerateAttestation generates a provenance statement with SLSA v1.0 predicate for a pipeline run.","func GenerateAttestation(ctx context.Context, pro *objects.PipelineRunObjectV1, slsaconfig *slsaconfig.SlsaConfig) (interface{}, error) {","\tbp, err := byproducts(pro)","\tif err != nil {","\t\treturn nil, err","\t}","","\tbd, err := builddefinition.GetPipelineRunBuildDefinition(ctx, pro, slsaconfig, resolveddependencies.ResolveOptions{})","\tif err != nil {","\t\treturn nil, err","\t}","","\tsub := extract.SubjectDigests(ctx, pro, slsaconfig)","","\treturn provenance.GetSLSA1Statement(pro, sub, \u0026bd, bp, slsaconfig)","}","","// byproducts contains the pipelineRunResults","func byproducts(pro *objects.PipelineRunObjectV1) ([]*intoto.ResourceDescriptor, error) {","\tbyProd := []*intoto.ResourceDescriptor{}","\tfor _, key := range pro.Status.Results {","\t\tcontent, err := json.Marshal(key.Value)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tbp := \u0026intoto.ResourceDescriptor{","\t\t\tName:      fmt.Sprintf(pipelineRunResults, key.Name),","\t\t\tContent:   content,","\t\t\tMediaType: JsonMediaType,","\t\t}","\t\tbyProd = append(byProd, bp)","\t}","\treturn byProd, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,1,1,0,2,2,1,1,0,2,2,2,0,0,0,2,2,2,2,2,1,1,2,2,2,2,2,2,0,2,0]},{"id":23,"path":"pkg/chains/formats/slsa/v2alpha3/internal/taskrun/taskrun.go","lines":["/*","Copyright 2023 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package taskrun","","import (","\t\"context\"","\t\"encoding/json\"","\t\"fmt\"","","\tintoto \"github.com/in-toto/attestation/go/v1\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/extract\"","\tbuilddefinition \"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/build_definition\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/provenance\"","\tresolveddependencies \"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/resolved_dependencies\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/slsaconfig\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"",")","","const taskRunResults = \"taskRunResults/%s\"","","// GenerateAttestation generates a provenance statement with SLSA v1.0 predicate for a task run.","func GenerateAttestation(ctx context.Context, tro *objects.TaskRunObjectV1, slsaConfig *slsaconfig.SlsaConfig) (interface{}, error) {","\tbp, err := byproducts(tro)","\tif err != nil {","\t\treturn nil, err","\t}","","\tbd, err := builddefinition.GetTaskRunBuildDefinition(ctx, tro, slsaConfig.BuildType, resolveddependencies.ResolveOptions{})","\tif err != nil {","\t\treturn nil, err","\t}","","\tsub := extract.SubjectDigests(ctx, tro, slsaConfig)","","\treturn provenance.GetSLSA1Statement(tro, sub, \u0026bd, bp, slsaConfig)","}","","// byproducts contains the taskRunResults","func byproducts(tro *objects.TaskRunObjectV1) ([]*intoto.ResourceDescriptor, error) {","\tbyProd := []*intoto.ResourceDescriptor{}","\tfor _, key := range tro.Status.Results {","\t\tcontent, err := json.Marshal(key.Value)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tbp := intoto.ResourceDescriptor{","\t\t\tName:      fmt.Sprintf(taskRunResults, key.Name),","\t\t\tContent:   content,","\t\t\tMediaType: \"application/json\",","\t\t}","\t\tbyProd = append(byProd, \u0026bp)","\t}","\treturn byProd, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,1,1,0,2,2,1,1,0,2,2,2,0,0,0,2,2,2,2,2,1,1,2,2,2,2,2,2,0,2,0]},{"id":24,"path":"pkg/chains/formats/slsa/v2alpha3/slsav2.go","lines":["/*","Copyright 2021 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v2alpha3","","import (","\t\"context\"","\t\"fmt\"","","\t\"github.com/tektoncd/chains/pkg/chains/formats\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/extract\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/slsaconfig\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/v2alpha3/internal/pipelinerun\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/v2alpha3/internal/taskrun\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"github.com/tektoncd/chains/pkg/config\"",")","","const (","\tPayloadTypeSlsav2alpha3 = formats.PayloadTypeSlsav2alpha3",")","","func init() {","\tformats.RegisterPayloader(PayloadTypeSlsav2alpha3, NewFormatter)","}","","type Slsa struct {","\tslsaConfig *slsaconfig.SlsaConfig","}","","func NewFormatter(cfg config.Config) (formats.Payloader, error) {","\treturn \u0026Slsa{","\t\tslsaConfig: \u0026slsaconfig.SlsaConfig{","\t\t\tBuilderID:             cfg.Builder.ID,","\t\t\tDeepInspectionEnabled: cfg.Artifacts.PipelineRuns.DeepInspectionEnabled,","\t\t\tBuildType:             cfg.BuildDefinition.BuildType,","\t\t},","\t}, nil","}","","func (s *Slsa) Wrap() bool {","\treturn true","}","","func (s *Slsa) CreatePayload(ctx context.Context, obj interface{}) (interface{}, error) {","\tswitch v := obj.(type) {","\tcase *objects.TaskRunObjectV1:","\t\treturn taskrun.GenerateAttestation(ctx, v, s.slsaConfig)","\tcase *objects.PipelineRunObjectV1:","\t\treturn pipelinerun.GenerateAttestation(ctx, v, s.slsaConfig)","\tdefault:","\t\treturn nil, fmt.Errorf(\"intoto does not support type: %s\", v)","\t}","}","","func (s *Slsa) Type() config.PayloadType {","\treturn formats.PayloadTypeSlsav2alpha3","}","","// RetrieveAllArtifactURIs returns the full URI of all artifacts detected as subjects.","func (s *Slsa) RetrieveAllArtifactURIs(ctx context.Context, obj interface{}) ([]string, error) {","\ttkObj, ok := obj.(objects.TektonObject)","\tif !ok {","\t\treturn nil, fmt.Errorf(\"intoto does not support type\")","\t}","\treturn extract.RetrieveAllArtifactURIs(ctx, tkObj, s.slsaConfig.DeepInspectionEnabled), nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,1,1,1,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,0,0,1,1,1,1,1,1,0]},{"id":25,"path":"pkg/chains/formats/slsa/v2alpha4/internal/pipelinerun/pipelinerun.go","lines":["/*","Copyright 2023 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pipelinerun","","import (","\t\"context\"","","\tintoto \"github.com/in-toto/attestation/go/v1\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/extract\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/artifact\"","\tbuilddefinition \"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/build_definition\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/provenance\"","\tresolveddependencies \"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/resolved_dependencies\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/results\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/slsaconfig\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/v2alpha4/internal/taskrun\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"",")","","const (","\tpipelineRunResults = \"pipelineRunResults/%s/%s\"","\t// JSONMediaType is the media type of json encoded content used in resource descriptors","\tJSONMediaType = \"application/json\"",")","","// GenerateAttestation generates a provenance statement with SLSA v1.0 predicate for a pipeline run.","func GenerateAttestation(ctx context.Context, pro *objects.PipelineRunObjectV1, slsaconfig *slsaconfig.SlsaConfig) (interface{}, error) {","\tbp, err := byproducts(pro, slsaconfig)","\tif err != nil {","\t\treturn nil, err","\t}","","\topts := resolveddependencies.ResolveOptions{WithStepActionsResults: true}","\tbd, err := builddefinition.GetPipelineRunBuildDefinition(ctx, pro, slsaconfig, opts)","\tif err != nil {","\t\treturn nil, err","\t}","","\tsub := SubjectDigests(ctx, pro, slsaconfig)","","\treturn provenance.GetSLSA1Statement(pro, sub, \u0026bd, bp, slsaconfig)","}","","// byproducts contains the pipelineRunResults that are not subjects.","func byproducts(pro *objects.PipelineRunObjectV1, slsaconfig *slsaconfig.SlsaConfig) ([]*intoto.ResourceDescriptor, error) {","\tbyProd, err := results.GetResultsWithoutBuildArtifacts(pro.GetName(), pro.GetResults(), pipelineRunResults)","\tif err != nil {","\t\treturn nil, err","\t}","","\tif !slsaconfig.DeepInspectionEnabled {","\t\treturn byProd, nil","\t}","","\tfor _, tro := range pro.GetExecutedTasks() {","\t\ttaskProds, err := taskrun.ByProducts(tro)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tbyProd = append(byProd, taskProds...)","\t}","","\treturn byProd, nil","}","","// SubjectDigests calculates the subjects associated with the given PipelineRun.","func SubjectDigests(ctx context.Context, pro *objects.PipelineRunObjectV1, slsaconfig *slsaconfig.SlsaConfig) []*intoto.ResourceDescriptor {","\tsubjects := extract.SubjectsFromBuildArtifact(ctx, pro.GetResults())","","\tif !slsaconfig.DeepInspectionEnabled {","\t\treturn subjects","\t}","","\tfor _, task := range pro.GetExecutedTasks() {","\t\tsubjects = artifact.AppendSubjects(subjects, taskrun.SubjectDigests(ctx, task)...)","\t}","","\treturn subjects","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,1,1,0,2,2,2,1,1,0,2,2,2,0,0,0,2,2,2,1,1,0,2,2,2,0,2,2,2,1,1,2,0,0,2,0,0,0,2,2,2,2,2,2,0,2,2,2,0,2,0]},{"id":26,"path":"pkg/chains/formats/slsa/v2alpha4/internal/taskrun/taskrun.go","lines":["/*","Copyright 2024 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package taskrun","","import (","\t\"context\"","","\tintoto \"github.com/in-toto/attestation/go/v1\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/extract\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/artifact\"","\tbuilddefinition \"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/build_definition\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/provenance\"","\tresolveddependencies \"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/resolved_dependencies\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/results\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/slsaconfig\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"",")","","const (","\ttaskRunResults     = \"taskRunResults/%s/%s\"","\ttaskRunStepResults = \"stepResults/%s/%s\"",")","","// GenerateAttestation returns the provenance for the given taskrun in SALSA 1.0 format.","func GenerateAttestation(ctx context.Context, tro *objects.TaskRunObjectV1, slsaConfig *slsaconfig.SlsaConfig) (interface{}, error) {","\tbp, err := ByProducts(tro)","\tif err != nil {","\t\treturn nil, err","\t}","","\tresOpts := resolveddependencies.ResolveOptions{WithStepActionsResults: true}","\tbd, err := builddefinition.GetTaskRunBuildDefinition(ctx, tro, slsaConfig.BuildType, resOpts)","\tif err != nil {","\t\treturn nil, err","\t}","","\tsub := SubjectDigests(ctx, tro)","","\treturn provenance.GetSLSA1Statement(tro, sub, \u0026bd, bp, slsaConfig)","}","","// ByProducts returns the results categorized as byproduct from the given TaskRun.","func ByProducts(tro *objects.TaskRunObjectV1) ([]*intoto.ResourceDescriptor, error) {","\tbyProd := []*intoto.ResourceDescriptor{}","","\tres, err := results.GetResultsWithoutBuildArtifacts(tro.GetName(), tro.GetResults(), taskRunResults)","\tif err != nil {","\t\treturn nil, err","\t}","\tbyProd = append(byProd, res...)","","\tres, err = results.GetResultsWithoutBuildArtifacts(tro.GetName(), tro.GetStepResults(), taskRunStepResults)","\tif err != nil {","\t\treturn nil, err","\t}","\tbyProd = append(byProd, res...)","","\treturn byProd, nil","}","","// SubjectDigests returns the subjects detected in the given TaskRun. It takes into account taskrun and step results.","func SubjectDigests(ctx context.Context, tro *objects.TaskRunObjectV1) []*intoto.ResourceDescriptor {","\tvar subjects []*intoto.ResourceDescriptor","\tfor _, step := range tro.Status.Steps {","\t\tres := getObjectResults(step.Results)","\t\tstepSubjects := extract.SubjectsFromBuildArtifact(ctx, res)","\t\tsubjects = artifact.AppendSubjects(subjects, stepSubjects...)","\t}","","\ttaskSubjects := extract.SubjectsFromBuildArtifact(ctx, tro.GetResults())","\tsubjects = artifact.AppendSubjects(subjects, taskSubjects...)","","\treturn subjects","}","","func getObjectResults(tresults []v1.TaskRunResult) (res []objects.Result) {","\tfor _, r := range tresults {","\t\tres = append(res, objects.Result{","\t\t\tName:  r.Name,","\t\t\tValue: r.Value,","\t\t})","\t}","\treturn","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,1,1,0,2,2,2,1,1,0,2,2,2,0,0,0,2,2,2,2,2,1,1,2,2,2,2,1,1,2,2,2,0,0,0,2,2,2,2,2,2,2,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0]},{"id":27,"path":"pkg/chains/formats/slsa/v2alpha4/slsav2.go","lines":["/*","Copyright 2024 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v2alpha4","","import (","\t\"context\"","\t\"fmt\"","","\tintoto \"github.com/in-toto/attestation/go/v1\"","\t\"github.com/tektoncd/chains/pkg/chains/formats\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/internal/slsaconfig\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/v2alpha4/internal/pipelinerun\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/v2alpha4/internal/taskrun\"","","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"github.com/tektoncd/chains/pkg/config\"",")","","const (","\tpayloadTypeSlsav2alpha4 = formats.PayloadTypeSlsav2alpha4",")","","func init() {","\tformats.RegisterPayloader(payloadTypeSlsav2alpha4, NewFormatter)","}","","// Slsa is a v2alpha4 payloader implementation.","type Slsa struct {","\tslsaConfig *slsaconfig.SlsaConfig","}","","// NewFormatter returns a new v2alpha4 payloader.","func NewFormatter(cfg config.Config) (formats.Payloader, error) { //nolint:ireturn","\treturn \u0026Slsa{","\t\tslsaConfig: \u0026slsaconfig.SlsaConfig{","\t\t\tBuilderID:             cfg.Builder.ID,","\t\t\tDeepInspectionEnabled: cfg.Artifacts.PipelineRuns.DeepInspectionEnabled,","\t\t\tBuildType:             cfg.BuildDefinition.BuildType,","\t\t},","\t}, nil","}","","// Wrap indicates if the resulting payload should be wrapped.","func (s *Slsa) Wrap() bool {","\treturn true","}","","// CreatePayload returns the payload for the given object using the v2alpha4 formatter logic.","func (s *Slsa) CreatePayload(ctx context.Context, obj interface{}) (interface{}, error) {","\tswitch v := obj.(type) {","\tcase *objects.TaskRunObjectV1:","\t\treturn taskrun.GenerateAttestation(ctx, v, s.slsaConfig)","\tcase *objects.PipelineRunObjectV1:","\t\treturn pipelinerun.GenerateAttestation(ctx, v, s.slsaConfig)","\tdefault:","\t\treturn nil, fmt.Errorf(\"intoto does not support type: %s\", v)","\t}","}","","// Type returns the version of this payloader.","func (s *Slsa) Type() config.PayloadType {","\treturn payloadTypeSlsav2alpha4","}","","// RetrieveAllArtifactURIs returns the full URI of all artifacts detected as subjects.","func (s *Slsa) RetrieveAllArtifactURIs(ctx context.Context, obj interface{}) ([]string, error) {","\tvar subjects []*intoto.ResourceDescriptor","\tvar fullURIs []string","","\tswitch v := obj.(type) {","\tcase *objects.TaskRunObjectV1:","\t\tsubjects = taskrun.SubjectDigests(ctx, v)","\tcase *objects.PipelineRunObjectV1:","\t\tsubjects = pipelinerun.SubjectDigests(ctx, v, s.slsaConfig)","\tdefault:","\t\treturn nil, fmt.Errorf(\"intoto does not support type: %s\", v)","\t}","","\tfor _, s := range subjects {","\t\tfor algo, digest := range s.Digest {","\t\t\tfullURIs = append(fullURIs, fmt.Sprintf(\"%s@%s:%s\", s.Name, algo, digest))","\t\t}","\t}","\treturn fullURIs, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,1,1,1,0,0,2,2,2,2,1,1,2,2,0,0,0,0,2,2,2,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,0,1,0]},{"id":28,"path":"pkg/chains/objects/objects.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package objects","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","\t\"strings\"","\t\"time\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"","\tapierrors \"k8s.io/apimachinery/pkg/api/errors\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/apimachinery/pkg/types\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/logging\"","\t\"knative.dev/pkg/ptr\"",")","","// Label added to TaskRuns identifying the associated pipeline Task","const PipelineTaskLabel = \"tekton.dev/pipelineTask\"","","// patchOptions contains the default patch options","var patchOptions = metav1.PatchOptions{","\tFieldManager: \"tekton-chains-controller\",","\tForce:        ptr.Bool(false),","}","","// Object is used as a base object of all Kubernetes objects","// ref: https://pkg.go.dev/sigs.k8s.io/controller-runtime@v0.9.4/pkg/client#Object","type Object interface {","\t// Metadata associated to all Kubernetes objects","\tmetav1.Object","\t// Runtime identifying data","\truntime.Object","}","","// Result is a generic key value store containing the results","// of Tekton operations. (eg. PipelineRun and TaskRun results)","type Result struct {","\tName  string","\tType  v1.ResultsType","\tValue v1.ParamValue","}","","// Tekton object is an extended Kubernetes object with operations specific","// to Tekton objects.","type TektonObject interface {","\tObject","\tGetGVK() string","\tGetKindName() string","\tGetObject() interface{}","\tGetLatestAnnotations(ctx context.Context, clientSet versioned.Interface) (map[string]string, error)","\tPatch(ctx context.Context, clientSet versioned.Interface, patchBytes []byte) error","\tGetResults() []Result","\tGetProvenance() *v1.Provenance","\tGetServiceAccountName() string","\tIsDone() bool","\tIsSuccessful() bool","\tSupportsTaskRunArtifact() bool","\tSupportsPipelineRunArtifact() bool","\tSupportsOCIArtifact() bool","\tGetRemoteProvenance() *v1.Provenance","\tIsRemote() bool","\tGetStartTime() *time.Time","\tGetCompletitionTime() *time.Time","}","","func NewTektonObject(i interface{}) (TektonObject, error) {","\tswitch o := i.(type) {","\tcase *v1.PipelineRun:","\t\treturn NewPipelineRunObjectV1(o), nil","\tcase *v1.TaskRun:","\t\treturn NewTaskRunObjectV1(o), nil","\tdefault:","\t\treturn nil, errors.New(\"unrecognized type when attempting to create tekton object\")","\t}","}","","// TaskRunObjectV1 extends v1.TaskRun with additional functions.","type TaskRunObjectV1 struct {","\t*v1.TaskRun","}","","var _ TektonObject = \u0026TaskRunObjectV1{}","","func NewTaskRunObjectV1(tr *v1.TaskRun) *TaskRunObjectV1 {","\treturn \u0026TaskRunObjectV1{","\t\ttr,","\t}","}","","// Get the TaskRun GroupVersionKind","func (tro *TaskRunObjectV1) GetGVK() string {","\treturn fmt.Sprintf(\"%s/%s\", tro.GetGroupVersionKind().GroupVersion().String(), tro.GetGroupVersionKind().Kind)","}","","func (tro *TaskRunObjectV1) GetKindName() string {","\treturn strings.ToLower(tro.GetGroupVersionKind().Kind)","}","","func (tro *TaskRunObjectV1) GetProvenance() *v1.Provenance {","\treturn tro.Status.Provenance","}","","// Get the latest annotations on the TaskRun","func (tro *TaskRunObjectV1) GetLatestAnnotations(ctx context.Context, clientSet versioned.Interface) (map[string]string, error) {","\ttr, err := clientSet.TektonV1().TaskRuns(tro.Namespace).Get(ctx, tro.Name, metav1.GetOptions{})","\treturn tr.Annotations, err","}","","// Get the base TaskRun object","func (tro *TaskRunObjectV1) GetObject() interface{} {","\treturn tro.TaskRun","}","","// Patch the original TaskRun object","func (tro *TaskRunObjectV1) Patch(ctx context.Context, clientSet versioned.Interface, patchBytes []byte) error {","\tlogger := logging.FromContext(ctx)","\t_, err := clientSet.TektonV1().TaskRuns(tro.Namespace).Patch(","\t\tctx, tro.Name, types.ApplyPatchType, patchBytes, patchOptions)","\tif apierrors.IsConflict(err) {","\t\t// Since we only update the list of annotations we manage, there shouldn't be any conflicts unless","\t\t// another controller/client is updating our annotations. We log the issue and force patch.","\t\tlogger.Warnf(\"failed to patch object %s/%s due to Server-Side Apply patch conflict, using force patch.\", tro.Namespace, tro.Name)","\t\t// use a copy to avoid changing the global var","\t\tpatchOptionsForce := patchOptions","\t\tpatchOptionsForce.Force = ptr.Bool(true)","\t\t_, err = clientSet.TektonV1().TaskRuns(tro.Namespace).Patch(","\t\t\tctx, tro.Name, types.ApplyPatchType, patchBytes, patchOptionsForce)","\t}","\treturn err","}","","// Get the TaskRun results","func (tro *TaskRunObjectV1) GetResults() []Result {","\tres := []Result{}","\tfor _, key := range tro.Status.Results {","\t\tres = append(res, Result{","\t\t\tName:  key.Name,","\t\t\tValue: key.Value,","\t\t})","\t}","\treturn res","}","","// GetStepResults returns all the results from associated StepActions.","func (tro *TaskRunObjectV1) GetStepResults() []Result {","\tres := []Result{}","\tfor _, s := range tro.Status.Steps {","\t\tfor _, r := range s.Results {","\t\t\tres = append(res, Result{","\t\t\t\tName:  r.Name,","\t\t\t\tValue: r.Value,","\t\t\t})","\t\t}","\t}","\treturn res","}","","func (tro *TaskRunObjectV1) GetStepImages() []string {","\timages := []string{}","\tfor _, stepState := range tro.Status.Steps {","\t\timages = append(images, stepState.ImageID)","\t}","\treturn images","}","","func (tro *TaskRunObjectV1) GetSidecarImages() []string {","\timages := []string{}","\tfor _, sidecarState := range tro.Status.Sidecars {","\t\timages = append(images, sidecarState.ImageID)","\t}","\treturn images","}","","// Get the ServiceAccount declared in the TaskRun","func (tro *TaskRunObjectV1) GetServiceAccountName() string {","\treturn tro.Spec.ServiceAccountName","}","","func (tro *TaskRunObjectV1) SupportsTaskRunArtifact() bool {","\treturn true","}","","func (tro *TaskRunObjectV1) SupportsPipelineRunArtifact() bool {","\treturn false","}","","func (tro *TaskRunObjectV1) SupportsOCIArtifact() bool {","\treturn true","}","","func (tro *TaskRunObjectV1) GetRemoteProvenance() *v1.Provenance {","\tif t := tro.Status.Provenance; t != nil \u0026\u0026 t.RefSource != nil \u0026\u0026 tro.IsRemote() {","\t\treturn tro.Status.Provenance","\t}","\treturn nil","}","","func (tro *TaskRunObjectV1) IsRemote() bool {","\tisRemoteTask := false","\tif tro.Spec.TaskRef != nil {","\t\tif tro.Spec.TaskRef.Resolver != \"\" \u0026\u0026 tro.Spec.TaskRef.Resolver != \"Cluster\" {","\t\t\tisRemoteTask = true","\t\t}","\t}","\treturn isRemoteTask","}","","// GetStartTime returns the time when the TaskRun started.","func (tro *TaskRunObjectV1) GetStartTime() *time.Time {","\tvar utc *time.Time","\tif tro.Status.StartTime != nil {","\t\tval := tro.Status.StartTime.Time.UTC()","\t\tutc = \u0026val","\t}","\treturn utc","}","","// GetCompletitionTime returns the time when the TaskRun finished.","func (tro *TaskRunObjectV1) GetCompletitionTime() *time.Time {","\tvar utc *time.Time","\tif tro.Status.CompletionTime != nil {","\t\tval := tro.Status.CompletionTime.Time.UTC()","\t\tutc = \u0026val","\t}","\treturn utc","}","","// PipelineRunObjectV1 extends v1.PipelineRun with additional functions.","type PipelineRunObjectV1 struct {","\t// The base PipelineRun","\t*v1.PipelineRun","\t// taskRuns that were apart of this PipelineRun","\ttaskRuns []*v1.TaskRun","}","","var _ TektonObject = \u0026PipelineRunObjectV1{}","","func NewPipelineRunObjectV1(pr *v1.PipelineRun) *PipelineRunObjectV1 {","\treturn \u0026PipelineRunObjectV1{","\t\tPipelineRun: pr,","\t}","}","","// Get the PipelineRun GroupVersionKind","func (pro *PipelineRunObjectV1) GetGVK() string {","\treturn fmt.Sprintf(\"%s/%s\", pro.GetGroupVersionKind().GroupVersion().String(), pro.GetGroupVersionKind().Kind)","}","","func (pro *PipelineRunObjectV1) GetKindName() string {","\treturn strings.ToLower(pro.GetGroupVersionKind().Kind)","}","","// Request the current annotations on the PipelineRun object","func (pro *PipelineRunObjectV1) GetLatestAnnotations(ctx context.Context, clientSet versioned.Interface) (map[string]string, error) {","\tpr, err := clientSet.TektonV1().PipelineRuns(pro.Namespace).Get(ctx, pro.Name, metav1.GetOptions{})","\treturn pr.Annotations, err","}","","// Get the base PipelineRun","func (pro *PipelineRunObjectV1) GetObject() interface{} {","\treturn pro.PipelineRun","}","","// Patch the original PipelineRun object","func (pro *PipelineRunObjectV1) Patch(ctx context.Context, clientSet versioned.Interface, patchBytes []byte) error {","\tlogger := logging.FromContext(ctx)","\t_, err := clientSet.TektonV1().PipelineRuns(pro.Namespace).Patch(","\t\tctx, pro.Name, types.ApplyPatchType, patchBytes, patchOptions)","\tif apierrors.IsConflict(err) {","\t\t// Since we only update the list of annotations we manage, there shouldn't be any conflicts unless","\t\t// another controller/client is updating our annotations. We log the issue and force patch.","\t\tlogger.Warnf(\"failed to patch object %s/%s due to Server-Side Apply patch conflict, using force patch.\", pro.Namespace, pro.Name)","\t\t// use a copy to avoid changing the global var","\t\tpatchOptionsForce := patchOptions","\t\tpatchOptionsForce.Force = ptr.Bool(true)","\t\t_, err = clientSet.TektonV1().PipelineRuns(pro.Namespace).Patch(","\t\t\tctx, pro.Name, types.ApplyPatchType, patchBytes, patchOptionsForce)","\t}","\treturn err","}","","func (pro *PipelineRunObjectV1) GetProvenance() *v1.Provenance {","\treturn pro.Status.Provenance","}","","// Get the resolved Pipelinerun results","func (pro *PipelineRunObjectV1) GetResults() []Result {","\tres := []Result{}","\tfor _, key := range pro.Status.Results {","\t\tres = append(res, Result{","\t\t\tName:  key.Name,","\t\t\tValue: key.Value,","\t\t})","\t}","\treturn res","}","","// Get the ServiceAccount declared in the PipelineRun","func (pro *PipelineRunObjectV1) GetServiceAccountName() string {","\treturn pro.Spec.TaskRunTemplate.ServiceAccountName","}","","// Get the ServiceAccount declared in the PipelineRun","func (pro *PipelineRunObjectV1) IsSuccessful() bool {","\treturn pro.Status.GetCondition(apis.ConditionSucceeded).IsTrue()","}","","// Append TaskRuns to this PipelineRun","func (pro *PipelineRunObjectV1) AppendTaskRun(tr *v1.TaskRun) {","\tpro.taskRuns = append(pro.taskRuns, tr)","}","","// Append TaskRuns to this PipelineRun","func (pro *PipelineRunObjectV1) GetTaskRuns() []*v1.TaskRun {","\treturn pro.taskRuns","}","","// Get the associated TaskRun via the Task name","func (pro *PipelineRunObjectV1) GetTaskRunsFromTask(taskName string) []*TaskRunObjectV1 {","\tvar taskRuns []*TaskRunObjectV1","\tfor _, tr := range pro.taskRuns {","\t\tval, ok := tr.Labels[PipelineTaskLabel]","\t\tif ok \u0026\u0026 val == taskName {","\t\t\ttaskRuns = append(taskRuns, NewTaskRunObjectV1(tr))","\t\t}","\t}","\treturn taskRuns","}","","func (pro *PipelineRunObjectV1) SupportsTaskRunArtifact() bool {","\treturn false","}","","func (pro *PipelineRunObjectV1) SupportsPipelineRunArtifact() bool {","\treturn true","}","","func (pro *PipelineRunObjectV1) SupportsOCIArtifact() bool {","\treturn false","}","","func (pro *PipelineRunObjectV1) GetRemoteProvenance() *v1.Provenance {","\tif p := pro.Status.Provenance; p != nil \u0026\u0026 p.RefSource != nil \u0026\u0026 pro.IsRemote() {","\t\treturn pro.Status.Provenance","\t}","\treturn nil","}","","func (pro *PipelineRunObjectV1) IsRemote() bool {","\tisRemotePipeline := false","\tif pro.Spec.PipelineRef != nil {","\t\tif pro.Spec.PipelineRef.Resolver != \"\" \u0026\u0026 pro.Spec.PipelineRef.Resolver != \"Cluster\" {","\t\t\tisRemotePipeline = true","\t\t}","\t}","\treturn isRemotePipeline","}","","// GetStartTime returns the time when the PipelineRun started.","func (pro *PipelineRunObjectV1) GetStartTime() *time.Time {","\tvar utc *time.Time","\tif pro.Status.StartTime != nil {","\t\tval := pro.Status.StartTime.Time.UTC()","\t\tutc = \u0026val","\t}","\treturn utc","}","","// GetCompletitionTime returns the time when the PipelineRun finished.","func (pro *PipelineRunObjectV1) GetCompletitionTime() *time.Time {","\tvar utc *time.Time","\tif pro.Status.CompletionTime != nil {","\t\tval := pro.Status.CompletionTime.Time.UTC()","\t\tutc = \u0026val","\t}","\treturn utc","}","","// GetExecutedTasks returns the tasks that were executed during the pipeline run.","func (pro *PipelineRunObjectV1) GetExecutedTasks() (tro []*TaskRunObjectV1) {","\tpSpec := pro.Status.PipelineSpec","\tif pSpec == nil {","\t\treturn","\t}","\ttasks := pSpec.Tasks","\ttasks = append(tasks, pSpec.Finally...)","\tfor _, task := range tasks {","\t\ttaskRuns := pro.GetTaskRunsFromTask(task.Name)","\t\tif len(taskRuns) == 0 {","\t\t\tcontinue","\t\t}","\t\tfor _, tr := range taskRuns {","\t\t\tif tr == nil || tr.Status.CompletionTime == nil {","\t\t\t\tcontinue","\t\t\t}","","\t\t\ttro = append(tro, tr)","\t\t}","\t}","","\treturn","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,2,2,2,0,2,2,2,0,2,2,2,0,0,1,1,1,1,0,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,1,1,1,1,1,1,1,1,1,0,1,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,0,2,2,2,0,1,1,1,0,1,1,1,0,1,1,1,0,1,1,1,1,1,0,0,2,2,2,2,2,2,0,2,0,0,0,1,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,2,2,2,0,2,2,2,0,0,1,1,1,1,0,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,0,0,1,1,1,0,0,2,2,2,0,0,1,1,1,0,0,2,2,2,2,2,2,2,0,2,0,0,1,1,1,0,1,1,1,0,1,1,1,0,1,1,1,1,1,0,0,2,2,2,2,2,2,0,2,0,0,0,1,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,0,1,0,0,0,1,0]},{"id":29,"path":"pkg/chains/rekor.go","lines":["/*","Copyright 2020 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package chains","","import (","\t\"context\"","\t\"crypto/sha256\"","","\t\"github.com/pkg/errors\"","\t\"github.com/sigstore/cosign/v2/pkg/cosign\"","\trc \"github.com/sigstore/rekor/pkg/client\"","\t\"github.com/sigstore/rekor/pkg/generated/client\"","\t\"github.com/sigstore/rekor/pkg/generated/models\"","\t\"github.com/sigstore/sigstore/pkg/cryptoutils\"","\t\"github.com/tektoncd/chains/pkg/chains/annotations\"","\t\"github.com/tektoncd/chains/pkg/chains/formats\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"github.com/tektoncd/chains/pkg/chains/signing\"","\t\"github.com/tektoncd/chains/pkg/config\"",")","","const (","\tRekorAnnotation = \"chains.tekton.dev/transparency-upload\"",")","","type rekor struct {","\tc *client.Rekor","}","","type rekorClient interface {","\tUploadTlog(ctx context.Context, signer signing.Signer, signature, rawPayload []byte, cert, payloadFormat string) (*models.LogEntryAnon, error)","}","","func (r *rekor) UploadTlog(ctx context.Context, signer signing.Signer, signature, rawPayload []byte, cert, payloadFormat string) (*models.LogEntryAnon, error) {","\tpkoc, err := publicKeyOrCert(signer, cert)","\tif err != nil {","\t\treturn nil, errors.Wrap(err, \"public key or cert\")","\t}","\tif _, ok := formats.IntotoAttestationSet[config.PayloadType(payloadFormat)]; ok {","\t\treturn cosign.TLogUploadInTotoAttestation(ctx, r.c, signature, pkoc)","\t}","","\th := sha256.New()","\tif _, err := h.Write(rawPayload); err != nil {","\t\treturn nil, errors.Wrap(err, \"error checksuming payload\")","\t}","\treturn cosign.TLogUpload(ctx, r.c, signature, h, pkoc)","}","","// return the cert if we have it, otherwise return public key","func publicKeyOrCert(signer signing.Signer, cert string) ([]byte, error) {","\tif cert != \"\" {","\t\treturn []byte(cert), nil","\t}","\tpub, err := signer.PublicKey()","\tif err != nil {","\t\treturn nil, errors.Wrap(err, \"getting public key\")","\t}","\tpem, err := cryptoutils.MarshalPublicKeyToPEM(pub)","\tif err != nil {","\t\treturn nil, errors.Wrap(err, \"key to pem\")","\t}","\treturn pem, nil","}","","var getRekor = func(url string) (rekorClient, error) {","\trekorClient, err := rc.GetRekorClient(url)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn \u0026rekor{","\t\tc: rekorClient,","\t}, nil","}","","func shouldUploadTlog(cfg config.Config, obj objects.TektonObject) bool {","\t// if transparency isn't enabled, return false","\tif !cfg.Transparency.Enabled {","\t\treturn false","\t}","\t// if transparency is enabled and verification is disabled, return true","\tif !cfg.Transparency.VerifyAnnotation {","\t\treturn true","\t}","","\t// Already uploaded, don't do it again","\tif _, ok := obj.GetAnnotations()[annotations.ChainsTransparencyAnnotation]; ok {","\t\treturn false","\t}","","\t// verify the annotation","\tann := obj.GetAnnotations()[RekorAnnotation]","\treturn ann == \"true\"","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,0,2,2,2,2,2,0,2,2,2,0,0,2,2,2,0,0,2,2,0]},{"id":30,"path":"pkg/chains/signing.go","lines":["/*","Copyright 2020 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package chains","","import (","\t\"bytes\"","\t\"context\"","\t\"encoding/json\"","\t\"fmt\"","","\t\"github.com/hashicorp/go-multierror\"","\tintoto \"github.com/in-toto/attestation/go/v1\"","\t\"github.com/tektoncd/chains/pkg/artifacts\"","\t\"github.com/tektoncd/chains/pkg/chains/annotations\"","\t\"github.com/tektoncd/chains/pkg/chains/formats\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"github.com/tektoncd/chains/pkg/chains/signing\"","\t\"github.com/tektoncd/chains/pkg/chains/signing/kms\"","\t\"github.com/tektoncd/chains/pkg/chains/signing/x509\"","\t\"github.com/tektoncd/chains/pkg/chains/storage\"","\t\"github.com/tektoncd/chains/pkg/config\"","\t\"github.com/tektoncd/chains/pkg/metrics\"","\tversioned \"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"","\t\"golang.org/x/exp/maps\"","\t\"google.golang.org/protobuf/encoding/protojson\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"knative.dev/pkg/logging\"",")","","type Signer interface {","\tSign(ctx context.Context, obj objects.TektonObject) error","}","","type ObjectSigner struct {","\t// Backends: store payload and signature","\t// The keys are different storage option's name. {docdb, gcs, grafeas, oci, tekton}","\t// The values are the actual storage backends that will be used to store and retrieve provenance.","\tBackends          map[string]storage.Backend","\tSecretPath        string","\tPipelineclientset versioned.Interface","","\tRecorder metrics.Recorder","}","","func allSigners(ctx context.Context, sp string, cfg config.Config) map[string]signing.Signer {","\tl := logging.FromContext(ctx)","\tall := map[string]signing.Signer{}","\tneededSigners := map[string]struct{}{","\t\tcfg.Artifacts.OCI.Signer:          {},","\t\tcfg.Artifacts.TaskRuns.Signer:     {},","\t\tcfg.Artifacts.PipelineRuns.Signer: {},","\t}","","\tfor _, s := range signing.AllSigners {","\t\tif _, ok := neededSigners[s]; !ok {","\t\t\tcontinue","\t\t}","\t\tswitch s {","\t\tcase signing.TypeX509:","\t\t\tsigner, err := x509.NewSigner(ctx, sp, cfg)","\t\t\tif err != nil {","\t\t\t\tl.Warnf(\"error configuring x509 signer: %s\", err)","\t\t\t\tcontinue","\t\t\t}","\t\t\tall[s] = signer","\t\tcase signing.TypeKMS:","\t\t\tsigner, err := kms.NewSigner(ctx, cfg.Signers.KMS)","\t\t\tif err != nil {","\t\t\t\tl.Warnf(\"error configuring kms signer with config %v: %s\", cfg.Signers.KMS, err)","\t\t\t\tcontinue","\t\t\t}","\t\t\tall[s] = signer","\t\tdefault:","\t\t\t// This should never happen, so panic","\t\t\tl.Panicf(\"unsupported signer: %s\", s)","\t\t}","\t}","\treturn all","}","","// TODO: Hook this up to config.","func getSignableTypes(ctx context.Context, obj objects.TektonObject) ([]artifacts.Signable, error) {","\tvar types []artifacts.Signable","","\tif obj.SupportsTaskRunArtifact() {","\t\ttypes = append(types, \u0026artifacts.TaskRunArtifact{})","\t}","","\tif obj.SupportsPipelineRunArtifact() {","\t\ttypes = append(types, \u0026artifacts.PipelineRunArtifact{})","\t}","","\tif obj.SupportsOCIArtifact() {","\t\ttypes = append(types, \u0026artifacts.OCIArtifact{})","\t}","","\tif len(types) == 0 {","\t\treturn nil, fmt.Errorf(\"no signable artifacts found for %v\", obj)","\t}","","\treturn types, nil","}","","// Sign TaskRun and PipelineRun objects, as well as generates attestations for each.","// Follows process of extract payload, sign payload, store payload and signature.","func (o *ObjectSigner) Sign(ctx context.Context, tektonObj objects.TektonObject) error {","\tcfg := *config.FromContext(ctx)","\tlogger := logging.FromContext(ctx)","","\tsignableTypes, err := getSignableTypes(ctx, tektonObj)","\tif err != nil {","\t\treturn err","\t}","","\tsigners := allSigners(ctx, o.SecretPath, cfg)","","\tvar merr *multierror.Error","\textraAnnotations := map[string]string{}","\tfor _, signableType := range signableTypes {","\t\tif !signableType.Enabled(cfg) {","\t\t\tcontinue","\t\t}","\t\tpayloadFormat := signableType.PayloadFormat(cfg)","\t\t// Find the right payload format and format the object","\t\tpayloader, err := formats.GetPayloader(payloadFormat, cfg)","\t\tif err != nil {","\t\t\tlogger.Warnf(\"Format %s configured for %s: %v was not found\", payloadFormat, tektonObj.GetGVK(), signableType.Type())","\t\t\tcontinue","\t\t}","","\t\t// Extract all the \"things\" to be signed.","\t\t// We might have a few of each type (several binaries, or images)","\t\tobjects := signableType.ExtractObjects(ctx, tektonObj)","\t\t// Go through each object one at a time.","\t\tfor _, obj := range objects {","","\t\t\tpayload, err := payloader.CreatePayload(ctx, obj)","\t\t\tif err != nil {","\t\t\t\tlogger.Error(err)","\t\t\t\to.recordError(ctx, signableType.Type(), metrics.PayloadCreationError)","\t\t\t\tcontinue","\t\t\t}","\t\t\tlogger.Infof(\"Created payload of type %s for %s %s/%s\", string(payloadFormat), tektonObj.GetGVK(), tektonObj.GetNamespace(), tektonObj.GetName())","","\t\t\t// Sign it!","\t\t\tsignerType := signableType.Signer(cfg)","\t\t\tsigner, ok := signers[signerType]","\t\t\tif !ok {","\t\t\t\tlogger.Warnf(\"No signer %s configured for %s\", signerType, signableType.Type())","\t\t\t\tcontinue","\t\t\t}","","\t\t\tif payloader.Wrap() {","\t\t\t\twrapped, err := signing.Wrap(signer)","\t\t\t\tif err != nil {","\t\t\t\t\treturn err","\t\t\t\t}","\t\t\t\tlogger.Infof(\"Using wrapped envelope signer for %s\", payloader.Type())","\t\t\t\tsigner = wrapped","\t\t\t}","","\t\t\tlogger.Infof(\"Signing object with %s\", signerType)","\t\t\trawPayload, err := getRawPayload(payload)","\t\t\tif err != nil {","\t\t\t\tlogger.Warnf(\"Unable to marshal payload for %s: %v\", signerType, err)","\t\t\t\to.recordError(ctx, signableType.Type(), metrics.MarshalPayloadError)","\t\t\t\tcontinue","\t\t\t}","","\t\t\tsignature, err := signer.SignMessage(bytes.NewReader(rawPayload))","\t\t\tif err != nil {","\t\t\t\tlogger.Error(err)","\t\t\t\to.recordError(ctx, signableType.Type(), metrics.SigningError)","\t\t\t\tcontinue","\t\t\t}","\t\t\tmeasureMetrics(ctx, metrics.SignedMessagesCount, o.Recorder)","","\t\t\t// Now store those!","\t\t\tfor _, backend := range sets.List[string](signableType.StorageBackend(cfg)) {","\t\t\t\tb, ok := o.Backends[backend]","\t\t\t\tif !ok {","\t\t\t\t\tbackendErr := fmt.Errorf(\"could not find backend '%s' in configured backends (%v) while trying sign: %s/%s\", backend, maps.Keys(o.Backends), tektonObj.GetKindName(), tektonObj.GetName())","\t\t\t\t\tlogger.Error(backendErr)","\t\t\t\t\to.recordError(ctx, signableType.Type(), metrics.StorageError)","\t\t\t\t\tmerr = multierror.Append(merr, backendErr)","\t\t\t\t\tcontinue","\t\t\t\t}","","\t\t\t\tstorageOpts := config.StorageOpts{","\t\t\t\t\tShortKey:      signableType.ShortKey(obj),","\t\t\t\t\tFullKey:       signableType.FullKey(obj),","\t\t\t\t\tCert:          signer.Cert(),","\t\t\t\t\tChain:         signer.Chain(),","\t\t\t\t\tPayloadFormat: payloadFormat,","\t\t\t\t}","\t\t\t\tif err := b.StorePayload(ctx, tektonObj, rawPayload, string(signature), storageOpts); err != nil {","\t\t\t\t\tlogger.Error(err)","\t\t\t\t\to.recordError(ctx, signableType.Type(), metrics.StorageError)","\t\t\t\t\tmerr = multierror.Append(merr, err)","\t\t\t\t} else {","\t\t\t\t\tmeasureMetrics(ctx, metrics.SignsStoredCount, o.Recorder)","\t\t\t\t}","\t\t\t}","","\t\t\tif shouldUploadTlog(cfg, tektonObj) {","\t\t\t\trekorClient, err := getRekor(cfg.Transparency.URL)","\t\t\t\tif err != nil {","\t\t\t\t\treturn err","\t\t\t\t}","","\t\t\t\tentry, err := rekorClient.UploadTlog(ctx, signer, signature, rawPayload, signer.Cert(), string(payloadFormat))","\t\t\t\tif err != nil {","\t\t\t\t\tlogger.Warnf(\"error uploading entry to tlog: %v\", err)","\t\t\t\t\to.recordError(ctx, signableType.Type(), metrics.TlogError)","\t\t\t\t\tmerr = multierror.Append(merr, err)","\t\t\t\t} else {","\t\t\t\t\tlogger.Infof(\"Uploaded entry to %s with index %d\", cfg.Transparency.URL, *entry.LogIndex)","\t\t\t\t\textraAnnotations[annotations.ChainsTransparencyAnnotation] = fmt.Sprintf(\"%s/api/v1/log/entries?logIndex=%d\", cfg.Transparency.URL, *entry.LogIndex)","\t\t\t\t\tmeasureMetrics(ctx, metrics.PayloadUploadeCount, o.Recorder)","\t\t\t\t}","\t\t\t}","","\t\t}","\t\tif merr.ErrorOrNil() != nil {","\t\t\tif retryErr := annotations.HandleRetry(ctx, tektonObj, o.Pipelineclientset, extraAnnotations); retryErr != nil {","\t\t\t\tlogger.Warnf(\"error handling retry: %v\", retryErr)","\t\t\t\tmerr = multierror.Append(merr, retryErr)","\t\t\t}","\t\t\treturn merr","\t\t}","\t}","","\t// Now mark the TektonObject as signed","\tif err := annotations.MarkSigned(ctx, tektonObj, o.Pipelineclientset, extraAnnotations); err != nil {","\t\treturn err","\t}","\tmeasureMetrics(ctx, metrics.MarkedAsSignedCount, o.Recorder)","\treturn nil","}","","func measureMetrics(ctx context.Context, metrictype metrics.Metric, mtr metrics.Recorder) {","\tif mtr != nil {","\t\tmtr.RecordCountMetrics(ctx, metrictype)","\t}","}","","// recordError abstracts the check and calls RecordErrorMetric if appropriate.","func (o *ObjectSigner) recordError(ctx context.Context, kind string, errType metrics.MetricErrorType) {","\tshouldRecordError := kind == \"TaskRunArtifact\" || kind == \"PipelineRunArtifact\"","\tif shouldRecordError \u0026\u0026 o.Recorder != nil {","\t\to.Recorder.RecordErrorMetric(ctx, errType)","\t}","}","","// getRawPayload returns the payload as a json string. If the given payload is a intoto.Statement type, protojson.Marshal","// is used to get the proper labels/field names in the resulting json.","func getRawPayload(payload interface{}) ([]byte, error) {","\tswitch payloadObj := payload.(type) {","\tcase intoto.Statement:","\t\treturn protojson.Marshal(\u0026payloadObj)","\tcase *intoto.Statement:","\t\tif payloadObj == nil {","\t\t\treturn json.Marshal(payload)","\t\t}","\t\treturn protojson.Marshal(payloadObj)","\tdefault:","\t\treturn json.Marshal(payload)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,1,1,0,2,1,1,1,1,1,0,1,1,1,1,0,0,2,0,0,0,2,2,2,2,2,2,0,2,2,2,0,2,2,2,0,2,1,1,0,2,0,0,0,0,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,1,0,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,1,1,1,0,2,2,2,2,2,2,1,1,0,0,2,2,2,1,1,2,2,0,0,2,2,2,1,1,1,0,0,2,2,1,1,1,0,2,2,2,2,2,2,1,1,1,1,1,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,1,1,0,2,2,1,1,1,2,2,2,2,2,0,0,0,2,2,1,1,1,2,0,0,0,0,2,1,1,2,2,0,0,2,2,1,1,0,0,0,2,2,2,1,1,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0]},{"id":31,"path":"pkg/chains/signing/kms/kms.go","lines":["/*","Copyright 2020 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","// Package kms creates a signer using a key management server","package kms","","import (","\t\"context\"","\t\"crypto\"","\t\"fmt\"","\t\"net\"","\t\"net/url\"","\t\"os\"","\t\"strings\"","\t\"time\"","","\t\"github.com/sigstore/sigstore/pkg/signature\"","\t\"github.com/sigstore/sigstore/pkg/signature/kms\"","\t_ \"github.com/sigstore/sigstore/pkg/signature/kms/aws\"","\t_ \"github.com/sigstore/sigstore/pkg/signature/kms/azure\"","\t_ \"github.com/sigstore/sigstore/pkg/signature/kms/gcp\"","\t_ \"github.com/sigstore/sigstore/pkg/signature/kms/hashivault\"","\t\"github.com/sigstore/sigstore/pkg/signature/options\"","\t\"github.com/tektoncd/chains/pkg/config\"","","\t\"github.com/spiffe/go-spiffe/v2/svid/jwtsvid\"","\t\"github.com/spiffe/go-spiffe/v2/workloadapi\"","\t\"github.com/tektoncd/chains/pkg/chains/signing\"",")","","// Signer exposes methods to sign payloads using a KMS","type Signer struct {","\tsignature.SignerVerifier","}","","// NewSigner returns a configured Signer","func NewSigner(ctx context.Context, cfg config.KMSSigner) (*Signer, error) {","\tkmsOpts := []signature.RPCOption{}","","\t// Checks if the vault address provide by the user is a valid address or not","\tif cfg.Auth.Address != \"\" {","\t\tvaultAddress, err := url.Parse(cfg.Auth.Address)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","","\t\tvar vaultUrl *url.URL","\t\tswitch {","\t\tcase vaultAddress.Port() != \"\":","\t\t\tvaultUrl = vaultAddress","\t\tcase vaultAddress.Scheme == \"http\":","\t\t\tvaultUrl = \u0026url.URL{","\t\t\t\tScheme: vaultAddress.Scheme,","\t\t\t\tHost:   vaultAddress.Host + \":80\",","\t\t\t}","\t\tcase vaultAddress.Scheme == \"https\":","\t\t\tvaultUrl = \u0026url.URL{","\t\t\t\tScheme: vaultAddress.Scheme,","\t\t\t\tHost:   vaultAddress.Host + \":443\",","\t\t\t}","\t\tcase vaultAddress.Scheme == \"\":","\t\t\tvaultUrl = \u0026url.URL{","\t\t\t\tScheme: \"http\",","\t\t\t\tHost:   cfg.Auth.Address + \":80\",","\t\t\t}","\t\tcase vaultAddress.Scheme != \"\" \u0026\u0026 vaultAddress.Scheme != \"http\" \u0026\u0026 vaultAddress.Scheme != \"https\":","\t\t\tvaultUrl = \u0026url.URL{","\t\t\t\tScheme: \"http\",","\t\t\t\tHost:   cfg.Auth.Address,","\t\t\t}","\t\t\tif vaultUrl.Port() == \"\" {","\t\t\t\tvaultUrl.Host = cfg.Auth.Address + \":80\"","\t\t\t}","\t\t}","","\t\tif vaultUrl != nil {","\t\t\tconn, err := net.DialTimeout(\"tcp\", vaultUrl.Host, 5*time.Second)","\t\t\tif err != nil {","\t\t\t\treturn nil, err","\t\t\t}","\t\t\tdefer conn.Close()","\t\t} else {","\t\t\treturn nil, fmt.Errorf(\"Error connecting to URL %s\\n\", cfg.Auth.Address)","\t\t}","\t}","","\t// pass through configuration options to RPCAuth used by KMS in sigstore","\trpcAuth := options.RPCAuth{","\t\tAddress: cfg.Auth.Address,","\t\tOIDC: options.RPCAuthOIDC{","\t\t\tRole: cfg.Auth.OIDC.Role,","\t\t\tPath: cfg.Auth.OIDC.Path,","\t\t},","\t}","","\t// get token from file KMS_AUTH_TOKEN, a mounted secret at signers.kms.auth.token-dir or","\t// as direct value set from signers.kms.auth.token.","\t// If both values are set, priority will be given to token-dir.","","\tif cfg.Auth.TokenPath != \"\" {","\t\trpcAuthToken, err := getKMSAuthToken(cfg.Auth.TokenPath)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\trpcAuth.Token = rpcAuthToken","\t} else {","\t\trpcAuth.Token = cfg.Auth.Token","\t}","","\t// get token from spire","\tif cfg.Auth.Spire.Sock != \"\" {","\t\ttoken, err := newSpireToken(ctx, cfg)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\trpcAuth.OIDC.Token = token","\t}","\tkmsOpts = append(kmsOpts, options.WithRPCAuthOpts(rpcAuth))","\t// get the signer/verifier from sigstore","\tk, err := kms.Get(ctx, cfg.KMSRef, crypto.SHA256, kmsOpts...)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn \u0026Signer{","\t\tSignerVerifier: k,","\t}, nil","}","","// getKMSAuthToken retreives token from the given mount path","func getKMSAuthToken(path string) (string, error) {","\tfileData, err := os.ReadFile(path)","\tif err != nil {","\t\treturn \"\", fmt.Errorf(\"reading file in %q: %w\", path, err)","\t}","","\t// A trailing newline is fairly common in mounted files, so remove it.","\tfileDataNormalized := strings.TrimSuffix(string(fileData), \"\\n\")","\treturn fileDataNormalized, nil","}","","// newSpireToken retrieves an SVID token from Spire","func newSpireToken(ctx context.Context, cfg config.KMSSigner) (string, error) {","\tjwtSource, err := workloadapi.NewJWTSource(","\t\tctx,","\t\tworkloadapi.WithClientOptions(workloadapi.WithAddr(cfg.Auth.Spire.Sock)),","\t)","\tif err != nil {","\t\treturn \"\", err","\t}","\tsvid, err := jwtSource.FetchJWTSVID(ctx, jwtsvid.Params{Audience: cfg.Auth.Spire.Audience})","\tif err != nil {","\t\treturn \"\", err","\t}","\treturn svid.Marshal(), nil","}","","// Type returns the type of the signer","func (s *Signer) Type() string {","\treturn signing.TypeKMS","}","","// Cert there is no cert, return nothing","func (s *Signer) Cert() string {","\treturn \"\"","}","","// Chain there is no chain, return nothing","func (s *Signer) Chain() string {","\treturn \"\"","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,1,1,0,2,2,2,2,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,1,1,0,0,2,2,2,2,2,2,1,1,1,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,2,2,2,0,0,2,1,1,1,1,1,0,2,2,2,2,2,2,1,1,1,0,0,0,2,2,2,2,2,0,0,2,2,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1]},{"id":32,"path":"pkg/chains/signing/wrap.go","lines":["/*","Copyright 2021 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package signing","","import (","\t\"bytes\"","\t\"context\"","\t\"crypto\"","\t\"encoding/json\"","\t\"fmt\"","\t\"io\"","","\t\"github.com/in-toto/in-toto-golang/in_toto\"","\t\"github.com/secure-systems-lab/go-securesystemslib/dsse\"","\t\"github.com/sigstore/sigstore/pkg/signature\"","","\t\"golang.org/x/crypto/ssh\"",")","","func Wrap(s Signer) (Signer, error) {","\tpub, err := s.PublicKey()","\tif err != nil {","\t\treturn nil, err","\t}","","\t// Generate public key fingerprint","\tsshpk, err := ssh.NewPublicKey(pub)","\tif err != nil {","\t\treturn nil, err","\t}","\tfingerprint := ssh.FingerprintSHA256(sshpk)","","\tadapter := sslAdapter{","\t\twrapped: s,","\t\tkeyID:   fingerprint,","\t\tpk:      sshpk,","\t}","","\tenvelope, err := dsse.NewEnvelopeSigner(\u0026adapter)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn \u0026sslSigner{","\t\twrapper: envelope,","\t\ttyp:     s.Type(),","\t\tpub:     pub,","\t\tcert:    s.Cert(),","\t\tchain:   s.Chain(),","\t}, nil","}","","// sslAdapter converts our signing objects into the type expected by the Envelope signer for wrapping.","type sslAdapter struct {","\twrapped Signer","\tkeyID   string","\tpk      crypto.PublicKey","}","","func (w *sslAdapter) Sign(ctx context.Context, data []byte) ([]byte, error) {","\tsig, err := w.wrapped.SignMessage(bytes.NewReader(data))","\treturn sig, err","}","","func (w *sslAdapter) KeyID() (string, error) {","\treturn w.keyID, nil","}","","func (w *sslAdapter) Public() crypto.PublicKey {","\treturn w.pk","}","","func (w *sslAdapter) Verify(_ context.Context, data, sig []byte) error {","\tpanic(\"unimplemented\")","}","","// sslSigner converts the EnvelopeSigners back into our types, after wrapping.","type sslSigner struct {","\twrapper *dsse.EnvelopeSigner","\ttyp     string","\tpub     crypto.PublicKey","\tcert    string","\tchain   string","}","","func (w *sslSigner) Type() string {","\treturn w.typ","}","func (w *sslSigner) PublicKey(opts ...signature.PublicKeyOption) (crypto.PublicKey, error) {","\treturn w.pub, nil","}","","func (w *sslSigner) Sign(ctx context.Context, payload []byte) ([]byte, []byte, error) {","\tenv, err := w.wrapper.SignPayload(ctx, in_toto.PayloadType, payload)","\tif err != nil {","\t\treturn nil, nil, err","\t}","\tb, err := json.Marshal(env)","\tif err != nil {","\t\treturn nil, nil, err","\t}","\treturn b, []byte(env.Payload), nil","}","","func (w *sslSigner) SignMessage(payload io.Reader, opts ...signature.SignOption) ([]byte, error) {","\tm, err := io.ReadAll(payload)","\tif err != nil {","\t\treturn nil, err","\t}","\tenv, err := w.wrapper.SignPayload(context.TODO(), in_toto.PayloadType, m)","\tif err != nil {","\t\treturn nil, err","\t}","\tb, err := json.Marshal(env)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn b, nil","}","","func (w *sslSigner) Cert() string {","\treturn w.cert","}","","func (w *sslSigner) Chain() string {","\treturn w.chain","}","","func (w *sslSigner) VerifySignature(signature, message io.Reader, opts ...signature.VerifyOption) error {","\treturn fmt.Errorf(\"not implemented\")","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,0,1,1,1,0,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,0,1,1,1]},{"id":33,"path":"pkg/chains/signing/x509/fsprovider.go","lines":["//","// Copyright 2023 The Sigstore Authors.","//","// Licensed under the Apache License, Version 2.0 (the \"License\");","// you may not use this file except in compliance with the License.","// You may obtain a copy of the License at","//","//     http://www.apache.org/licenses/LICENSE-2.0","//","// Unless required by applicable law or agreed to in writing, software","// distributed under the License is distributed on an \"AS IS\" BASIS,","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","// See the License for the specific language governing permissions and","// limitations under the License.","","package x509","","import (","\t\"context\"","\t\"os\"","","\t\"github.com/sigstore/cosign/v2/pkg/providers\"","\t\"github.com/sigstore/cosign/v2/pkg/providers/filesystem\"",")","","const (","\tfsCustomTokenPathProvider        = \"filesystem-custom-path\"","\tfsDefaultCosignTokenPathProvider = \"filesystem\"",")","","func init() {","\tproviders.Register(fsCustomTokenPathProvider, \u0026filesystemCustomPath{})","}","","type filesystemCustomPath struct{}","","var _ providers.Interface = (*filesystemCustomPath)(nil)","","var (","\t// FilesystemTokenPath is the path to where we read an OIDC","\t// token from the filesystem. This is the hard-coded value from cosign.","\t// If identity.token.file is configured, this variable will be updated to match.","\t// nolint","\tFilesystemTokenPath = filesystem.FilesystemTokenPath",")","","// Enabled implements providers.Interface","func (ga *filesystemCustomPath) Enabled(ctx context.Context) bool {","\t// If we can stat the file without error then this is enabled.","\t_, err := os.Stat(FilesystemTokenPath)","\treturn err == nil","}","","// Provide implements providers.Interface","func (ga *filesystemCustomPath) Provide(ctx context.Context, audience string) (string, error) {","\tb, err := os.ReadFile(FilesystemTokenPath)","\tif err != nil {","\t\treturn \"\", err","\t}","\treturn string(b), nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,2,2,2,1,1,2,0]},{"id":34,"path":"pkg/chains/signing/x509/x509.go","lines":["/*","Copyright 2020 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package x509","","import (","\t\"context\"","\t\"crypto\"","\t\"crypto/ecdsa\"","\tcx509 \"crypto/x509\"","\t\"encoding/json\"","\t\"encoding/pem\"","\t\"fmt\"","\t\"io\"","\t\"net/http\"","\t\"net/url\"","\t\"os\"","\t\"path/filepath\"","","\t\"github.com/pkg/errors\"","\t\"github.com/sigstore/cosign/v2/cmd/cosign/cli/fulcio\"","\t\"github.com/sigstore/cosign/v2/cmd/cosign/cli/options\"","\t\"github.com/sigstore/cosign/v2/pkg/cosign\"","\t\"github.com/sigstore/cosign/v2/pkg/providers\"","\t\"knative.dev/pkg/logging\"","","\t\"github.com/sigstore/sigstore/pkg/signature\"","\t\"github.com/sigstore/sigstore/pkg/tuf\"","\t\"github.com/tektoncd/chains/pkg/chains/signing\"","\t\"github.com/tektoncd/chains/pkg/config\"",")","","const (","\tdefaultOIDCClientID = \"sigstore\"",")","","// Signer exposes methods to sign payloads.","type Signer struct {","\tcert  string","\tchain string","\tsignature.SignerVerifier","}","","// NewSigner returns a configured Signer","func NewSigner(ctx context.Context, secretPath string, cfg config.Config) (*Signer, error) {","\tx509PrivateKeyPath := filepath.Join(secretPath, \"x509.pem\")","\tcosignPrivateKeypath := filepath.Join(secretPath, \"cosign.key\")","","\tif cfg.Signers.X509.FulcioEnabled {","\t\treturn fulcioSigner(ctx, cfg.Signers.X509)","\t} else if contents, err := os.ReadFile(x509PrivateKeyPath); err == nil {","\t\treturn x509Signer(ctx, contents)","\t} else if contents, err := os.ReadFile(cosignPrivateKeypath); err == nil {","\t\treturn cosignSigner(ctx, secretPath, contents)","\t}","\treturn nil, errors.New(\"no valid private key found, looked for: [x509.pem, cosign.key]\")","}","","func fulcioSigner(ctx context.Context, cfg config.X509Signer) (*Signer, error) {","\tlogger := logging.FromContext(ctx)","","\tprovidersEnabled := providers.Enabled(ctx)","","\tif cfg.IdentityTokenFile != \"\" {","\t\tFilesystemTokenPath = cfg.IdentityTokenFile","\t\tprovidersEnabled = true","\t}","\tif !providersEnabled {","\t\treturn nil, fmt.Errorf(\"no auth provider for fulcio is enabled\")","\t}","\tvar tok string","\tvar err error","\tif cfg.TUFMirrorURL != tuf.DefaultRemoteRoot {","\t\tif err = initializeTUF(ctx, cfg.TUFMirrorURL); err != nil {","\t\t\treturn nil, errors.Wrap(err, \"initialize tuf\")","\t\t}","\t}","","\tif cfg.IdentityTokenFile != \"\" {","\t\tswitch cfg.FulcioProvider {","\t\t// cosign providers package hardcodes the token path value","\t\t// \"filesystem-custom-path\" accepts a variable for the token path","\t\tcase fsDefaultCosignTokenPathProvider, \"\", fsCustomTokenPathProvider:","\t\t\tcfg.FulcioProvider = fsCustomTokenPathProvider","\t\t}","\t}","","\tif cfg.FulcioProvider != \"\" {","\t\tlogger.Infof(\"Attempting to get id token from provider %s\", cfg.FulcioProvider)","\t\tp, err := providers.ProvideFrom(ctx, cfg.FulcioProvider)","\t\tif err != nil {","\t\t\treturn nil, errors.Wrap(err, \"provide from\")","\t\t}","\t\ttok, err = p.Provide(ctx, defaultOIDCClientID)","\t\tif err != nil {","\t\t\treturn nil, errors.Wrapf(err, \"getting token from provider %s\", cfg.FulcioProvider)","\t\t}","\t} else {","\t\t// if FulcioProvider is not set, all will be tried","\t\ttok, err = providers.Provide(ctx, defaultOIDCClientID)","\t}","\tif err != nil {","\t\treturn nil, errors.Wrap(err, \"getting provider\")","\t}","","\tlogger.Info(\"Signing with fulcio ...\")","\tpriv, err := cosign.GeneratePrivateKey()","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"error generating keypair: %w\", err)","\t}","\tsigner, err := signature.LoadECDSASignerVerifier(priv, crypto.SHA256)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"error loading sigstore signer: %w\", err)","\t}","\tk, err := fulcio.NewSigner(ctx, options.KeyOpts{","\t\tFulcioURL:    cfg.FulcioAddr,","\t\tIDToken:      tok,","\t\tOIDCIssuer:   cfg.FulcioOIDCIssuer,","\t\tOIDCClientID: defaultOIDCClientID,","\t}, signer)","\tif err != nil {","\t\treturn nil, errors.Wrap(err, \"new signer\")","\t}","\treturn \u0026Signer{","\t\tSignerVerifier: signer,","\t\tcert:           string(k.Cert),","\t\tchain:          string(k.Chain),","\t}, nil","}","","// root: TUF_URL/root.json","// mirror: TUF_URL","func initializeTUF(ctx context.Context, mirror string) error {","\tlogger := logging.FromContext(ctx)","\t// Get the initial trusted root contents.","\troot, err := url.JoinPath(mirror, \"root.json\")","\tif err != nil {","\t\treturn err","\t}","\trootFileBytes, err := loadRootFromURL(root)","\tif err != nil {","\t\treturn err","\t}","\tif err = tuf.Initialize(ctx, mirror, rootFileBytes); err != nil {","\t\treturn err","\t}","\tstatus, err := tuf.GetRootStatus(ctx)","\tif err != nil {","\t\treturn err","\t}","\tb, err := json.MarshalIndent(status, \"\", \"\\t\")","\tif err != nil {","\t\treturn err","\t}","\tlogger.Infof(\"Root status: %s\", string(b))","\treturn nil","}","","func loadRootFromURL(root string) ([]byte, error) {","\tresp, err := http.Get(root)","\tif err != nil {","\t\treturn nil, err","\t}","\tdefer resp.Body.Close()","\treturn io.ReadAll(resp.Body)","}","","func x509Signer(ctx context.Context, privateKey []byte) (*Signer, error) {","\tlogger := logging.FromContext(ctx)","\tlogger.Info(\"Found x509 key...\")","","\tp, _ := pem.Decode(privateKey)","\tif p.Type != \"PRIVATE KEY\" {","\t\treturn nil, fmt.Errorf(\"expected private key, found object of type %s\", p.Type)","\t}","\tpk, err := cx509.ParsePKCS8PrivateKey(p.Bytes)","\tif err != nil {","\t\treturn nil, err","\t}","\tsigner, err := signature.LoadECDSASignerVerifier(pk.(*ecdsa.PrivateKey), crypto.SHA256)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn \u0026Signer{SignerVerifier: signer}, nil","}","","func cosignSigner(ctx context.Context, secretPath string, privateKey []byte) (*Signer, error) {","\tlogger := logging.FromContext(ctx)","\tlogger.Info(\"Found cosign key...\")","\tcosignPasswordPath := filepath.Join(secretPath, \"cosign.password\")","\tpassword, err := os.ReadFile(cosignPasswordPath)","\tif err != nil {","\t\treturn nil, errors.Wrap(err, \"reading cosign.password file\")","\t}","\tsigner, err := cosign.LoadPrivateKey(privateKey, password, nil)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn \u0026Signer{SignerVerifier: signer}, nil","}","","func (s *Signer) Type() string {","\treturn signing.TypeX509","}","","func (s *Signer) Cert() string {","\treturn s.cert","}","","// there is no cert or chain, return nothing","func (s *Signer) Chain() string {","\treturn s.chain","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,1,1,1,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,0,0,2,2,0,0,2,2,0,0,0,2,2,2,2,1,1,2,2,1,1,1,1,1,1,2,1,1,0,2,2,2,1,1,2,2,1,1,2,2,2,2,2,2,2,2,2,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,0,0,2,2,2,2,2,2,1,1,2,2,1,1,2,2,1,1,2,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,0,0,1,1,1]},{"id":35,"path":"pkg/chains/storage/archivista/archivista.go","lines":["/*","Copyright 2025 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package archivista","","import (","\t\"context\"","\t\"encoding/json\"","\t\"errors\"","\t\"fmt\"","\t\"net/http\"","\t\"strings\"","","\tarchivistaClient \"github.com/in-toto/archivista/pkg/http-client\"","\t\"github.com/in-toto/go-witness/dsse\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"github.com/tektoncd/chains/pkg/config\"","\t\"knative.dev/pkg/logging\"",")","","const (","\t// StorageBackendArchivista is the name of the Archivista storage backend","\tStorageBackendArchivista = \"archivista\"",")","","// Backend is a storage backend that is capable of storing Payloaders that are signed and wrapped","// with a DSSE envelope. Archivista is an in-toto attestation storage service.","type Backend struct {","\tclient *archivistaClient.ArchivistaClient","\turl    string","\tcfg    config.ArchivistaStorageConfig","}","","// NewStorageBackend returns a new Archivista StorageBackend that can store Payloaders that are signed","// and wrapped in a DSSE envelope","func NewStorageBackend(cfg config.Config) (*Backend, error) {","\tarchCfg := cfg.Storage.Archivista","\tif strings.TrimSpace(archCfg.URL) == \"\" {","\t\treturn nil, fmt.Errorf(\"missing archivista URL in storage configuration\")","\t}","","\tclient, err := archivistaClient.CreateArchivistaClient(\u0026http.Client{}, archCfg.URL)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"failed to create Archivista client: %w\", err)","\t}","","\treturn \u0026Backend{","\t\tclient: client,","\t\turl:    archCfg.URL,","\t\tcfg:    archCfg,","\t}, nil","}","","// StorePayload attempts to parse `signature` as a DSSE envelope, and if successful","// sends it to an Archivista server for storage.","func (b *Backend) StorePayload(ctx context.Context, _ objects.TektonObject, _ []byte, signature string, _ config.StorageOpts) error {","\tlogger := logging.FromContext(ctx)","\tvar env dsse.Envelope","\tif err := json.Unmarshal([]byte(signature), \u0026env); err != nil {","\t\tlogger.Errorf(\"Failed to parse DSSE envelope: %w\", err)","\t\treturn errors.Join(errors.New(\"Failed to parse DSSE envelope\"), err)","\t}","","\tuploadResp, err := b.client.Store(ctx, env)","\tif err != nil {","\t\tlogger.Errorw(\"Failed to upload DSSE envelope to Archivista\", \"error\", err)","\t\treturn err","\t}","\tlogger.Infof(\"Successfully uploaded DSSE envelope to Archivista, response: %+v\", uploadResp)","\treturn nil","}","","// RetrievePayload is not implemented for Archivista.","func (b *Backend) RetrievePayload(_ context.Context, _ string) ([]byte, []byte, error) {","\treturn nil, nil, fmt.Errorf(\"RetrievePayload not implemented for Archivista\")","}","","// RetrievePayloads is not implemented for Archivista.","func (b *Backend) RetrievePayloads(_ context.Context, _ objects.TektonObject, _ config.StorageOpts) (map[string]string, error) {","\treturn nil, fmt.Errorf(\"RetrievePayloads not implemented for Archivista\")","}","","// RetrieveSignatures is not implemented for Archivista.","func (b *Backend) RetrieveSignatures(_ context.Context, _ objects.TektonObject, _ config.StorageOpts) (map[string][]string, error) {","\treturn nil, fmt.Errorf(\"RetrieveSignatures not implemented for Archivista\")","}","","// Type returns the name of the storage backend","func (b *Backend) Type() string {","\treturn StorageBackendArchivista","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,1,1,0,2,2,1,1,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,0,2,2,1,1,1,2,2,0,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1]},{"id":36,"path":"pkg/chains/storage/docdb/docdb.go","lines":["/*","Copyright 2021 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package docdb","","import (","\t\"context\"","\t\"encoding/base64\"","\t\"encoding/json\"","\t\"fmt\"","\t\"net/url\"","\t\"os\"","\t\"path/filepath\"","\t\"strings\"","","\t\"github.com/fsnotify/fsnotify\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"github.com/tektoncd/chains/pkg/config\"","\t\"gocloud.dev/docstore\"","\t_ \"gocloud.dev/docstore/awsdynamodb\"","\t_ \"gocloud.dev/docstore/gcpfirestore\"","\t\"gocloud.dev/docstore/mongodocstore\"","\t_ \"gocloud.dev/docstore/mongodocstore\"","\t\"knative.dev/pkg/logging\"",")","","const (","\tStorageTypeDocDB = \"docdb\"","\tmongoEnv         = \"MONGO_SERVER_URL\"",")","","// ErrNothingToWatch is an error that's returned when the backend doesn't have anything to \"watch\"","var ErrNothingToWatch = fmt.Errorf(\"backend has nothing to watch\")","","// Backend is a storage backend that stores signed payloads in the TaskRun metadata as an annotation.","// It is stored as base64 encoded JSON.","type Backend struct {","\tcoll *docstore.Collection","}","","type SignedDocument struct {","\tSigned    []byte","\tSignature string","\tCert      string","\tChain     string","\tObject    interface{}","\tName      string","}","","// NewStorageBackend returns a new Tekton StorageBackend that stores signatures on a TaskRun","func NewStorageBackend(ctx context.Context, cfg config.Config) (*Backend, error) {","\tdocdbURL := cfg.Storage.DocDB.URL","","\tu, err := url.Parse(docdbURL)","\tif err != nil {","\t\treturn nil, err","\t}","","\tif u.Scheme == mongodocstore.Scheme {","\t\t// MONGO_SERVER_URL can be passed in as an environment variable or via config fields","\t\tif err := populateMongoServerURL(ctx, cfg); err != nil {","\t\t\treturn nil, err","\t\t}","\t}","","\tcoll, err := docstore.OpenCollection(ctx, docdbURL)","\tif err != nil {","\t\treturn nil, err","\t}","","\treturn \u0026Backend{","\t\tcoll: coll,","\t}, nil","}","","// WatchBackend returns a channel that receives a new Backend each time it needs to be updated","func WatchBackend(ctx context.Context, cfg config.Config, watcherStop chan bool) (chan *Backend, error) {","\tlogger := logging.FromContext(ctx)","\tdocDBURL := cfg.Storage.DocDB.URL","","\tu, err := url.Parse(docDBURL)","\tif err != nil {","\t\treturn nil, err","\t}","","\t// Set up the watcher only for mongo backends","\tif u.Scheme != mongodocstore.Scheme {","\t\treturn nil, ErrNothingToWatch","\t}","","\tpathsToWatch := getPathsToWatch(ctx, cfg)","\tif len(pathsToWatch) == 0 {","\t\treturn nil, ErrNothingToWatch","\t}","","\twatcher, err := fsnotify.NewWatcher()","\tif err != nil {","\t\treturn nil, err","\t}","","\tbackendChan := make(chan *Backend)","\t// Start listening for events.","\tgo func() {","\t\tfor {","\t\t\tselect {","\t\t\tcase event, ok := \u003c-watcher.Events:","\t\t\t\tif !ok {","\t\t\t\t\treturn","\t\t\t\t}","\t\t\t\tlogger.Infof(\"received event: %s, path: %s\", event.Op.String(), event.Name)","\t\t\t\t// Only respond to create/write/remove events in the directory","\t\t\t\tif !(event.Has(fsnotify.Create) || event.Has(fsnotify.Write) || event.Has(fsnotify.Remove)) {","\t\t\t\t\tcontinue","\t\t\t\t}","","\t\t\t\t// Checking if the event.name matches ANY of the pathsToWatch","\t\t\t\tmatched := false","\t\t\t\tfor _, p := range pathsToWatch {","\t\t\t\t\tif strings.HasPrefix(event.Name, p) {","\t\t\t\t\t\tmatched = true","\t\t\t\t\t\tbreak","\t\t\t\t\t}","\t\t\t\t}","\t\t\t\tif !matched {","\t\t\t\t\tcontinue","\t\t\t\t}","","\t\t\t\tvar updatedEnv string","\t\t\t\tif cfg.Storage.DocDB.MongoServerURLPath != \"\" {","\t\t\t\t\tupdatedEnv, err = getMongoServerURLFromPath(cfg.Storage.DocDB.MongoServerURLPath)","\t\t\t\t\tif err != nil {","\t\t\t\t\t\tlogger.Error(err)","\t\t\t\t\t\tbackendChan \u003c- nil","\t\t\t\t\t\tcontinue","\t\t\t\t\t}","\t\t\t\t} else if cfg.Storage.DocDB.MongoServerURLDir != \"\" {","\t\t\t\t\tupdatedEnv, err = getMongoServerURLFromDir(cfg.Storage.DocDB.MongoServerURLDir)","\t\t\t\t\tif err != nil {","\t\t\t\t\t\tlogger.Error(err)","\t\t\t\t\t\tbackendChan \u003c- nil","\t\t\t\t\t\tcontinue","\t\t\t\t\t}","\t\t\t\t}","","\t\t\t\tif updatedEnv != os.Getenv(\"MONGO_SERVER_URL\") {","\t\t\t\t\tlogger.Info(\"Mongo server url has been updated, reconfiguring backend...\")","","\t\t\t\t\t// Now that MONGO_SERVER_URL has been updated, we should update docdb backend again","\t\t\t\t\tnewDocDBBackend, err := NewStorageBackend(ctx, cfg)","\t\t\t\t\tif err != nil {","\t\t\t\t\t\tlogger.Error(err)","\t\t\t\t\t\tbackendChan \u003c- nil","\t\t\t\t\t} else {","\t\t\t\t\t\t// Storing the backend in the signer so everyone has access to the up-to-date backend","\t\t\t\t\t\tbackendChan \u003c- newDocDBBackend","\t\t\t\t\t}","\t\t\t\t} else {","\t\t\t\t\tlogger.Infof(\"MONGO_SERVER_URL has not changed in path: %s, backend will not be reconfigured\", cfg.Storage.DocDB.MongoServerURLDir)","\t\t\t\t}","","\t\t\tcase err, ok := \u003c-watcher.Errors:","\t\t\t\tif !ok {","\t\t\t\t\treturn","\t\t\t\t}","\t\t\t\tlogger.Error(err)","","\t\t\tcase \u003c-watcherStop:","\t\t\t\tlogger.Info(\"stopping fsnotify context...\")","\t\t\t\treturn","\t\t\t}","\t\t}","\t}()","","\tif cfg.Storage.DocDB.MongoServerURLPath != \"\" {","\t\tdirPath := filepath.Dir(cfg.Storage.DocDB.MongoServerURLPath)","\t\t// Add a path.","\t\terr = watcher.Add(dirPath)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t}","","\tif cfg.Storage.DocDB.MongoServerURLDir != \"\" {","\t\t// Add a path.","\t\terr = watcher.Add(cfg.Storage.DocDB.MongoServerURLDir)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t}","","\treturn backendChan, nil","}","","// StorePayload implements the Payloader interface.","func (b *Backend) StorePayload(ctx context.Context, _ objects.TektonObject, rawPayload []byte, signature string, opts config.StorageOpts) error {","\tvar obj interface{}","\tif err := json.Unmarshal(rawPayload, \u0026obj); err != nil {","\t\treturn err","\t}","","\tentry := SignedDocument{","\t\tSigned:    rawPayload,","\t\tSignature: base64.StdEncoding.EncodeToString([]byte(signature)),","\t\tObject:    obj,","\t\tName:      opts.ShortKey,","\t\tCert:      opts.Cert,","\t\tChain:     opts.Chain,","\t}","","\tif err := b.coll.Put(ctx, \u0026entry); err != nil {","\t\treturn err","\t}","","\treturn nil","}","","func (b *Backend) Type() string {","\treturn StorageTypeDocDB","}","","func (b *Backend) RetrieveSignatures(ctx context.Context, _ objects.TektonObject, opts config.StorageOpts) (map[string][]string, error) {","\t// Retrieve the document.","\tdocuments, err := b.retrieveDocuments(ctx, opts)","\tif err != nil {","\t\treturn nil, err","\t}","","\tm := make(map[string][]string)","\tfor _, d := range documents {","\t\t// Extract and decode the signature.","\t\tsig, err := base64.StdEncoding.DecodeString(d.Signature)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tm[d.Name] = []string{string(sig)}","\t}","\treturn m, nil","}","","func (b *Backend) RetrievePayloads(ctx context.Context, _ objects.TektonObject, opts config.StorageOpts) (map[string]string, error) {","\tdocuments, err := b.retrieveDocuments(ctx, opts)","\tif err != nil {","\t\treturn nil, err","\t}","","\tm := make(map[string]string)","\tfor _, d := range documents {","\t\tm[d.Name] = string(d.Signed)","\t}","","\treturn m, nil","}","","func (b *Backend) retrieveDocuments(ctx context.Context, opts config.StorageOpts) ([]SignedDocument, error) {","\td := SignedDocument{Name: opts.ShortKey}","\tif err := b.coll.Get(ctx, \u0026d); err != nil {","\t\treturn []SignedDocument{}, err","\t}","\treturn []SignedDocument{d}, nil","}","","func populateMongoServerURL(ctx context.Context, cfg config.Config) error {","\t// First preference is given to the key `storage.docdb.mongo-server-url-path`.","\t// If that doesn't exist, then we move on to `storage.docdb.mongo-server-url-dir`.","\t// If that doesn't exist, then we move on to `storage.docdb.mongo-server-url`.","\t// If that doesn't exist, then we check if `MONGO_SERVER_URL` env var is set.","\tlogger := logging.FromContext(ctx)","","\tif cfg.Storage.DocDB.MongoServerURLPath != \"\" {","\t\tlogger.Infof(\"setting %s from storage.docdb.mongo-server-url-path: %s\", mongoEnv, cfg.Storage.DocDB.MongoServerURLPath)","\t\tmongoServerURL, err := getMongoServerURLFromPath(cfg.Storage.DocDB.MongoServerURLPath)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tif err := os.Setenv(mongoEnv, mongoServerURL); err != nil {","\t\t\treturn err","\t\t}","\t\treturn nil","\t}","","\tif cfg.Storage.DocDB.MongoServerURLDir != \"\" {","\t\tlogger.Infof(\"setting %s from storage.docdb.mongo-server-url-dir: %s\", mongoEnv, cfg.Storage.DocDB.MongoServerURLDir)","\t\tif err := setMongoServerURLFromDir(cfg.Storage.DocDB.MongoServerURLDir); err != nil {","\t\t\treturn err","\t\t}","\t\treturn nil","\t}","","\tif cfg.Storage.DocDB.MongoServerURL != \"\" {","\t\tlogger.Infof(\"setting %s from storage.docdb.mongo-server-url\", mongoEnv)","\t\tif err := os.Setenv(mongoEnv, cfg.Storage.DocDB.MongoServerURL); err != nil {","\t\t\treturn err","\t\t}","\t\treturn nil","\t}","","\tif _, envExists := os.LookupEnv(mongoEnv); !envExists {","\t\treturn fmt.Errorf(\"mongo docstore configured but %s environment variable not set, \"+","\t\t\t\"supply one of storage.docdb.mongo-server-url-path, storage.docdb.mongo-server-url-dir, storage.docdb.mongo-server-url or set %s\", mongoEnv, mongoEnv)","\t}","","\treturn nil","}","","func setMongoServerURLFromDir(dir string) error {","\tfileDataNormalized, err := getMongoServerURLFromDir(dir)","\tif err != nil {","\t\treturn err","\t}","","\tif err = os.Setenv(mongoEnv, fileDataNormalized); err != nil {","\t\treturn err","\t}","","\treturn nil","}","","func getMongoServerURLFromDir(dir string) (string, error) {","\tstat, err := os.Stat(dir)","\tif err != nil {","\t\tif os.IsNotExist(err) {","\t\t\t// If directory does not exist, then create it. This is needed for","\t\t\t// the fsnotify watcher.","\t\t\t// fsnotify does not receive events if the path that it's watching","\t\t\t// is created later.","\t\t\tif err := os.MkdirAll(dir, 0755); err != nil {","\t\t\t\treturn \"\", err","\t\t\t}","\t\t\treturn \"\", nil","\t\t}","\t\treturn \"\", err","\t}","\t// If the path exists but is not a directory, then throw an error","\tif !stat.IsDir() {","\t\treturn \"\", fmt.Errorf(\"path specified at storage.docdb.mongo-server-url-dir: %s is not a directory\", dir)","\t}","","\tfilePath := filepath.Join(dir, mongoEnv)","\tfileData, err := os.ReadFile(filePath)","\tif err != nil {","\t\treturn \"\", err","\t}","\t// A trailing newline is fairly common in mounted files, let's remove it.","\tfileDataNormalized := strings.TrimSuffix(string(fileData), \"\\n\")","","\treturn fileDataNormalized, nil","}","","// getMongoServerURLFromPath retreives token from the given mount path","func getMongoServerURLFromPath(path string) (string, error) {","\tfileData, err := os.ReadFile(path)","\tif err != nil {","\t\treturn \"\", fmt.Errorf(\"reading file in %q: %w\", path, err)","\t}","","\t// A trailing newline is fairly common in mounted files, so remove it.","\tfileDataNormalized := strings.TrimSuffix(string(fileData), \"\\n\")","\treturn fileDataNormalized, nil","}","","func getPathsToWatch(ctx context.Context, cfg config.Config) []string {","\tvar pathsToWatch = []string{}","\tlogger := logging.FromContext(ctx)","","\tif cfg.Storage.DocDB.MongoServerURLPath != \"\" {","\t\tlogger.Infof(\"setting up fsnotify watcher for mongo server url path: %s\", cfg.Storage.DocDB.MongoServerURLPath)","\t\tdirPath := filepath.Dir(cfg.Storage.DocDB.MongoServerURLPath)","\t\tpathsToWatch = []string{","\t\t\t// mongo-server-url-path/\u003cpath\u003e is where the mongo server url token","\t\t\t// When a Kubernetes secret is mounted on a path, the `data` in that secret is mounted","\t\t\t// under path/..data that is then `symlink`ed to the key of the data. In this instance,","\t\t\t// the mounted path is going to look like:","\t\t\t// file 1 - ..2024_05_03_11_23_23.1253599725","\t\t\t// file 2 - ..data -\u003e ..2024_05_03_11_23_23.1253599725","\t\t\t// file 3 - ..data/\u003cpath\u003e","\t\t\t// So each time the secret is updated, the file is not updated,","\t\t\t// instead the underlying symlink at `..data` is updated and that's what we want to","\t\t\t// capture via the fsnotify event watcher","\t\t\t// filepath.Join(cfg.Storage.DocDB.MongoServerURLPath, \"..data\"),","\t\t\tfilepath.Join(dirPath, \"..data\"),","\t\t}","\t\treturn pathsToWatch","\t}","","\tif cfg.Storage.DocDB.MongoServerURLDir != \"\" {","\t\tlogger.Infof(\"setting up fsnotify watcher for directory: %s\", cfg.Storage.DocDB.MongoServerURLDir)","\t\tpathsToWatch = []string{","\t\t\t// mongo-server-url-dir/MONGO_SERVER_URL is where the MONGO_SERVER_URL environment","\t\t\t// variable is expected to be mounted, either manually or via a Kubernetes secret, etc.","\t\t\tfilepath.Join(cfg.Storage.DocDB.MongoServerURLDir, \"MONGO_SERVER_URL\"),","\t\t\t// When a Kubernetes secret is mounted on a path, the `data` in that secret is mounted","\t\t\t// under path/..data that is then `symlink`ed to the key of the data. In this instance,","\t\t\t// the mounted path is going to look like:","\t\t\t// file 1 - ..2024_05_03_11_23_23.1253599725","\t\t\t// file 2 - ..data -\u003e ..2024_05_03_11_23_23.1253599725","\t\t\t// file 3 - MONGO_SERVER_URL -\u003e ..data/MONGO_SERVER_URL","\t\t\t// So each time the secret is updated, the file `MONGO_SERVER_URL` is not updated,","\t\t\t// instead the underlying symlink at `..data` is updated and that's what we want to","\t\t\t// capture via the fsnotify event watcher","\t\t\tfilepath.Join(cfg.Storage.DocDB.MongoServerURLDir, \"..data\"),","\t\t}","\t\treturn pathsToWatch","\t}","","\treturn pathsToWatch","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,1,1,0,2,2,2,1,1,0,0,2,2,2,2,0,2,2,2,0,0,0,2,2,2,2,2,2,1,1,0,0,2,2,2,0,2,2,2,2,0,2,2,1,1,0,2,2,2,2,2,2,2,1,1,2,2,2,1,0,0,0,2,2,2,2,2,0,0,2,1,0,0,2,2,1,1,1,1,1,0,2,2,2,1,1,1,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,1,1,1,1,1,0,1,1,1,0,0,0,0,2,1,1,1,1,1,1,0,0,2,2,2,2,1,1,0,0,2,0,0,0,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,1,1,0,2,0,0,1,1,1,0,2,2,2,2,1,1,0,2,2,2,2,2,1,1,2,0,2,0,0,2,2,2,1,1,0,2,2,2,2,0,2,0,0,2,2,2,1,1,2,0,0,2,2,2,2,2,2,2,2,2,2,2,1,1,2,1,1,2,0,0,2,2,2,1,1,2,0,0,2,2,2,1,1,2,0,0,2,2,2,2,0,2,0,0,2,2,2,2,2,0,2,1,1,0,2,0,0,2,2,2,2,2,2,2,2,2,1,1,2,0,1,0,0,2,2,2,0,2,2,2,1,1,0,2,2,2,0,0,0,2,2,2,1,1,0,0,2,2,0,0,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0]},{"id":37,"path":"pkg/chains/storage/gcs/gcs.go","lines":["/*","Copyright 2020 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package gcs","","import (","\t\"context\"","\t\"fmt\"","\t\"io\"","","\t\"cloud.google.com/go/storage\"","\t\"knative.dev/pkg/logging\"","","\t\"github.com/in-toto/in-toto-golang/in_toto\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"github.com/tektoncd/chains/pkg/chains/signing\"","\t\"github.com/tektoncd/chains/pkg/chains/storage/api\"","\t\"github.com/tektoncd/chains/pkg/config\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"",")","","const (","\tStorageBackendGCS = \"gcs\"","\t// taskrun-$namespace-$name/$key.\u003ctype\u003e","\tSignatureNameFormatTaskRun = \"taskrun-%s-%s/%s.signature\"","\tPayloadNameFormatTaskRun   = \"taskrun-%s-%s/%s.payload\"","\t// pipelinerun-$namespace-$name/$key.\u003ctype\u003e","\tSignatureNameFormatPipelineRun = \"pipelinerun-%s-%s/%s.signature\"","\tPayloadNameFormatPipelineRun   = \"pipelinerun-%s-%s/%s.payload\"",")","","// Backend is a storage backend that stores signed payloads in the TaskRun metadata as an annotation.","// It is stored as base64 encoded JSON.","// Deprecated: Use TaskRunStorer instead.","type Backend struct {","\twriter gcsWriter","\treader gcsReader","\tcfg    config.Config","}","","// NewStorageBackend returns a new Tekton StorageBackend that stores signatures on a TaskRun","func NewStorageBackend(ctx context.Context, cfg config.Config) (*Backend, error) {","\tclient, err := storage.NewClient(ctx)","\tif err != nil {","\t\treturn nil, err","\t}","\tbucket := cfg.Storage.GCS.Bucket","\treturn \u0026Backend{","\t\twriter: \u0026writer{client: client, bucket: bucket},","\t\treader: \u0026reader{client: client, bucket: bucket},","\t\tcfg:    cfg,","\t}, nil","}","","// StorePayload implements the storage.Backend interface.","func (b *Backend) StorePayload(ctx context.Context, obj objects.TektonObject, rawPayload []byte, signature string, opts config.StorageOpts) error {","\tlogger := logging.FromContext(ctx)","","\tif tr, isTaskRun := obj.GetObject().(*v1.TaskRun); isTaskRun {","\t\tstore := \u0026TaskRunStorer{","\t\t\twriter: b.writer,","\t\t\tkey:    opts.ShortKey,","\t\t}","\t\tif _, err := store.Store(ctx, \u0026api.StoreRequest[*v1.TaskRun, *in_toto.Statement]{","\t\t\tObject:   obj,","\t\t\tArtifact: tr,","\t\t\t// We don't actually use payload - we store the raw bundle values directly.","\t\t\tPayload: nil,","\t\t\tBundle: \u0026signing.Bundle{","\t\t\t\tContent:   rawPayload,","\t\t\t\tSignature: []byte(signature),","\t\t\t\tCert:      []byte(opts.Cert),","\t\t\t\tChain:     []byte(opts.Chain),","\t\t\t},","\t\t}); err != nil {","\t\t\tlogger.Errorf(\"error writing to GCS: %w\", err)","\t\t\treturn err","\t\t}","\t} else if pr, isPipelineRun := obj.GetObject().(*v1.PipelineRun); isPipelineRun {","\t\tstore := \u0026PipelineRunStorer{","\t\t\twriter: b.writer,","\t\t\tkey:    opts.ShortKey,","\t\t}","\t\tif _, err := store.Store(ctx, \u0026api.StoreRequest[*v1.PipelineRun, *in_toto.Statement]{ //nolint:staticcheck","\t\t\tObject:   obj,","\t\t\tArtifact: pr,","\t\t\t// We don't actually use payload - we store the raw bundle values directly.","\t\t\tPayload: nil,","\t\t\tBundle: \u0026signing.Bundle{","\t\t\t\tContent:   rawPayload,","\t\t\t\tSignature: []byte(signature),","\t\t\t\tCert:      []byte(opts.Cert),","\t\t\t\tChain:     []byte(opts.Chain),","\t\t\t},","\t\t}); err != nil {","\t\t\tlogger.Errorf(\"error writing to GCS: %w\", err)","\t\t\treturn err","\t\t}","\t} else {","\t\treturn fmt.Errorf(\"type %T not supported - supported types: [*v1.TaskRun, *v1.PipelineRun]\", obj.GetObject())","\t}","\treturn nil","}","","func (b *Backend) Type() string {","\treturn StorageBackendGCS","}","","type gcsWriter interface {","\tGetWriter(ctx context.Context, object string) io.WriteCloser","}","","type writer struct {","\tclient *storage.Client","\tbucket string","}","","type gcsReader interface {","\tGetReader(ctx context.Context, object string) (io.ReadCloser, error)","}","","type reader struct {","\tclient *storage.Client","\tbucket string","}","","func (r *writer) GetWriter(ctx context.Context, object string) io.WriteCloser {","\treturn r.client.Bucket(r.bucket).Object(object).NewWriter(ctx)","}","","func (r *reader) GetReader(ctx context.Context, object string) (io.ReadCloser, error) {","\treturn r.client.Bucket(r.bucket).Object(object).NewReader(ctx)","}","","func (b *Backend) RetrieveSignatures(ctx context.Context, obj objects.TektonObject, opts config.StorageOpts) (map[string][]string, error) {","\tvar object string","","\tswitch t := obj.GetObject().(type) {","\tcase *v1.TaskRun:","\t\tobject = taskRunSigNameV1(t, opts)","\tcase *v1.PipelineRun:","\t\tobject = pipelineRunSignameV1(t, opts)","\tdefault:","\t\treturn nil, fmt.Errorf(\"unsupported TektonObject type: %T\", t)","\t}","","\tsignature, err := b.retrieveObject(ctx, object)","\tif err != nil {","\t\treturn nil, err","\t}","","\tm := make(map[string][]string)","\tm[object] = []string{signature}","\treturn m, nil","}","","func (b *Backend) RetrievePayloads(ctx context.Context, obj objects.TektonObject, opts config.StorageOpts) (map[string]string, error) {","\tvar object string","","\tswitch t := obj.GetObject().(type) {","\tcase *v1.TaskRun:","\t\tobject = taskRunPayloadNameV1(t, opts)","\tcase *v1.PipelineRun:","\t\tobject = pipelineRunPayloadNameV1(t, opts)","\tdefault:","\t\treturn nil, fmt.Errorf(\"unsupported TektonObject type: %T\", t)","\t}","","\tpayload, err := b.retrieveObject(ctx, object)","\tif err != nil {","\t\treturn nil, err","\t}","","\tm := make(map[string]string)","\tm[object] = payload","\treturn m, nil","}","","func (b *Backend) retrieveObject(ctx context.Context, object string) (string, error) {","\treader, err := b.reader.GetReader(ctx, object)","\tif err != nil {","\t\treturn \"\", err","\t}","","\tdefer reader.Close()","\tpayload, err := io.ReadAll(reader)","\tif err != nil {","\t\treturn \"\", err","\t}","\treturn string(payload), nil","}","","func taskRunSigNameV1(tr *v1.TaskRun, opts config.StorageOpts) string {","\treturn fmt.Sprintf(SignatureNameFormatTaskRun, tr.Namespace, tr.Name, opts.ShortKey)","}","","func taskRunPayloadNameV1(tr *v1.TaskRun, opts config.StorageOpts) string {","\treturn fmt.Sprintf(PayloadNameFormatTaskRun, tr.Namespace, tr.Name, opts.ShortKey)","}","","func pipelineRunSignameV1(pr *v1.PipelineRun, opts config.StorageOpts) string {","\treturn fmt.Sprintf(SignatureNameFormatPipelineRun, pr.Namespace, pr.Name, opts.ShortKey)","}","","func pipelineRunPayloadNameV1(pr *v1.PipelineRun, opts config.StorageOpts) string {","\treturn fmt.Sprintf(PayloadNameFormatPipelineRun, pr.Namespace, pr.Name, opts.ShortKey)","}","","//nolint:staticcheck","var (","\t_ api.Storer[*v1.TaskRun, *in_toto.Statement]     = \u0026TaskRunStorer{}","\t_ api.Storer[*v1.PipelineRun, *in_toto.Statement] = \u0026PipelineRunStorer{}",")","","// TaskRunStorer stores TaskRuns in GCS.","type TaskRunStorer struct {","\twriter gcsWriter","","\t// Optional key to store objects as. If not set, the object UID will be used.","\t// The resulting name will look like: $bucket/taskrun-$namespace-$name/$key.signature","\tkey string","}","","// Store stores the TaskRun chains information in GCS","//","//nolint:staticcheck","func (s *TaskRunStorer) Store(ctx context.Context, req *api.StoreRequest[*v1.TaskRun, *in_toto.Statement]) (*api.StoreResponse, error) {","\ttr := req.Artifact","\tkey := s.key","\tif key == \"\" {","\t\tkey = string(tr.GetUID())","\t}","\tprefix := fmt.Sprintf(\"%s-%s-%s/%s\", \"taskrun\", tr.GetNamespace(), tr.GetName(), key)","","\treturn store(ctx, s.writer, prefix,","\t\treq.Bundle.Signature, req.Bundle.Content, req.Bundle.Cert, req.Bundle.Chain)","}","","// PipelineRunStorer stores PipelineRuns in GCS.","type PipelineRunStorer struct {","\twriter gcsWriter","","\t// Optional key to store objects as. If not set, the object UID will be used.","\t// The resulting name will look like: $bucket/pipelinerun-$namespace-$name/$key.signature","\tkey string","}","","// Store stores the PipelineRun chains information in GCS","//","//nolint:staticcheck","func (s *PipelineRunStorer) Store(ctx context.Context, req *api.StoreRequest[*v1.PipelineRun, *in_toto.Statement]) (*api.StoreResponse, error) {","\tpr := req.Artifact","\tkey := s.key","\tif key == \"\" {","\t\tkey = string(pr.GetUID())","\t}","\tprefix := fmt.Sprintf(\"%s-%s-%s/%s\", \"pipelinerun\", pr.GetNamespace(), pr.GetName(), key)","","\treturn store(ctx, s.writer, prefix,","\t\treq.Bundle.Signature, req.Bundle.Content, req.Bundle.Cert, req.Bundle.Chain)","}","","func store(ctx context.Context, writer gcsWriter, prefix string,","\tsignature, content, cert, chain []byte) (*api.StoreResponse, error) {","\tlogger := logging.FromContext(ctx)","","\t// Write signature","\tsigName := prefix + \".signature\"","\tlogger.Infof(\"Storing signature at %s\", sigName)","\tif _, err := write(ctx, writer, sigName, signature); err != nil {","\t\treturn nil, err","\t}","","\t// Write payload","\tpayloadName := prefix + \".payload\"","\tif _, err := write(ctx, writer, payloadName, content); err != nil {","\t\treturn nil, err","\t}","","\t// Only write cert+chain if it is present.","\tif cert == nil {","\t\treturn nil, nil","\t}","\tcertName := prefix + \".cert\"","\tif _, err := write(ctx, writer, certName, cert); err != nil {","\t\treturn nil, err","\t}","","\tchainName := prefix + \".chain\"","\tif _, err := write(ctx, writer, chainName, chain); err != nil {","\t\treturn nil, err","\t}","","\treturn \u0026api.StoreResponse{}, nil","}","","func write(ctx context.Context, client gcsWriter, name string, content []byte) (int, error) {","\tw := client.GetWriter(ctx, name)","\tdefer w.Close()","\treturn w.Write(content)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,2,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,1,1,1,0,2,2,2,2,2,2,2,2,1,1,0,0,2,2,1,1,0,2,2,2,0,0,2,2,2,2,2,2,2,2,1,1,0,0,2,2,1,1,0,2,2,2,0,0,2,2,2,1,1,0,2,2,2,1,1,2,0,0,2,2,2,0,2,2,2,0,2,2,2,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,1,1,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,1,1,2,2,2,2,0,0,0,2,2,2,2,2,2,2,1,1,0,0,2,2,1,1,0,0,2,1,1,2,2,1,1,0,2,2,1,1,0,2,0,0,2,2,2,2,2]},{"id":38,"path":"pkg/chains/storage/grafeas/grafeas.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package grafeas","","import (","\t\"context\"","\t\"crypto/tls\"","\t\"encoding/json\"","\t\"fmt\"","\t\"strings\"","","\tgrafeasutil \"github.com/grafeas/grafeas/go/utils/intoto\"","\tpb \"github.com/grafeas/grafeas/proto/v1/grafeas_go_proto\"","\tintoto \"github.com/in-toto/in-toto-golang/in_toto\"","\t\"github.com/pkg/errors\"","\t\"github.com/sigstore/cosign/v2/pkg/types\"","\t\"github.com/tektoncd/chains/pkg/chains/formats\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/slsa/extract\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"github.com/tektoncd/chains/pkg/config\"","\t\"google.golang.org/grpc\"","\t\"google.golang.org/grpc/codes\"","\t\"google.golang.org/grpc/credentials\"","\t\"google.golang.org/grpc/credentials/oauth\"","\t\"google.golang.org/grpc/status\"","\t\"knative.dev/pkg/logging\"",")","","const (","\tStorageBackendGrafeas     = \"grafeas\"","\tprojectPathFormat         = \"projects/%s\"","\tnotePathFormat            = \"projects/%s/notes/%s\"","\tattestationNoteNameFormat = \"%s-simplesigning\"","\tbuildNoteNameFormat       = \"%s-%s-intoto\"",")","","// Backend is a storage backend that stores signed payloads in the storage that","// is built on the top of grafeas i.e. container analysis.","type Backend struct {","\tclient pb.GrafeasClient","\tcfg    config.Config","}","","// NewStorageBackend returns a new Grafeas StorageBackend that stores signatures in a Grafeas server","func NewStorageBackend(ctx context.Context, cfg config.Config) (*Backend, error) {","\t// build connection through grpc","\t// implicit uses Application Default Credentials to authenticate.","\t// Requires `gcloud auth application-default login` to work locally","\tcreds, err := oauth.NewApplicationDefault(ctx, \"https://www.googleapis.com/auth/cloud-platform\")","\tif err != nil {","\t\treturn nil, err","\t}","","\t// TODO: make grafeas server configurable including checking if hostname is trusted","\tserver := \"dns:///containeranalysis.googleapis.com\"","","\tconn, err := grpc.Dial(server,","\t\tgrpc.WithTransportCredentials(credentials.NewTLS(\u0026tls.Config{})),","\t\tgrpc.WithDefaultCallOptions(grpc.PerRPCCredentials(creds)),","\t)","\tif err != nil {","\t\treturn nil, err","\t}","","\t// connection client","\tclient := pb.NewGrafeasClient(conn)","","\t// create backend instance","\treturn \u0026Backend{","\t\tclient: client,","\t\tcfg:    cfg,","\t}, nil","}","","// StorePayload implements the storage.Backend interface.","func (b *Backend) StorePayload(ctx context.Context, obj objects.TektonObject, rawPayload []byte, signature string, opts config.StorageOpts) error {","\tlogger := logging.FromContext(ctx)","\t// We only support simplesigning for OCI images, and in-toto for taskrun \u0026 pipelinerun.","\tif _, ok := formats.IntotoAttestationSet[opts.PayloadFormat]; !ok \u0026\u0026 opts.PayloadFormat != formats.PayloadTypeSimpleSigning {","\t\treturn errors.New(\"Grafeas storage backend only supports simplesigning and intoto payload format.\")","\t}","","\t// Check if projectID is configured. If not, stop and return an error","\tif b.cfg.Storage.Grafeas.ProjectID == \"\" {","\t\treturn errors.New(\"Project ID must be configured!\")","\t}","","\t// check if noteID is configured. If not, we give it a name as `tekton-\u003cnamespace\u003e`","\tif b.cfg.Storage.Grafeas.NoteID == \"\" {","\t\tgeneratedNoteID := fmt.Sprintf(\"tekton-%s\", obj.GetNamespace())","\t\tb.cfg.Storage.Grafeas.NoteID = generatedNoteID","\t}","","\t// step1: create note","\t// If the note already exists, just move to the next step of creating occurrence.","\tif _, err := b.createNote(ctx, obj, opts); err != nil \u0026\u0026 status.Code(err) != codes.AlreadyExists {","\t\treturn err","\t}","","\t// step2: create occurrences","\toccurrences, err := b.createOccurrence(ctx, obj, rawPayload, signature, opts)","\tif err != nil {","\t\treturn err","\t}","","\toccNames := []string{}","\tfor _, occ := range occurrences {","\t\toccNames = append(occNames, occ.GetName())","\t}","","\tif len(occNames) == 0 {","\t\tlogger.Infof(\"No occurrences created for payload of type %s for %s %s/%s\", string(opts.PayloadFormat), obj.GetGVK(), obj.GetNamespace(), obj.GetName())","\t} else {","\t\tlogger.Infof(\"Successfully created grafeas occurrences %v for %s %s/%s\", occNames, obj.GetGVK(), obj.GetNamespace(), obj.GetName())","\t}","","\treturn nil","}","","// Retrieve payloads from grafeas server and store it in a map","func (b *Backend) RetrievePayloads(ctx context.Context, obj objects.TektonObject, opts config.StorageOpts) (map[string]string, error) {","\t// initialize an empty map for result","\tresult := make(map[string]string)","","\t// get all occurrences created using this backend","\toccurrences, err := b.getAllOccurrences(ctx, obj, opts)","\tif err != nil {","\t\treturn nil, err","\t}","","\tfor _, occ := range occurrences {","\t\t// get payload identifier","\t\tname := occ.GetResourceUri()","","\t\t// get \"Payload\" field from the occurrence","\t\tpayload := occ.GetEnvelope().GetPayload()","","\t\tresult[name] = string(payload)","\t}","","\treturn result, nil","}","","// Retrieve signatures from grafeas server and store it in a map","func (b *Backend) RetrieveSignatures(ctx context.Context, obj objects.TektonObject, opts config.StorageOpts) (map[string][]string, error) {","\t// initialize an empty map for result","\tresult := make(map[string][]string)","","\t// get all occurrences created using this backend","\toccurrences, err := b.getAllOccurrences(ctx, obj, opts)","\tif err != nil {","\t\treturn nil, err","\t}","","\tfor _, occ := range occurrences {","\t\t// get the Signature identifier","\t\tname := occ.GetResourceUri()","","\t\t// get \"Signatures\" field from the occurrence","\t\tsignatures := occ.GetEnvelope().GetSignatures()","\t\t// signature string","\t\tsigStrings := []string{}","\t\tfor _, sig := range signatures {","\t\t\tsigStrings = append(sigStrings, string(sig.GetSig()))","\t\t}","","\t\tresult[name] = sigStrings","\t}","","\treturn result, nil","}","","func (b *Backend) Type() string {","\treturn StorageBackendGrafeas","}","","// ----------------------------- Helper Functions ----------------------------","// createNote creates grafeas note that will be linked to grafeas occurrences","func (b *Backend) createNote(ctx context.Context, obj objects.TektonObject, opts config.StorageOpts) (*pb.Note, error) {","\tnotePrefix := b.cfg.Storage.Grafeas.NoteID","","\t// for oci image: AttestationNote","\tif opts.PayloadFormat == formats.PayloadTypeSimpleSigning {","\t\treturn b.client.CreateNote(ctx,","\t\t\t\u0026pb.CreateNoteRequest{","\t\t\t\tParent: b.getProjectPath(),","\t\t\t\tNoteId: fmt.Sprintf(attestationNoteNameFormat, b.cfg.Storage.Grafeas.NoteID),","\t\t\t\tNote: \u0026pb.Note{","\t\t\t\t\tShortDescription: \"OCI Artifact Attestation Note\",","\t\t\t\t\tType: \u0026pb.Note_Attestation{","\t\t\t\t\t\tAttestation: \u0026pb.AttestationNote{","\t\t\t\t\t\t\tHint: \u0026pb.AttestationNote_Hint{","\t\t\t\t\t\t\t\tHumanReadableName: b.cfg.Storage.Grafeas.NoteHint,","\t\t\t\t\t\t\t},","\t\t\t\t\t\t},","\t\t\t\t\t},","\t\t\t\t},","\t\t\t},","\t\t)","\t}","","\treturn b.createBuildNote(ctx, fmt.Sprintf(buildNoteNameFormat, notePrefix, obj.GetKindName()), obj)","}","","func (b *Backend) createBuildNote(ctx context.Context, noteid string, obj objects.TektonObject) (*pb.Note, error) {","\treturn b.client.CreateNote(ctx,","\t\t\u0026pb.CreateNoteRequest{","\t\t\tParent: b.getProjectPath(),","\t\t\tNoteId: noteid,","\t\t\tNote: \u0026pb.Note{","\t\t\t\tShortDescription: \"Build Provenance Note for TaskRun\",","\t\t\t\tType: \u0026pb.Note_Build{","\t\t\t\t\tBuild: \u0026pb.BuildNote{","\t\t\t\t\t\tBuilderVersion: obj.GetGVK(),","\t\t\t\t\t},","\t\t\t\t},","\t\t\t},","\t\t},","\t)","}","","// createOccurrence creates grafeas occurrences in the grafeas server that stores the original payload and its signature","// for a single oci artifact","//   - its simplesigning payload and signature will be stored in ATTESTATION occurrence","//   - the identifier/ResourceUri is IMAGE_URL@IMAGE_DIGEST","//","// for a taskrun/pipelinerun object","//   - its intoto payload and signature will be stored in a BUILD occurrences for each image artifact generated from the taskrun/pipelinerun","//   - each BUILD occurrence will have the same data but differ in the ResourceUri field","//   - the identifier/ResourceUri is IMAGE_URL@IMAGE_DIGEST","func (b *Backend) createOccurrence(ctx context.Context, obj objects.TektonObject, payload []byte, signature string, opts config.StorageOpts) ([]*pb.Occurrence, error) {","\toccs := []*pb.Occurrence{}","","\t// create Occurrence_Attestation for OCI","\tif opts.PayloadFormat == formats.PayloadTypeSimpleSigning {","\t\tocc, err := b.createAttestationOccurrence(ctx, payload, signature, opts.FullKey)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\toccs = append(occs, occ)","\t\treturn occs, nil","\t}","","\t// create Occurrence_Build for TaskRun","\tallURIs := b.getAllArtifactURIs(ctx, opts.PayloadFormat, obj)","\tfor _, uri := range allURIs {","\t\tocc, err := b.createBuildOccurrence(ctx, obj, payload, signature, uri)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\toccs = append(occs, occ)","\t}","\treturn occs, nil","}","","func (b *Backend) getAllArtifactURIs(ctx context.Context, payloadFormat config.PayloadType, obj objects.TektonObject) []string {","\tlogger := logging.FromContext(ctx)","\tpayloader, err := formats.GetPayloader(payloadFormat, b.cfg)","\tif err != nil {","\t\tlogger.Infof(\"couldn't get payloader for %v format, will use extract.RetrieveAllArtifactURIs method instead\", payloadFormat)","\t\treturn extract.RetrieveAllArtifactURIs(ctx, obj, b.cfg.Artifacts.PipelineRuns.DeepInspectionEnabled)","\t}","","\tif uris, err := payloader.RetrieveAllArtifactURIs(ctx, obj); err == nil {","\t\treturn uris","\t}","","\tlogger.Infof(\"couldn't get URIs from payloader %v, will use extract.RetrieveAllArtifactURIs method instead\", payloadFormat)","\treturn extract.RetrieveAllArtifactURIs(ctx, obj, b.cfg.Artifacts.PipelineRuns.DeepInspectionEnabled)","}","","func (b *Backend) createAttestationOccurrence(ctx context.Context, payload []byte, signature string, uri string) (*pb.Occurrence, error) {","\toccurrenceDetails := \u0026pb.Occurrence_Attestation{","\t\tAttestation: \u0026pb.AttestationOccurrence{","\t\t\tSerializedPayload: payload,","\t\t\tSignatures: []*pb.Signature{","\t\t\t\t{","\t\t\t\t\tSignature: []byte(signature),","\t\t\t\t\t// TODO (#471): currently we only support storing KMS keyID, may add other keys' ids later i.e. k8s secret, fulcio","\t\t\t\t\tPublicKeyId: b.cfg.Signers.KMS.KMSRef,","\t\t\t\t},","\t\t\t},","\t\t},","\t}","\tenvelope := \u0026pb.Envelope{","\t\tPayload:     payload,","\t\tPayloadType: types.SimpleSigningMediaType,","\t\tSignatures: []*pb.EnvelopeSignature{","\t\t\t{","\t\t\t\tSig: []byte(signature),","\t\t\t\t// TODO (#471): currently we only support storing KMS keyID, may add other keys' ids later i.e. k8s secret, fulcio","\t\t\t\tKeyid: b.cfg.Signers.KMS.KMSRef,","\t\t\t},","\t\t},","\t}","","\treturn b.client.CreateOccurrence(ctx,","\t\t\u0026pb.CreateOccurrenceRequest{","\t\t\tParent: b.getProjectPath(),","\t\t\tOccurrence: \u0026pb.Occurrence{","\t\t\t\tResourceUri: uri,","\t\t\t\tNoteName:    b.getAttestationNotePath(),","\t\t\t\tDetails:     occurrenceDetails,","\t\t\t\tEnvelope:    envelope,","\t\t\t},","\t\t},","\t)","}","","func (b *Backend) createBuildOccurrence(ctx context.Context, obj objects.TektonObject, payload []byte, signature string, uri string) (*pb.Occurrence, error) {","\tin := intoto.ProvenanceStatement{}","\tif err := json.Unmarshal(payload, \u0026in); err != nil {","\t\treturn nil, err","\t}","","\tpbf, err := grafeasutil.ToProto(\u0026in)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"Unable to convert to Grafeas proto: %w\", err)","\t}","","\toccurrenceDetails := \u0026pb.Occurrence_Build{","\t\tBuild: \u0026pb.BuildOccurrence{","\t\t\tIntotoStatement: pbf,","\t\t},","\t}","","\tenvelope := \u0026pb.Envelope{","\t\tPayload:     payload,","\t\tPayloadType: types.IntotoPayloadType,","\t\tSignatures: []*pb.EnvelopeSignature{","\t\t\t{","\t\t\t\tSig:   []byte(signature),","\t\t\t\tKeyid: b.cfg.Signers.KMS.KMSRef,","\t\t\t},","\t\t},","\t}","","\treturn b.client.CreateOccurrence(ctx,","\t\t\u0026pb.CreateOccurrenceRequest{","\t\t\tParent: b.getProjectPath(),","\t\t\tOccurrence: \u0026pb.Occurrence{","\t\t\t\tResourceUri: uri,","\t\t\t\tNoteName:    b.getBuildNotePath(obj),","\t\t\t\tDetails:     occurrenceDetails,","\t\t\t\tEnvelope:    envelope,","\t\t\t},","\t\t},","\t)","}","","func (b *Backend) getProjectPath() string {","\tprojectID := b.cfg.Storage.Grafeas.ProjectID","\treturn fmt.Sprintf(projectPathFormat, projectID)","}","","func (b *Backend) getAttestationNotePath() string {","\tprojectID := b.cfg.Storage.Grafeas.ProjectID","\tnoteID := b.cfg.Storage.Grafeas.NoteID","\treturn fmt.Sprintf(notePathFormat, projectID, fmt.Sprintf(attestationNoteNameFormat, noteID))","}","","func (b *Backend) getBuildNotePath(obj objects.TektonObject) string {","\tprojectID := b.cfg.Storage.Grafeas.ProjectID","\tnoteID := b.cfg.Storage.Grafeas.NoteID","\treturn fmt.Sprintf(notePathFormat, projectID, fmt.Sprintf(buildNoteNameFormat, noteID, obj.GetKindName()))","}","","// getAllOccurrences retrieves back all occurrences created for a taskrun","func (b *Backend) getAllOccurrences(ctx context.Context, obj objects.TektonObject, opts config.StorageOpts) ([]*pb.Occurrence, error) {","\tresult := []*pb.Occurrence{}","\t// step 1: get all resource URIs created under the taskrun","\turiFilters := b.getAllArtifactURIs(ctx, opts.PayloadFormat, obj)","","\t// step 2: find all build occurrences","\tif _, ok := formats.IntotoAttestationSet[opts.PayloadFormat]; ok {","\t\toccs, err := b.findOccurrencesForCriteria(ctx, b.getBuildNotePath(obj), uriFilters)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tresult = append(result, occs...)","\t}","","\t// step 3: find all attestation occurrences","\tif opts.PayloadFormat == formats.PayloadTypeSimpleSigning {","\t\toccs, err := b.findOccurrencesForCriteria(ctx, b.getAttestationNotePath(), uriFilters)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tresult = append(result, occs...)","\t}","","\treturn result, nil","}","","// findOccurrencesForCriteria lookups a project's occurrences by the resource uri","func (b *Backend) findOccurrencesForCriteria(ctx context.Context, noteName string, resourceURIs []string) ([]*pb.Occurrence, error) {","","\tvar uriFilters []string","\tfor _, url := range resourceURIs {","\t\turiFilters = append(uriFilters, fmt.Sprintf(\"resourceUrl=%q\", url))","\t}","","\toccurences, err := b.client.ListNoteOccurrences(ctx,","\t\t\u0026pb.ListNoteOccurrencesRequest{","\t\t\tName:   noteName,","\t\t\tFilter: strings.Join(uriFilters, \" OR \"),","\t\t},","\t)","","\tif err != nil {","\t\treturn nil, err","\t}","\treturn occurences.GetOccurrences(), nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,0,0,0,2,2,2,2,2,2,0,0,2,1,1,0,0,2,1,1,1,0,0,0,2,1,1,0,0,2,2,1,1,0,2,2,2,2,0,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,2,0,0,1,1,1,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,1,1,2,2,0,0,0,2,2,2,2,1,1,2,0,2,0,0,2,2,2,2,1,1,1,0,2,2,2,0,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,1,1,0,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,1,1,2,0,0,0,2,2,2,1,1,2,0,0,2,0,0,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,1,1,2,0]},{"id":39,"path":"pkg/chains/storage/oci/attestation.go","lines":["// Copyright 2023 The Tekton Authors","//","// Licensed under the Apache License, Version 2.0 (the \"License\");","// you may not use this file except in compliance with the License.","// You may obtain a copy of the License at","//","//      http://www.apache.org/licenses/LICENSE-2.0","//","// Unless required by applicable law or agreed to in writing, software","// distributed under the License is distributed on an \"AS IS\" BASIS,","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","// See the License for the specific language governing permissions and","// limitations under the License.","","package oci","","import (","\t\"context\"","","\t\"github.com/google/go-containerregistry/pkg/name\"","\t\"github.com/google/go-containerregistry/pkg/v1/remote\"","\tintoto \"github.com/in-toto/attestation/go/v1\"","\t\"github.com/pkg/errors\"","\t\"github.com/sigstore/cosign/v2/pkg/oci/mutate\"","\tociremote \"github.com/sigstore/cosign/v2/pkg/oci/remote\"","\t\"github.com/sigstore/cosign/v2/pkg/oci/static\"","\t\"github.com/sigstore/cosign/v2/pkg/types\"","\t\"github.com/tektoncd/chains/pkg/chains/storage/api\"","\t\"knative.dev/pkg/logging\"",")","","var (","\t_ api.Storer[name.Digest, *intoto.Statement] = \u0026AttestationStorer{}",")","","// AttestationStorer stores in-toto Attestation payloads in OCI registries.","type AttestationStorer struct {","\t// repo configures the repo where data should be stored.","\t// If empty, the repo is inferred from the Artifact.","\trepo *name.Repository","\t// remoteOpts are additional remote options (i.e. auth) to use for client operations.","\tremoteOpts []remote.Option","}","","func NewAttestationStorer(opts ...AttestationStorerOption) (*AttestationStorer, error) {","\ts := \u0026AttestationStorer{}","\tfor _, o := range opts {","\t\tif err := o.applyAttestationStorer(s); err != nil {","\t\t\treturn nil, err","\t\t}","\t}","\treturn s, nil","}","","// Store saves the given statement.","func (s *AttestationStorer) Store(ctx context.Context, req *api.StoreRequest[name.Digest, *intoto.Statement]) (*api.StoreResponse, error) {","\tlogger := logging.FromContext(ctx)","","\trepo := req.Artifact.Repository","\tif s.repo != nil {","\t\trepo = *s.repo","\t}","\tse, err := ociremote.SignedEntity(req.Artifact, ociremote.WithRemoteOptions(s.remoteOpts...))","\tvar entityNotFoundError *ociremote.EntityNotFoundError","\tif errors.As(err, \u0026entityNotFoundError) {","\t\tse = ociremote.SignedUnknown(req.Artifact, ociremote.WithRemoteOptions(s.remoteOpts...))","\t} else if err != nil {","\t\treturn nil, errors.Wrap(err, \"getting signed image\")","\t}","","\t// Create the new attestation for this entity.","\tattOpts := []static.Option{static.WithLayerMediaType(types.DssePayloadType)}","\tif req.Bundle.Cert != nil {","\t\tattOpts = append(attOpts, static.WithCertChain(req.Bundle.Cert, req.Bundle.Chain))","\t}","\tatt, err := static.NewAttestation(req.Bundle.Signature, attOpts...)","\tif err != nil {","\t\treturn nil, err","\t}","\tnewImage, err := mutate.AttachAttestationToEntity(se, att)","\tif err != nil {","\t\treturn nil, err","\t}","","\t// Publish the signatures associated with this entity","\tif err := ociremote.WriteAttestations(repo, newImage, ociremote.WithRemoteOptions(s.remoteOpts...)); err != nil {","\t\treturn nil, err","\t}","\tlogger.Infof(\"Successfully uploaded attestation for %s\", req.Artifact.String())","","\treturn \u0026api.StoreResponse{}, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,1,1,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,0,2,2,2,2,2,2,1,1,2,2,1,1,0,0,2,1,1,2,2,2,0]},{"id":40,"path":"pkg/chains/storage/oci/legacy.go","lines":["/*","Copyright 2020 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package oci","","import (","\t\"context\"","\t\"crypto/tls\"","\t\"encoding/base64\"","\t\"encoding/json\"","\t\"fmt\"","\t\"net/http\"","","\t\"github.com/tektoncd/chains/pkg/chains/formats\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"github.com/tektoncd/chains/pkg/chains/signing\"","\t\"github.com/tektoncd/chains/pkg/chains/storage/api\"","","\t\"knative.dev/pkg/logging\"","","\tintoto \"github.com/in-toto/attestation/go/v1\"","\t\"github.com/secure-systems-lab/go-securesystemslib/dsse\"","","\t\"github.com/google/go-containerregistry/pkg/authn/k8schain\"","\t\"github.com/google/go-containerregistry/pkg/name\"","\t\"github.com/google/go-containerregistry/pkg/v1/remote\"","\t\"github.com/pkg/errors\"","\t\"github.com/sigstore/cosign/v2/pkg/oci\"","\tociremote \"github.com/sigstore/cosign/v2/pkg/oci/remote\"","\t\"github.com/tektoncd/chains/pkg/artifacts\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/simple\"","\t\"github.com/tektoncd/chains/pkg/config\"","\t\"k8s.io/client-go/kubernetes\"",")","","const StorageBackendOCI = \"oci\"","","// Backend implements a storage backend for OCI artifacts.","// Deprecated: Use SimpleStorer and AttestationStorer instead.","type Backend struct {","\tcfg              config.Config","\tclient           kubernetes.Interface","\tgetAuthenticator func(ctx context.Context, obj objects.TektonObject, client kubernetes.Interface) (remote.Option, error)","}","","// NewStorageBackend returns a new OCI StorageBackend that stores signatures in an OCI registry","func NewStorageBackend(ctx context.Context, client kubernetes.Interface, cfg config.Config) *Backend {","\treturn \u0026Backend{","\t\tcfg: cfg,","","\t\tclient: client,","\t\tgetAuthenticator: func(ctx context.Context, obj objects.TektonObject, client kubernetes.Interface) (remote.Option, error) {","\t\t\tkc, err := k8schain.New(ctx, client,","\t\t\t\tk8schain.Options{","\t\t\t\t\tNamespace:          obj.GetNamespace(),","\t\t\t\t\tServiceAccountName: obj.GetServiceAccountName(),","\t\t\t\t\tUseMountSecrets:    true,","\t\t\t\t})","\t\t\tif err != nil {","\t\t\t\treturn nil, errors.Wrapf(err, \"creating new keychain from serviceaccount %s/%s\", obj.GetNamespace(), obj.GetServiceAccountName())","\t\t\t}","\t\t\treturn remote.WithAuthFromKeychain(kc), nil","\t\t},","\t}","}","","// StorePayload implements the storage.Backend interface.","func (b *Backend) StorePayload(ctx context.Context, obj objects.TektonObject, rawPayload []byte, signature string, storageOpts config.StorageOpts) error {","\tlogger := logging.FromContext(ctx)","\tremoteOpts, err := b.buildRemoteOptions(ctx, obj)","\tif err != nil {","\t\treturn errors.Wrap(err, \"getting oci authenticator\")","\t}","","\tlogger.Infof(\"Storing payload on %s/%s/%s\", obj.GetGVK(), obj.GetNamespace(), obj.GetName())","","\tif storageOpts.PayloadFormat == formats.PayloadTypeSimpleSigning {","\t\tformat := simple.SimpleContainerImage{}","\t\tif err := json.Unmarshal(rawPayload, \u0026format); err != nil {","\t\t\treturn errors.Wrap(err, \"unmarshal simplesigning\")","\t\t}","\t\treturn b.uploadSignature(ctx, format, rawPayload, signature, storageOpts, remoteOpts...)","\t}","","\tif _, ok := formats.IntotoAttestationSet[storageOpts.PayloadFormat]; ok {","\t\tattestation := intoto.Statement{}","\t\tif err := json.Unmarshal(rawPayload, \u0026attestation); err != nil {","\t\t\treturn errors.Wrap(err, \"unmarshal attestation\")","\t\t}","","\t\t// This can happen if the Task/TaskRun does not adhere to specific naming conventions","\t\t// like *IMAGE_URL that would serve as hints. This may be intentional for a Task/TaskRun","\t\t// that is not intended to produce an image, e.g. git-clone.","\t\tif len(attestation.Subject) == 0 {","\t\t\tlogger.Infof(","\t\t\t\t\"No image subject to attest for %s/%s/%s. Skipping upload to registry\", obj.GetGVK(), obj.GetNamespace(), obj.GetName())","\t\t\treturn nil","\t\t}","","\t\treturn b.uploadAttestation(ctx, \u0026attestation, signature, storageOpts, remoteOpts...)","\t}","","\t// Fallback in case unsupported payload format is used or the deprecated \"tekton\" format","\tlogger.Info(\"Skipping upload to OCI registry, OCI storage backend is only supported for OCI images and in-toto attestations\")","\treturn nil","}","","// buildRemoteOptions build remote options for OCI storage backend","func (b *Backend) buildRemoteOptions(ctx context.Context, obj objects.TektonObject) ([]remote.Option, error) {","\topts := []remote.Option{}","\tauth, err := b.getAuthenticator(ctx, obj, b.client)","\tif err != nil {","\t\treturn nil, err","\t}","\topts = append(opts, auth)","\tif b.cfg.Storage.OCI.Insecure {","\t\tlogger := logging.FromContext(ctx)","\t\tlogger.Warn(\"Using insecure OCI registry connection. This skips TLS certificate verification and poses security risks. Only use this in testing or development environments.\")","\t\t// InsecureSkipVerify is used only when explicitly configured for testing or development environments","\t\t// This is controlled by the user through configuration and should not be used in production","\t\topts = append(opts, remote.WithTransport(\u0026http.Transport{","\t\t\tTLSClientConfig: \u0026tls.Config{","\t\t\t\tInsecureSkipVerify: true, // #nosec G402","\t\t\t},","\t\t}))","\t}","\treturn opts, nil","}","","func (b *Backend) uploadSignature(ctx context.Context, format simple.SimpleContainerImage, rawPayload []byte, signature string, storageOpts config.StorageOpts, remoteOpts ...remote.Option) error {","\tlogger := logging.FromContext(ctx)","","\timageName := format.ImageName()","\tlogger.Infof(\"Uploading %s signature\", imageName)","","\tref, err := name.NewDigest(imageName)","\tif err != nil {","\t\treturn errors.Wrap(err, \"getting digest\")","\t}","","\trepo, err := newRepo(b.cfg, ref)","\tif err != nil {","\t\treturn errors.Wrapf(err, \"getting storage repo for sub %s\", imageName)","\t}","","\tstore, err := NewSimpleStorerFromConfig(WithTargetRepository(repo))","\tif err != nil {","\t\treturn err","\t}","\t// TODO: make these creation opts.","\tstore.remoteOpts = remoteOpts","\tif _, err := store.Store(ctx, \u0026api.StoreRequest[name.Digest, simple.SimpleContainerImage]{","\t\tObject:   nil,","\t\tArtifact: ref,","\t\tPayload:  format,","\t\tBundle: \u0026signing.Bundle{","\t\t\tContent:   rawPayload,","\t\t\tSignature: []byte(signature),","\t\t\tCert:      []byte(storageOpts.Cert),","\t\t\tChain:     []byte(storageOpts.Chain),","\t\t},","\t}); err != nil {","\t\treturn err","\t}","\treturn nil","}","","func (b *Backend) uploadAttestation(ctx context.Context, attestation *intoto.Statement, signature string, storageOpts config.StorageOpts, remoteOpts ...remote.Option) error {","\tlogger := logging.FromContext(ctx)","\t// upload an attestation for each subject","\tlogger.Info(\"Starting to upload attestations to OCI ...\")","\tfor _, subj := range attestation.Subject {","\t\timageName := fmt.Sprintf(\"%s@sha256:%s\", subj.Name, subj.Digest[\"sha256\"])","\t\tlogger.Infof(\"Starting attestation upload to OCI for %s...\", imageName)","","\t\tref, err := name.NewDigest(imageName)","\t\tif err != nil {","\t\t\treturn errors.Wrapf(err, \"getting digest for subj %s\", imageName)","\t\t}","","\t\trepo, err := newRepo(b.cfg, ref)","\t\tif err != nil {","\t\t\treturn errors.Wrapf(err, \"getting storage repo for sub %s\", imageName)","\t\t}","","\t\tstore, err := NewAttestationStorer(WithTargetRepository(repo))","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\t// TODO: make these creation opts.","\t\tstore.remoteOpts = remoteOpts","\t\tif _, err := store.Store(ctx, \u0026api.StoreRequest[name.Digest, *intoto.Statement]{","\t\t\tObject:   nil,","\t\t\tArtifact: ref,","\t\t\tPayload:  attestation,","\t\t\tBundle: \u0026signing.Bundle{","\t\t\t\tContent:   nil,","\t\t\t\tSignature: []byte(signature),","\t\t\t\tCert:      []byte(storageOpts.Cert),","\t\t\t\tChain:     []byte(storageOpts.Chain),","\t\t\t},","\t\t}); err != nil {","\t\t\treturn err","\t\t}","\t}","\treturn nil","}","","func (b *Backend) Type() string {","\treturn StorageBackendOCI","}","","func (b *Backend) RetrieveSignatures(ctx context.Context, obj objects.TektonObject, opts config.StorageOpts) (map[string][]string, error) {","\timages, err := b.RetrieveArtifact(ctx, obj, opts)","\tif err != nil {","\t\treturn nil, err","\t}","","\tm := make(map[string][]string)","\tfor ref, img := range images {","\t\tsigImage, err := img.Signatures()","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tsigs, err := sigImage.Get()","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","","\t\tsignatures := []string{}","\t\tfor _, s := range sigs {","\t\t\tif sig, err := s.Base64Signature(); err == nil {","\t\t\t\tsignatures = append(signatures, sig)","\t\t\t}","\t\t}","\t\tm[ref] = signatures","\t}","\treturn m, nil","}","","func (b *Backend) RetrievePayloads(ctx context.Context, obj objects.TektonObject, opts config.StorageOpts) (map[string]string, error) {","\tvar err error","\timages, err := b.RetrieveArtifact(ctx, obj, opts)","\tif err != nil {","\t\treturn nil, err","\t}","","\tm := make(map[string]string)","\tvar attImage oci.Signatures","\tfor ref, img := range images {","\t\tif opts.PayloadFormat == formats.PayloadTypeSimpleSigning {","\t\t\tattImage, err = img.Signatures()","\t\t} else {","\t\t\tattImage, err = img.Attestations()","\t\t}","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tatts, err := attImage.Get()","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","","\t\tfor _, s := range atts {","\t\t\tif payload, err := s.Payload(); err == nil {","\t\t\t\tenvelope := dsse.Envelope{}","\t\t\t\tif err := json.Unmarshal(payload, \u0026envelope); err != nil {","\t\t\t\t\treturn nil, fmt.Errorf(\"cannot decode the envelope: %s\", err)","\t\t\t\t}","","\t\t\t\tvar decodedPayload []byte","\t\t\t\tdecodedPayload, err = base64.StdEncoding.DecodeString(envelope.Payload)","\t\t\t\tif err != nil {","\t\t\t\t\treturn nil, fmt.Errorf(\"error decoding the payload: %s\", err)","\t\t\t\t}","","\t\t\t\tm[ref] = string(decodedPayload)","\t\t\t}","","\t\t}","\t}","\treturn m, nil","}","","func (b *Backend) RetrieveArtifact(ctx context.Context, obj objects.TektonObject, opts config.StorageOpts) (map[string]oci.SignedImage, error) {","\t// Given the TaskRun, retrieve the OCI images.","\timages := artifacts.ExtractOCIImagesFromResults(ctx, obj.GetResults())","\tm := make(map[string]oci.SignedImage)","","\tfor _, image := range images {","\t\tref, ok := image.(name.Digest)","\t\tif !ok {","\t\t\treturn nil, errors.New(\"error parsing image\")","\t\t}","\t\timg, err := ociremote.SignedImage(ref)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tm[ref.DigestStr()] = img","\t}","","\treturn m, nil","}","","func newRepo(cfg config.Config, imageName name.Digest) (name.Repository, error) {","\tvar opts []name.Option","\tif cfg.Storage.OCI.Insecure {","\t\topts = append(opts, name.Insecure)","\t}","","\tif storageOCIRepository := cfg.Storage.OCI.Repository; storageOCIRepository != \"\" {","\t\treturn name.NewRepository(storageOCIRepository, opts...)","\t}","\treturn name.NewRepository(imageName.Repository.Name(), opts...)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,2,2,2,2,1,1,0,2,2,2,2,2,1,1,2,0,0,2,2,2,1,1,0,0,0,0,2,2,2,2,2,0,2,0,0,0,2,2,0,0,0,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,1,1,0,2,2,1,1,0,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,1,1,0,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,0,0,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,0,1,0,0,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,0,2,2,2,2,2,0,2,2,2,2,0]},{"id":41,"path":"pkg/chains/storage/oci/options.go","lines":["// Copyright 2023 The Tekton Authors","//","// Licensed under the Apache License, Version 2.0 (the \"License\");","// you may not use this file except in compliance with the License.","// You may obtain a copy of the License at","//","//      http://www.apache.org/licenses/LICENSE-2.0","//","// Unless required by applicable law or agreed to in writing, software","// distributed under the License is distributed on an \"AS IS\" BASIS,","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","// See the License for the specific language governing permissions and","// limitations under the License.","","package oci","","import \"github.com/google/go-containerregistry/pkg/name\"","","// Option provides a config option compatible with all OCI storers.","type Option interface {","\tAttestationStorerOption","\tSimpleStorerOption","}","","// AttestationStorerOption provides a config option compatible with AttestationStorer.","type AttestationStorerOption interface {","\tapplyAttestationStorer(s *AttestationStorer) error","}","","// SimpleStorerOption provides a config option compatible with SimpleStorer.","type SimpleStorerOption interface {","\tapplySimpleStorer(s *SimpleStorer) error","}","","// WithTargetRepository configures the target repository where objects will be stored.","func WithTargetRepository(repo name.Repository) Option {","\treturn \u0026targetRepoOption{","\t\trepo: repo,","\t}","}","","type targetRepoOption struct {","\trepo name.Repository","}","","func (o *targetRepoOption) applyAttestationStorer(s *AttestationStorer) error {","\ts.repo = \u0026o.repo","\treturn nil","}","","func (o *targetRepoOption) applySimpleStorer(s *SimpleStorer) error {","\ts.repo = \u0026o.repo","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,0,0,0,2,2,2,2,0,2,2,2,2]},{"id":42,"path":"pkg/chains/storage/oci/simple.go","lines":["// Copyright 2023 The Tekton Authors","//","// Licensed under the Apache License, Version 2.0 (the \"License\");","// you may not use this file except in compliance with the License.","// You may obtain a copy of the License at","//","//      http://www.apache.org/licenses/LICENSE-2.0","//","// Unless required by applicable law or agreed to in writing, software","// distributed under the License is distributed on an \"AS IS\" BASIS,","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","// See the License for the specific language governing permissions and","// limitations under the License.","","package oci","","import (","\t\"context\"","\t\"encoding/base64\"","","\t\"github.com/google/go-containerregistry/pkg/name\"","\t\"github.com/google/go-containerregistry/pkg/v1/remote\"","\t\"github.com/pkg/errors\"","\t\"github.com/sigstore/cosign/v2/pkg/oci/mutate\"","\tociremote \"github.com/sigstore/cosign/v2/pkg/oci/remote\"","\t\"github.com/sigstore/cosign/v2/pkg/oci/static\"","\t\"github.com/tektoncd/chains/pkg/chains/formats/simple\"","\t\"github.com/tektoncd/chains/pkg/chains/storage/api\"","\t\"knative.dev/pkg/logging\"",")","","// SimpleStorer stores SimpleSigning payloads in OCI registries.","type SimpleStorer struct {","\t// repo configures the repo where data should be stored.","\t// If empty, the repo is inferred from the Artifact.","\trepo *name.Repository","\t// remoteOpts are additional remote options (i.e. auth) to use for client operations.","\tremoteOpts []remote.Option","}","","var (","\t_ api.Storer[name.Digest, simple.SimpleContainerImage] = \u0026SimpleStorer{}",")","","func NewSimpleStorerFromConfig(opts ...SimpleStorerOption) (*SimpleStorer, error) {","\ts := \u0026SimpleStorer{}","\tfor _, o := range opts {","\t\tif err := o.applySimpleStorer(s); err != nil {","\t\t\treturn nil, err","\t\t}","\t}","\treturn s, nil","}","","func (s *SimpleStorer) Store(ctx context.Context, req *api.StoreRequest[name.Digest, simple.SimpleContainerImage]) (*api.StoreResponse, error) {","\tlogger := logging.FromContext(ctx).With(\"image\", req.Artifact.String())","\tlogger.Info(\"Uploading signature\")","","\tse, err := ociremote.SignedEntity(req.Artifact, ociremote.WithRemoteOptions(s.remoteOpts...))","\tvar entityNotFoundError *ociremote.EntityNotFoundError","\tif errors.As(err, \u0026entityNotFoundError) {","\t\tse = ociremote.SignedUnknown(req.Artifact, ociremote.WithRemoteOptions(s.remoteOpts...))","\t} else if err != nil {","\t\treturn nil, errors.Wrap(err, \"getting signed image\")","\t}","","\tsigOpts := []static.Option{}","\tif req.Bundle.Cert != nil {","\t\tsigOpts = append(sigOpts, static.WithCertChain(req.Bundle.Cert, req.Bundle.Chain))","\t}","\t// Create the new signature for this entity.","\tb64sig := base64.StdEncoding.EncodeToString(req.Bundle.Signature)","\tsig, err := static.NewSignature(req.Bundle.Content, b64sig, sigOpts...)","\tif err != nil {","\t\treturn nil, err","\t}","\t// Attach the signature to the entity.","\tnewSE, err := mutate.AttachSignatureToEntity(se, sig)","\tif err != nil {","\t\treturn nil, err","\t}","","\trepo := req.Artifact.Repository","\tif s.repo != nil {","\t\trepo = *s.repo","\t}","\t// Publish the signatures associated with this entity","\tif err := ociremote.WriteSignatures(repo, newSE, ociremote.WithRemoteOptions(s.remoteOpts...)); err != nil {","\t\treturn nil, err","\t}","\tlogger.Info(\"Successfully uploaded signature\")","\treturn \u0026api.StoreResponse{}, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,1,1,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,2,2,2,1,1,0,2,2,1,1,0,2,2,2,2,0,2,1,1,2,2,0]},{"id":43,"path":"pkg/chains/storage/pubsub/pubsub.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pubsub","","import (","\t\"context\"","\t\"encoding/base64\"","\t\"fmt\"","","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"github.com/tektoncd/chains/pkg/config\"","\t\"gocloud.dev/pubsub/kafkapubsub\"","\t\"knative.dev/pkg/logging\"","","\t\"gocloud.dev/pubsub\"","\t_ \"gocloud.dev/pubsub/mempubsub\"",")","","const (","\tStorageBackendPubSub   = \"pubsub\"","\tPubSubProviderInMemory = \"inmemory\"","\tPubSubProviderKafka    = \"kafka\"",")","","// Backend is a storage backend that stores signed payloads in the TaskRun metadata as an annotation.","// It is stored as base64 encoded JSON.","type Backend struct {","\tcfg config.Config","}","","// NewStorageBackend returns a new Tekton StorageBackend that stores signatures on a TaskRun","func NewStorageBackend(ctx context.Context, cfg config.Config) (*Backend, error) {","\treturn \u0026Backend{","\t\tcfg: cfg,","\t}, nil","}","","func (b *Backend) Type() string {","\treturn StorageBackendPubSub","}","","func (b *Backend) StorePayload(ctx context.Context, obj objects.TektonObject, rawPayload []byte, signature string, opts config.StorageOpts) error {","\tlogger := logging.FromContext(ctx)","\tlogger.Infof(\"Storing payload on Object %s/%s\", obj.GetNamespace(), obj.GetName())","","\t// Construct a *pubsub.Topic.","\ttopic, err := b.NewTopic(ctx)","\tif err != nil {","\t\treturn err","\t}","\tdefer func() {","\t\tif err := topic.Shutdown(ctx); err != nil {","\t\t\tlogger.Error(err)","\t\t}","\t}()","","\t// Send the message with the DSSE signature.","\terr = topic.Send(ctx, \u0026pubsub.Message{","\t\tBody: []byte(signature),","\t\tMetadata: map[string]string{","\t\t\t\"payload\":   base64.StdEncoding.EncodeToString(rawPayload),","\t\t\t\"signature\": signature,","\t\t},","\t})","\tif err != nil {","\t\treturn err","\t}","","\treturn nil","}","","func (b *Backend) RetrievePayloads(ctx context.Context, _ objects.TektonObject, opts config.StorageOpts) (map[string]string, error) {","\treturn nil, fmt.Errorf(\"not implemented for this storage backend: %s\", b.Type())","}","","func (b *Backend) RetrieveSignatures(ctx context.Context, _ objects.TektonObject, opts config.StorageOpts) (map[string][]string, error) {","\treturn nil, fmt.Errorf(\"not implemented for this storage backend: %s\", b.Type())","}","","func (b *Backend) NewTopic(ctx context.Context) (*pubsub.Topic, error) {","\tlogger := logging.FromContext(ctx)","\tprovider := b.cfg.Storage.PubSub.Provider","\ttopic := b.cfg.Storage.PubSub.Topic","\tlogger.Infof(\"Creating new %q pubsub producer for %q topic\", provider, topic)","\tswitch provider {","\tcase PubSubProviderKafka:","\t\t// The set of brokers in the Kafka cluster.","\t\taddrs := []string{b.cfg.Storage.PubSub.Kafka.BootstrapServers}","\t\tlogger.Infof(\"Configuring Kafka brokers: %s\", addrs)","\t\t// The Kafka client configuration to use.","\t\tconfig := kafkapubsub.MinimalConfig()","\t\treturn kafkapubsub.OpenTopic(addrs, config, topic, nil)","\tcase PubSubProviderInMemory:","\t\taddr := fmt.Sprintf(\"mem://%s\", b.cfg.Storage.PubSub.Topic)","\t\tlogger.Infof(\"Configuring in-memory producer: %s\", addr)","\t\treturn pubsub.OpenTopic(context.TODO(), addr)","\tdefault:","\t\treturn nil, fmt.Errorf(\"invalid provider: %q\", provider)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,2,2,2,0,2,2,2,2,2,2,2,1,1,2,2,1,1,0,0,0,2,2,2,2,2,2,2,2,1,1,0,2,0,0,1,1,1,0,1,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,0]},{"id":44,"path":"pkg/chains/storage/storage.go","lines":["/*","Copyright 2020 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package storage","","import (","\t\"context\"","\t\"errors\"","","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"github.com/tektoncd/chains/pkg/chains/storage/archivista\"","\t\"github.com/tektoncd/chains/pkg/chains/storage/docdb\"","\t\"github.com/tektoncd/chains/pkg/chains/storage/gcs\"","\t\"github.com/tektoncd/chains/pkg/chains/storage/grafeas\"","\t\"github.com/tektoncd/chains/pkg/chains/storage/oci\"","\t\"github.com/tektoncd/chains/pkg/chains/storage/pubsub\"","\t\"github.com/tektoncd/chains/pkg/chains/storage/tekton\"","\t\"github.com/tektoncd/chains/pkg/config\"","\t\"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"","\t\"golang.org/x/exp/maps\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"k8s.io/client-go/kubernetes\"","\t\"knative.dev/pkg/logging\"",")","","// Backend is an interface to store a chains Payload","type Backend interface {","\tStorePayload(ctx context.Context, obj objects.TektonObject, rawPayload []byte, signature string, opts config.StorageOpts) error","\t// RetrievePayloads maps [ref]:[payload] for a TaskRun","\tRetrievePayloads(ctx context.Context, obj objects.TektonObject, opts config.StorageOpts) (map[string]string, error)","\t// RetrieveSignatures maps [ref]:[list of signatures] for a TaskRun","\tRetrieveSignatures(ctx context.Context, obj objects.TektonObject, opts config.StorageOpts) (map[string][]string, error)","\t// Type is the string representation of the backend","\tType() string","}","","// InitializeBackends creates and initializes every configured storage backend.","func InitializeBackends(ctx context.Context, ps versioned.Interface, kc kubernetes.Interface, cfg config.Config) (map[string]Backend, error) {","\tlogger := logging.FromContext(ctx)","","\t// Add an entry here for every configured backend","\tconfiguredBackends := []string{}","\tif cfg.Artifacts.TaskRuns.Enabled() {","\t\tconfiguredBackends = append(configuredBackends, sets.List[string](cfg.Artifacts.TaskRuns.StorageBackend)...)","\t}","\tif cfg.Artifacts.OCI.Enabled() {","\t\tconfiguredBackends = append(configuredBackends, sets.List[string](cfg.Artifacts.OCI.StorageBackend)...)","\t}","\tif cfg.Artifacts.PipelineRuns.Enabled() {","\t\tconfiguredBackends = append(configuredBackends, sets.List[string](cfg.Artifacts.PipelineRuns.StorageBackend)...)","\t}","\tlogger.Infof(\"configured backends from config: %v\", configuredBackends)","","\t// Now only initialize and return the configured ones.","\tbackends := map[string]Backend{}","\tfor _, backendType := range configuredBackends {","\t\tswitch backendType {","\t\tcase gcs.StorageBackendGCS:","\t\t\tgcsBackend, err := gcs.NewStorageBackend(ctx, cfg)","\t\t\tif err != nil {","\t\t\t\treturn nil, err","\t\t\t}","\t\t\tbackends[backendType] = gcsBackend","\t\tcase tekton.StorageBackendTekton:","\t\t\tbackends[backendType] = tekton.NewStorageBackend(ps)","\t\tcase oci.StorageBackendOCI:","\t\t\tociBackend := oci.NewStorageBackend(ctx, kc, cfg)","\t\t\tbackends[backendType] = ociBackend","\t\tcase docdb.StorageTypeDocDB:","\t\t\tdocdbBackend, err := docdb.NewStorageBackend(ctx, cfg)","\t\t\tif err != nil {","\t\t\t\treturn nil, err","\t\t\t}","\t\t\tbackends[backendType] = docdbBackend","\t\tcase grafeas.StorageBackendGrafeas:","\t\t\tgrafeasBackend, err := grafeas.NewStorageBackend(ctx, cfg)","\t\t\tif err != nil {","\t\t\t\treturn nil, err","\t\t\t}","\t\t\tbackends[backendType] = grafeasBackend","\t\tcase pubsub.StorageBackendPubSub:","\t\t\tpubsubBackend, err := pubsub.NewStorageBackend(ctx, cfg)","\t\t\tif err != nil {","\t\t\t\treturn nil, err","\t\t\t}","\t\t\tbackends[backendType] = pubsubBackend","\t\tcase archivista.StorageBackendArchivista:","\t\t\tarchivistaBackend, err := archivista.NewStorageBackend(cfg)","\t\t\tif err != nil {","\t\t\t\treturn nil, err","\t\t\t}","\t\t\tbackends[backendType] = archivistaBackend","\t\t}","\t}","","\tlogger.Infof(\"successfully initialized backends: %v\", maps.Keys(backends))","\treturn backends, nil","}","","// WatchBackends watches backends for any update and keeps them up to date.","func WatchBackends(ctx context.Context, watcherStop chan bool, backends map[string]Backend, cfg config.Config) error {","\tlogger := logging.FromContext(ctx)","\tfor backend := range backends {","\t\tswitch backend {","\t\tcase docdb.StorageTypeDocDB:","\t\t\tdocdbWatcherStop := make(chan bool)","\t\t\tbackendChan, err := docdb.WatchBackend(ctx, cfg, docdbWatcherStop)","\t\t\tif err != nil {","\t\t\t\tif errors.Is(err, docdb.ErrNothingToWatch) {","\t\t\t\t\tlogger.Info(err)","\t\t\t\t\tcontinue","\t\t\t\t}","\t\t\t\treturn err","\t\t\t}","\t\t\tgo func() {","\t\t\t\tfor {","\t\t\t\t\tselect {","\t\t\t\t\tcase newBackend := \u003c-backendChan:","\t\t\t\t\t\tif newBackend == nil {","\t\t\t\t\t\t\tlogger.Errorf(\"removing backend %s from backends\", docdb.StorageTypeDocDB)","\t\t\t\t\t\t\tdelete(backends, docdb.StorageTypeDocDB)","\t\t\t\t\t\t\tcontinue","\t\t\t\t\t\t}","\t\t\t\t\t\tlogger.Infof(\"adding to backends: %s\", docdb.StorageTypeDocDB)","\t\t\t\t\t\tbackends[docdb.StorageTypeDocDB] = newBackend","\t\t\t\t\tcase \u003c-watcherStop:","\t\t\t\t\t\t// Stop the DocDB watcher first","\t\t\t\t\t\tselect {","\t\t\t\t\t\tcase docdbWatcherStop \u003c- true:","\t\t\t\t\t\t\tlogger.Info(\"sent close event to docdb.WatchBackend()...\")","\t\t\t\t\t\tdefault:","\t\t\t\t\t\t\tlogger.Info(\"could not send close event to docdb.WatchBackend()...\")","\t\t\t\t\t\t}","","\t\t\t\t\t\t// Now stop this backend","\t\t\t\t\t\tlogger.Info(\"stop watching backends...\")","\t\t\t\t\t\treturn","\t\t\t\t\t}","\t\t\t\t}","\t\t\t}()","\t\tdefault:","\t\t\tlogger.Debugf(\"no backends to watch...\")","\t\t}","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,1,1,2,1,1,1,1,1,1,0,0,0,2,2,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0,0,0,1,1,0,0,0,1,1,0,0,1,0]},{"id":45,"path":"pkg/chains/storage/tekton/tekton.go","lines":["/*","Copyright 2020 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package tekton","","import (","\t\"context\"","\t\"encoding/base64\"","\t\"fmt\"","","\tintoto \"github.com/in-toto/attestation/go/v1\"","\t\"github.com/tektoncd/chains/pkg/chains/annotations\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"github.com/tektoncd/chains/pkg/chains/signing\"","\t\"github.com/tektoncd/chains/pkg/chains/storage/api\"","\t\"github.com/tektoncd/chains/pkg/config\"","\t\"knative.dev/pkg/logging\"","","\t\"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"",")","","//nolint:revive,exported","const (","\t// StorageBackendTekton is the identifier for the Tekton storage backend","\tStorageBackendTekton      = \"tekton\"","\tPayloadAnnotationFormat   = annotations.ChainsAnnotationPrefix + \"payload-%s\"","\tSignatureAnnotationFormat = annotations.ChainsAnnotationPrefix + \"signature-%s\"","\tCertAnnotationsFormat     = annotations.ChainsAnnotationPrefix + \"cert-%s\"","\tChainAnnotationFormat     = annotations.ChainsAnnotationPrefix + \"chain-%s\"",")","","// Backend is a storage backend that stores signed payloads in the TaskRun metadata as an annotation.","// It is stored as base64 encoded JSON.","// Deprecated: use Storer instead.","type Backend struct {","\tpipelineclientset versioned.Interface","}","","// NewStorageBackend returns a new Tekton StorageBackend that stores signatures on a TaskRun","func NewStorageBackend(ps versioned.Interface) *Backend {","\treturn \u0026Backend{","\t\tpipelineclientset: ps,","\t}","}","","// StorePayload implements the Payloader interface.","func (b *Backend) StorePayload(ctx context.Context, obj objects.TektonObject, rawPayload []byte, signature string, opts config.StorageOpts) error {","\tlogger := logging.FromContext(ctx)","","\tstore := \u0026Storer{","\t\tclient: b.pipelineclientset,","\t\tkey:    opts.ShortKey,","\t}","\tif _, err := store.Store(ctx, \u0026api.StoreRequest[objects.TektonObject, *intoto.Statement]{","\t\tObject:   obj,","\t\tArtifact: obj,","\t\t// We don't actually use payload - we store the raw bundle values directly.","\t\tPayload: nil,","\t\tBundle: \u0026signing.Bundle{","\t\t\tContent:   rawPayload,","\t\t\tSignature: []byte(signature),","\t\t\tCert:      []byte(opts.Cert),","\t\t\tChain:     []byte(opts.Chain),","\t\t},","\t}); err != nil {","\t\tlogger.Errorf(\"error writing to Tekton object: %w\", err)","\t\treturn err","\t}","\treturn nil","}","","func (b *Backend) Type() string {","\treturn StorageBackendTekton","}","","// retrieveAnnotationValue retrieve the value of an annotation and base64 decode it if needed.","func (b *Backend) retrieveAnnotationValue(ctx context.Context, obj objects.TektonObject, annotationKey string, decode bool) (string, error) {","\tlogger := logging.FromContext(ctx)","\tlogger.Infof(\"Retrieving annotation %q on %s/%s/%s\", annotationKey, obj.GetGVK(), obj.GetNamespace(), obj.GetName())","","\tvar annotationValue string","\tannotations, err := obj.GetLatestAnnotations(ctx, b.pipelineclientset)","\tif err != nil {","\t\treturn \"\", fmt.Errorf(\"error retrieving the annotation value for the key %q: %w\", annotationKey, err)","\t}","\tval, ok := annotations[annotationKey]","","\t// Ensure it exists.","\tif ok {","\t\t// Decode it if needed.","\t\tif decode {","\t\t\tdecodedAnnotation, err := base64.StdEncoding.DecodeString(val)","\t\t\tif err != nil {","\t\t\t\treturn \"\", fmt.Errorf(\"error decoding the annotation value for the key %q: %w\", annotationKey, err)","\t\t\t}","\t\t\tannotationValue = string(decodedAnnotation)","\t\t} else {","\t\t\tannotationValue = val","\t\t}","\t}","","\treturn annotationValue, nil","}","","// RetrieveSignatures retrieve the signature stored in the taskrun.","func (b *Backend) RetrieveSignatures(ctx context.Context, obj objects.TektonObject, opts config.StorageOpts) (map[string][]string, error) {","\tlogger := logging.FromContext(ctx)","\tlogger.Infof(\"Retrieving signature on %s/%s/%s\", obj.GetGVK(), obj.GetNamespace(), obj.GetName())","\tsignatureAnnotation := sigName(opts)","\tsignature, err := b.retrieveAnnotationValue(ctx, obj, signatureAnnotation, true)","\tif err != nil {","\t\treturn nil, err","\t}","\tm := make(map[string][]string)","\tm[signatureAnnotation] = []string{signature}","\treturn m, nil","}","","// RetrievePayloads retrieve the payload stored in the taskrun.","func (b *Backend) RetrievePayloads(ctx context.Context, obj objects.TektonObject, opts config.StorageOpts) (map[string]string, error) {","\tlogger := logging.FromContext(ctx)","\tlogger.Infof(\"Retrieving payload on %s/%s/%s\", obj.GetGVK(), obj.GetNamespace(), obj.GetName())","\tpayloadAnnotation := payloadName(opts)","\tpayload, err := b.retrieveAnnotationValue(ctx, obj, payloadAnnotation, true)","\tif err != nil {","\t\treturn nil, err","\t}","\tm := make(map[string]string)","\tm[payloadAnnotation] = payload","\treturn m, nil","}","","func sigName(opts config.StorageOpts) string {","\treturn fmt.Sprintf(SignatureAnnotationFormat, opts.ShortKey)","}","","func payloadName(opts config.StorageOpts) string {","\treturn fmt.Sprintf(PayloadAnnotationFormat, opts.ShortKey)","}","","type Storer struct {","\tclient versioned.Interface","\t// optional key override. If not specified, the UID of the object is used.","\tkey string","}","","var (","\t_ api.Storer[objects.TektonObject, *intoto.Statement] = \u0026Storer{}",")","","// Store stores the statement in the TaskRun metadata as an annotation.","func (s *Storer) Store(ctx context.Context, req *api.StoreRequest[objects.TektonObject, *intoto.Statement]) (*api.StoreResponse, error) {","\tlogger := logging.FromContext(ctx)","","\tobj := req.Object","\tlogger.Infof(\"Storing payload on %s/%s/%s\", obj.GetGVK(), obj.GetNamespace(), obj.GetName())","","\tkey := s.key","\tif key == \"\" {","\t\tkey = string(obj.GetUID())","\t}","","\tstoredAnnotations := map[string]string{","\t\tfmt.Sprintf(PayloadAnnotationFormat, key):   base64.StdEncoding.EncodeToString(req.Bundle.Content),","\t\tfmt.Sprintf(SignatureAnnotationFormat, key): base64.StdEncoding.EncodeToString(req.Bundle.Signature),","\t\tfmt.Sprintf(CertAnnotationsFormat, key):     base64.StdEncoding.EncodeToString(req.Bundle.Cert),","\t\tfmt.Sprintf(ChainAnnotationFormat, key):     base64.StdEncoding.EncodeToString(req.Bundle.Chain),","\t}","","\tif err := annotations.AddAnnotations(ctx, obj, s.client, storedAnnotations); err != nil {","\t\treturn nil, err","\t}","","\treturn \u0026api.StoreResponse{}, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,2,0,0,1,1,1,0,0,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,1,1,2,1,1,1,0,0,2,0,0,0,2,2,2,2,2,2,1,1,2,2,2,0,0,0,2,2,2,2,2,2,1,1,2,2,2,0,0,2,2,2,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,2,1,1,0,2,0]},{"id":46,"path":"pkg/chains/verifier.go","lines":["/*","Copyright 2020 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package chains","","import (","\t\"context\"","\t\"strings\"","","\t\"github.com/tektoncd/chains/pkg/artifacts\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\t\"github.com/tektoncd/chains/pkg/chains/storage\"","\t\"github.com/tektoncd/chains/pkg/config\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tversioned \"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"k8s.io/client-go/kubernetes\"","\t\"knative.dev/pkg/logging\"",")","","type Verifier interface {","\tVerifyTaskRun(ctx context.Context, tr *v1.TaskRun) error","}","","type TaskRunVerifier struct {","\tKubeClient        kubernetes.Interface","\tPipelineclientset versioned.Interface","\tSecretPath        string","}","","func (tv *TaskRunVerifier) VerifyTaskRun(ctx context.Context, tr *v1.TaskRun) error {","\t// Get all the things we might need (storage backends, signers and formatters)","\tcfg := *config.FromContext(ctx)","\tlogger := logging.FromContext(ctx)","\tlogger.Infof(\"Verifying signature for TaskRun %s/%s\", tr.Namespace, tr.Name)","","\t// TODO: Hook this up to config.","\tenabledSignableTypes := []artifacts.Signable{","\t\t\u0026artifacts.TaskRunArtifact{},","\t\t\u0026artifacts.OCIArtifact{},","\t}","","\ttrObj := objects.NewTaskRunObjectV1(tr)","","\t// Storage","\tallBackends, err := storage.InitializeBackends(ctx, tv.Pipelineclientset, tv.KubeClient, cfg)","\tif err != nil {","\t\treturn err","\t}","\tsigners := allSigners(ctx, tv.SecretPath, cfg)","","\tfor _, signableType := range enabledSignableTypes {","\t\tif !signableType.Enabled(cfg) {","\t\t\tcontinue","\t\t}","\t\t// Verify the signature.","\t\tsignerType := signableType.Signer(cfg)","\t\tsigner, ok := signers[signerType]","\t\tif !ok {","\t\t\tlogger.Warnf(\"No signer %s configured for %s\", signerType, signableType.Type())","\t\t\tcontinue","\t\t}","","\t\tfor _, backend := range sets.List[string](signableType.StorageBackend(cfg)) {","\t\t\tb := allBackends[backend]","\t\t\tsignatures, err := b.RetrieveSignatures(ctx, trObj, config.StorageOpts{})","\t\t\tif err != nil {","\t\t\t\treturn err","\t\t\t}","\t\t\tpayload, err := b.RetrievePayloads(ctx, trObj, config.StorageOpts{})","\t\t\tif err != nil {","\t\t\t\treturn err","\t\t\t}","\t\t\tfor image, sigs := range signatures {","\t\t\t\tfor _, sig := range sigs {","\t\t\t\t\tif err := signer.VerifySignature(strings.NewReader(sig), strings.NewReader(payload[image])); err != nil {","\t\t\t\t\t\treturn err","\t\t\t\t\t}","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,1,0]},{"id":47,"path":"pkg/config/config.go","lines":["/*","Copyright 2021 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package config","","import (","\t\"fmt\"","\t\"strconv\"","\t\"strings\"","","\t\"github.com/sigstore/sigstore/pkg/tuf\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\tcm \"knative.dev/pkg/configmap\"",")","","type Config struct {","\tArtifacts       ArtifactConfigs","\tStorage         StorageConfigs","\tSigners         SignerConfigs","\tBuilder         BuilderConfig","\tTransparency    TransparencyConfig","\tBuildDefinition BuildDefinitionConfig","}","","// ArtifactConfigs contains the configuration for how to sign/store/format the signatures for each artifact type","type ArtifactConfigs struct {","\tOCI          Artifact","\tPipelineRuns Artifact","\tTaskRuns     Artifact","}","","// Artifact contains the configuration for how to sign/store/format the signatures for a single artifact","type Artifact struct {","\tFormat                string","\tStorageBackend        sets.Set[string]","\tSigner                string","\tDeepInspectionEnabled bool","}","","// StorageConfigs contains the configuration to instantiate different storage providers","type StorageConfigs struct {","\tGCS        GCSStorageConfig","\tOCI        OCIStorageConfig","\tTekton     TektonStorageConfig","\tDocDB      DocDBStorageConfig","\tGrafeas    GrafeasConfig","\tPubSub     PubSubStorageConfig","\tArchivista ArchivistaStorageConfig","}","","// SignerConfigs contains the configuration to instantiate different signers","type SignerConfigs struct {","\tX509 X509Signer","\tKMS  KMSSigner","}","","type BuilderConfig struct {","\tID string","}","","type BuildDefinitionConfig struct {","\tBuildType string","}","","type X509Signer struct {","\tFulcioEnabled     bool","\tFulcioAddr        string","\tFulcioOIDCIssuer  string","\tFulcioProvider    string","\tIdentityTokenFile string","\tTUFMirrorURL      string","}","","type KMSSigner struct {","\tKMSRef string","\tAuth   KMSAuth","}","","// KMSAuth configures authentication to the KMS server","type KMSAuth struct {","\tAddress   string","\tToken     string","\tTokenPath string","\tOIDC      KMSAuthOIDC","\tSpire     KMSAuthSpire","}","","// KMSAuthOIDC configures settings to authenticate with OIDC","type KMSAuthOIDC struct {","\tPath string","\tRole string","}","","// KMSAuthSpire configures settings to get an auth token from spire","type KMSAuthSpire struct {","\tSock     string","\tAudience string","}","","type GCSStorageConfig struct {","\tBucket string","}","","type OCIStorageConfig struct {","\tRepository string","\tInsecure   bool","}","","type TektonStorageConfig struct {","}","","type DocDBStorageConfig struct {","\tURL                string","\tMongoServerURL     string","\tMongoServerURLDir  string","\tMongoServerURLPath string","}","","type GrafeasConfig struct {","\t// project id that is used to store notes and occurences","\tProjectID string","\t// note id used to create a note that an occurrence will be attached to","\tNoteID string","","\t// NoteHint is used to set the attestation note","\tNoteHint string","}","","type PubSubStorageConfig struct {","\tProvider string","\tTopic    string","\tKafka    KafkaStorageConfig","}","","type KafkaStorageConfig struct {","\tBootstrapServers string","}","","type TransparencyConfig struct {","\tEnabled          bool","\tVerifyAnnotation bool","\tURL              string","}","","// ArchivistaStorageConfig holds configuration for the Archivista storage backend.","type ArchivistaStorageConfig struct {","\t// URL is the endpoint for the Archivista service.","\tURL string `json:\"url\"`","}","","const (","\ttaskrunFormatKey  = \"artifacts.taskrun.format\"","\ttaskrunStorageKey = \"artifacts.taskrun.storage\"","\ttaskrunSignerKey  = \"artifacts.taskrun.signer\"","","\tpipelinerunFormatKey               = \"artifacts.pipelinerun.format\"","\tpipelinerunStorageKey              = \"artifacts.pipelinerun.storage\"","\tpipelinerunSignerKey               = \"artifacts.pipelinerun.signer\"","\tpipelinerunEnableDeepInspectionKey = \"artifacts.pipelinerun.enable-deep-inspection\"","","\tociFormatKey  = \"artifacts.oci.format\"","\tociStorageKey = \"artifacts.oci.storage\"","\tociSignerKey  = \"artifacts.oci.signer\"","","\tgcsBucketKey               = \"storage.gcs.bucket\"","\tociRepositoryKey           = \"storage.oci.repository\"","\tociRepositoryInsecureKey   = \"storage.oci.repository.insecure\"","\tdocDBUrlKey                = \"storage.docdb.url\"","\tdocDBMongoServerURLKey     = \"storage.docdb.mongo-server-url\"","\tdocDBMongoServerURLDirKey  = \"storage.docdb.mongo-server-url-dir\"","\tdocDBMongoServerURLPathKey = \"storage.docdb.mongo-server-url-path\"","","\tarchivistaURLKey = \"storage.archivista.url\"","","\tgrafeasProjectIDKey = \"storage.grafeas.projectid\"","\tgrafeasNoteIDKey    = \"storage.grafeas.noteid\"","\tgrafeasNoteHint     = \"storage.grafeas.notehint\"","","\t// PubSub - General","\tpubsubProvider = \"storage.pubsub.provider\"","\tpubsubTopic    = \"storage.pubsub.topic\"","","\t// No config for PubSub - In-Memory","","\t// PubSub - Kafka","\tpubsubKafkaBootstrapServer = \"storage.pubsub.kafka.bootstrap.servers\"","","\t// KMS","\tkmsSignerKMSRef      = \"signers.kms.kmsref\"","\tkmsAuthAddress       = \"signers.kms.auth.address\"","\tkmsAuthToken         = \"signers.kms.auth.token\"","\tkmsAuthOIDCPath      = \"signers.kms.auth.oidc.path\"","\tkmsAuthTokenPath     = \"signers.kms.auth.token-path\" // #nosec G101","\tkmsAuthOIDCRole      = \"signers.kms.auth.oidc.role\"","\tkmsAuthSpireSock     = \"signers.kms.auth.spire.sock\"","\tkmsAuthSpireAudience = \"signers.kms.auth.spire.audience\"","","\t// Fulcio","\tx509SignerFulcioEnabled     = \"signers.x509.fulcio.enabled\"","\tx509SignerFulcioAddr        = \"signers.x509.fulcio.address\"","\tx509SignerFulcioOIDCIssuer  = \"signers.x509.fulcio.issuer\"","\tx509SignerFulcioProvider    = \"signers.x509.fulcio.provider\"","\tx509SignerIdentityTokenFile = \"signers.x509.identity.token.file\"","\tx509SignerTUFMirrorURL      = \"signers.x509.tuf.mirror.url\"","","\t// Builder config","\tbuilderIDKey = \"builder.id\"","","\ttransparencyEnabledKey = \"transparency.enabled\"","\ttransparencyURLKey     = \"transparency.url\"","","\t// Build type","\tbuildTypeKey = \"builddefinition.buildtype\"","","\tChainsConfig = \"chains-config\"",")","","func (artifact *Artifact) Enabled() bool {","\t// If signer is \"none\", signing is disabled","\tif artifact.Signer == \"none\" {","\t\treturn false","\t}","\treturn !(artifact.StorageBackend.Len() == 1 \u0026\u0026 artifact.StorageBackend.Has(\"\"))","}","","func defaultConfig() *Config {","\treturn \u0026Config{","\t\tArtifacts: ArtifactConfigs{","\t\t\tTaskRuns: Artifact{","\t\t\t\tFormat:         \"in-toto\",","\t\t\t\tStorageBackend: sets.New[string](\"tekton\"),","\t\t\t\tSigner:         \"x509\",","\t\t\t},","\t\t\tPipelineRuns: Artifact{","\t\t\t\tFormat:                \"in-toto\",","\t\t\t\tStorageBackend:        sets.New[string](\"tekton\"),","\t\t\t\tSigner:                \"x509\",","\t\t\t\tDeepInspectionEnabled: false,","\t\t\t},","\t\t\tOCI: Artifact{","\t\t\t\tFormat:         \"simplesigning\",","\t\t\t\tStorageBackend: sets.New[string](\"oci\"),","\t\t\t\tSigner:         \"x509\",","\t\t\t},","\t\t},","\t\tTransparency: TransparencyConfig{","\t\t\tURL: \"https://rekor.sigstore.dev\",","\t\t},","\t\tSigners: SignerConfigs{","\t\t\tX509: X509Signer{","\t\t\t\tFulcioAddr:       \"https://fulcio.sigstore.dev\",","\t\t\t\tFulcioOIDCIssuer: \"https://oauth2.sigstore.dev/auth\",","\t\t\t\tTUFMirrorURL:     tuf.DefaultRemoteRoot,","\t\t\t},","\t\t},","\t\tStorage: StorageConfigs{","\t\t\tGrafeas: GrafeasConfig{","\t\t\t\tNoteHint: \"This attestation note was generated by Tekton Chains\",","\t\t\t},","\t\t},","\t\tBuilder: BuilderConfig{","\t\t\tID: \"https://tekton.dev/chains/v2\",","\t\t},","\t\tBuildDefinition: BuildDefinitionConfig{","\t\t\tBuildType: \"https://tekton.dev/chains/v2/slsa\",","\t\t},","\t}","}","","// NewConfigFromMap creates a Config from the supplied map","func NewConfigFromMap(data map[string]string) (*Config, error) {","\tcfg := defaultConfig()","","\tif err := cm.Parse(data,","\t\t// Artifact-specific configs","\t\t// TaskRuns","\t\tasString(taskrunFormatKey, \u0026cfg.Artifacts.TaskRuns.Format, \"in-toto\", \"slsa/v1\", \"slsa/v2alpha3\", \"slsa/v2alpha4\"),","\t\tasStringSet(taskrunStorageKey, \u0026cfg.Artifacts.TaskRuns.StorageBackend, sets.New[string](\"tekton\", \"oci\", \"gcs\", \"docdb\", \"grafeas\", \"kafka\", \"archivista\")),","\t\tasString(taskrunSignerKey, \u0026cfg.Artifacts.TaskRuns.Signer, \"x509\", \"kms\", \"none\"),","","\t\t// PipelineRuns","\t\tasString(pipelinerunFormatKey, \u0026cfg.Artifacts.PipelineRuns.Format, \"in-toto\", \"slsa/v1\", \"slsa/v2alpha3\", \"slsa/v2alpha4\"),","\t\tasStringSet(pipelinerunStorageKey, \u0026cfg.Artifacts.PipelineRuns.StorageBackend, sets.New[string](\"tekton\", \"oci\", \"gcs\", \"docdb\", \"grafeas\", \"archivista\")),","\t\tasString(pipelinerunSignerKey, \u0026cfg.Artifacts.PipelineRuns.Signer, \"x509\", \"kms\", \"none\"),","\t\tasBool(pipelinerunEnableDeepInspectionKey, \u0026cfg.Artifacts.PipelineRuns.DeepInspectionEnabled),","","\t\t// OCI","\t\tasString(ociFormatKey, \u0026cfg.Artifacts.OCI.Format, \"simplesigning\"),","\t\tasStringSet(ociStorageKey, \u0026cfg.Artifacts.OCI.StorageBackend, sets.New[string](\"tekton\", \"oci\", \"gcs\", \"docdb\", \"grafeas\", \"kafka\", \"archivista\")),","\t\tasString(ociSignerKey, \u0026cfg.Artifacts.OCI.Signer, \"x509\", \"kms\", \"none\"),","","\t\t// PubSub - General","\t\tasString(pubsubProvider, \u0026cfg.Storage.PubSub.Provider, \"inmemory\", \"kafka\"),","\t\tasString(pubsubTopic, \u0026cfg.Storage.PubSub.Topic),","","\t\t// PubSub - Kafka","\t\tasString(pubsubKafkaBootstrapServer, \u0026cfg.Storage.PubSub.Kafka.BootstrapServers),","","\t\t// Storage level configs","\t\tasString(gcsBucketKey, \u0026cfg.Storage.GCS.Bucket),","\t\tasString(ociRepositoryKey, \u0026cfg.Storage.OCI.Repository),","\t\tasBool(ociRepositoryInsecureKey, \u0026cfg.Storage.OCI.Insecure),","\t\tasString(docDBUrlKey, \u0026cfg.Storage.DocDB.URL),","\t\tasString(docDBMongoServerURLKey, \u0026cfg.Storage.DocDB.MongoServerURL),","\t\tasString(docDBMongoServerURLDirKey, \u0026cfg.Storage.DocDB.MongoServerURLDir),","\t\tasString(docDBMongoServerURLPathKey, \u0026cfg.Storage.DocDB.MongoServerURLPath),","","\t\tasString(archivistaURLKey, \u0026cfg.Storage.Archivista.URL),","","\t\tasString(grafeasProjectIDKey, \u0026cfg.Storage.Grafeas.ProjectID),","\t\tasString(grafeasNoteIDKey, \u0026cfg.Storage.Grafeas.NoteID),","\t\tasString(grafeasNoteHint, \u0026cfg.Storage.Grafeas.NoteHint),","","\t\toneOf(transparencyEnabledKey, \u0026cfg.Transparency.Enabled, \"true\", \"manual\"),","\t\toneOf(transparencyEnabledKey, \u0026cfg.Transparency.VerifyAnnotation, \"manual\"),","\t\tasString(transparencyURLKey, \u0026cfg.Transparency.URL),","","\t\tasString(kmsSignerKMSRef, \u0026cfg.Signers.KMS.KMSRef),","\t\tasString(kmsAuthAddress, \u0026cfg.Signers.KMS.Auth.Address),","\t\tasString(kmsAuthToken, \u0026cfg.Signers.KMS.Auth.Token),","\t\tasString(kmsAuthTokenPath, \u0026cfg.Signers.KMS.Auth.TokenPath),","\t\tasString(kmsAuthOIDCPath, \u0026cfg.Signers.KMS.Auth.OIDC.Path),","\t\tasString(kmsAuthOIDCRole, \u0026cfg.Signers.KMS.Auth.OIDC.Role),","\t\tasString(kmsAuthSpireSock, \u0026cfg.Signers.KMS.Auth.Spire.Sock),","\t\tasString(kmsAuthSpireAudience, \u0026cfg.Signers.KMS.Auth.Spire.Audience),","","\t\t// Fulcio","\t\tasBool(x509SignerFulcioEnabled, \u0026cfg.Signers.X509.FulcioEnabled),","\t\tasString(x509SignerFulcioAddr, \u0026cfg.Signers.X509.FulcioAddr),","\t\tasString(x509SignerFulcioOIDCIssuer, \u0026cfg.Signers.X509.FulcioOIDCIssuer),","\t\tasString(x509SignerFulcioProvider, \u0026cfg.Signers.X509.FulcioProvider),","\t\tasString(x509SignerIdentityTokenFile, \u0026cfg.Signers.X509.IdentityTokenFile),","\t\tasString(x509SignerTUFMirrorURL, \u0026cfg.Signers.X509.TUFMirrorURL),","","\t\t// Build config","\t\tasString(builderIDKey, \u0026cfg.Builder.ID),","","\t\t// Build type","\t\tasString(buildTypeKey, \u0026cfg.BuildDefinition.BuildType, \"https://tekton.dev/chains/v2/slsa\", \"https://tekton.dev/chains/v2/slsa-tekton\"),","\t); err != nil {","\t\treturn nil, fmt.Errorf(\"failed to parse data: %w\", err)","\t}","","\treturn cfg, nil","}","","// NewConfigFromConfigMap creates a Config from the supplied ConfigMap","func NewConfigFromConfigMap(configMap *corev1.ConfigMap) (*Config, error) {","\treturn NewConfigFromMap(configMap.Data)","}","","// oneOf sets target to true if it maches any of the values","func oneOf(key string, target *bool, values ...string) cm.ParseFunc {","\treturn func(data map[string]string) error {","\t\traw, ok := data[key]","\t\tif !ok {","\t\t\treturn nil","\t\t}","\t\tif values == nil {","\t\t\treturn nil","\t\t}","\t\tfor _, v := range values {","\t\t\tif v == raw {","\t\t\t\t*target = true","\t\t\t}","\t\t}","\t\treturn nil","\t}","}","","// allow additional supported values for a \"true\" decision","// in additional to the usual ones provided by strconv.ParseBool","func asBool(key string, target *bool) cm.ParseFunc {","\treturn func(data map[string]string) error {","\t\traw, ok := data[key]","\t\tif !ok {","\t\t\treturn nil","\t\t}","\t\tval, err := strconv.ParseBool(raw)","\t\tif err == nil {","\t\t\t*target = val","\t\t\treturn nil","\t\t}","\t\treturn nil","\t}","}","","// asString passes the value at key through into the target, if it exists.","// TODO(mattmoor): This might be a nice variation on cm.AsString to upstream.","func asString(key string, target *string, values ...string) cm.ParseFunc {","\treturn func(data map[string]string) error {","\t\traw, ok := data[key]","\t\tif !ok {","\t\t\treturn nil","\t\t}","\t\tif len(values) \u003e 0 {","\t\t\tvals := sets.New[string](values...)","\t\t\tif !vals.Has(raw) {","\t\t\t\treturn fmt.Errorf(\"invalid value %q wanted one of %v\", raw, sets.List[string](vals))","\t\t\t}","\t\t}","\t\t*target = raw","\t\treturn nil","\t}","}","","// asStringSet parses the value at key as a sets.Set[string] (split by ',') into the target, if it exists.","func asStringSet(key string, target *sets.Set[string], allowed sets.Set[string]) cm.ParseFunc {","\treturn func(data map[string]string) error {","\t\tif raw, ok := data[key]; ok {","\t\t\tif raw == \"\" {","\t\t\t\t*target = sets.New[string](\"\")","\t\t\t\treturn nil","\t\t\t}","\t\t\tsplitted := strings.Split(raw, \",\")","\t\t\tif allowed.Len() \u003e 0 {","\t\t\t\tfor i, v := range splitted {","\t\t\t\t\tsplitted[i] = strings.TrimSpace(v)","\t\t\t\t\tif !allowed.Has(splitted[i]) {","\t\t\t\t\t\treturn fmt.Errorf(\"invalid value %q wanted one of %v\", splitted[i], sets.List[string](allowed))","\t\t\t\t\t}","\t\t\t\t}","\t\t\t}","\t\t\t*target = sets.New[string](splitted...)","\t\t}","\t\treturn nil","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,0,0,0,2,2,2,0,0,2,2,2,2,2,2,2,1,1,2,2,2,2,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,1,1,0,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,0,2,0,2,0,0]},{"id":48,"path":"pkg/config/store.go","lines":["/*","Copyright 2021 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package config","","import (","\t\"context\"","","\t\"knative.dev/pkg/configmap\"","\t\"knative.dev/pkg/reconciler\"",")","","type cfgKey struct{}","","// ConfigStore is the configuration from a ConfigMap","// +k8s:deepcopy-gen=false","type ConfigStore struct {","\t*configmap.UntypedStore","}","","var _ reconciler.ConfigStore = (*ConfigStore)(nil)","","// FromContext fetch config from context.","func FromContext(ctx context.Context) *Config {","\treturn ctx.Value(cfgKey{}).(*Config)","}","","// ToContext adds config to given context.","func ToContext(ctx context.Context, c *Config) context.Context {","\treturn context.WithValue(ctx, cfgKey{}, c)","}","","// ToContext adds Store contents to given context.","func (s *ConfigStore) ToContext(ctx context.Context) context.Context {","\treturn ToContext(ctx, s.Load())","}","","// Load fetches config from Store.","func (s *ConfigStore) Load() *Config {","\treturn s.UntypedLoad(ChainsConfig).(*Config).DeepCopy()","}","","// NewConfigStore returns a reconciler.ConfigStore for the chains configuration data.","func NewConfigStore(logger configmap.Logger, onAfterStore ...func(name string, value interface{})) *ConfigStore {","\treturn \u0026ConfigStore{","\t\tUntypedStore: configmap.NewUntypedStore(","\t\t\t\"chains\",","\t\t\tlogger,","\t\t\tconfigmap.Constructors{","\t\t\t\tChainsConfig: NewConfigFromConfigMap,","\t\t\t},","\t\t\tonAfterStore...,","\t\t),","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2]},{"id":49,"path":"pkg/internal/mocksigner/mocksigner.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package mocksigner","","import (","\t\"context\"","","\t\"github.com/tektoncd/chains/pkg/chains/objects\"",")","","type Signer struct {","\tSigned bool","}","","func (m *Signer) Sign(ctx context.Context, obj objects.TektonObject) error {","\tm.Signed = true","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1]},{"id":50,"path":"pkg/internal/objectloader/objectloader.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package objectloader","","import (","\t\"encoding/json\"","\t\"os\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"",")","","func TaskRunV1FromFile(f string) (*v1.TaskRun, error) {","\tcontents, err := os.ReadFile(f)","\tif err != nil {","\t\treturn nil, err","\t}","\tvar tr v1.TaskRun","\tif err := json.Unmarshal(contents, \u0026tr); err != nil {","\t\treturn nil, err","\t}","\treturn \u0026tr, nil","}","","func PipelineRunV1FromFile(f string) (*v1.PipelineRun, error) {","\tcontents, err := os.ReadFile(f)","\tif err != nil {","\t\treturn nil, err","\t}","\tvar pr v1.PipelineRun","\tif err := json.Unmarshal(contents, \u0026pr); err != nil {","\t\treturn nil, err","\t}","\treturn \u0026pr, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,0]},{"id":51,"path":"pkg/pipelinerunmetrics/fake/fake.go","lines":["/*","Copyright 2024 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package fake","","import (","\t\"context\"","","\t\"github.com/tektoncd/chains/pkg/pipelinerunmetrics\"","\t_ \"github.com/tektoncd/pipeline/pkg/client/injection/informers/pipeline/v1/pipelinerun/fake\" // Make sure the fake pipelinerun informer is setup","\t\"k8s.io/client-go/rest\"","\t\"knative.dev/pkg/injection\"",")","","func init() {","\tinjection.Fake.RegisterClient(func(ctx context.Context, _ *rest.Config) context.Context { return pipelinerunmetrics.WithClient(ctx) })","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0]},{"id":52,"path":"pkg/pipelinerunmetrics/injection.go","lines":["/*","Copyright 2024 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pipelinerunmetrics","","import (","\t\"context\"","","\t\"k8s.io/client-go/rest\"","\t\"knative.dev/pkg/injection\"","\t\"knative.dev/pkg/logging\"",")","","func init() {","\tinjection.Default.RegisterClient(func(ctx context.Context, _ *rest.Config) context.Context { return WithClient(ctx) })","}","","// RecorderKey is used for associating the Recorder inside the context.Context.","type RecorderKey struct{}","","// WithClient adds a metrics recorder to the given context","func WithClient(ctx context.Context) context.Context {","\trec, err := NewRecorder(ctx)","\tif err != nil {","\t\tlogging.FromContext(ctx).Errorf(\"Failed to create pipelinerun metrics recorder %v\", err)","\t}","\treturn context.WithValue(ctx, RecorderKey{}, rec)","}","","// Get extracts the pipelinerunmetrics.Recorder from the context.","func Get(ctx context.Context) *Recorder {","\tuntyped := ctx.Value(RecorderKey{})","\tif untyped == nil {","\t\tlogging.FromContext(ctx).Errorf(\"Unable to fetch *pipelinerunmetrics.Recorder from context.\")","\t}","\treturn untyped.(*Recorder)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,0,0,0,0,0,0,2,2,2,1,1,2,0,0,0,2,2,2,1,1,2,0]},{"id":53,"path":"pkg/pipelinerunmetrics/metrics.go","lines":["/*","Copyright 2024 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pipelinerunmetrics","","import (","\t\"context\"","\t\"sync\"","","\t\"go.opencensus.io/stats\"","\t\"go.opencensus.io/stats/view\"","\t\"go.opencensus.io/tag\"","\t\"knative.dev/pkg/logging\"","\t\"knative.dev/pkg/metrics\"","","\tcommon \"github.com/tektoncd/chains/pkg/metrics\"",")","","const (","\tpipelineRunSignedName     common.Metric = \"pipelinerun_sign_created_total\"","\tpipelineRunSignedDesc     string        = \"Total number of signed messages for pipelineruns\"","\tpipelineRunUploadedName   common.Metric = \"pipelinerun_payload_uploaded_total\"","\tpipelineRunUploadedDesc   string        = \"Total number of uploaded payloads for pipelineruns\"","\tpipelineRunStoredName     common.Metric = \"pipelinerun_payload_stored_total\"","\tpipelineRunStoredDesc     string        = \"Total number of stored payloads for pipelineruns\"","\tpipelineRunMarkedName     common.Metric = \"pipelinerun_marked_signed_total\"","\tpipelineRunMarkedDesc     string        = \"Total number of objects marked as signed for pipelineruns\"","\tpipelineRunErrorCountName common.Metric = \"pipelinerun_signing_failures_total\"","\tpipelineRunErrorCountDesc string        = \"Total number of PipelineRun signing failures\"",")","","var (","\tsgCount = stats.Float64(string(pipelineRunSignedName),","\t\tpipelineRunSignedDesc,","\t\tstats.UnitDimensionless)","","\tsgCountView *view.View","","\tplCount = stats.Float64(string(pipelineRunUploadedName),","\t\tpipelineRunUploadedDesc,","\t\tstats.UnitDimensionless)","","\tplCountView *view.View","","\tstCount = stats.Float64(string(pipelineRunStoredName),","\t\tpipelineRunStoredDesc,","\t\tstats.UnitDimensionless)","","\tstCountView *view.View","","\tmrCount = stats.Float64(string(pipelineRunMarkedName),","\t\tpipelineRunMarkedDesc,","\t\tstats.UnitDimensionless)","","\tmrCountView *view.View","","\tpipelineRunErrorCount = stats.Float64(","\t\tstring(pipelineRunErrorCountName),","\t\tpipelineRunErrorCountDesc,","\t\tstats.UnitDimensionless,","\t)","","\tpipelineErrorView *view.View","","\terrorTypeKey, _ = tag.NewKey(\"error_type\")",")","","var _ common.Recorder = \u0026Recorder{}","","// Recorder holds keys for PipelineRun metrics.","type Recorder struct {","\tinitialized bool","}","","// We cannot register the view multiple times, so NewRecorder lazily","// initializes this singleton and returns the same recorder across any","// subsequent invocations.","var (","\tonce sync.Once","\tr    *Recorder",")","","// NewRecorder creates a new metrics recorder instance","// to log the PipelineRun related metrics.","func NewRecorder(ctx context.Context) (*Recorder, error) {","\tvar errRegistering error","\tlogger := logging.FromContext(ctx)","\tonce.Do(func() {","\t\tr = \u0026Recorder{","\t\t\tinitialized: true,","\t\t}","\t\terrRegistering = viewRegister()","\t\tif errRegistering != nil {","\t\t\tr.initialized = false","\t\t\tlogger.Errorf(\"View Register Failed \", r.initialized)","\t\t\treturn","\t\t}","\t})","","\treturn r, errRegistering","}","","func viewRegister() error {","\tsgCountView = \u0026view.View{","\t\tDescription: sgCount.Description(),","\t\tMeasure:     sgCount,","\t\tAggregation: view.Count(),","\t}","","\tplCountView = \u0026view.View{","\t\tDescription: plCount.Description(),","\t\tMeasure:     plCount,","\t\tAggregation: view.Count(),","\t}","","\tstCountView = \u0026view.View{","\t\tDescription: stCount.Description(),","\t\tMeasure:     stCount,","\t\tAggregation: view.Count(),","\t}","","\tmrCountView = \u0026view.View{","\t\tDescription: mrCount.Description(),","\t\tMeasure:     mrCount,","\t\tAggregation: view.Count(),","\t}","","\tpipelineErrorView = \u0026view.View{","\t\tDescription: pipelineRunErrorCount.Description(),","\t\tMeasure:     pipelineRunErrorCount,","\t\tTagKeys:     []tag.Key{errorTypeKey},","\t\tAggregation: view.Count(),","\t}","","\treturn view.Register(","\t\tsgCountView,","\t\tplCountView,","\t\tstCountView,","\t\tmrCountView,","\t\tpipelineErrorView,","\t)","}","","// RecordCountMetrics implements github.com/tektoncd/chains/pkg/metrics.Recorder.RecordCountMetrics","func (r *Recorder) RecordCountMetrics(ctx context.Context, metricType common.Metric) {","\tlogger := logging.FromContext(ctx)","\tif !r.initialized {","\t\tlogger.Errorf(\"Ignoring the metrics recording as recorder not initialized \")","\t\treturn","\t}","\tswitch mt := metricType; mt {","\tcase common.SignedMessagesCount:","\t\tr.countMetrics(ctx, sgCount)","\tcase common.PayloadUploadeCount:","\t\tr.countMetrics(ctx, plCount)","\tcase common.SignsStoredCount:","\t\tr.countMetrics(ctx, stCount)","\tcase common.MarkedAsSignedCount:","\t\tr.countMetrics(ctx, mrCount)","\tdefault:","\t\tlogger.Errorf(\"Ignoring the metrics recording as valid Metric type matching %v was not found\", mt)","\t}","}","","func (r *Recorder) countMetrics(ctx context.Context, measure *stats.Float64Measure) {","\tmetrics.Record(ctx, measure.M(1))","}","","// RecordErrorMetric records a PipelineRun signing failure with a given error type tag.","func (r *Recorder) RecordErrorMetric(ctx context.Context, errType common.MetricErrorType) {","\t// Add the error_type tag to the context.","\tctx, _ = tag.New(ctx, tag.Upsert(errorTypeKey, string(errType)))","\tmetrics.Record(ctx, pipelineRunErrorCount.M(1))","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,1,1,1,1,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,0,0,2,2,2,0,0,2,2,2,2,2]},{"id":54,"path":"pkg/reconciler/filter.go","lines":["/*","Copyright 2024 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package reconciler","","import (","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"knative.dev/pkg/controller\"","\t\"slices\"",")","","// PipelineRunInformerFilterFunc returns a filter function","// for PipelineRuns ensuring PipelineRuns are filtered by list of namespaces membership","func PipelineRunInformerFilterFunc(namespaces []string) func(obj interface{}) bool {","\treturn func(obj interface{}) bool {","\t\t// Namespace filter","\t\tif len(namespaces) == 0 {","\t\t\treturn true","\t\t}","\t\tif pr, ok := obj.(*v1.PipelineRun); ok {","\t\t\tif slices.Contains(namespaces, pr.Namespace) {","\t\t\t\treturn true","\t\t\t}","\t\t}","\t\treturn false","\t}","}","","// TaskRunInformerFilterFunc returns a filter function","// for TaskRuns ensuring TaskRuns are filtered by list of namespaces membership","func TaskRunInformerFilterFunc(namespaces []string) func(obj interface{}) bool {","\treturn func(obj interface{}) bool {","\t\t// Namespace filter","\t\tif len(namespaces) == 0 {","\t\t\treturn true","\t\t}","\t\tif tr, ok := obj.(*v1.TaskRun); ok {","\t\t\tif slices.Contains(namespaces, tr.Namespace) {","\t\t\t\treturn true","\t\t\t}","\t\t}","\t\treturn false","\t}","}","","// TaskRunInformerFilterFuncWithOwnership returns a filter function","// for TaskRuns ensuring Ownership by a PipelineRun and filtered by list of namespaces membership and","func TaskRunInformerFilterFuncWithOwnership(namespaces []string) func(obj interface{}) bool {","\treturn func(obj interface{}) bool {","\t\t// Ownership filter","\t\tif !controller.FilterController(\u0026v1.PipelineRun{})(obj) {","\t\t\treturn false","\t\t}","\t\t// Namespace filter","\t\tif len(namespaces) == 0 {","\t\t\treturn true","\t\t}","\t\tif tr, ok := obj.(*v1.TaskRun); ok {","\t\t\tif slices.Contains(namespaces, tr.Namespace) {","\t\t\t\treturn true","\t\t\t}","\t\t}","\t\treturn false","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,2,0,0]},{"id":55,"path":"pkg/reconciler/pipelinerun/controller.go","lines":["/*","Copyright 2021 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pipelinerun","","import (","\t\"context\"","","\t\"github.com/tektoncd/chains/pkg/chains\"","\t\"github.com/tektoncd/chains/pkg/chains/storage\"","\t\"github.com/tektoncd/chains/pkg/config\"","\t\"github.com/tektoncd/chains/pkg/pipelinerunmetrics\"","\t\"github.com/tektoncd/chains/pkg/reconciler\"","\tpipelineclient \"github.com/tektoncd/pipeline/pkg/client/injection/client\"","\tpipelineruninformer \"github.com/tektoncd/pipeline/pkg/client/injection/informers/pipeline/v1/pipelinerun\"","\ttaskruninformer \"github.com/tektoncd/pipeline/pkg/client/injection/informers/pipeline/v1/taskrun\"","\tpipelinerunreconciler \"github.com/tektoncd/pipeline/pkg/client/injection/reconciler/pipeline/v1/pipelinerun\"","\t\"k8s.io/client-go/tools/cache\"","\tkubeclient \"knative.dev/pkg/client/injection/kube/client\"","\t\"knative.dev/pkg/configmap\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/logging\"","","\t_ \"github.com/tektoncd/chains/pkg/chains/formats/all\"",")","","// NewNamespacesScopedController returns a new controller implementation where informer is filtered","// given a list of namespaces","func NewNamespacesScopedController(namespaces []string) func(ctx context.Context, cmw configmap.Watcher) *controller.Impl {","\treturn func(ctx context.Context, cmw configmap.Watcher) *controller.Impl {","\t\tlogger := logging.FromContext(ctx)","\t\tpipelineRunInformer := pipelineruninformer.Get(ctx)","\t\ttaskRunInformer := taskruninformer.Get(ctx)","","\t\tkubeClient := kubeclient.Get(ctx)","\t\tpipelineClient := pipelineclient.Get(ctx)","","\t\tpsSigner := \u0026chains.ObjectSigner{","\t\t\tSecretPath:        SecretPath,","\t\t\tPipelineclientset: pipelineClient,","\t\t\tRecorder:          pipelinerunmetrics.Get(ctx),","\t\t}","","\t\tc := \u0026Reconciler{","\t\t\tPipelineRunSigner: psSigner,","\t\t\tPipelineclientset: pipelineClient,","\t\t\tTaskRunLister:     taskRunInformer.Lister(),","\t\t}","","\t\timpl := pipelinerunreconciler.NewImpl(ctx, c, func(_ *controller.Impl) controller.Options {","\t\t\twatcherStop := make(chan bool)","","\t\t\tcfgStore := config.NewConfigStore(logger, func(_ string, value interface{}) {","\t\t\t\tselect {","\t\t\t\tcase watcherStop \u003c- true:","\t\t\t\t\tlogger.Info(\"sent close event to WatchBackends()...\")","\t\t\t\tdefault:","\t\t\t\t\tlogger.Info(\"could not send close event to WatchBackends()...\")","\t\t\t\t}","","\t\t\t\t// get updated config","\t\t\t\tcfg := *value.(*config.Config)","","\t\t\t\t// get all backends for storing provenance","\t\t\t\tbackends, err := storage.InitializeBackends(ctx, pipelineClient, kubeClient, cfg)","\t\t\t\tif err != nil {","\t\t\t\t\tlogger.Error(err)","\t\t\t\t}","\t\t\t\tpsSigner.Backends = backends","","\t\t\t\tif err := storage.WatchBackends(ctx, watcherStop, psSigner.Backends, cfg); err != nil {","\t\t\t\t\tlogger.Error(err)","\t\t\t\t}","\t\t\t})","","\t\t\t// setup watches for the config names provided by client","\t\t\tcfgStore.WatchConfigs(cmw)","","\t\t\treturn controller.Options{","\t\t\t\t// The chains reconciler shouldn't mutate the pipelinerun's status.","\t\t\t\tSkipStatusUpdates: true,","\t\t\t\tConfigStore:       cfgStore,","\t\t\t\tFinalizerName:     \"chains.tekton.dev/pipelinerun\", // TODO: unique name required?","\t\t\t}","\t\t})","","\t\tc.Tracker = impl.Tracker","","\t\tif _, err := pipelineRunInformer.Informer().AddEventHandler(cache.FilteringResourceEventHandler{","\t\t\tFilterFunc: reconciler.PipelineRunInformerFilterFunc(namespaces),","\t\t\tHandler:    controller.HandleAll(impl.Enqueue),","\t\t}); err != nil {","\t\t\tlogger.Errorf(\"adding event handler for pipelinerun controller's pipelinerun informer encountered error: %v\", err)","\t\t}","","\t\tif _, err := taskRunInformer.Informer().AddEventHandler(cache.FilteringResourceEventHandler{","\t\t\tFilterFunc: reconciler.TaskRunInformerFilterFuncWithOwnership(namespaces),","\t\t\tHandler:    controller.HandleAll(impl.EnqueueControllerOf),","\t\t}); err != nil {","\t\t\tlogger.Errorf(\"adding event handler for pipelinerun controller's taskrun informer encountered error: %v\", err)","\t\t}","","\t\treturn impl","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,0,0,0,2,2,2,2,2,1,1,2,2,2,1,1,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,1,1,0,2,2,2,2,1,1,0,2,0,0]},{"id":56,"path":"pkg/reconciler/pipelinerun/pipelinerun.go","lines":["/*","Copyright 2020 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pipelinerun","","import (","\t\"context\"","\t\"fmt\"","","\tsigning \"github.com/tektoncd/chains/pkg/chains\"","\t\"github.com/tektoncd/chains/pkg/chains/annotations\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"","\tpipelinerunreconciler \"github.com/tektoncd/pipeline/pkg/client/injection/reconciler/pipeline/v1/pipelinerun\"","\tlisters \"github.com/tektoncd/pipeline/pkg/client/listers/pipeline/v1\"","\t\"k8s.io/apimachinery/pkg/api/errors\"","\t\"knative.dev/pkg/logging\"","\tpkgreconciler \"knative.dev/pkg/reconciler\"","\t\"knative.dev/pkg/tracker\"",")","","const (","\t// SecretPath contains the path to the secrets volume that is mounted in.","\tSecretPath = \"/etc/signing-secrets\"",")","","type Reconciler struct {","\tPipelineRunSigner signing.Signer","\tPipelineclientset versioned.Interface","\tTaskRunLister     listers.TaskRunLister","\tTracker           tracker.Interface","}","","// Check that our Reconciler implements pipelinerunreconciler.Interface and pipelinerunreconciler.Finalizer","var _ pipelinerunreconciler.Interface = (*Reconciler)(nil)","var _ pipelinerunreconciler.Finalizer = (*Reconciler)(nil)","","// ReconcileKind  handles a changed or created PipelineRun.","// This is the main entrypoint for chains business logic.","func (r *Reconciler) ReconcileKind(ctx context.Context, pr *v1.PipelineRun) pkgreconciler.Event {","\tlog := logging.FromContext(ctx).With(\"pipelinerun\", fmt.Sprintf(\"%s/%s\", pr.Namespace, pr.Name))","\treturn r.FinalizeKind(logging.WithLogger(ctx, log), pr)","}","","// FinalizeKind implements pipelinerunreconciler.Finalizer","// We utilize finalizers to ensure that we get a crack at signing every pipelinerun","// that we see flowing through the system.  If we don't add a finalizer, it could","// get cleaned up before we see the final state and sign it.","func (r *Reconciler) FinalizeKind(ctx context.Context, pr *v1.PipelineRun) pkgreconciler.Event {","\t// Check to make sure the PipelineRun is finished.","\tif !pr.IsDone() {","\t\tlogging.FromContext(ctx).Infof(\"pipelinerun is still running\")","\t\treturn nil","\t}","\tpro := objects.NewPipelineRunObjectV1(pr)","","\t// Check to see if it has already been signed.","\tif annotations.Reconciled(ctx, r.Pipelineclientset, pro) {","\t\tlogging.FromContext(ctx).Infof(\"pipelinerun has been reconciled\")","\t\treturn nil","\t}","","\t// Get TaskRun names depending on whether embeddedstatus feature is set or not","\tvar trs []string","\tfor _, cr := range pr.Status.ChildReferences {","\t\ttrs = append(trs, cr.Name)","\t}","","\t// Signing both taskruns and pipelineruns causes a race condition when using oci storage","\t// during the push to the registry. This checks the taskruns to ensure they've been reconciled","\t// before attempting to sign the pippelinerun.","\tfor _, name := range trs {","\t\ttr, err := r.TaskRunLister.TaskRuns(pr.Namespace).Get(name)","\t\tif err != nil {","\t\t\tlogging.FromContext(ctx).Errorf(\"Unable to get reconciled status of taskrun %s within pipelinerun\", name)","\t\t\tif errors.IsNotFound(err) {","\t\t\t\t// Since this is an unrecoverable scenario, returning the error would prevent the","\t\t\t\t// finalizer from being removed, thus preventing the PipelineRun from being deleted.","\t\t\t\treturn nil","\t\t\t}","\t\t\treturn err","\t\t}","\t\tif tr == nil {","\t\t\tlogging.FromContext(ctx).Infof(\"taskrun %s within pipelinerun is not found\", name)","\t\t\treturn nil","\t\t}","\t\tif tr.Status.CompletionTime == nil {","\t\t\tlogging.FromContext(ctx).Infof(\"taskrun %s within pipelinerun is not yet finalized: status is not complete\", name)","\t\t\treturn r.trackTaskRun(tr, pr)","\t\t}","\t\treconciled := annotations.Reconciled(ctx, r.Pipelineclientset, objects.NewTaskRunObjectV1(tr))","\t\tif !reconciled {","\t\t\tlogging.FromContext(ctx).Infof(\"taskrun %s within pipelinerun is not yet reconciled\", name)","\t\t\treturn r.trackTaskRun(tr, pr)","\t\t}","\t\tpro.AppendTaskRun(tr)","\t}","","\tif err := r.PipelineRunSigner.Sign(ctx, pro); err != nil {","\t\treturn err","\t}","\treturn nil","}","","func (r *Reconciler) trackTaskRun(tr *v1.TaskRun, pr *v1.PipelineRun) error {","\tref := tracker.Reference{","\t\tAPIVersion: \"tekton.dev/v1\",","\t\tKind:       \"TaskRun\",","\t\tNamespace:  tr.Namespace,","\t\tName:       tr.Name,","\t}","\treturn r.Tracker.TrackReference(ref, pr)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,1,0,2,1,1,1,2,2,2,2,2,2,1,1,1,2,0,0,2,1,1,2,0,0,2,2,2,2,2,2,2,2,2]},{"id":57,"path":"pkg/reconciler/taskrun/controller.go","lines":["/*","Copyright 2021 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package taskrun","","import (","\t\"context\"","","\t\"github.com/tektoncd/chains/pkg/chains\"","\t\"github.com/tektoncd/chains/pkg/chains/storage\"","\t\"github.com/tektoncd/chains/pkg/config\"","\t\"github.com/tektoncd/chains/pkg/reconciler\"","\t\"github.com/tektoncd/chains/pkg/taskrunmetrics\"","\tpipelineclient \"github.com/tektoncd/pipeline/pkg/client/injection/client\"","\ttaskruninformer \"github.com/tektoncd/pipeline/pkg/client/injection/informers/pipeline/v1/taskrun\"","\ttaskrunreconciler \"github.com/tektoncd/pipeline/pkg/client/injection/reconciler/pipeline/v1/taskrun\"","\t\"k8s.io/client-go/tools/cache\"","\tkubeclient \"knative.dev/pkg/client/injection/kube/client\"","\t\"knative.dev/pkg/configmap\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/logging\"","","\t_ \"github.com/tektoncd/chains/pkg/chains/formats/all\"",")","","// NewNamespacesScopedController returns a new controller implementation where informer is filtered","// given a list of namespaces","func NewNamespacesScopedController(namespaces []string) func(ctx context.Context, cmw configmap.Watcher) *controller.Impl {","\treturn func(ctx context.Context, cmw configmap.Watcher) *controller.Impl {","\t\tlogger := logging.FromContext(ctx)","\t\ttaskRunInformer := taskruninformer.Get(ctx)","","\t\tkubeClient := kubeclient.Get(ctx)","\t\tpipelineClient := pipelineclient.Get(ctx)","","\t\ttsSigner := \u0026chains.ObjectSigner{","\t\t\tSecretPath:        SecretPath,","\t\t\tPipelineclientset: pipelineClient,","\t\t\tRecorder:          taskrunmetrics.Get(ctx),","\t\t}","","\t\tc := \u0026Reconciler{","\t\t\tTaskRunSigner:     tsSigner,","\t\t\tPipelineclientset: pipelineClient,","\t\t}","\t\timpl := taskrunreconciler.NewImpl(ctx, c, func(_ *controller.Impl) controller.Options {","\t\t\twatcherStop := make(chan bool)","","\t\t\tcfgStore := config.NewConfigStore(logger, func(_ string, value interface{}) {","\t\t\t\tselect {","\t\t\t\tcase watcherStop \u003c- true:","\t\t\t\t\tlogger.Info(\"sent close event to WatchBackends()...\")","\t\t\t\tdefault:","\t\t\t\t\tlogger.Info(\"could not send close event to WatchBackends()...\")","\t\t\t\t}","","\t\t\t\t// get updated config","\t\t\t\tcfg := *value.(*config.Config)","","\t\t\t\t// get all backends for storing provenance","\t\t\t\tbackends, err := storage.InitializeBackends(ctx, pipelineClient, kubeClient, cfg)","\t\t\t\tif err != nil {","\t\t\t\t\tlogger.Error(err)","\t\t\t\t}","\t\t\t\ttsSigner.Backends = backends","","\t\t\t\tif err := storage.WatchBackends(ctx, watcherStop, tsSigner.Backends, cfg); err != nil {","\t\t\t\t\tlogger.Error(err)","\t\t\t\t}","\t\t\t})","","\t\t\t// setup watches for the config names provided by client","\t\t\tcfgStore.WatchConfigs(cmw)","","\t\t\treturn controller.Options{","\t\t\t\t// The chains reconciler shouldn't mutate the taskrun's status.","\t\t\t\tSkipStatusUpdates: true,","\t\t\t\tConfigStore:       cfgStore,","\t\t\t\tFinalizerName:     \"chains.tekton.dev/taskrun\",","\t\t\t}","\t\t})","","\t\tif _, err := taskRunInformer.Informer().AddEventHandler(cache.FilteringResourceEventHandler{","\t\t\tFilterFunc: reconciler.TaskRunInformerFilterFunc(namespaces),","\t\t\tHandler:    controller.HandleAll(impl.Enqueue),","\t\t}); err != nil {","\t\t\tlogger.Errorf(\"adding event handler for taskrun controller's taskrun informer encountered error: %v\", err)","\t\t}","","\t\treturn impl","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,0,0,0,2,2,2,2,2,1,1,2,2,2,1,1,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,1,1,0,2,0,0]},{"id":58,"path":"pkg/reconciler/taskrun/taskrun.go","lines":["/*","Copyright 2020 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package taskrun","","import (","\t\"context\"","","\tsigning \"github.com/tektoncd/chains/pkg/chains\"","\t\"github.com/tektoncd/chains/pkg/chains/annotations\"","\t\"github.com/tektoncd/chains/pkg/chains/objects\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"","\ttaskrunreconciler \"github.com/tektoncd/pipeline/pkg/client/injection/reconciler/pipeline/v1/taskrun\"","\t\"knative.dev/pkg/logging\"","\tpkgreconciler \"knative.dev/pkg/reconciler\"",")","","const (","\t// SecretPath contains the path to the secrets volume that is mounted in.","\tSecretPath = \"/etc/signing-secrets\"",")","","type Reconciler struct {","\tTaskRunSigner     signing.Signer","\tPipelineclientset versioned.Interface","}","","// Check that our Reconciler implements taskrunreconciler.Interface and taskrunreconciler.Finalizer","var _ taskrunreconciler.Interface = (*Reconciler)(nil)","var _ taskrunreconciler.Finalizer = (*Reconciler)(nil)","","// ReconcileKind  handles a changed or created TaskRun.","// This is the main entrypoint for chains business logic.","func (r *Reconciler) ReconcileKind(ctx context.Context, tr *v1.TaskRun) pkgreconciler.Event {","\treturn r.FinalizeKind(ctx, tr)","}","","// 01-Jul-2025; this is a temp solution util we consider the old finalizer name no longer used.","// removeOldFinalizerIfExists removes the old finalizer from the TaskRun if it exists.","func removeOldFinalizerIfExists(tr *v1.TaskRun) {","\tconst oldFinalizerName = \"chains.tekton.dev\"","\tfor i, f := range tr.ObjectMeta.Finalizers {","\t\tif f == oldFinalizerName {","\t\t\ttr.ObjectMeta.Finalizers = append(tr.ObjectMeta.Finalizers[:i], tr.ObjectMeta.Finalizers[i+1:]...)","\t\t\tbreak","\t\t}","\t}","}","","// FinalizeKind implements taskrunreconciler.Finalizer","// We utilize finalizers to ensure that we get a crack at signing every taskrun","// that we see flowing through the system.  If we don't add a finalizer, it could","// get cleaned up before we see the final state and sign it.","func (r *Reconciler) FinalizeKind(ctx context.Context, tr *v1.TaskRun) pkgreconciler.Event {","\t// Check to make sure the TaskRun is finished.","\tif !tr.IsDone() {","\t\tlogging.FromContext(ctx).Infof(\"taskrun %s/%s is still running\", tr.Namespace, tr.Name)","\t\treturn nil","\t}","","\tobj := objects.NewTaskRunObjectV1(tr)","","\t// Check to see if it has already been signed.","\tif annotations.Reconciled(ctx, r.Pipelineclientset, obj) {","\t\tlogging.FromContext(ctx).Infof(\"taskrun %s/%s has been reconciled\", tr.Namespace, tr.Name)","\t\tremoveOldFinalizerIfExists(tr)","\t\treturn nil","\t}","","\tif err := r.TaskRunSigner.Sign(ctx, obj); err != nil {","\t\treturn err","\t}","\tremoveOldFinalizerIfExists(tr)","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,2,2,2,1,1,1,0,0,0,0,0,0,0,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,0,2,1,1,2,2,0]},{"id":59,"path":"pkg/taskrunmetrics/fake/fake.go","lines":["/*","Copyright 2024 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package fake","","import (","\t\"context\"","","\t\"github.com/tektoncd/chains/pkg/taskrunmetrics\"","\t_ \"github.com/tektoncd/pipeline/pkg/client/injection/informers/pipeline/v1/taskrun/fake\" // Make sure the fake taskrun informer is setup","\t\"k8s.io/client-go/rest\"","\t\"knative.dev/pkg/injection\"",")","","func init() {","\tinjection.Fake.RegisterClient(func(ctx context.Context, _ *rest.Config) context.Context { return taskrunmetrics.WithClient(ctx) })","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0]},{"id":60,"path":"pkg/taskrunmetrics/injection.go","lines":["/*","Copyright 2024 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package taskrunmetrics","","import (","\t\"context\"","","\t\"k8s.io/client-go/rest\"","\t\"knative.dev/pkg/injection\"","\t\"knative.dev/pkg/logging\"",")","","func init() {","\tinjection.Default.RegisterClient(func(ctx context.Context, _ *rest.Config) context.Context { return WithClient(ctx) })","}","","// RecorderKey is used for associating the Recorder inside the context.Context.","type RecorderKey struct{}","","// WithClient adds a metrics recorder to the given context","func WithClient(ctx context.Context) context.Context {","\trec, err := NewRecorder(ctx)","\tif err != nil {","\t\tlogging.FromContext(ctx).Errorf(\"Failed to create taskrun metrics recorder %v\", err)","\t}","\treturn context.WithValue(ctx, RecorderKey{}, rec)","}","","// Get extracts the taskrunmetrics.Recorder from the context.","func Get(ctx context.Context) *Recorder {","\tuntyped := ctx.Value(RecorderKey{})","\tif untyped == nil {","\t\tlogging.FromContext(ctx).Panic(\"Unable to fetch *taskrunmetrics.Recorder from context.\")","\t}","\treturn untyped.(*Recorder)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,0,0,0,0,0,0,2,2,2,1,1,2,0,0,0,2,2,2,1,1,2,0]},{"id":61,"path":"pkg/taskrunmetrics/metrics.go","lines":["/*","Copyright 2024 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package taskrunmetrics","","import (","\t\"context\"","\t\"sync\"","","\t\"go.opencensus.io/stats\"","\t\"go.opencensus.io/stats/view\"","\t\"go.opencensus.io/tag\"","\t\"knative.dev/pkg/logging\"","\t\"knative.dev/pkg/metrics\"","","\tcommon \"github.com/tektoncd/chains/pkg/metrics\"",")","","const (","\ttaskRunSignedName     common.Metric = \"taskrun_sign_created_total\"","\ttaskRunSignedDesc     string        = \"Total number of signed messages for taskruns\"","\ttaskRunUploadedName   common.Metric = \"taskrun_payload_uploaded_total\"","\ttaskRunUploadedDesc   string        = \"Total number of uploaded payloads for taskruns\"","\ttaskRunStoredName     common.Metric = \"taskrun_payload_stored_total\"","\ttaskRunStoredDesc     string        = \"Total number of stored payloads for taskruns\"","\ttaskRunMarkedName     common.Metric = \"taskrun_marked_signed_total\"","\ttaskRunMarkedDesc     string        = \"Total number of objects marked as signed for taskruns\"","\ttaskRunErrorCountName common.Metric = \"taskrun_signing_failures_total\"","\ttaskRunErrorCountDesc string        = \"Total number of TaskRun signing failures\"",")","","var (","\tsgCountView *view.View","","\tsgCount = stats.Float64(string(taskRunSignedName),","\t\ttaskRunSignedDesc,","\t\tstats.UnitDimensionless)","","\tplCount = stats.Float64(string(taskRunUploadedName),","\t\ttaskRunUploadedDesc,","\t\tstats.UnitDimensionless)","","\tplCountView *view.View","","\tstCount = stats.Float64(string(taskRunStoredName),","\t\ttaskRunStoredDesc,","\t\tstats.UnitDimensionless)","","\tstCountView *view.View","","\tmrCount = stats.Float64(string(taskRunMarkedName),","\t\ttaskRunMarkedDesc,","\t\tstats.UnitDimensionless)","","\tmrCountView *view.View","","\ttaskRunErrorCount = stats.Float64(","\t\tstring(taskRunErrorCountName),","\t\ttaskRunErrorCountDesc,","\t\tstats.UnitDimensionless,","\t)","","\terrorCountView *view.View","","\terrorTypeKey, _ = tag.NewKey(\"error_type\")",")","","var _ common.Recorder = \u0026Recorder{}","","// Recorder is used to actually record TaskRun metrics.","type Recorder struct {","\tinitialized bool","}","","// We cannot register the view multiple times, so NewRecorder lazily","// initializes this singleton and returns the same recorder across any","// subsequent invocations.","var (","\tonce sync.Once","\tr    *Recorder",")","","// NewRecorder creates a new metrics recorder instance","// to log the TaskRun related metrics.","func NewRecorder(ctx context.Context) (*Recorder, error) {","\tvar errRegistering error","\tlogger := logging.FromContext(ctx)","\tonce.Do(func() {","\t\tr = \u0026Recorder{","\t\t\tinitialized: true,","\t\t}","\t\terrRegistering = viewRegister()","\t\tif errRegistering != nil {","\t\t\tr.initialized = false","\t\t\tlogger.Errorf(\"View Register Failed \", r.initialized)","\t\t\treturn","\t\t}","\t})","","\treturn r, errRegistering","}","","func viewRegister() error {","","\tsgCountView = \u0026view.View{","\t\tDescription: sgCount.Description(),","\t\tMeasure:     sgCount,","\t\tAggregation: view.Count(),","\t}","","\tplCountView = \u0026view.View{","\t\tDescription: plCount.Description(),","\t\tMeasure:     plCount,","\t\tAggregation: view.Count(),","\t}","","\tstCountView = \u0026view.View{","\t\tDescription: stCount.Description(),","\t\tMeasure:     stCount,","\t\tAggregation: view.Count(),","\t}","","\tmrCountView = \u0026view.View{","\t\tDescription: mrCount.Description(),","\t\tMeasure:     mrCount,","\t\tAggregation: view.Count(),","\t}","","\terrorCountView = \u0026view.View{","\t\tDescription: taskRunErrorCount.Description(),","\t\tMeasure:     taskRunErrorCount,","\t\tTagKeys:     []tag.Key{errorTypeKey},","\t\tAggregation: view.Count(),","\t}","","\treturn view.Register(","\t\tsgCountView,","\t\tplCountView,","\t\tstCountView,","\t\tmrCountView,","\t\terrorCountView,","\t)","}","","// RecordCountMetrics implements github.com/tektoncd/chains/pkg/metrics.Recorder.RecordCountMetrics","func (r *Recorder) RecordCountMetrics(ctx context.Context, metricType common.Metric) {","\tlogger := logging.FromContext(ctx)","","\tif !r.initialized {","\t\tlogger.Errorf(\"ignoring the metrics recording as recorder not initialized \")","\t}","\tswitch mt := metricType; mt {","\tcase common.SignedMessagesCount:","\t\tr.countMetrics(ctx, sgCount)","\tcase common.PayloadUploadeCount:","\t\tr.countMetrics(ctx, plCount)","\tcase common.SignsStoredCount:","\t\tr.countMetrics(ctx, stCount)","\tcase common.MarkedAsSignedCount:","\t\tr.countMetrics(ctx, mrCount)","\tdefault:","\t\tlogger.Errorf(\"Ignoring the metrics recording as valid Metric type matching %v was not found\", mt)","\t}","}","","func (r *Recorder) countMetrics(ctx context.Context, measure *stats.Float64Measure) {","\tmetrics.Record(ctx, measure.M(1))","}","","// RecordErrorMetric records a TaskRun signing failure with a given error type tag.","func (r *Recorder) RecordErrorMetric(ctx context.Context, errType common.MetricErrorType) {","\t// Add the error_type tag to the context.","\tctx, _ = tag.New(ctx, tag.Upsert(errorTypeKey, string(errType)))","\tmetrics.Record(ctx, taskRunErrorCount.M(1))","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,1,1,1,1,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,0,0,2,2,2,0,0,2,2,2,2,2]}],"tree":{"name":".","type":"dir","children":[{"name":"pkg","type":"dir","children":[{"name":"artifacts","type":"dir","children":[{"name":"signable.go","type":"file","fileId":0},{"name":"structured.go","type":"file","fileId":1}]},{"name":"chains","type":"dir","children":[{"name":"annotations","type":"dir","children":[{"name":"annotations.go","type":"file","fileId":2}]},{"name":"formats","type":"dir","children":[{"name":"simple","type":"dir","children":[{"name":"simple.go","type":"file","fileId":4}]},{"name":"slsa","type":"dir","children":[{"name":"attest","type":"dir","children":[{"name":"attest.go","type":"file","fileId":5}]},{"name":"extract","type":"dir","children":[{"name":"extract.go","type":"file","fileId":6}]},{"name":"internal","type":"dir","children":[{"name":"artifact","type":"dir","children":[{"name":"append.go","type":"file","fileId":7}]},{"name":"build_definition","type":"dir","children":[{"name":"build_definition.go","type":"file","fileId":8}]},{"name":"compare","type":"dir","children":[{"name":"slsacompare.go","type":"file","fileId":9}]},{"name":"external_parameters","type":"dir","children":[{"name":"external_parameters.go","type":"file","fileId":10}]},{"name":"internal_parameters","type":"dir","children":[{"name":"internal_parameters.go","type":"file","fileId":11}]},{"name":"material","type":"dir","children":[{"name":"material.go","type":"file","fileId":12}]},{"name":"metadata","type":"dir","children":[{"name":"metadata.go","type":"file","fileId":13}]},{"name":"provenance","type":"dir","children":[{"name":"provenance.go","type":"file","fileId":14}]},{"name":"resolved_dependencies","type":"dir","children":[{"name":"resolved_dependencies.go","type":"file","fileId":15}]},{"name":"results","type":"dir","children":[{"name":"results.go","type":"file","fileId":16}]}]},{"name":"v1","type":"dir","children":[{"name":"internal","type":"dir","children":[{"name":"protos","type":"dir","children":[{"name":"protos.go","type":"file","fileId":17}]}]},{"name":"pipelinerun","type":"dir","children":[{"name":"pipelinerun.go","type":"file","fileId":19}]},{"name":"taskrun","type":"dir","children":[{"name":"buildconfig.go","type":"file","fileId":20},{"name":"taskrun.go","type":"file","fileId":21}]},{"name":"intotoite6.go","type":"file","fileId":18}]},{"name":"v2alpha3","type":"dir","children":[{"name":"internal","type":"dir","children":[{"name":"pipelinerun","type":"dir","children":[{"name":"pipelinerun.go","type":"file","fileId":22}]},{"name":"taskrun","type":"dir","children":[{"name":"taskrun.go","type":"file","fileId":23}]}]},{"name":"slsav2.go","type":"file","fileId":24}]},{"name":"v2alpha4","type":"dir","children":[{"name":"internal","type":"dir","children":[{"name":"pipelinerun","type":"dir","children":[{"name":"pipelinerun.go","type":"file","fileId":25}]},{"name":"taskrun","type":"dir","children":[{"name":"taskrun.go","type":"file","fileId":26}]}]},{"name":"slsav2.go","type":"file","fileId":27}]}]},{"name":"format.go","type":"file","fileId":3}]},{"name":"objects","type":"dir","children":[{"name":"objects.go","type":"file","fileId":28}]},{"name":"signing","type":"dir","children":[{"name":"kms","type":"dir","children":[{"name":"kms.go","type":"file","fileId":31}]},{"name":"x509","type":"dir","children":[{"name":"fsprovider.go","type":"file","fileId":33},{"name":"x509.go","type":"file","fileId":34}]},{"name":"wrap.go","type":"file","fileId":32}]},{"name":"storage","type":"dir","children":[{"name":"archivista","type":"dir","children":[{"name":"archivista.go","type":"file","fileId":35}]},{"name":"docdb","type":"dir","children":[{"name":"docdb.go","type":"file","fileId":36}]},{"name":"gcs","type":"dir","children":[{"name":"gcs.go","type":"file","fileId":37}]},{"name":"grafeas","type":"dir","children":[{"name":"grafeas.go","type":"file","fileId":38}]},{"name":"oci","type":"dir","children":[{"name":"attestation.go","type":"file","fileId":39},{"name":"legacy.go","type":"file","fileId":40},{"name":"options.go","type":"file","fileId":41},{"name":"simple.go","type":"file","fileId":42}]},{"name":"pubsub","type":"dir","children":[{"name":"pubsub.go","type":"file","fileId":43}]},{"name":"tekton","type":"dir","children":[{"name":"tekton.go","type":"file","fileId":45}]},{"name":"storage.go","type":"file","fileId":44}]},{"name":"rekor.go","type":"file","fileId":29},{"name":"signing.go","type":"file","fileId":30},{"name":"verifier.go","type":"file","fileId":46}]},{"name":"config","type":"dir","children":[{"name":"config.go","type":"file","fileId":47},{"name":"store.go","type":"file","fileId":48}]},{"name":"internal","type":"dir","children":[{"name":"mocksigner","type":"dir","children":[{"name":"mocksigner.go","type":"file","fileId":49}]},{"name":"objectloader","type":"dir","children":[{"name":"objectloader.go","type":"file","fileId":50}]}]},{"name":"pipelinerunmetrics","type":"dir","children":[{"name":"fake","type":"dir","children":[{"name":"fake.go","type":"file","fileId":51}]},{"name":"injection.go","type":"file","fileId":52},{"name":"metrics.go","type":"file","fileId":53}]},{"name":"reconciler","type":"dir","children":[{"name":"pipelinerun","type":"dir","children":[{"name":"controller.go","type":"file","fileId":55},{"name":"pipelinerun.go","type":"file","fileId":56}]},{"name":"taskrun","type":"dir","children":[{"name":"controller.go","type":"file","fileId":57},{"name":"taskrun.go","type":"file","fileId":58}]},{"name":"filter.go","type":"file","fileId":54}]},{"name":"taskrunmetrics","type":"dir","children":[{"name":"fake","type":"dir","children":[{"name":"fake.go","type":"file","fileId":59}]},{"name":"injection.go","type":"file","fileId":60},{"name":"metrics.go","type":"file","fileId":61}]}]}]},"summary":{"totalLines":4657,"coveredLines":3085,"percent":66.24436332402834}};
    </script>
    <script>
      window.COVERAGE_CONFIG = {"syntaxEnabled":true};
    </script>
    <script>
      (function() {
  'use strict';

  const data = window.COVERAGE_DATA;
  const config = window.COVERAGE_CONFIG || { syntaxEnabled: true };

  // State
  let currentFileId = null;
  let searchQuery = '';
  let contentSearchQuery = '';
  let matches = [];
  let currentMatchIndex = -1;
  let expandedDirs = new Set();
  let syntaxHighlightEnabled = config.syntaxEnabled;
  let sortMode = 'name'; // 'name' or 'coverage'
  let anchorLine = null;        // First line clicked (anchor for shift-select)
  let selectedRange = null;     // { start: N, end: M } or null

  // DOM elements
  const fileTree = document.getElementById('file-tree');
  const viewport = document.getElementById('viewport');
  const filePath = document.getElementById('file-path');
  const summary = document.getElementById('summary');
  const searchInput = document.getElementById('search-input');
  const contentSearch = document.getElementById('content-search');
  const matchInfo = document.getElementById('match-info');
  const prevMatch = document.getElementById('prev-match');
  const nextMatch = document.getElementById('next-match');
  const themeToggle = document.getElementById('theme-toggle');
  const syntaxToggle = document.getElementById('syntax-toggle');
  const helpModal = document.getElementById('help-modal');
  const closeHelp = document.getElementById('close-help');
  const helpToggle = document.getElementById('help-toggle');

  // Coverage cache: fileId -> percentage
  let coverageCache = new Map();

  function initCoverageCache() {
    data.files.forEach((file, idx) => {
      coverageCache.set(idx, calculateFileCoverage(idx));
    });
  }

  function calculateFileCoverage(fileId) {
    const file = data.files[fileId];
    let totalStatements = 0;
    let coveredStatements = 0;

    file.coverage.forEach(cov => {
      if (cov > 0) totalStatements++;
      if (cov === 2) coveredStatements++;
    });

    return totalStatements === 0 ? 0 : (coveredStatements / totalStatements) * 100;
  }

  function calculateDirectoryCoverage(node) {
    if (node.type === 'file') {
      return coverageCache.get(node.fileId) || 0;
    }

    let totalCoverage = 0;
    let fileCount = 0;

    node.children?.forEach(child => {
      const childCov = calculateDirectoryCoverage(child);
      totalCoverage += childCov;
      fileCount++;
    });

    return fileCount === 0 ? 0 : totalCoverage / fileCount;
  }

  function sortTreeNodes(node, mode) {
    if (!node.children || node.children.length === 0) return node;

    // Deep copy to avoid mutating original
    const sorted = { ...node };
    sorted.children = [...node.children].map(child => sortTreeNodes(child, mode));

    // Sort children
    sorted.children.sort((a, b) => {
      // Directories always first
      if (a.type !== b.type) return a.type === 'dir' ? -1 : 1;

      if (mode === 'coverage') {
        const aCov = calculateDirectoryCoverage(a);
        const bCov = calculateDirectoryCoverage(b);
        console.log('Sorting:', a.name, '('+aCov.toFixed(1)+'%) vs', b.name, '('+bCov.toFixed(1)+'%)', '=', bCov - aCov);
        // Descending: high coverage first
        return aCov !== bCov ? bCov - aCov : a.name.localeCompare(b.name);
      }

      return a.name.localeCompare(b.name);
    });

    return sorted;
  }

  // Initialize
  function init() {
    initCoverageCache();
    loadSortPreference();
    renderSummary();
    renderTree();
    setupEventListeners();
    loadTheme();
    loadSyntaxPreference();

    // Check for deep link hash first, otherwise select first file
    if (!navigateToHash() && data.files.length > 0) {
      selectFile(0);
    }

    // Listen for hash changes (browser back/forward)
    window.addEventListener('hashchange', navigateToHash);
  }

  // Deep linking: parse URL hash
  function parseHash() {
    const hash = window.location.hash.slice(1);
    if (!hash) return null;

    const match = hash.match(/^file-(\d+)(?::line-(\d+)(?:-(\d+))?)?$/);
    if (!match) return null;

    return {
      fileId: parseInt(match[1], 10),
      lineStart: match[2] ? parseInt(match[2], 10) : null,
      lineEnd: match[3] ? parseInt(match[3], 10) : null
    };
  }

  // Deep linking: navigate to hash location
  function navigateToHash() {
    const target = parseHash();
    if (!target) return false;

    if (target.fileId < 0 || target.fileId >= data.files.length) return false;

    selectFile(target.fileId);

    if (target.lineStart) {
      requestAnimationFrame(() => {
        const lineEnd = target.lineEnd || target.lineStart;
        anchorLine = target.lineStart;
        selectedRange = { start: target.lineStart, end: lineEnd };
        selectLineRange(target.lineStart, lineEnd);
        scrollToLine(target.lineStart);
      });
    }

    return true;
  }

  // Deep linking: scroll to and highlight a line
  function scrollToLine(lineNum) {
    const lineEl = document.querySelector('.code-line[data-line="' + lineNum + '"]');
    if (!lineEl) return;

    lineEl.scrollIntoView({ behavior: 'smooth', block: 'center' });
  }

  // Clear all selected lines
  function clearLineSelection() {
    document.querySelectorAll('.code-line.selected-line').forEach(el => {
      el.classList.remove('selected-line');
    });
  }

  // Select a range of lines (inclusive)
  function selectLineRange(start, end) {
    clearLineSelection();
    const minLine = Math.min(start, end);
    const maxLine = Math.max(start, end);
    for (let i = minLine; i <= maxLine; i++) {
      const lineEl = document.querySelector('.code-line[data-line="' + i + '"]');
      if (lineEl) {
        lineEl.classList.add('selected-line');
      }
    }
  }

  // Deep linking: update URL hash
  function updateHash(fileId, lineStart, lineEnd) {
    let hash = 'file-' + fileId;
    if (lineStart) {
      hash += ':line-' + lineStart;
      if (lineEnd && lineEnd !== lineStart) {
        // Normalise so start < end
        const minLine = Math.min(lineStart, lineEnd);
        const maxLine = Math.max(lineStart, lineEnd);
        hash = 'file-' + fileId + ':line-' + minLine + '-' + maxLine;
      }
    }
    history.replaceState(null, '', '#' + hash);
  }

  function renderSummary() {
    // Build summary safely using DOM methods
    summary.textContent = '';
    const span = document.createElement('span');
    span.className = 'percent';
    span.textContent = data.summary.percent.toFixed(1) + '%';
    summary.appendChild(span);
    summary.appendChild(document.createTextNode(
      ' coverage (' + data.summary.coveredLines + '/' + data.summary.totalLines + ' lines)'
    ));
  }

  function renderTree() {
    fileTree.textContent = '';
    // Auto-expand all top-level directories
    if (data.tree.children && data.tree.children.length > 0) {
      data.tree.children.forEach(child => {
        if (child.type === 'dir') {
          expandedDirs.add(getNodePath(child, 0));
        }
      });
    }
    const sortedTree = sortTreeNodes(data.tree, sortMode);
    renderNode(sortedTree, fileTree, 0);
  }

  function renderNode(node, container, depth) {
    if (node.name === '.' && node.type === 'dir') {
      // Root node, render children directly
      node.children.forEach(child => renderNode(child, container, depth));
      return;
    }

    const nodeEl = document.createElement('div');
    nodeEl.className = 'tree-node';
    nodeEl.dataset.name = node.name.toLowerCase();

    const item = document.createElement('div');
    item.className = 'tree-item';
    item.style.setProperty('--depth', depth);

    const icon = document.createElement('span');
    icon.className = 'icon';

    const name = document.createElement('span');
    name.className = 'name';
    name.textContent = node.name;

    if (node.type === 'dir') {
      const dirPath = getNodePath(node, depth);
      icon.textContent = expandedDirs.has(dirPath) ? '\u25BC' : '\u25B6';
      if (expandedDirs.has(dirPath)) {
        nodeEl.classList.add('expanded');
      }

      item.addEventListener('click', (e) => {
        e.stopPropagation();
        toggleDir(nodeEl, dirPath, icon);
      });

      item.appendChild(icon);
      item.appendChild(name);

      // Add coverage badge to all directories
      const badge = document.createElement('span');
      badge.className = 'coverage-badge';
      badge.textContent = calculateDirectoryCoverage(node).toFixed(1) + '%';
      item.appendChild(badge);

      nodeEl.appendChild(item);

      if (node.children && node.children.length > 0) {
        const children = document.createElement('div');
        children.className = 'tree-children';
        node.children.forEach(child => renderNode(child, children, depth + 1));
        nodeEl.appendChild(children);
      }
    } else {
      icon.textContent = '\uD83D\uDCC4';
      nodeEl.dataset.fileId = node.fileId;

      item.addEventListener('click', (e) => {
        e.stopPropagation();
        selectFile(node.fileId);
      });

      item.appendChild(icon);
      item.appendChild(name);

      // Add coverage badge to files
      const badge = document.createElement('span');
      badge.className = 'coverage-badge';
      badge.textContent = calculateDirectoryCoverage(node).toFixed(1) + '%';
      item.appendChild(badge);

      nodeEl.appendChild(item);
    }

    container.appendChild(nodeEl);
  }

  function getNodePath(node, depth) {
    return node.name + '_' + depth;
  }

  function toggleDir(nodeEl, path, icon) {
    if (nodeEl.classList.contains('expanded')) {
      nodeEl.classList.remove('expanded');
      expandedDirs.delete(path);
      icon.textContent = '\u25B6';
    } else {
      nodeEl.classList.add('expanded');
      expandedDirs.add(path);
      icon.textContent = '\u25BC';
    }
  }

  function selectFile(fileId) {
    currentFileId = fileId;
    matches = [];
    currentMatchIndex = -1;
    matchInfo.textContent = '';
    contentSearch.value = '';
    contentSearchQuery = '';
    anchorLine = null;
    selectedRange = null;

    // Update selection in tree
    document.querySelectorAll('.tree-item.selected').forEach(el => {
      el.classList.remove('selected');
    });
    const selected = document.querySelector('[data-file-id="' + fileId + '"] .tree-item');
    if (selected) {
      selected.classList.add('selected');
    }

    const file = data.files[fileId];
    if (!file) return;

    filePath.textContent = file.path;
    renderCode(file);

    // Update URL hash for deep linking
    updateHash(fileId, null);
  }

  function renderCode(file) {
    viewport.textContent = '';

    if (!file.lines || file.lines.length === 0) {
      const empty = document.createElement('div');
      empty.className = 'empty-state';
      const iconDiv = document.createElement('div');
      iconDiv.className = 'icon';
      iconDiv.textContent = '\uD83D\uDCED';
      const textDiv = document.createElement('div');
      textDiv.textContent = 'No content';
      empty.appendChild(iconDiv);
      empty.appendChild(textDiv);
      viewport.appendChild(empty);
      return;
    }

    const container = document.createElement('div');
    container.className = 'code-container';

    file.lines.forEach((line, idx) => {
      const lineEl = document.createElement('div');
      lineEl.className = 'code-line';
      lineEl.dataset.line = idx + 1;

      const cov = file.coverage[idx];
      if (cov === 2) {
        lineEl.classList.add('covered');
      } else if (cov === 1) {
        lineEl.classList.add('uncovered');
      }

      const gutter = document.createElement('div');
      gutter.className = 'gutter';

      const lineNum = document.createElement('div');
      lineNum.className = 'line-number';
      lineNum.textContent = idx + 1;
      lineNum.title = 'Click to select line, Shift+Click for range';

      // Add click handler for line number deep linking
      const lineNumber = idx + 1;
      lineNum.addEventListener('click', (e) => {
        e.stopPropagation();

        if (e.shiftKey && anchorLine !== null) {
          // Shift-click: select range from anchor to clicked line
          const start = Math.min(anchorLine, lineNumber);
          const end = Math.max(anchorLine, lineNumber);
          selectedRange = { start: start, end: end };
          selectLineRange(start, end);
          updateHash(currentFileId, start, end);
        } else {
          // Regular click: set anchor and select single line
          anchorLine = lineNumber;
          selectedRange = { start: lineNumber, end: lineNumber };
          selectLineRange(lineNumber, lineNumber);
          updateHash(currentFileId, lineNumber, null);
        }
      });

      const content = document.createElement('div');
      content.className = 'line-content';
      content.textContent = line || ' ';

      lineEl.appendChild(gutter);
      lineEl.appendChild(lineNum);
      lineEl.appendChild(content);
      container.appendChild(lineEl);
    });

    viewport.appendChild(container);

    // Apply syntax highlighting after rendering if enabled
    if (syntaxHighlightEnabled) {
      applySyntaxHighlighting();
    }
  }

  function setupEventListeners() {
    // File search
    let searchTimeout;
    searchInput.addEventListener('input', (e) => {
      clearTimeout(searchTimeout);
      searchTimeout = setTimeout(() => {
        searchQuery = e.target.value.toLowerCase();
        filterTree();
      }, 300);
    });

    // Content search
    let contentTimeout;
    contentSearch.addEventListener('input', (e) => {
      clearTimeout(contentTimeout);
      contentTimeout = setTimeout(() => {
        contentSearchQuery = e.target.value;
        searchInFile();
      }, 300);
    });

    contentSearch.addEventListener('keydown', (e) => {
      if (e.key === 'Enter') {
        if (e.shiftKey) {
          goToPrevMatch();
        } else {
          goToNextMatch();
        }
      }
    });

    prevMatch.addEventListener('click', goToPrevMatch);
    nextMatch.addEventListener('click', goToNextMatch);

    // Theme toggle
    themeToggle.addEventListener('click', toggleTheme);

    // Syntax toggle
    syntaxToggle.addEventListener('click', toggleSyntax);

    // Sort controls
    const sortButtons = document.querySelectorAll('.sort-btn');
    console.log('Found', sortButtons.length, 'sort buttons');
    sortButtons.forEach(btn => {
      console.log('Attaching click handler to button:', btn.dataset.sort);
      btn.addEventListener('click', () => {
        console.log('Sort button clicked:', btn.dataset.sort);
        changeSortMode(btn.dataset.sort);
      });
    });

    // Keyboard shortcuts
    document.addEventListener('keydown', (e) => {
      if ((e.ctrlKey || e.metaKey) && e.key === 'f' && currentFileId !== null) {
        e.preventDefault();
        contentSearch.focus();
      }
      if ((e.ctrlKey || e.metaKey) && e.key === 'p') {
        e.preventDefault();
        searchInput.focus();
      }
      // Help modal
      if (e.key === '?' && !e.ctrlKey && !e.metaKey) {
        e.preventDefault();
        showHelp();
      }
      if (e.key === 'Escape') {
        // Exit search if focused
        if (document.activeElement === searchInput) {
          searchInput.value = '';
          searchQuery = '';
          filterTree();
          searchInput.blur();
          viewport.focus();
          return;
        }
        if (document.activeElement === contentSearch) {
          contentSearch.value = '';
          contentSearchQuery = '';
          matchInfo.textContent = '';
          matches = [];
          currentMatchIndex = -1;
          if (currentFileId !== null) {
            renderCode(data.files[currentFileId]);
          }
          contentSearch.blur();
          viewport.focus();
          return;
        }
        hideHelp();
      }
    });

    closeHelp.addEventListener('click', hideHelp);
    helpToggle.addEventListener('click', showHelp);
    helpModal.addEventListener('click', (e) => {
      if (e.target === helpModal) hideHelp();
    });
  }

  function filterTree() {
    const nodes = document.querySelectorAll('.tree-node');

    if (!searchQuery) {
      nodes.forEach(n => n.classList.remove('hidden'));
      return;
    }

    nodes.forEach(node => {
      const name = node.dataset.name || '';
      const fileId = node.dataset.fileId;

      if (fileId !== undefined) {
        const file = data.files[parseInt(fileId)];
        const matchesQuery = file && file.path.toLowerCase().includes(searchQuery);
        node.classList.toggle('hidden', !matchesQuery);
      } else {
        const hasVisibleChild = Array.from(node.querySelectorAll('[data-file-id]')).some(f => {
          const fid = parseInt(f.dataset.fileId);
          const file = data.files[fid];
          return file && file.path.toLowerCase().includes(searchQuery);
        });
        node.classList.toggle('hidden', !hasVisibleChild);
        if (hasVisibleChild && searchQuery) {
          node.classList.add('expanded');
          const icon = node.querySelector('.icon');
          if (icon && icon.textContent === '\u25B6') {
            icon.textContent = '\u25BC';
          }
        }
      }
    });
  }

  function searchInFile() {
    matches = [];
    currentMatchIndex = -1;

    // Re-render code to clear highlights
    if (currentFileId !== null) {
      const file = data.files[currentFileId];
      if (file) {
        renderCode(file);
      }
    }

    if (!contentSearchQuery || currentFileId === null) {
      matchInfo.textContent = '';
      return;
    }

    const file = data.files[currentFileId];
    if (!file) return;

    const query = contentSearchQuery.toLowerCase();

    file.lines.forEach((line, idx) => {
      const text = line || '';
      const lowerText = text.toLowerCase();
      let pos = 0;
      let matchIndex;

      while ((matchIndex = lowerText.indexOf(query, pos)) !== -1) {
        matches.push({ line: idx, start: matchIndex, length: query.length });
        pos = matchIndex + 1;
      }
    });

    if (matches.length > 0) {
      highlightMatches();
      currentMatchIndex = 0;
      scrollToMatch(0);
      updateMatchInfo();
    } else {
      matchInfo.textContent = 'No matches';
    }
  }

  function highlightMatches() {
    const file = data.files[currentFileId];
    if (!file) return;

    const lineEls = document.querySelectorAll('.code-line');

    // Group matches by line
    const matchesByLine = {};
    matches.forEach((m, idx) => {
      if (!matchesByLine[m.line]) matchesByLine[m.line] = [];
      matchesByLine[m.line].push({ ...m, idx });
    });

    Object.keys(matchesByLine).forEach(lineIdx => {
      const lineEl = lineEls[parseInt(lineIdx)];
      if (!lineEl) return;

      const content = lineEl.querySelector('.line-content');
      if (!content) return;

      const text = file.lines[parseInt(lineIdx)] || '';
      const lineMatches = matchesByLine[lineIdx].sort((a, b) => a.start - b.start);

      // Build content using DOM nodes for safety
      content.textContent = '';
      let lastEnd = 0;

      lineMatches.forEach(m => {
        // Text before match
        if (m.start > lastEnd) {
          content.appendChild(document.createTextNode(text.substring(lastEnd, m.start)));
        }
        // Match span
        const span = document.createElement('span');
        span.className = 'match-highlight';
        span.dataset.matchIdx = m.idx;
        span.textContent = text.substring(m.start, m.start + m.length);
        content.appendChild(span);
        lastEnd = m.start + m.length;
      });

      // Text after last match
      if (lastEnd < text.length) {
        content.appendChild(document.createTextNode(text.substring(lastEnd)));
      }

      // Handle empty line
      if (content.childNodes.length === 0) {
        content.textContent = ' ';
      }
    });
  }

  function scrollToMatch(idx) {
    document.querySelectorAll('.current-match').forEach(el => {
      el.classList.remove('current-match');
    });

    const matchEl = document.querySelector('[data-match-idx="' + idx + '"]');
    if (matchEl) {
      matchEl.classList.add('current-match');
      matchEl.scrollIntoView({ behavior: 'smooth', block: 'center' });
    }
  }

  function updateMatchInfo() {
    if (matches.length === 0) {
      matchInfo.textContent = 'No matches';
    } else {
      matchInfo.textContent = (currentMatchIndex + 1) + '/' + matches.length;
    }
  }

  function goToNextMatch() {
    if (matches.length === 0) return;
    currentMatchIndex = (currentMatchIndex + 1) % matches.length;
    scrollToMatch(currentMatchIndex);
    updateMatchInfo();
  }

  function goToPrevMatch() {
    if (matches.length === 0) return;
    currentMatchIndex = (currentMatchIndex - 1 + matches.length) % matches.length;
    scrollToMatch(currentMatchIndex);
    updateMatchInfo();
  }

  function toggleTheme() {
    const body = document.body;
    const current = body.dataset.theme;
    const next = current === 'dark' ? 'light' : 'dark';
    body.dataset.theme = next;
    localStorage.setItem('coverage-theme', next);
  }

  function loadTheme() {
    const saved = localStorage.getItem('coverage-theme');
    if (saved) {
      document.body.dataset.theme = saved;
    }
  }

  function applySyntaxHighlighting() {
    if (!syntaxHighlightEnabled || currentFileId === null) return;
    if (typeof hljs === 'undefined') return;

    const file = data.files[currentFileId];
    if (!file) return;

    const lineEls = document.querySelectorAll('.code-line');

    lineEls.forEach((lineEl, idx) => {
      const cov = file.coverage[idx];
      // Only highlight lines with no coverage info
      if (cov !== 0) return;

      const content = lineEl.querySelector('.line-content');
      if (!content || !content.textContent.trim()) return;

      const text = content.textContent;

      // Use hljs.highlight() which returns result object
      const result = hljs.highlight(text, { language: 'go' });

      // Parse the highlighted HTML safely using DOMParser
      const parser = new DOMParser();
      const doc = parser.parseFromString('<div>' + result.value + '</div>', 'text/html');
      const wrapper = doc.body.firstChild;

      // Clear and append parsed nodes
      content.textContent = '';
      while (wrapper.firstChild) {
        content.appendChild(wrapper.firstChild);
      }
    });
  }

  function toggleSyntax() {
    syntaxHighlightEnabled = !syntaxHighlightEnabled;
    syntaxToggle.classList.toggle('active', syntaxHighlightEnabled);
    localStorage.setItem('coverage-syntax', syntaxHighlightEnabled ? 'on' : 'off');

    // Re-render current file
    if (currentFileId !== null) {
      const file = data.files[currentFileId];
      if (file) {
        renderCode(file);
      }
    }
  }

  function loadSyntaxPreference() {
    const saved = localStorage.getItem('coverage-syntax');
    if (saved !== null) {
      // User preference overrides default
      syntaxHighlightEnabled = saved === 'on';
    }
    // Update button state
    syntaxToggle.classList.toggle('active', syntaxHighlightEnabled);
  }

  function changeSortMode(mode) {
    if (sortMode === mode) return;

    console.log('Changing sort mode from', sortMode, 'to', mode);
    sortMode = mode;
    localStorage.setItem('coverage-sort-mode', mode);

    // Update button states
    document.querySelectorAll('.sort-btn').forEach(btn => {
      btn.classList.toggle('active', btn.dataset.sort === mode);
    });

    // Re-render tree
    renderTree();
  }

  function loadSortPreference() {
    const saved = localStorage.getItem('coverage-sort-mode');
    if (saved && (saved === 'name' || saved === 'coverage')) {
      sortMode = saved;
    }

    // Update button states
    document.querySelectorAll('.sort-btn').forEach(btn => {
      btn.classList.toggle('active', btn.dataset.sort === sortMode);
    });
  }

  function showHelp() {
    helpModal.classList.remove('hidden');
  }

  function hideHelp() {
    helpModal.classList.add('hidden');
  }

  // Start the app
  init();
})();

    </script>
  </body>
</html>
