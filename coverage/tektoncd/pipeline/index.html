<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Coverage Report</title>
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/go.min.js"></script>
    <style>
      :root {
  --sidebar-width: 280px;
  --topbar-height: 48px;
  --line-height: 20px;
  --font-mono: ui-monospace, SFMono-Regular, "SF Mono", Menlo, Consolas, "Liberation Mono", monospace;
}

[data-theme="dark"] {
  --bg: #1e1e1e;
  --bg-secondary: #252526;
  --bg-tertiary: #2d2d2d;
  --text: #d4d4d4;
  --text-muted: #808080;
  --border: #3c3c3c;
  --covered: rgba(35, 134, 54, 0.25);
  --covered-gutter: #238636;
  --uncovered: rgba(218, 54, 51, 0.25);
  --uncovered-gutter: #da3633;
  --highlight: #264f78;
  --highlight-match: #613214;
  --accent: #569cd6;
  --hover: #2a2d2e;
}

[data-theme="light"] {
  --bg: #ffffff;
  --bg-secondary: #f3f3f3;
  --bg-tertiary: #e8e8e8;
  --text: #24292f;
  --text-muted: #656d76;
  --border: #d0d7de;
  --covered: rgba(35, 134, 54, 0.15);
  --covered-gutter: #1a7f37;
  --uncovered: rgba(218, 54, 51, 0.15);
  --uncovered-gutter: #cf222e;
  --highlight: #ddf4ff;
  --highlight-match: #fff8c5;
  --accent: #0969da;
  --hover: #f6f8fa;
}

* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

html, body {
  height: 100%;
  overflow: hidden;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
  font-size: 14px;
  background: var(--bg);
  color: var(--text);
}

#app {
  display: grid;
  grid-template-columns: var(--sidebar-width) 1fr;
  height: 100%;
}

/* Sidebar */
#sidebar {
  display: flex;
  flex-direction: column;
  background: var(--bg-secondary);
  border-right: 1px solid var(--border);
  overflow: hidden;
}

#sidebar-header {
  padding: 16px;
  border-bottom: 1px solid var(--border);
}

/* Logo link */
#logo-link {
  text-decoration: none;
  color: inherit;
  display: block;
}

#logo-link:hover #logo-container {
  opacity: 0.8;
}

#logo-container {
  display: flex;
  align-items: center;
  gap: 10px;
  margin-bottom: 12px;
  transition: opacity 0.15s ease;
}

#logo-container .github-icon {
  flex-shrink: 0;
  color: var(--text-muted);
  transition: color 0.15s ease;
}

#logo-link:hover .github-icon {
  color: var(--accent);
}

#logo {
  flex-shrink: 0;
  width: 32px;
  height: 32px;
}

#logo-text {
  flex: 1;
  min-width: 0;
}

#sidebar-header h1 {
  font-size: 16px;
  font-weight: 600;
  margin: 0;
  line-height: 1.2;
}

#tagline {
  font-size: 12px;
  font-weight: 500;
  color: var(--text-muted);
  margin: 2px 0 0 0;
  line-height: 1.3;
}

#summary {
  font-size: 13px;
  color: var(--text-muted);
}

#summary .percent {
  font-weight: 600;
  color: var(--text);
}

#search-box {
  padding: 8px 16px;
  border-bottom: 1px solid var(--border);
}

#search-input {
  width: 100%;
  padding: 6px 10px;
  border: 1px solid var(--border);
  border-radius: 4px;
  background: var(--bg);
  color: var(--text);
  font-size: 13px;
}

#search-input:focus {
  outline: none;
  border-color: var(--accent);
}

/* Sort controls */
#sort-controls {
  display: flex;
  gap: 0;
  margin: 8px 12px;
  border: 1px solid var(--border);
  border-radius: 4px;
  overflow: hidden;
}

.sort-btn {
  flex: 1;
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 4px;
  padding: 6px 8px;
  background: var(--bg-secondary);
  color: var(--text);
  border: none;
  cursor: pointer;
  font-size: 12px;
  transition: background-color 0.2s, color 0.2s;
}

.sort-btn:hover {
  background: var(--hover);
}

.sort-btn.active {
  background: var(--accent);
  color: #fff;
}

.sort-btn .icon {
  font-weight: 600;
}

.sort-btn .label {
  font-size: 11px;
}

/* Coverage badges for directories */
.coverage-badge {
  margin-left: auto;
  padding-left: 8px;
  font-size: 11px;
  color: var(--text-muted);
  font-weight: 500;
  font-family: var(--font-mono);
}

#file-tree {
  flex: 1;
  overflow-y: auto;
  padding: 8px 0;
}

/* Sidebar footer */
#sidebar-footer {
  padding: 12px 16px;
  border-top: 1px solid var(--border);
  font-size: 12px;
  text-align: center;
}

#sidebar-footer a {
  color: var(--text-muted);
  text-decoration: none;
  display: inline-flex;
  align-items: center;
  gap: 6px;
}

#sidebar-footer a:hover {
  color: var(--accent);
  text-decoration: underline;
}

#sidebar-footer .github-icon {
  flex-shrink: 0;
}

.tree-node {
  cursor: pointer;
  user-select: none;
}

.tree-item {
  display: flex;
  align-items: center;
  padding: 4px 16px;
  gap: 6px;
  white-space: nowrap;
}

.tree-item:hover {
  background: var(--hover);
}

.tree-item.selected {
  background: var(--highlight);
}

.tree-item .icon {
  width: 16px;
  text-align: center;
  font-size: 12px;
  color: var(--text-muted);
}

.tree-item .name {
  font-size: 13px;
  overflow: hidden;
  text-overflow: ellipsis;
  flex: 1;
  min-width: 0;
}

.tree-children {
  display: none;
}

.tree-node.expanded > .tree-children {
  display: block;
}

.tree-children .tree-item {
  padding-left: calc(16px + var(--depth, 0) * 16px);
}

.tree-node.hidden {
  display: none;
}

/* Canvas */
#canvas {
  display: flex;
  flex-direction: column;
  overflow: hidden;
}

#topbar {
  display: flex;
  align-items: center;
  justify-content: space-between;
  height: var(--topbar-height);
  padding: 0 16px;
  background: var(--bg-secondary);
  border-bottom: 1px solid var(--border);
  gap: 16px;
}

#file-path {
  font-size: 13px;
  font-family: var(--font-mono);
  color: var(--text-muted);
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

#topbar-actions {
  display: flex;
  align-items: center;
  gap: 12px;
}

#in-file-search {
  display: flex;
  align-items: center;
  gap: 8px;
}

#content-search {
  width: 180px;
  padding: 4px 8px;
  border: 1px solid var(--border);
  border-radius: 4px;
  background: var(--bg);
  color: var(--text);
  font-size: 12px;
}

#content-search:focus {
  outline: none;
  border-color: var(--accent);
}

#match-info {
  font-size: 12px;
  color: var(--text-muted);
  min-width: 60px;
}

#prev-match, #next-match {
  padding: 2px 8px;
  border: 1px solid var(--border);
  border-radius: 4px;
  background: var(--bg);
  color: var(--text);
  cursor: pointer;
  font-size: 10px;
}

#prev-match:hover, #next-match:hover {
  background: var(--hover);
}

#theme-toggle {
  padding: 6px 10px;
  border: 1px solid var(--border);
  border-radius: 4px;
  background: var(--bg);
  color: var(--text);
  cursor: pointer;
  font-size: 16px;
}

#theme-toggle:hover {
  background: var(--hover);
}

#syntax-toggle {
  padding: 6px 10px;
  border: 1px solid var(--border);
  border-radius: 4px;
  background: var(--bg);
  color: var(--text);
  cursor: pointer;
  font-size: 14px;
  font-family: var(--font-mono);
}

#syntax-toggle:hover {
  background: var(--hover);
}

#syntax-toggle.active {
  background: var(--accent);
  color: #fff;
  border-color: var(--accent);
}

#help-toggle {
  padding: 6px 10px;
  border: 1px solid var(--border);
  border-radius: 4px;
  background: var(--bg);
  color: var(--text);
  cursor: pointer;
  font-size: 14px;
  font-weight: 600;
}

#help-toggle:hover {
  background: var(--hover);
}

/* Override highlight.js to use theme-aware colors */
.hljs { background: transparent !important; }

[data-theme="dark"] .hljs-keyword { color: #569cd6; }
[data-theme="dark"] .hljs-type { color: #4ec9b0; }
[data-theme="dark"] .hljs-string { color: #ce9178; }
[data-theme="dark"] .hljs-number { color: #b5cea8; }
[data-theme="dark"] .hljs-comment { color: #6a9955; }
[data-theme="dark"] .hljs-built_in { color: #dcdcaa; }
[data-theme="dark"] .hljs-literal { color: #569cd6; }
[data-theme="dark"] .hljs-function { color: #dcdcaa; }

[data-theme="light"] .hljs-keyword { color: #0000ff; }
[data-theme="light"] .hljs-type { color: #267f99; }
[data-theme="light"] .hljs-string { color: #a31515; }
[data-theme="light"] .hljs-number { color: #098658; }
[data-theme="light"] .hljs-comment { color: #008000; }
[data-theme="light"] .hljs-built_in { color: #795e26; }
[data-theme="light"] .hljs-literal { color: #0000ff; }
[data-theme="light"] .hljs-function { color: #795e26; }

/* Viewport */
#viewport {
  flex: 1;
  overflow: auto;
  background: var(--bg);
  outline: none;
}

#viewport::-webkit-scrollbar {
  width: 14px;
  height: 14px;
}

#viewport::-webkit-scrollbar-track {
  background: var(--bg);
}

#viewport::-webkit-scrollbar-thumb {
  background: var(--border);
  border: 3px solid var(--bg);
  border-radius: 7px;
}

#viewport::-webkit-scrollbar-thumb:hover {
  background: var(--text-muted);
}

.code-container {
  display: table;
  min-width: 100%;
  font-family: var(--font-mono);
  font-size: 13px;
  line-height: var(--line-height);
}

.code-line {
  display: table-row;
}

.code-line:hover {
  background: var(--hover);
}

.code-line.covered {
  background: var(--covered);
}

.code-line.uncovered {
  background: var(--uncovered);
}

.code-line.covered:hover {
  background: var(--covered);
}

.code-line.uncovered:hover {
  background: var(--uncovered);
}

.gutter {
  display: table-cell;
  width: 4px;
  min-width: 4px;
}

.code-line.covered .gutter {
  background: var(--covered-gutter);
}

.code-line.uncovered .gutter {
  background: var(--uncovered-gutter);
}

.line-number {
  display: table-cell;
  width: 50px;
  min-width: 50px;
  padding: 0 12px 0 8px;
  text-align: right;
  color: var(--text-muted);
  user-select: none;
  vertical-align: top;
}

.line-content {
  display: table-cell;
  padding-right: 16px;
  white-space: pre;
  tab-size: 4;
}

.match-highlight {
  background: var(--highlight-match);
  border-radius: 2px;
}

.current-match {
  background: var(--accent);
  color: #fff;
}

/* Empty state */
.empty-state {
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  height: 100%;
  color: var(--text-muted);
  gap: 8px;
}

.empty-state .icon {
  font-size: 48px;
  opacity: 0.5;
}

/* Scrollbar for file tree */
#file-tree::-webkit-scrollbar {
  width: 8px;
}

#file-tree::-webkit-scrollbar-track {
  background: transparent;
}

#file-tree::-webkit-scrollbar-thumb {
  background: var(--border);
  border-radius: 4px;
}

#file-tree::-webkit-scrollbar-thumb:hover {
  background: var(--text-muted);
}

/* Help modal */
.modal {
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background: rgba(0, 0, 0, 0.5);
  display: flex;
  align-items: center;
  justify-content: center;
  z-index: 1000;
}

.modal.hidden {
  display: none;
}

.modal-content {
  background: var(--bg-secondary);
  border: 1px solid var(--border);
  border-radius: 8px;
  padding: 24px;
  max-width: 400px;
  width: 90%;
}

.modal-content h2 {
  margin-bottom: 16px;
  font-size: 18px;
}

.modal-content dl {
  display: grid;
  grid-template-columns: auto 1fr;
  gap: 8px 16px;
}

.modal-content dt {
  font-family: var(--font-mono);
  background: var(--bg-tertiary);
  padding: 2px 6px;
  border-radius: 4px;
  font-size: 13px;
}

.modal-content dd {
  color: var(--text-muted);
}

.modal-content button {
  margin-top: 20px;
  padding: 8px 16px;
  border: 1px solid var(--border);
  border-radius: 4px;
  background: var(--accent);
  color: #fff;
  cursor: pointer;
  width: 100%;
}

/* Selected line range (multi-line selection) */
.code-line.selected-line {
  background-color: var(--highlight);
}

.code-line.selected-line.covered {
  background-color: var(--highlight);
}

.code-line.selected-line.uncovered {
  background-color: var(--highlight);
}

/* Line number click indicator */
.line-number {
  cursor: pointer;
}

.line-number:hover {
  color: var(--accent);
}

    </style>
  </head>
  <body data-theme="dark">
    <div id="app">
      <aside id="sidebar">
        <div id="sidebar-header">
          <a
            href="https://github.com/chmouel/go-better-html-coverage"
            id="logo-link"
            target="_blank"
            rel="noopener"
          >
            <div id="logo-container">
              <svg id="logo" viewBox="0 0 32 32" width="32" height="32">
                <defs>
                  <linearGradient
                    id="logoGradient"
                    x1="0%"
                    y1="0%"
                    x2="100%"
                    y2="100%"
                  >
                    <stop
                      offset="0%"
                      style="stop-color: var(--accent); stop-opacity: 1"
                    />
                    <stop
                      offset="100%"
                      style="stop-color: var(--accent); stop-opacity: 0.7"
                    />
                  </linearGradient>
                </defs>
                
                <circle
                  cx="16"
                  cy="16"
                  r="14"
                  fill="none"
                  stroke="url(#logoGradient)"
                  stroke-width="2"
                  opacity="0.3"
                />
                
                <path
                  d="M 10 17 L 14 21 L 22 11"
                  fill="none"
                  stroke="var(--accent)"
                  stroke-width="2.5"
                  stroke-linecap="round"
                  stroke-linejoin="round"
                />
                
                <circle
                  cx="24"
                  cy="10"
                  r="1.5"
                  fill="var(--accent)"
                  opacity="0.6"
                />
                <circle
                  cx="26"
                  cy="12"
                  r="1.5"
                  fill="var(--accent)"
                  opacity="0.6"
                />
              </svg>
              <div id="logo-text">
                <h1>GO Coverage</h1>
                <div id="tagline">A better HTML Go Coverage</div>
              </div>
            </div>
          </a>
          <div id="summary"></div>
        </div>
        <div id="search-box">
          <input type="text" id="search-input" placeholder="Search files..." />
        </div>
        <div id="sort-controls">
          <button
            class="sort-btn active"
            data-sort="name"
            title="Sort alphabetically"
          >
            <span class="icon">Aâ†’Z</span>
            <span class="label">Name</span>
          </button>
          <button
            class="sort-btn"
            data-sort="coverage"
            title="Sort by coverage percentage"
          >
            <span class="icon">%</span>
            <span class="label">Coverage</span>
          </button>
        </div>
        <div id="file-tree"></div>
        <footer id="sidebar-footer">
          <a
            href="https://github.com/chmouel/go-better-html-coverage"
            target="_blank"
            rel="noopener"
          >
            <svg
              class="github-icon"
              viewBox="0 0 16 16"
              width="14"
              height="14"
              fill="currentColor"
            >
              <path
                d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"
              />
            </svg>
            chmouel/go-better-html-coverage
          </a>
        </footer>
      </aside>
      <main id="canvas">
        <header id="topbar">
          <div id="file-path"></div>
          <div id="topbar-actions">
            <div id="in-file-search">
              <input
                type="text"
                id="content-search"
                placeholder="Search in file..."
              />
              <span id="match-info"></span>
              <button id="prev-match" title="Previous match">&#9650;</button>
              <button id="next-match" title="Next match">&#9660;</button>
            </div>
            <button id="syntax-toggle" title="Toggle syntax highlighting">
              &lt;/&gt;
            </button>
            <button id="theme-toggle" title="Toggle theme">&#9788;</button>
            <button id="help-toggle" title="Keyboard shortcuts">?</button>
          </div>
        </header>
        <div id="viewport" tabindex="-1"></div>
      </main>
      <div id="help-modal" class="modal hidden">
        <div class="modal-content">
          <h2>Keyboard Shortcuts</h2>
          <dl>
            <dt>Ctrl+P</dt>
            <dd>Focus file search</dd>
            <dt>Ctrl+F</dt>
            <dd>Search in file</dd>
            <dt>Enter</dt>
            <dd>Next match</dd>
            <dt>Shift+Enter</dt>
            <dd>Previous match</dd>
            <dt>?</dt>
            <dd>Show this help</dd>
            <dt>Esc</dt>
            <dd>Close modal</dd>
          </dl>
          <h2>Permalinks</h2>
          <dl>
            <dt>Click line</dt>
            <dd>Select line, update URL</dd>
            <dt>Shift+Click</dt>
            <dd>Select line range</dd>
          </dl>
          <button id="close-help">Close</button>
        </div>
      </div>
    </div>
    <script>
      window.COVERAGE_DATA = {"files":[{"id":0,"path":"internal/sidecarlogresults/sidecarlogresults.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package sidecarlogresults","","import (","\t\"bufio\"","\t\"context\"","\t\"encoding/json\"","\t\"errors\"","\t\"fmt\"","\t\"io\"","\t\"os\"","\t\"path/filepath\"","\t\"strings\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/result\"","\t\"golang.org/x/sync/errgroup\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/client-go/kubernetes\"",")","","// ErrSizeExceeded indicates that the result exceeded its maximum allowed size","var (","\tErrSizeExceeded = errors.New(\"results size exceeds configured limit\")","\tstepDir         = pipeline.StepsDir",")","","type SidecarLogResultType string","","const (","\ttaskResultType SidecarLogResultType = \"task\"","\tstepResultType SidecarLogResultType = \"step\"","","\tstepArtifactType           SidecarLogResultType = \"stepArtifact\"","\ttaskArtifactType           SidecarLogResultType = \"taskArtifact\"","\tsidecarResultNameSeparator string               = \".\"",")","","// SidecarLogResult holds fields for storing extracted results","type SidecarLogResult struct {","\tName  string               `json:\"name\"`","\tValue string               `json:\"value\"`","\tType  SidecarLogResultType `json:\"type\"`","}","","func fileExists(filename string) (bool, error) {","\tinfo, err := os.Stat(filename)","\tif os.IsNotExist(err) {","\t\treturn false, nil","\t} else if err != nil {","\t\treturn false, fmt.Errorf(\"error checking for file existence %w\", err)","\t}","\treturn !info.IsDir(), nil","}","","func encode(w io.Writer, v any) error {","\treturn json.NewEncoder(w).Encode(v)","}","","func waitForStepsToFinish(runDir string, sleepInterval time.Duration) error {","\tsteps := make(map[string]bool)","\tfiles, err := os.ReadDir(runDir)","\tif err != nil {","\t\treturn fmt.Errorf(\"error parsing the run dir  %w\", err)","\t}","\tfor _, file := range files {","\t\tsteps[filepath.Join(runDir, file.Name(), \"out\")] = true","\t}","\tfor len(steps) \u003e 0 {","\t\tfor stepFile := range steps {","\t\t\t// check if there is a post file without error","\t\t\texists, err := fileExists(stepFile)","\t\t\tif err != nil {","\t\t\t\treturn fmt.Errorf(\"error checking for out file's existence %w\", err)","\t\t\t}","\t\t\tif exists {","\t\t\t\tdelete(steps, stepFile)","\t\t\t\tcontinue","\t\t\t}","\t\t\t// check if there is a post file with error","\t\t\t// if err is nil then either the out.err file does not exist or it does and there was no issue","\t\t\t// in either case, existence of out.err marks that the step errored and the following steps will","\t\t\t// not run. We want the function to break out with nil error in that case so that","\t\t\t// the existing results can be logged.","\t\t\tif exists, err = fileExists(stepFile + \".err\"); exists || err != nil {","\t\t\t\treturn err","\t\t\t}","\t\t}","\t\tif sleepInterval \u003e 0 {","\t\t\ttime.Sleep(sleepInterval)","\t\t}","\t}","\treturn nil","}","","func createSidecarResultName(stepName, resultName string) string {","\treturn fmt.Sprintf(\"%s%s%s\", stepName, sidecarResultNameSeparator, resultName)","}","","// ExtractStepAndResultFromSidecarResultName splits the result name to extract the step","// and result name from it. It only works if the format is \u003cstepName\u003e.\u003cresultName\u003e","func ExtractStepAndResultFromSidecarResultName(sidecarResultName string) (string, string, error) {","\tsplitString := strings.SplitN(sidecarResultName, sidecarResultNameSeparator, 2)","\tif len(splitString) != 2 {","\t\treturn \"\", \"\", fmt.Errorf(\"invalid string %s : expected somtthing that looks like \u003cstepName\u003e.\u003cresultName\u003e\", sidecarResultName)","\t}","\treturn splitString[0], splitString[1], nil","}","","func readResults(resultsDir, resultFile, stepName string, resultType SidecarLogResultType) (SidecarLogResult, error) {","\tvalue, err := os.ReadFile(filepath.Join(resultsDir, resultFile))","\tif os.IsNotExist(err) {","\t\treturn SidecarLogResult{}, nil","\t} else if err != nil {","\t\treturn SidecarLogResult{}, fmt.Errorf(\"error reading the results file %w\", err)","\t}","\tresultName := resultFile","\tif resultType == stepResultType {","\t\tresultName = createSidecarResultName(stepName, resultFile)","\t}","\treturn SidecarLogResult{","\t\tName:  resultName,","\t\tValue: string(value),","\t\tType:  resultType,","\t}, nil","}","","// LookForResults waits for results to be written out by the steps","// in their results path and prints them in a structured way to its","// stdout so that the reconciler can parse those logs.","func LookForResults(w io.Writer, runDir string, resultsDir string, resultNames []string, stepResultsDir string, stepResults map[string][]string) error {","\tinterval, err := getSidecarLogPollingInterval()","\tif err != nil {","\t\treturn fmt.Errorf(\"error getting polling interval: %w\", err)","\t}","\tif err := waitForStepsToFinish(runDir, interval); err != nil {","\t\treturn fmt.Errorf(\"error while waiting for the steps to finish  %w\", err)","\t}","\tresults := make(chan SidecarLogResult)","\tg := new(errgroup.Group)","\tfor _, resultFile := range resultNames {","\t\tg.Go(func() error {","\t\t\tnewResult, err := readResults(resultsDir, resultFile, \"\", taskResultType)","\t\t\tif err != nil {","\t\t\t\treturn err","\t\t\t}","\t\t\tif newResult.Name == \"\" {","\t\t\t\treturn nil","\t\t\t}","\t\t\tresults \u003c- newResult","\t\t\treturn nil","\t\t})","\t}","","\tfor sName, sresults := range stepResults {","\t\tfor _, resultName := range sresults {","\t\t\tstepResultsDir := filepath.Join(stepResultsDir, sName, \"results\")","","\t\t\tg.Go(func() error {","\t\t\t\tnewResult, err := readResults(stepResultsDir, resultName, sName, stepResultType)","\t\t\t\tif err != nil {","\t\t\t\t\treturn err","\t\t\t\t}","\t\t\t\tif newResult.Name == \"\" {","\t\t\t\t\treturn nil","\t\t\t\t}","\t\t\t\tresults \u003c- newResult","\t\t\t\treturn nil","\t\t\t})","\t\t}","\t}","","\tchannelGroup := new(errgroup.Group)","\tchannelGroup.Go(func() error {","\t\tif err := g.Wait(); err != nil {","\t\t\treturn fmt.Errorf(\"error parsing results: %w\", err)","\t\t}","\t\tclose(results)","\t\treturn nil","\t})","","\tfor result := range results {","\t\tif err := encode(w, result); err != nil {","\t\t\treturn fmt.Errorf(\"error writing results: %w\", err)","\t\t}","\t}","\tif err := channelGroup.Wait(); err != nil {","\t\treturn err","\t}","\treturn nil","}","","// LookForArtifacts searches for and processes artifacts within a specified run directory.","// It looks for \"provenance.json\" files within the \"artifacts\" subdirectory of each named step.","// If the provenance file exists, the function extracts artifact information, formats it into a","// JSON string, and encodes it for output alongside relevant metadata (step name, artifact type).","func LookForArtifacts(w io.Writer, names []string, runDir string) error {","\tinterval, err := getSidecarLogPollingInterval()","\tif err != nil {","\t\treturn fmt.Errorf(\"error getting polling interval: %w\", err)","\t}","\tif err := waitForStepsToFinish(runDir, interval); err != nil {","\t\treturn err","\t}","","\tfor _, name := range names {","\t\tp := filepath.Join(stepDir, name, \"artifacts\", \"provenance.json\")","\t\tif exist, err := fileExists(p); err != nil {","\t\t\treturn err","\t\t} else if !exist {","\t\t\tcontinue","\t\t}","\t\tsubRes, err := extractArtifactsFromFile(p)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tvalues, err := json.Marshal(\u0026subRes)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tif err := encode(w, SidecarLogResult{Name: name, Value: string(values), Type: stepArtifactType}); err != nil {","\t\t\treturn err","\t\t}","\t}","\treturn nil","}","","// GetResultsFromSidecarLogs extracts results from the logs of the results sidecar","func GetResultsFromSidecarLogs(ctx context.Context, clientset kubernetes.Interface, namespace string, name string, container string, podPhase corev1.PodPhase) ([]result.RunResult, error) {","\tsidecarLogResults := []result.RunResult{}","\tif podPhase == corev1.PodPending {","\t\treturn sidecarLogResults, nil","\t}","\tpodLogOpts := corev1.PodLogOptions{Container: container}","\treq := clientset.CoreV1().Pods(namespace).GetLogs(name, \u0026podLogOpts)","\tsidecarLogs, err := req.Stream(ctx)","\tif err != nil {","\t\treturn sidecarLogResults, err","\t}","\tdefer sidecarLogs.Close()","\tmaxResultLimit := config.FromContextOrDefaults(ctx).FeatureFlags.MaxResultSize","\treturn extractResultsFromLogs(sidecarLogs, sidecarLogResults, maxResultLimit)","}","","func extractResultsFromLogs(logs io.Reader, sidecarLogResults []result.RunResult, maxResultLimit int) ([]result.RunResult, error) {","\treader := bufio.NewReader(logs)","\tfor {","\t\tline, isPrefix, err := reader.ReadLine()","\t\tif err != nil {","\t\t\tif errors.Is(err, io.EOF) {","\t\t\t\tbreak","\t\t\t}","\t\t\treturn nil, err","\t\t}","","\t\tlineLength := len(line)","\t\tfor isPrefix {","\t\t\tmore, nextPrefix, err := reader.ReadLine()","\t\t\tif err != nil {","\t\t\t\tif errors.Is(err, io.EOF) {","\t\t\t\t\tbreak","\t\t\t\t}","\t\t\t\treturn nil, err","\t\t\t}","\t\t\tlineLength += len(more)","","\t\t\tif lineLength \u003c= maxResultLimit {","\t\t\t\tline = append(line, more...)","\t\t\t}","\t\t\tisPrefix = nextPrefix","\t\t}","","\t\tif lineLength \u003e maxResultLimit {","\t\t\treturn sidecarLogResults, fmt.Errorf(\"%d bytes %w of %d bytes\", lineLength, ErrSizeExceeded, maxResultLimit)","\t\t}","","\t\tresult, err := parseResults(line, maxResultLimit)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tsidecarLogResults = append(sidecarLogResults, result)","\t}","","\treturn sidecarLogResults, nil","}","","func parseResults(resultBytes []byte, maxResultLimit int) (result.RunResult, error) {","\trunResult := result.RunResult{}","\tvar res SidecarLogResult","\tif err := json.Unmarshal(resultBytes, \u0026res); err != nil {","\t\treturn runResult, fmt.Errorf(\"invalid result \\\"%s\\\": %w\", res.Name, err)","\t}","\tif len(resultBytes) \u003e maxResultLimit {","\t\treturn runResult, fmt.Errorf(\"invalid result \\\"%s\\\": %w of %d\", res.Name, ErrSizeExceeded, maxResultLimit)","\t}","\tvar resultType result.ResultType","\tswitch res.Type {","\tcase taskResultType:","\t\tresultType = result.TaskRunResultType","\tcase stepResultType:","\t\tresultType = result.StepResultType","\tcase stepArtifactType:","\t\tresultType = result.StepArtifactsResultType","\tcase taskArtifactType:","\t\tresultType = result.TaskRunArtifactsResultType","\tdefault:","\t\treturn result.RunResult{}, fmt.Errorf(\"invalid sidecar result type %v. Must be %v or %v or %v\", res.Type, taskResultType, stepResultType, stepArtifactType)","\t}","\trunResult = result.RunResult{","\t\tKey:        res.Name,","\t\tValue:      res.Value,","\t\tResultType: resultType,","\t}","\treturn runResult, nil","}","","func parseArtifacts(fileContent []byte) (v1.Artifacts, error) {","\tvar as v1.Artifacts","\tif err := json.Unmarshal(fileContent, \u0026as); err != nil {","\t\treturn as, fmt.Errorf(\"invalid artifacts : %w\", err)","\t}","\treturn as, nil","}","","func extractArtifactsFromFile(filename string) (v1.Artifacts, error) {","\tb, err := os.ReadFile(filename)","\tif err != nil {","\t\treturn v1.Artifacts{}, fmt.Errorf(\"error reading the results file %w\", err)","\t}","\treturn parseArtifacts(b)","}","","// getSidecarLogPollingInterval reads the SIDECAR_LOG_POLLING_INTERVAL environment variable,","// parses it as a time.Duration, and returns the result. If the variable is not set or is invalid,","// it defaults to 100ms.","func getSidecarLogPollingInterval() (time.Duration, error) {","\tintervalStr := os.Getenv(\"SIDECAR_LOG_POLLING_INTERVAL\")","\tif intervalStr == \"\" {","\t\tintervalStr = \"100ms\"","\t}","\tinterval, err := time.ParseDuration(intervalStr)","\tif err != nil {","\t\treturn 100 * time.Millisecond, err","\t}","\treturn interval, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,1,1,2,0,0,2,2,2,0,2,2,2,2,1,1,2,2,2,2,2,2,2,2,1,1,2,2,2,0,0,0,0,0,0,2,2,2,0,2,2,2,0,2,0,0,2,2,2,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,1,1,2,1,1,2,2,2,2,2,2,1,1,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,1,1,2,2,2,2,2,0,0,0,0,2,2,2,1,1,2,2,0,0,2,2,1,1,0,2,1,1,2,0,0,0,0,0,0,2,2,2,1,1,2,1,1,0,2,2,2,1,2,2,0,2,2,2,2,2,2,1,1,2,1,1,0,2,0,0,0,2,2,2,2,2,2,2,2,2,1,1,2,2,2,0,0,2,2,2,2,2,2,2,0,1,0,0,2,2,2,2,1,1,0,1,0,2,2,2,1,1,2,0,0,2,2,2,0,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,2,2,2,1,1,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0]},{"id":1,"path":"pkg/apis/config/default.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package config","","import (","\t\"fmt\"","\t\"log\"","\t\"os\"","\t\"reflect\"","\t\"strconv\"","\t\"strings\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/pod\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"sigs.k8s.io/yaml\"",")","","const (","\t// DefaultTimeoutMinutes is used when no timeout is specified.","\tDefaultTimeoutMinutes = 60","\t// NoTimeoutDuration is used when a pipeline or task should never time out.","\tNoTimeoutDuration = 0 * time.Minute","\t// DefaultServiceAccountValue is the SA used when one is not specified.","\tDefaultServiceAccountValue = \"default\"","\t// DefaultManagedByLabelValue is the value for the managed-by label that is used by default.","\tDefaultManagedByLabelValue = \"tekton-pipelines\"","\t// DefaultCloudEventSinkValue is the default value for cloud event sinks.","\tDefaultCloudEventSinkValue = \"\"","\t// DefaultMaxMatrixCombinationsCount is used when no max matrix combinations count is specified.","\tDefaultMaxMatrixCombinationsCount = 256","\t// DefaultResolverTypeValue is used when no default resolver type is specified","\tDefaultResolverTypeValue = \"\"","\t// default resource requirements, will be applied to all the containers, which has empty resource requirements","\tResourceRequirementDefaultContainerKey = \"default\"","","\tDefaultImagePullBackOffTimeout = 0 * time.Minute","","\t// Default maximum resolution timeout used by the resolution controller before timing out when exceeded","\tDefaultMaximumResolutionTimeout = 1 * time.Minute","","\tDefaultSidecarLogPollingInterval = 100 * time.Millisecond","","\t// DefaultStepRefConcurrencyLimit is the default concurrency limit for resolving step references.","\tDefaultStepRefConcurrencyLimit = 5","","\tdefaultTimeoutMinutesKey                = \"default-timeout-minutes\"","\tdefaultServiceAccountKey                = \"default-service-account\"","\tdefaultManagedByLabelValueKey           = \"default-managed-by-label-value\"","\tdefaultPodTemplateKey                   = \"default-pod-template\"","\tdefaultAAPodTemplateKey                 = \"default-affinity-assistant-pod-template\"","\tdefaultCloudEventsSinkKey               = \"default-cloud-events-sink\"","\tdefaultTaskRunWorkspaceBinding          = \"default-task-run-workspace-binding\"","\tdefaultMaxMatrixCombinationsCountKey    = \"default-max-matrix-combinations-count\"","\tdefaultForbiddenEnv                     = \"default-forbidden-env\"","\tdefaultResolverTypeKey                  = \"default-resolver-type\"","\tdefaultContainerResourceRequirementsKey = \"default-container-resource-requirements\"","\tdefaultImagePullBackOffTimeout          = \"default-imagepullbackoff-timeout\"","\tdefaultMaximumResolutionTimeout         = \"default-maximum-resolution-timeout\"","\tdefaultSidecarLogPollingIntervalKey     = \"default-sidecar-log-polling-interval\"","\tDefaultStepRefConcurrencyLimitKey       = \"default-step-ref-concurrency-limit\"",")","","// DefaultConfig holds all the default configurations for the config.","var DefaultConfig, _ = NewDefaultsFromMap(map[string]string{})","","// Defaults holds the default configurations","// +k8s:deepcopy-gen=true","type Defaults struct {","\tDefaultTimeoutMinutes                int","\tDefaultServiceAccount                string","\tDefaultManagedByLabelValue           string","\tDefaultPodTemplate                   *pod.Template","\tDefaultAAPodTemplate                 *pod.AffinityAssistantTemplate","\tDefaultCloudEventsSink               string // Deprecated. Use the events package instead","\tDefaultTaskRunWorkspaceBinding       string","\tDefaultMaxMatrixCombinationsCount    int","\tDefaultForbiddenEnv                  []string","\tDefaultResolverType                  string","\tDefaultContainerResourceRequirements map[string]corev1.ResourceRequirements","\tDefaultImagePullBackOffTimeout       time.Duration","\tDefaultMaximumResolutionTimeout      time.Duration","\t// DefaultSidecarLogPollingInterval specifies how frequently (as a time.Duration) the Tekton sidecar log results container polls for step completion files.","\t// This value is loaded from the 'sidecar-log-polling-interval' key in the config-defaults ConfigMap.","\t// It is used to control the responsiveness and resource usage of the sidecar in both production and test environments.","\tDefaultSidecarLogPollingInterval time.Duration","\tDefaultStepRefConcurrencyLimit   int","}","","// GetDefaultsConfigName returns the name of the configmap containing all","// defined defaults.","func GetDefaultsConfigName() string {","\tif e := os.Getenv(\"CONFIG_DEFAULTS_NAME\"); e != \"\" {","\t\treturn e","\t}","\treturn \"config-defaults\"","}","","// Equals returns true if two Configs are identical","func (cfg *Defaults) Equals(other *Defaults) bool {","\tif cfg == nil \u0026\u0026 other == nil {","\t\treturn true","\t}","","\tif cfg == nil || other == nil {","\t\treturn false","\t}","","\treturn other.DefaultTimeoutMinutes == cfg.DefaultTimeoutMinutes \u0026\u0026","\t\tother.DefaultServiceAccount == cfg.DefaultServiceAccount \u0026\u0026","\t\tother.DefaultManagedByLabelValue == cfg.DefaultManagedByLabelValue \u0026\u0026","\t\tother.DefaultPodTemplate.Equals(cfg.DefaultPodTemplate) \u0026\u0026","\t\tother.DefaultAAPodTemplate.Equals(cfg.DefaultAAPodTemplate) \u0026\u0026","\t\tother.DefaultCloudEventsSink == cfg.DefaultCloudEventsSink \u0026\u0026","\t\tother.DefaultTaskRunWorkspaceBinding == cfg.DefaultTaskRunWorkspaceBinding \u0026\u0026","\t\tother.DefaultMaxMatrixCombinationsCount == cfg.DefaultMaxMatrixCombinationsCount \u0026\u0026","\t\tother.DefaultResolverType == cfg.DefaultResolverType \u0026\u0026","\t\tother.DefaultImagePullBackOffTimeout == cfg.DefaultImagePullBackOffTimeout \u0026\u0026","\t\tother.DefaultMaximumResolutionTimeout == cfg.DefaultMaximumResolutionTimeout \u0026\u0026","\t\tother.DefaultSidecarLogPollingInterval == cfg.DefaultSidecarLogPollingInterval \u0026\u0026","\t\tother.DefaultStepRefConcurrencyLimit == cfg.DefaultStepRefConcurrencyLimit \u0026\u0026","\t\treflect.DeepEqual(other.DefaultForbiddenEnv, cfg.DefaultForbiddenEnv)","}","","// NewDefaultsFromMap returns a Config given a map corresponding to a ConfigMap","func NewDefaultsFromMap(cfgMap map[string]string) (*Defaults, error) {","\ttc := Defaults{","\t\tDefaultTimeoutMinutes:             DefaultTimeoutMinutes,","\t\tDefaultServiceAccount:             DefaultServiceAccountValue,","\t\tDefaultManagedByLabelValue:        DefaultManagedByLabelValue,","\t\tDefaultCloudEventsSink:            DefaultCloudEventSinkValue,","\t\tDefaultMaxMatrixCombinationsCount: DefaultMaxMatrixCombinationsCount,","\t\tDefaultResolverType:               DefaultResolverTypeValue,","\t\tDefaultImagePullBackOffTimeout:    DefaultImagePullBackOffTimeout,","\t\tDefaultMaximumResolutionTimeout:   DefaultMaximumResolutionTimeout,","\t\tDefaultSidecarLogPollingInterval:  DefaultSidecarLogPollingInterval,","\t\tDefaultStepRefConcurrencyLimit:    DefaultStepRefConcurrencyLimit,","\t}","","\tif defaultTimeoutMin, ok := cfgMap[defaultTimeoutMinutesKey]; ok {","\t\ttimeout, err := strconv.ParseInt(defaultTimeoutMin, 10, 0)","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed parsing default config %q\", defaultTimeoutMinutesKey)","\t\t}","\t\ttc.DefaultTimeoutMinutes = int(timeout)","\t}","","\tif defaultServiceAccount, ok := cfgMap[defaultServiceAccountKey]; ok {","\t\ttc.DefaultServiceAccount = defaultServiceAccount","\t}","","\tif defaultManagedByLabelValue, ok := cfgMap[defaultManagedByLabelValueKey]; ok {","\t\ttc.DefaultManagedByLabelValue = defaultManagedByLabelValue","\t}","","\tif defaultPodTemplate, ok := cfgMap[defaultPodTemplateKey]; ok {","\t\tvar podTemplate pod.Template","\t\tif err := yamlUnmarshal(defaultPodTemplate, defaultPodTemplateKey, \u0026podTemplate); err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed to unmarshal %v\", defaultPodTemplate)","\t\t}","\t\ttc.DefaultPodTemplate = \u0026podTemplate","\t}","","\tif defaultAAPodTemplate, ok := cfgMap[defaultAAPodTemplateKey]; ok {","\t\tvar podTemplate pod.AffinityAssistantTemplate","\t\tif err := yamlUnmarshal(defaultAAPodTemplate, defaultAAPodTemplateKey, \u0026podTemplate); err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed to unmarshal %v\", defaultAAPodTemplate)","\t\t}","\t\ttc.DefaultAAPodTemplate = \u0026podTemplate","\t}","","\tif defaultCloudEventsSink, ok := cfgMap[defaultCloudEventsSinkKey]; ok {","\t\ttc.DefaultCloudEventsSink = defaultCloudEventsSink","\t}","","\tif bindingYAML, ok := cfgMap[defaultTaskRunWorkspaceBinding]; ok {","\t\ttc.DefaultTaskRunWorkspaceBinding = bindingYAML","\t}","","\tif defaultMaxMatrixCombinationsCount, ok := cfgMap[defaultMaxMatrixCombinationsCountKey]; ok {","\t\tmatrixCombinationsCount, err := strconv.ParseInt(defaultMaxMatrixCombinationsCount, 10, 0)","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed parsing default config %q\", defaultMaxMatrixCombinationsCountKey)","\t\t}","\t\ttc.DefaultMaxMatrixCombinationsCount = int(matrixCombinationsCount)","\t}","\tif defaultForbiddenEnvString, ok := cfgMap[defaultForbiddenEnv]; ok {","\t\ttmpString := sets.NewString()","\t\tfEnvs := strings.Split(defaultForbiddenEnvString, \",\")","\t\tfor _, fEnv := range fEnvs {","\t\t\ttmpString.Insert(strings.TrimSpace(fEnv))","\t\t}","\t\ttc.DefaultForbiddenEnv = tmpString.List()","\t}","","\tif defaultResolverType, ok := cfgMap[defaultResolverTypeKey]; ok {","\t\ttc.DefaultResolverType = defaultResolverType","\t}","","\tif resourceRequirementsStringValue, ok := cfgMap[defaultContainerResourceRequirementsKey]; ok {","\t\tresourceRequirementsValue := make(map[string]corev1.ResourceRequirements)","\t\tif err := yamlUnmarshal(resourceRequirementsStringValue, defaultContainerResourceRequirementsKey, \u0026resourceRequirementsValue); err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed to unmarshal %v\", resourceRequirementsStringValue)","\t\t}","\t\ttc.DefaultContainerResourceRequirements = resourceRequirementsValue","\t}","","\tif defaultImagePullBackOff, ok := cfgMap[defaultImagePullBackOffTimeout]; ok {","\t\ttimeout, err := time.ParseDuration(defaultImagePullBackOff)","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed parsing default config %q\", defaultImagePullBackOffTimeout)","\t\t}","\t\ttc.DefaultImagePullBackOffTimeout = timeout","\t}","","\tif defaultMaximumResolutionTimeout, ok := cfgMap[defaultMaximumResolutionTimeout]; ok {","\t\ttimeout, err := time.ParseDuration(defaultMaximumResolutionTimeout)","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed parsing default config %q\", defaultMaximumResolutionTimeout)","\t\t}","\t\ttc.DefaultMaximumResolutionTimeout = timeout","\t}","","\tif defaultSidecarPollingInterval, ok := cfgMap[defaultSidecarLogPollingIntervalKey]; ok {","\t\tinterval, err := time.ParseDuration(defaultSidecarPollingInterval)","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed parsing default config %q\", defaultSidecarPollingInterval)","\t\t}","\t\ttc.DefaultSidecarLogPollingInterval = interval","\t}","","\tif DefaultStepRefConcurrencyLimit, ok := cfgMap[DefaultStepRefConcurrencyLimitKey]; ok {","\t\tstepRefConcurrencyLimit, err := strconv.ParseInt(DefaultStepRefConcurrencyLimit, 10, 0)","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed parsing default config %q\", DefaultStepRefConcurrencyLimitKey)","\t\t}","\t\ttc.DefaultStepRefConcurrencyLimit = int(stepRefConcurrencyLimit)","\t}","","\treturn \u0026tc, nil","}","","func yamlUnmarshal(s string, key string, o interface{}) error {","\tb := []byte(s)","\tif err := yaml.UnmarshalStrict(b, o); err != nil {","\t\tlog.Printf(\"warning: failed to decode %q: %q. Trying decode with non-strict mode\", key, err)","\t\treturn yaml.Unmarshal(b, o)","\t}","\treturn nil","}","","// NewDefaultsFromConfigMap returns a Config for the given configmap","func NewDefaultsFromConfigMap(config *corev1.ConfigMap) (*Defaults, error) {","\treturn NewDefaultsFromMap(config.Data)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,2,0,0,0,2,2,2,2,0,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,2,2,2,0,2,2,2,1,1,2,0,0,2,2,2,1,1,2,0,0,2,1,1,0,2,1,1,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,0,2,2,2,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,2,1,1,1,1,1,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2]},{"id":2,"path":"pkg/apis/config/events.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package config","","import (","\t\"errors\"","\t\"os\"","\t\"sort\"","\t\"strings\"","","\tcorev1 \"k8s.io/api/core/v1\"",")","","const (","\t// FormatTektonV1 represents the \"v1\" events in Tekton custom format","\tFormatTektonV1 EventFormat = \"tektonv1\"","","\t// DefaultSink is the default value for \"sink\"","\tDefaultSink = \"\"","","\tformatsKey = \"formats\"","\tsinkKey    = \"sink\"",")","","var (","\t// TODO(afrittoli): only one valid format for now, more to come","\t// See TEP-0137 https://github.com/tektoncd/community/pull/1028","\tvalidFormats = EventFormats{FormatTektonV1: struct{}{}}","","\t// DefaultFormat is the default value for \"formats\"","\tDefaultFormats = EventFormats{FormatTektonV1: struct{}{}}","","\t// DefaultConfig holds all the default configurations for the config.","\tDefaultEvents, _ = NewEventsFromMap(map[string]string{})",")","","// Events holds the events configurations","// +k8s:deepcopy-gen=true","type Events struct {","\tSink    string","\tFormats EventFormats","}","","// EventFormat is a single event format","type EventFormat string","","// EventFormats is a set of event formats","type EventFormats map[EventFormat]struct{}","","// String is a string representation of an EventFormat","func (ef EventFormat) String() string {","\treturn string(ef)","}","","// IsValid returns true is the EventFormat one of the valid ones","func (ef EventFormat) IsValid() bool {","\t_, ok := validFormats[ef]","\treturn ok","}","","// String is a string representation of an EventFormats","func (efs EventFormats) String() string {","\t// Make an array of map keys","\tkeys := make([]string, len(efs))","","\ti := 0","\tfor k := range efs {","\t\tkeys[i] = k.String()","\t\ti++","\t}","\t// Sorting helps with testing","\tsort.Strings(keys)","","\t// Build a comma separated list","\treturn strings.Join(keys, \",\")","}","","// Equals defines identity between EventFormats","func (efs EventFormats) Equals(other EventFormats) bool {","\tif len(efs) != len(other) {","\t\treturn false","\t}","\tfor key := range efs {","\t\tif _, ok := other[key]; !ok {","\t\t\treturn false","\t\t}","\t}","\treturn true","}","","// ParseEventFormats converts a comma separated list into a EventFormats set","func ParseEventFormats(formats string) (EventFormats, error) {","\t// An empty string is not a valid configuration","\tif formats == \"\" {","\t\treturn EventFormats{}, errors.New(\"formats cannot be empty\")","\t}","\tstringFormats := strings.Split(formats, \",\")","\tvar eventFormats EventFormats = make(map[EventFormat]struct{}, len(stringFormats))","\tfor _, format := range stringFormats {","\t\tif !EventFormat(format).IsValid() {","\t\t\treturn EventFormats{}, errors.New(\"invalid format: \" + format)","\t\t}","\t\t// If already in the map (duplicate), fail","\t\tif _, ok := eventFormats[EventFormat(format)]; ok {","\t\t\treturn EventFormats{}, errors.New(\"duplicate format: \" + format)","\t\t}","\t\teventFormats[EventFormat(format)] = struct{}{}","\t}","\treturn eventFormats, nil","}","","// GetEventsConfigName returns the name of the configmap containing all","// feature flags.","func GetEventsConfigName() string {","\tif e := os.Getenv(\"CONFIG_EVENTS_NAME\"); e != \"\" {","\t\treturn e","\t}","\treturn \"config-events\"","}","","// NewEventsFromMap returns a Config given a map corresponding to a ConfigMap","func NewEventsFromMap(cfgMap map[string]string) (*Events, error) {","\t// for any string field with no extra validation","\tsetField := func(key string, defaultValue string, field *string) {","\t\tif cfg, ok := cfgMap[key]; ok {","\t\t\t*field = cfg","\t\t} else {","\t\t\t*field = defaultValue","\t\t}","\t}","","\tevents := Events{}","\terr := setFormats(cfgMap, DefaultFormats, \u0026events.Formats)","\tif err != nil {","\t\treturn nil, err","\t}","\tsetField(sinkKey, DefaultSink, \u0026events.Sink)","\treturn \u0026events, nil","}","","func setFormats(cfgMap map[string]string, defaultValue EventFormats, field *EventFormats) error {","\tvalue := defaultValue","\tif cfg, ok := cfgMap[formatsKey]; ok {","\t\tv, err := ParseEventFormats(cfg)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tvalue = v","\t}","\t*field = value","\treturn nil","}","","// NewEventsFromConfigMap returns a Config for the given configmap","func NewEventsFromConfigMap(config *corev1.ConfigMap) (*Events, error) {","\treturn NewEventsFromMap(config.Data)","}","","// Equals returns true if two Configs are identical","func (cfg *Events) Equals(other *Events) bool {","\tif cfg == nil \u0026\u0026 other == nil {","\t\treturn true","\t}","","\tif cfg == nil || other == nil {","\t\treturn false","\t}","","\treturn other.Sink == cfg.Sink \u0026\u0026","\t\tother.Formats.Equals(cfg.Formats)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,2,0,0,0,0,2,2,1,1,2,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,2,2,0,0,0,2,2,2,0,0,2,2,2,2,0,2,2,2,0,2,2,0]},{"id":3,"path":"pkg/apis/config/feature_flags.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package config","","import (","\t\"fmt\"","\t\"os\"","\t\"strconv\"","\t\"strings\"",")","","const (","\t// StableAPIFields is the value used for API-driven features of stable stability level.","\tStableAPIFields = \"stable\"","\t// AlphaAPIFields is the value used for API-driven features of alpha stability level.","\tAlphaAPIFields = \"alpha\"","\t// BetaAPIFields is the value used for API-driven features of beta stability level.","\tBetaAPIFields = \"beta\"","\t// Features of \"alpha\" stability level are disabled by default","\tDefaultAlphaFeatureEnabled = false","\t// Features of \"beta\" stability level are disabled by default","\tDefaultBetaFeatureEnabled = false","\t// Features of \"stable\" stability level are enabled by default","\tDefaultStableFeatureEnabled = true","\t// FailNoMatchPolicy is the value used for \"trusted-resources-verification-no-match-policy\" to fail TaskRun or PipelineRun","\t// when no matching policies are found","\tFailNoMatchPolicy = \"fail\"","\t// WarnNoMatchPolicy is the value used for \"trusted-resources-verification-no-match-policy\" to log warning and skip verification","\t// when no matching policies are found","\tWarnNoMatchPolicy = \"warn\"","\t// IgnoreNoMatchPolicy is the value used for \"trusted-resources-verification-no-match-policy\" to skip verification","\t// when no matching policies are found","\tIgnoreNoMatchPolicy = \"ignore\"","\t// CoscheduleWorkspaces is the value used for \"coschedule\" to coschedule PipelineRun Pods sharing the same PVC workspaces to the same node","\tCoscheduleWorkspaces = \"workspaces\"","\t// CoschedulePipelineRuns is the value used for \"coschedule\" to coschedule all PipelineRun Pods to the same node","\tCoschedulePipelineRuns = \"pipelineruns\"","\t// CoscheduleIsolatePipelineRun is the value used for \"coschedule\" to coschedule all PipelineRun Pods to the same node, and only allows one PipelineRun to run on a node at a time","\tCoscheduleIsolatePipelineRun = \"isolate-pipelinerun\"","\t// CoscheduleDisabled is the value used for \"coschedule\" to disabled PipelineRun Pods coschedule","\tCoscheduleDisabled = \"disabled\"","\t// ResultExtractionMethodTerminationMessage is the value used for \"results-from\" as a way to extract results from tasks using kubernetes termination message.","\tResultExtractionMethodTerminationMessage = \"termination-message\"","\t// ResultExtractionMethodSidecarLogs is the value used for \"results-from\" as a way to extract results from tasks using sidecar logs.","\tResultExtractionMethodSidecarLogs = \"sidecar-logs\"","\t// DefaultDisableCredsInit is the default value for \"disable-creds-init\".","\tDefaultDisableCredsInit = false","\t// DefaultRunningInEnvWithInjectedSidecars is the default value for \"running-in-environment-with-injected-sidecars\".","\tDefaultRunningInEnvWithInjectedSidecars = true","\t// DefaultAwaitSidecarReadiness is the default value for \"await-sidecar-readiness\".","\tDefaultAwaitSidecarReadiness = true","\t// DefaultDisableInlineSpec is the default value of \"disable-inline-spec\"","\tDefaultDisableInlineSpec = \"\"","\t// DefaultRequireGitSSHSecretKnownHosts is the default value for \"require-git-ssh-secret-known-hosts\".","\tDefaultRequireGitSSHSecretKnownHosts = false","\t// DefaultEnableTektonOciBundles is the default value for \"enable-tekton-oci-bundles\".","\tDefaultEnableTektonOciBundles = false","\t// DefaultEnableAPIFields is the default value for \"enable-api-fields\".","\tDefaultEnableAPIFields = BetaAPIFields","\t// DefaultSendCloudEventsForRuns is the default value for \"send-cloudevents-for-runs\".","\tDefaultSendCloudEventsForRuns = false","\t// EnforceNonfalsifiabilityWithSpire is the value used for  \"enable-nonfalsifiability\" when SPIRE is used to enable non-falsifiability.","\tEnforceNonfalsifiabilityWithSpire = \"spire\"","\t// EnforceNonfalsifiabilityNone is the value used for  \"enable-nonfalsifiability\" when non-falsifiability is not enabled.","\tEnforceNonfalsifiabilityNone = \"none\"","\t// DefaultEnforceNonfalsifiability is the default value for \"enforce-nonfalsifiability\".","\tDefaultEnforceNonfalsifiability = EnforceNonfalsifiabilityNone","\t// DefaultNoMatchPolicyConfig is the default value for \"trusted-resources-verification-no-match-policy\".","\tDefaultNoMatchPolicyConfig = IgnoreNoMatchPolicy","\t// DefaultEnableProvenanceInStatus is the default value for \"enable-provenance-status\".","\tDefaultEnableProvenanceInStatus = true","\t// DefaultResultExtractionMethod is the default value for ResultExtractionMethod","\tDefaultResultExtractionMethod = ResultExtractionMethodTerminationMessage","\t// DefaultMaxResultSize is the default value in bytes for the size of a result","\tDefaultMaxResultSize = 4096","\t// DefaultSetSecurityContext is the default value for \"set-security-context\"","\tDefaultSetSecurityContext = false","\t// DefaultSetSecurityContextReadOnlyRootFilesystem is the default value for \"set-security-context-read-only-root-filesystem\"","\tDefaultSetSecurityContextReadOnlyRootFilesystem = false","\t// DefaultCoschedule is the default value for coschedule","\tDefaultCoschedule = CoscheduleWorkspaces","\t// KeepPodOnCancel is the flag used to enable cancelling a pod using the entrypoint, and keep pod on cancel","\tKeepPodOnCancel = \"keep-pod-on-cancel\"","\t// EnableCELInWhenExpression is the flag to enabled CEL in WhenExpression","\tEnableCELInWhenExpression = \"enable-cel-in-whenexpression\"","\t// EnableArtifacts is the flag to enable the use of Artifacts in Steps","\tEnableArtifacts = \"enable-artifacts\"","\t// EnableParamEnum is the flag to enabled enum in params","\tEnableParamEnum = \"enable-param-enum\"","\t// EnableConciseResolverSyntax is the flag to enable concise resolver syntax","\tEnableConciseResolverSyntax = \"enable-concise-resolver-syntax\"","\t// EnableKubernetesSidecar is the flag to enable kubernetes sidecar support","\tEnableKubernetesSidecar = \"enable-kubernetes-sidecar\"","\t// DefaultEnableKubernetesSidecar is the default value for EnableKubernetesSidecar","\tDefaultEnableKubernetesSidecar = false","\t// EnableWaitExponentialBackoff is the flag to enable exponential backoff strategy","\tEnableWaitExponentialBackoff = \"enable-wait-exponential-backoff\"","\t// DefaultEnableWaitExponentialBackoff is the default value for EnableWaitExponentialBackoff","\tDefaultEnableWaitExponentialBackoff = false","","\t// EnableStepActions is the flag to enable step actions (no-op since it's stable)","\tEnableStepActions = \"enable-step-actions\"","","\t// DisableInlineSpec is the flag to disable embedded spec","\t// in Taskrun or Pipelinerun","\tDisableInlineSpec = \"disable-inline-spec\"","","\tdisableCredsInitKey                 = \"disable-creds-init\"","\trunningInEnvWithInjectedSidecarsKey = \"running-in-environment-with-injected-sidecars\"","\tawaitSidecarReadinessKey            = \"await-sidecar-readiness\"","\trequireGitSSHSecretKnownHostsKey    = \"require-git-ssh-secret-known-hosts\" //nolint:gosec","\t// enableTektonOCIBundles              = \"enable-tekton-oci-bundles\"","","\tenableAPIFields                             = \"enable-api-fields\"","\tsendCloudEventsForRuns                      = \"send-cloudevents-for-runs\"","\tenforceNonfalsifiability                    = \"enforce-nonfalsifiability\"","\tverificationNoMatchPolicy                   = \"trusted-resources-verification-no-match-policy\"","\tenableProvenanceInStatus                    = \"enable-provenance-in-status\"","\tresultExtractionMethod                      = \"results-from\"","\tmaxResultSize                               = \"max-result-size\"","\tsetSecurityContextKey                       = \"set-security-context\"","\tsetSecurityContextReadOnlyRootFilesystemKey = \"set-security-context-read-only-root-filesystem\"","\tcoscheduleKey                               = \"coschedule\"",")","","// DefaultFeatureFlags holds all the default configurations for the feature flags configmap.","var (","\tDefaultFeatureFlags, _ = NewFeatureFlagsFromMap(map[string]string{})","","\t// DefaultEnableKeepPodOnCancel is the default PerFeatureFlag value for \"keep-pod-on-cancel\"","\tDefaultEnableKeepPodOnCancel = PerFeatureFlag{","\t\tName:      KeepPodOnCancel,","\t\tStability: BetaAPIFields,","\t\tEnabled:   DefaultBetaFeatureEnabled,","\t}","","\t// DefaultEnableCELInWhenExpression is the default PerFeatureFlag value for EnableCELInWhenExpression","\tDefaultEnableCELInWhenExpression = PerFeatureFlag{","\t\tName:      EnableCELInWhenExpression,","\t\tStability: AlphaAPIFields,","\t\tEnabled:   DefaultAlphaFeatureEnabled,","\t}","","\t// DefaultEnableArtifacts is the default PerFeatureFlag value for EnableArtifacts","\tDefaultEnableArtifacts = PerFeatureFlag{","\t\tName:      EnableArtifacts,","\t\tStability: AlphaAPIFields,","\t\tEnabled:   DefaultAlphaFeatureEnabled,","\t}","","\t// DefaultEnableParamEnum is the default PerFeatureFlag value for EnableParamEnum","\tDefaultEnableParamEnum = PerFeatureFlag{","\t\tName:      EnableParamEnum,","\t\tStability: AlphaAPIFields,","\t\tEnabled:   DefaultAlphaFeatureEnabled,","\t}","","\t// DefaultEnableConciseResolverSyntax is the default PerFeatureFlag value for EnableConciseResolverSyntax","\tDefaultEnableConciseResolverSyntax = PerFeatureFlag{","\t\tName:      EnableConciseResolverSyntax,","\t\tStability: AlphaAPIFields,","\t\tEnabled:   DefaultAlphaFeatureEnabled,","\t}",")","","// FeatureFlags holds the features configurations","// +k8s:deepcopy-gen=true","type FeatureFlags struct {","\tDisableCredsInit                 bool `json:\"disableCredsInit,omitempty\"`","\tRunningInEnvWithInjectedSidecars bool `json:\"runningInEnvWithInjectedSidecars,omitempty\"`","\tRequireGitSSHSecretKnownHosts    bool `json:\"requireGitSSHSecretKnownHosts,omitempty\"`","","\tEnableAPIFields          string `json:\"enableAPIFields,omitempty\"`","\tSendCloudEventsForRuns   bool   `json:\"sendCloudEventsForRuns,omitempty\"`","\tAwaitSidecarReadiness    bool   `json:\"awaitSidecarReadiness,omitempty\"`","\tEnforceNonfalsifiability string `json:\"enforceNonfalsifiability,omitempty\"`","\tEnableKeepPodOnCancel    bool   `json:\"enableKeepPodOnCancel,omitempty\"`","\t// VerificationNoMatchPolicy is the feature flag for \"trusted-resources-verification-no-match-policy\"","\t// VerificationNoMatchPolicy can be set to \"ignore\", \"warn\" and \"fail\" values.","\t// ignore: skip trusted resources verification when no matching verification policies found","\t// warn: skip trusted resources verification when no matching verification policies found and log a warning","\t// fail: fail the taskrun or pipelines run if no matching verification policies found","\tVerificationNoMatchPolicy                string `json:\"verificationNoMatchPolicy,omitempty\"`","\tEnableProvenanceInStatus                 bool   `json:\"enableProvenanceInStatus,omitempty\"`","\tResultExtractionMethod                   string `json:\"resultExtractionMethod,omitempty\"`","\tMaxResultSize                            int    `json:\"maxResultSize,omitempty\"`","\tSetSecurityContext                       bool   `json:\"setSecurityContext,omitempty\"`","\tSetSecurityContextReadOnlyRootFilesystem bool   `json:\"setSecurityContextReadOnlyRootFilesystem,omitempty\"`","\tCoschedule                               string `json:\"coschedule,omitempty\"`","\tEnableCELInWhenExpression                bool   `json:\"enableCELInWhenExpression,omitempty\"`","\t// EnableStepActions is a no-op flag since StepActions are stable","\tEnableStepActions            bool   `json:\"enableStepActions,omitempty\"`","\tEnableParamEnum              bool   `json:\"enableParamEnum,omitempty\"`","\tEnableArtifacts              bool   `json:\"enableArtifacts,omitempty\"`","\tDisableInlineSpec            string `json:\"disableInlineSpec,omitempty\"`","\tEnableConciseResolverSyntax  bool   `json:\"enableConciseResolverSyntax,omitempty\"`","\tEnableKubernetesSidecar      bool   `json:\"enableKubernetesSidecar,omitempty\"`","\tEnableWaitExponentialBackoff bool   `json:\"enableWaitExponentialBackoff,omitempty\"`","}","","// GetFeatureFlagsConfigName returns the name of the configmap containing all","// feature flags.","func GetFeatureFlagsConfigName() string {","\tif e := os.Getenv(\"CONFIG_FEATURE_FLAGS_NAME\"); e != \"\" {","\t\treturn e","\t}","\treturn \"feature-flags\"","}","","// NewFeatureFlagsFromMap returns a Config given a map corresponding to a ConfigMap","func NewFeatureFlagsFromMap(cfgMap map[string]string) (*FeatureFlags, error) {","\tsetPerFeatureFlag := func(key string, defaultValue PerFeatureFlag, feature *bool) error {","\t\tif cfg, ok := cfgMap[key]; ok {","\t\t\tvalue, err := strconv.ParseBool(cfg)","\t\t\tif err != nil {","\t\t\t\treturn fmt.Errorf(\"failed parsing feature flags config %q: %w for feature %s\", cfg, err, key)","\t\t\t}","\t\t\t*feature = value","\t\t\treturn nil","\t\t}","\t\t*feature = defaultValue.Enabled","\t\treturn nil","\t}","","\tsetFeature := func(key string, defaultValue bool, feature *bool) error {","\t\tif cfg, ok := cfgMap[key]; ok {","\t\t\tvalue, err := strconv.ParseBool(cfg)","\t\t\tif err != nil {","\t\t\t\treturn fmt.Errorf(\"failed parsing feature flags config %q: %w\", cfg, err)","\t\t\t}","\t\t\t*feature = value","\t\t\treturn nil","\t\t}","\t\t*feature = defaultValue","\t\treturn nil","\t}","","\ttc := FeatureFlags{}","\tif err := setFeature(disableCredsInitKey, DefaultDisableCredsInit, \u0026tc.DisableCredsInit); err != nil {","\t\treturn nil, err","\t}","\tif err := setFeature(runningInEnvWithInjectedSidecarsKey, DefaultRunningInEnvWithInjectedSidecars, \u0026tc.RunningInEnvWithInjectedSidecars); err != nil {","\t\treturn nil, err","\t}","\tif err := setFeature(awaitSidecarReadinessKey, DefaultAwaitSidecarReadiness, \u0026tc.AwaitSidecarReadiness); err != nil {","\t\treturn nil, err","\t}","\tif err := setFeature(requireGitSSHSecretKnownHostsKey, DefaultRequireGitSSHSecretKnownHosts, \u0026tc.RequireGitSSHSecretKnownHosts); err != nil {","\t\treturn nil, err","\t}","\tif err := setEnabledAPIFields(cfgMap, DefaultEnableAPIFields, \u0026tc.EnableAPIFields); err != nil {","\t\treturn nil, err","\t}","\tif err := setFeature(sendCloudEventsForRuns, DefaultSendCloudEventsForRuns, \u0026tc.SendCloudEventsForRuns); err != nil {","\t\treturn nil, err","\t}","\tif err := setVerificationNoMatchPolicy(cfgMap, DefaultNoMatchPolicyConfig, \u0026tc.VerificationNoMatchPolicy); err != nil {","\t\treturn nil, err","\t}","\tif err := setFeature(enableProvenanceInStatus, DefaultEnableProvenanceInStatus, \u0026tc.EnableProvenanceInStatus); err != nil {","\t\treturn nil, err","\t}","\tif err := setResultExtractionMethod(cfgMap, DefaultResultExtractionMethod, \u0026tc.ResultExtractionMethod); err != nil {","\t\treturn nil, err","\t}","\tif err := setMaxResultSize(cfgMap, DefaultMaxResultSize, \u0026tc.MaxResultSize); err != nil {","\t\treturn nil, err","\t}","\tif err := setPerFeatureFlag(KeepPodOnCancel, DefaultEnableKeepPodOnCancel, \u0026tc.EnableKeepPodOnCancel); err != nil {","\t\treturn nil, err","\t}","\tif err := setEnforceNonFalsifiability(cfgMap, \u0026tc.EnforceNonfalsifiability); err != nil {","\t\treturn nil, err","\t}","\tif err := setFeature(setSecurityContextKey, DefaultSetSecurityContext, \u0026tc.SetSecurityContext); err != nil {","\t\treturn nil, err","\t}","\tif err := setFeature(setSecurityContextReadOnlyRootFilesystemKey, DefaultSetSecurityContextReadOnlyRootFilesystem, \u0026tc.SetSecurityContextReadOnlyRootFilesystem); err != nil {","\t\treturn nil, err","\t}","\tif err := setCoschedule(cfgMap, DefaultCoschedule, \u0026tc.Coschedule); err != nil {","\t\treturn nil, err","\t}","\tif err := setPerFeatureFlag(EnableCELInWhenExpression, DefaultEnableCELInWhenExpression, \u0026tc.EnableCELInWhenExpression); err != nil {","\t\treturn nil, err","\t}","\tif err := setPerFeatureFlag(EnableParamEnum, DefaultEnableParamEnum, \u0026tc.EnableParamEnum); err != nil {","\t\treturn nil, err","\t}","\tif err := setPerFeatureFlag(EnableArtifacts, DefaultEnableArtifacts, \u0026tc.EnableArtifacts); err != nil {","\t\treturn nil, err","\t}","","\tif err := setFeatureInlineSpec(cfgMap, DisableInlineSpec, DefaultDisableInlineSpec, \u0026tc.DisableInlineSpec); err != nil {","\t\treturn nil, err","\t}","\tif err := setPerFeatureFlag(EnableConciseResolverSyntax, DefaultEnableConciseResolverSyntax, \u0026tc.EnableConciseResolverSyntax); err != nil {","\t\treturn nil, err","\t}","\tif err := setFeature(EnableKubernetesSidecar, DefaultEnableKubernetesSidecar, \u0026tc.EnableKubernetesSidecar); err != nil {","\t\treturn nil, err","\t}","\tif err := setFeature(EnableWaitExponentialBackoff, DefaultEnableWaitExponentialBackoff, \u0026tc.EnableWaitExponentialBackoff); err != nil {","\t\treturn nil, err","\t}","","\treturn \u0026tc, nil","}","","// setEnabledAPIFields sets the \"enable-api-fields\" flag based on the content of a given map.","// If the feature gate is invalid or missing then an error is returned.","func setEnabledAPIFields(cfgMap map[string]string, defaultValue string, feature *string) error {","\tvalue := defaultValue","\tif cfg, ok := cfgMap[enableAPIFields]; ok {","\t\tvalue = strings.ToLower(cfg)","\t}","\tswitch value {","\tcase AlphaAPIFields, BetaAPIFields, StableAPIFields:","\t\t*feature = value","\tdefault:","\t\treturn fmt.Errorf(\"invalid value for feature flag %q: %q\", enableAPIFields, value)","\t}","\treturn nil","}","","// setCoschedule sets the \"coschedule\" flag based on the content of a given map.","func setCoschedule(cfgMap map[string]string, defaultValue string, feature *string) error {","\tvalue := defaultValue","\tif cfg, ok := cfgMap[coscheduleKey]; ok {","\t\tvalue = strings.ToLower(cfg)","\t}","","\tswitch value {","\tcase CoscheduleDisabled, CoscheduleWorkspaces, CoschedulePipelineRuns, CoscheduleIsolatePipelineRun:","\t\t*feature = value","\tdefault:","\t\treturn fmt.Errorf(\"invalid value for feature flag %q: %q\", coscheduleKey, value)","\t}","","\treturn nil","}","","// setEnforceNonFalsifiability sets the \"enforce-nonfalsifiability\" flag based on the content of a given map.","// If the feature gate is invalid, then an error is returned.","func setEnforceNonFalsifiability(cfgMap map[string]string, feature *string) error {","\tvalue := DefaultEnforceNonfalsifiability","\tif cfg, ok := cfgMap[enforceNonfalsifiability]; ok {","\t\tvalue = strings.ToLower(cfg)","\t}","","\t// validate that \"enforce-nonfalsifiability\" is set to a valid value","\tswitch value {","\tcase EnforceNonfalsifiabilityNone, EnforceNonfalsifiabilityWithSpire:","\t\t*feature = value","\t\treturn nil","\tdefault:","\t\treturn fmt.Errorf(\"invalid value for feature flag %q: %q\", enforceNonfalsifiability, value)","\t}","}","","func setFeatureInlineSpec(cfgMap map[string]string, key string, defaultValue string, feature *string) error {","\tif cfg, ok := cfgMap[key]; ok {","\t\t*feature = cfg","\t\treturn nil","\t}","\t*feature = strings.ReplaceAll(defaultValue, \" \", \"\")","\treturn nil","}","","// setResultExtractionMethod sets the \"results-from\" flag based on the content of a given map.","// If the feature gate is invalid or missing then an error is returned.","func setResultExtractionMethod(cfgMap map[string]string, defaultValue string, feature *string) error {","\tvalue := defaultValue","\tif cfg, ok := cfgMap[resultExtractionMethod]; ok {","\t\tvalue = strings.ToLower(cfg)","\t}","\tswitch value {","\tcase ResultExtractionMethodTerminationMessage, ResultExtractionMethodSidecarLogs:","\t\t*feature = value","\tdefault:","\t\treturn fmt.Errorf(\"invalid value for feature flag %q: %q\", resultExtractionMethod, value)","\t}","\treturn nil","}","","// setMaxResultSize sets the \"max-result-size\" flag based on the content of a given map.","// If the feature gate is invalid or missing then an error is returned.","func setMaxResultSize(cfgMap map[string]string, defaultValue int, feature *int) error {","\tvalue := defaultValue","\tif cfg, ok := cfgMap[maxResultSize]; ok {","\t\tv, err := strconv.Atoi(cfg)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tvalue = v","\t}","\t// if max limit is \u003e 1.5 MB (CRD limit).","\tif value \u003e= 1572864 {","\t\treturn fmt.Errorf(\"invalid value for feature flag %q: %q. This is exceeding the CRD limit\", resultExtractionMethod, strconv.Itoa(value))","\t}","\t*feature = value","\treturn nil","}","","// setVerificationNoMatchPolicy sets the \"trusted-resources-verification-no-match-policy\" flag based on the content of a given map.","// If the value is invalid or missing then an error is returned.","func setVerificationNoMatchPolicy(cfgMap map[string]string, defaultValue string, feature *string) error {","\tvalue := defaultValue","\tif cfg, ok := cfgMap[verificationNoMatchPolicy]; ok {","\t\tvalue = strings.ToLower(cfg)","\t}","\tswitch value {","\tcase FailNoMatchPolicy, WarnNoMatchPolicy, IgnoreNoMatchPolicy:","\t\t*feature = value","\tdefault:","\t\treturn fmt.Errorf(\"invalid value for feature flag %q: %q\", verificationNoMatchPolicy, value)","\t}","\treturn nil","}","","type PerFeatureFlag struct {","\t// Name of the feature flag","\tName string","\t// Stability level of the feature, one of StableAPIFields, BetaAPIFields or AlphaAPIFields","\tStability string","\t// Enabled is whether the feature is turned on","\tEnabled bool","\t// Deprecated indicates whether the feature is deprecated","\t// +optional","\t//nolint:gocritic","\tDeprecated bool","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,2,2,0,0,2,2,2,2,2,2,2,2,0,2,2,0,0,2,2,2,2,2,2,2,2,1,1,2,1,1,2,2,2,2,1,1,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,1,1,2,2,2,2,2,2,2,1,1,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,0,2,2,2,2,2,0,0,2,0,0,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0]},{"id":4,"path":"pkg/apis/config/featureflags_validation.go","lines":["//go:build !disable_tls","","/*","Copyright 2021 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package config","","import (","\t\"context\"","\t\"fmt\"","","\t\"knative.dev/pkg/apis\"",")","","// ValidateEnabledAPIFields checks that the enable-api-fields feature gate is set","// to a version at most as stable as wantVersion, if not, returns an error stating which feature","// is dependent on the version and what the current version actually is.","func ValidateEnabledAPIFields(ctx context.Context, featureName string, wantVersion string) *apis.FieldError {","\tcurrentVersion := FromContextOrDefaults(ctx).FeatureFlags.EnableAPIFields","\tvar errs *apis.FieldError","\tmessage := `%s requires \"enable-api-fields\" feature gate to be %s but it is %q`","\tswitch wantVersion {","\tcase StableAPIFields:","\t\t// If the feature is stable, it doesn't matter what the current version is","\tcase BetaAPIFields:","\t\t// If the feature requires \"beta\" fields to be enabled, the current version may be \"beta\" or \"alpha\"","\t\tif currentVersion != BetaAPIFields \u0026\u0026 currentVersion != AlphaAPIFields {","\t\t\tmessage = fmt.Sprintf(message, featureName, fmt.Sprintf(\"%q or %q\", AlphaAPIFields, BetaAPIFields), currentVersion)","\t\t\terrs = apis.ErrGeneric(message)","\t\t}","\tcase AlphaAPIFields:","\t\t// If the feature requires \"alpha\" fields to be enabled, the current version must be \"alpha\"","\t\tif currentVersion != wantVersion {","\t\t\tmessage = fmt.Sprintf(message, featureName, fmt.Sprintf(\"%q\", AlphaAPIFields), currentVersion)","\t\t\terrs = apis.ErrGeneric(message)","\t\t}","\tdefault:","\t\terrs = apis.ErrGeneric(\"invalid wantVersion %s, must be one of (%s, %s, %s)\", wantVersion, AlphaAPIFields, BetaAPIFields, StableAPIFields)","\t}","\treturn errs","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0]},{"id":5,"path":"pkg/apis/config/metrics.go","lines":["/*","Copyright 2021 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package config","","import (","\tcorev1 \"k8s.io/api/core/v1\"",")","","const (","\t// metricsTaskrunLevel determines to what level to aggregate metrics","\t// for taskrun","\tmetricsTaskrunLevelKey = \"metrics.taskrun.level\"","","\t// metricsPipelinerunLevel determines to what level to aggregate metrics","\t// for pipelinerun","\tmetricsPipelinerunLevelKey = \"metrics.pipelinerun.level\"","\t// metricsRunningPipelinerunLevelKey determines to what level to aggregate metrics","\t// for running pipelineruns","\tmetricsRunningPipelinerunLevelKey = \"metrics.running-pipelinerun.level\"","\t// metricsDurationTaskrunType determines what type of","\t// metrics to use for aggregating duration for taskrun","\tmetricsDurationTaskrunType = \"metrics.taskrun.duration-type\"","\t// metricsDurationPipelinerunType determines what type of","\t// metrics to use for aggregating duration for pipelinerun","\tmetricsDurationPipelinerunType = \"metrics.pipelinerun.duration-type\"","","\t// countWithReasonKey sets if the reason label should be included on count metrics","\tcountWithReasonKey = \"metrics.count.enable-reason\"","","\t// throttledWithNamespaceKey sets if the namespace label should be included on the taskrun throttled metrics","\tthrottledWithNamespaceKey = \"metrics.taskrun.throttle.enable-namespace\"","","\t// DefaultTaskrunLevel determines to what level to aggregate metrics","\t// when it isn't specified in configmap","\tDefaultTaskrunLevel = TaskrunLevelAtTask","\t// TaskrunLevelAtTaskrun specify that aggregation will be done at","\t// taskrun level","\tTaskrunLevelAtTaskrun = \"taskrun\"","\t// TaskrunLevelAtTask specify that aggregation will be done at task level","\tTaskrunLevelAtTask = \"task\"","\t// TaskrunLevelAtNS specify that aggregation will be done at namespace level","\tTaskrunLevelAtNS = \"namespace\"","\t// DefaultPipelinerunLevel determines to what level to aggregate metrics","\t// when it isn't specified in configmap","\tDefaultPipelinerunLevel = PipelinerunLevelAtPipeline","\t// DefaultRunningPipelinerunLevel determines to what level to aggregate metrics","\t// when it isn't specified in configmap","\tDefaultRunningPipelinerunLevel = \"\"","\t// PipelinerunLevelAtPipelinerun specify that aggregation will be done at","\t// pipelinerun level","\tPipelinerunLevelAtPipelinerun = \"pipelinerun\"","\t// PipelinerunLevelAtPipeline specify that aggregation will be done at","\t// pipeline level","\tPipelinerunLevelAtPipeline = \"pipeline\"","\t// PipelinerunLevelAtNS specify that aggregation will be done at","\t// namespace level","\tPipelinerunLevelAtNS = \"namespace\"","","\t// DefaultDurationTaskrunType determines what type","\t// of metrics to use when we don't specify one in","\t// configmap","\tDefaultDurationTaskrunType = \"histogram\"","\t// DurationTaskrunTypeHistogram specify that histogram","\t// type metrics need to be use for Duration of Taskrun","\tDurationTaskrunTypeHistogram = \"histogram\"","\t// DurationTaskrunTypeLastValue specify that lastValue or","\t// gauge type metrics need to be use for Duration of Taskrun","\tDurationTaskrunTypeLastValue = \"lastvalue\"","","\t// DefaultDurationPipelinerunType determines what type","\t// of metrics to use when we don't specify one in","\t// configmap","\tDefaultDurationPipelinerunType = \"histogram\"","\t// DurationPipelinerunTypeHistogram specify that histogram","\t// type metrics need to be use for Duration of Pipelinerun","\tDurationPipelinerunTypeHistogram = \"histogram\"","\t// DurationPipelinerunTypeLastValue specify that lastValue or","\t// gauge type metrics need to be use for Duration of Pipelinerun","\tDurationPipelinerunTypeLastValue = \"lastvalue\"",")","","// DefaultMetrics holds all the default configurations for the metrics.","var DefaultMetrics, _ = newMetricsFromMap(map[string]string{})","","// Metrics holds the configurations for the metrics","// +k8s:deepcopy-gen=true","type Metrics struct {","\tTaskrunLevel            string","\tPipelinerunLevel        string","\tRunningPipelinerunLevel string","\tDurationTaskrunType     string","\tDurationPipelinerunType string","\tCountWithReason         bool","\tThrottleWithNamespace   bool","}","","// Equals returns true if two Configs are identical","func (cfg *Metrics) Equals(other *Metrics) bool {","\tif cfg == nil \u0026\u0026 other == nil {","\t\treturn true","\t}","","\tif cfg == nil || other == nil {","\t\treturn false","\t}","","\treturn other.TaskrunLevel == cfg.TaskrunLevel \u0026\u0026","\t\tother.PipelinerunLevel == cfg.PipelinerunLevel \u0026\u0026","\t\tother.DurationTaskrunType == cfg.DurationTaskrunType \u0026\u0026","\t\tother.DurationPipelinerunType == cfg.DurationPipelinerunType \u0026\u0026","\t\tother.CountWithReason == cfg.CountWithReason","}","","// newMetricsFromMap returns a Config given a map corresponding to a ConfigMap","func newMetricsFromMap(cfgMap map[string]string) (*Metrics, error) {","\ttc := Metrics{","\t\tTaskrunLevel:            DefaultTaskrunLevel,","\t\tPipelinerunLevel:        DefaultPipelinerunLevel,","\t\tRunningPipelinerunLevel: DefaultRunningPipelinerunLevel,","\t\tDurationTaskrunType:     DefaultDurationTaskrunType,","\t\tDurationPipelinerunType: DefaultDurationPipelinerunType,","\t\tCountWithReason:         false,","\t\tThrottleWithNamespace:   false,","\t}","","\tif taskrunLevel, ok := cfgMap[metricsTaskrunLevelKey]; ok {","\t\ttc.TaskrunLevel = taskrunLevel","\t}","","\tif pipelinerunLevel, ok := cfgMap[metricsPipelinerunLevelKey]; ok {","\t\ttc.PipelinerunLevel = pipelinerunLevel","\t}","\tif runningPipelinerunLevel, ok := cfgMap[metricsRunningPipelinerunLevelKey]; ok {","\t\ttc.RunningPipelinerunLevel = runningPipelinerunLevel","\t}","\tif durationTaskrun, ok := cfgMap[metricsDurationTaskrunType]; ok {","\t\ttc.DurationTaskrunType = durationTaskrun","\t}","\tif durationPipelinerun, ok := cfgMap[metricsDurationPipelinerunType]; ok {","\t\ttc.DurationPipelinerunType = durationPipelinerun","\t}","","\tif countWithReason, ok := cfgMap[countWithReasonKey]; ok \u0026\u0026 countWithReason != \"false\" {","\t\ttc.CountWithReason = true","\t}","","\tif throttleWithNamespace, ok := cfgMap[throttledWithNamespaceKey]; ok \u0026\u0026 throttleWithNamespace != \"false\" {","\t\ttc.ThrottleWithNamespace = true","\t}","","\treturn \u0026tc, nil","}","","// NewMetricsFromConfigMap returns a Config for the given configmap","func NewMetricsFromConfigMap(config *corev1.ConfigMap) (*Metrics, error) {","\treturn newMetricsFromMap(config.Data)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,1,1,1,0,1,1,1,1,1,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,0,2,0,0,0,2,2,2]},{"id":6,"path":"pkg/apis/config/metrics_tls.go","lines":["//go:build !disable_tls","","package config","","import (","\t\"context\"","","\tcorev1 \"k8s.io/api/core/v1\"","\t\"knative.dev/pkg/metrics\"",")","","// GetMetricsConfigName returns the name of the configmap containing all","// customizations for the storage bucket.","func GetMetricsConfigName() string {","\treturn metrics.ConfigMapName()","}","","// NewFeatureFlagsFromConfigMap returns a Config for the given configmap","func NewFeatureFlagsFromConfigMap(config *corev1.ConfigMap) (*FeatureFlags, error) {","\treturn NewFeatureFlagsFromMap(config.Data)","}","","// GetVerificationNoMatchPolicy returns the \"trusted-resources-verification-no-match-policy\" value","func GetVerificationNoMatchPolicy(ctx context.Context) string {","\treturn FromContextOrDefaults(ctx).FeatureFlags.VerificationNoMatchPolicy","}","","// IsSpireEnabled checks if non-falsifiable provenance is enforced through SPIRE","func IsSpireEnabled(ctx context.Context) bool {","\treturn FromContextOrDefaults(ctx).FeatureFlags.EnforceNonfalsifiability == EnforceNonfalsifiabilityWithSpire","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2]},{"id":7,"path":"pkg/apis/config/resolver/feature_flags.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resolver","","import (","\t\"fmt\"","\t\"os\"","\t\"strconv\"","","\tcorev1 \"k8s.io/api/core/v1\"",")","","const (","\t// DefaultEnableGitResolver is the default value for \"enable-git-resolver\".","\tDefaultEnableGitResolver = true","\t// DefaultEnableHubResolver is the default value for \"enable-hub-resolver\".","\tDefaultEnableHubResolver = true","\t// DefaultEnableBundlesResolver is the default value for \"enable-bundles-resolver\".","\tDefaultEnableBundlesResolver = true","\t// DefaultEnableClusterResolver is the default value for \"enable-cluster-resolver\".","\tDefaultEnableClusterResolver = true","\t// DefaultEnableHttpResolver is the default value for \"enable-http-resolver\".","\tDefaultEnableHttpResolver = true","","\t// EnableGitResolver is the flag used to enable the git remote resolver","\tEnableGitResolver = \"enable-git-resolver\"","\t// EnableHubResolver is the flag used to enable the hub remote resolver","\tEnableHubResolver = \"enable-hub-resolver\"","\t// EnableBundlesResolver is the flag used to enable the bundle remote resolver","\tEnableBundlesResolver = \"enable-bundles-resolver\"","\t// EnableClusterResolver is the flag used to enable the cluster remote resolver","\tEnableClusterResolver = \"enable-cluster-resolver\"","\t// EnableHttpResolver is the flag used to enable the http remote resolver","\tEnableHttpResolver = \"enable-http-resolver\"",")","","// FeatureFlags holds the features configurations","// +k8s:deepcopy-gen=true","type FeatureFlags struct {","\tEnableGitResolver     bool","\tEnableHubResolver     bool","\tEnableBundleResolver  bool","\tEnableClusterResolver bool","\tEnableHttpResolver    bool","}","","// GetFeatureFlagsConfigName returns the name of the configmap containing all","// feature flags.","func GetFeatureFlagsConfigName() string {","\tif e := os.Getenv(\"CONFIG_RESOLVERS_FEATURE_FLAGS_NAME\"); e != \"\" {","\t\treturn e","\t}","\treturn \"resolvers-feature-flags\"","}","","// NewFeatureFlagsFromMap returns a Config given a map corresponding to a ConfigMap","func NewFeatureFlagsFromMap(cfgMap map[string]string) (*FeatureFlags, error) {","\tsetFeature := func(key string, defaultValue bool, feature *bool) error {","\t\tif cfg, ok := cfgMap[key]; ok {","\t\t\tvalue, err := strconv.ParseBool(cfg)","\t\t\tif err != nil {","\t\t\t\treturn fmt.Errorf(\"failed parsing feature flags config %q: %w\", cfg, err)","\t\t\t}","\t\t\t*feature = value","\t\t\treturn nil","\t\t}","\t\t*feature = defaultValue","\t\treturn nil","\t}","","\ttc := FeatureFlags{}","\tif err := setFeature(EnableGitResolver, DefaultEnableGitResolver, \u0026tc.EnableGitResolver); err != nil {","\t\treturn nil, err","\t}","\tif err := setFeature(EnableHubResolver, DefaultEnableHubResolver, \u0026tc.EnableHubResolver); err != nil {","\t\treturn nil, err","\t}","\tif err := setFeature(EnableBundlesResolver, DefaultEnableBundlesResolver, \u0026tc.EnableBundleResolver); err != nil {","\t\treturn nil, err","\t}","\tif err := setFeature(EnableClusterResolver, DefaultEnableClusterResolver, \u0026tc.EnableClusterResolver); err != nil {","\t\treturn nil, err","\t}","\tif err := setFeature(EnableHttpResolver, DefaultEnableHttpResolver, \u0026tc.EnableHttpResolver); err != nil {","\t\treturn nil, err","\t}","\treturn \u0026tc, nil","}","","// NewFeatureFlagsFromConfigMap returns a Config for the given configmap","func NewFeatureFlagsFromConfigMap(config *corev1.ConfigMap) (*FeatureFlags, error) {","\treturn NewFeatureFlagsFromMap(config.Data)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,2,2,0,0,2,2,2,2,2,1,1,2,1,1,2,1,1,2,1,1,2,0,0,0,2,2,2]},{"id":8,"path":"pkg/apis/config/resolver/store.go","lines":["//go:build !disable_tls","","/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resolver","","import (","\t\"context\"","","\t\"knative.dev/pkg/configmap\"",")","","type cfgKey struct{}","","// Config holds the collection of configurations that we attach to contexts.","// +k8s:deepcopy-gen=false","type Config struct {","\tFeatureFlags *FeatureFlags","}","","// ResolversNamespace takes the pipelines namespace and appends \"-resolvers\" to it.","func ResolversNamespace(baseNS string) string {","\treturn baseNS + \"-resolvers\"","}","","// FromContext extracts a Config from the provided context.","func FromContext(ctx context.Context) *Config {","\tx, ok := ctx.Value(cfgKey{}).(*Config)","\tif ok {","\t\treturn x","\t}","\treturn nil","}","","// FromContextOrDefaults is like FromContext, but when no Config is attached it","// returns a Config populated with the defaults for each of the Config fields.","func FromContextOrDefaults(ctx context.Context) *Config {","\tif cfg := FromContext(ctx); cfg != nil {","\t\treturn cfg","\t}","\tfeatureFlags, _ := NewFeatureFlagsFromMap(map[string]string{})","\treturn \u0026Config{","\t\tFeatureFlags: featureFlags,","\t}","}","","// ToContext attaches the provided Config to the provided context, returning the","// new context with the Config attached.","func ToContext(ctx context.Context, c *Config) context.Context {","\treturn context.WithValue(ctx, cfgKey{}, c)","}","","// Store is a typed wrapper around configmap.Untyped store to handle our configmaps.","// +k8s:deepcopy-gen=false","type Store struct {","\t*configmap.UntypedStore","}","","// NewStore creates a new store of Configs and optionally calls functions when ConfigMaps are updated.","func NewStore(logger configmap.Logger, onAfterStore ...func(name string, value interface{})) *Store {","\tstore := \u0026Store{","\t\tUntypedStore: configmap.NewUntypedStore(","\t\t\t\"features\",","\t\t\tlogger,","\t\t\tconfigmap.Constructors{","\t\t\t\tGetFeatureFlagsConfigName(): NewFeatureFlagsFromConfigMap,","\t\t\t},","\t\t\tonAfterStore...,","\t\t),","\t}","","\treturn store","}","","// ToContext attaches the current Config state to the provided context.","func (s *Store) ToContext(ctx context.Context) context.Context {","\treturn ToContext(ctx, s.Load())","}","","// Load creates a Config from the current config state of the Store.","func (s *Store) Load() *Config {","\tfeatureFlags := s.UntypedLoad(GetFeatureFlagsConfigName())","\tif featureFlags == nil {","\t\tfeatureFlags, _ = NewFeatureFlagsFromMap(map[string]string{})","\t}","\treturn \u0026Config{","\t\tFeatureFlags: featureFlags.(*FeatureFlags).DeepCopy(),","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,2,2,2,2,2,1,0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,2,2,2,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,0,2,2,2,1,1,2,2,2,0]},{"id":9,"path":"pkg/apis/config/spire_config.go","lines":["//go:build !disable_tls","","/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package config","","import (","\t\"fmt\"","\t\"os\"","","\tsc \"github.com/tektoncd/pipeline/pkg/spire/config\"","\tcorev1 \"k8s.io/api/core/v1\"",")","","const (","\t// SpireConfigMapName is the name of the trusted resources configmap","\tSpireConfigMapName = \"config-spire\"","","\t// SpireTrustDomain is the key to extract out the SPIRE trust domain to use","\tSpireTrustDomain = \"spire-trust-domain\"","\t// SpireSocketPath is the key to extract out the SPIRE agent socket for SPIFFE workload API","\tSpireSocketPath = \"spire-socket-path\"","\t// SpireServerAddr is the key to extract out the SPIRE server address for workload/node registration","\tSpireServerAddr = \"spire-server-addr\"","\t// SpireNodeAliasPrefix is the key to extract out the SPIRE node alias prefix to use","\tSpireNodeAliasPrefix = \"spire-node-alias-prefix\"","","\t// SpireTrustDomainDefault is the default value for the SpireTrustDomain","\tSpireTrustDomainDefault = \"example.org\"","\t// SpireSocketPathDefault is the default value for the SpireSocketPath","\tSpireSocketPathDefault = \"unix:///spiffe-workload-api/spire-agent.sock\"","\t// SpireServerAddrDefault is the default value for the SpireServerAddr","\tSpireServerAddrDefault = \"spire-server.spire.svc.cluster.local:8081\"","\t// SpireNodeAliasPrefixDefault is the default value for the SpireNodeAliasPrefix","\tSpireNodeAliasPrefixDefault = \"/tekton-node/\"",")","","// DefaultSpire hols all the default configurations for the spire.","var DefaultSpire, _ = NewSpireConfigFromMap(map[string]string{})","","// NewSpireConfigFromMap creates a Config from the supplied map","func NewSpireConfigFromMap(data map[string]string) (*sc.SpireConfig, error) {","\tcfg := \u0026sc.SpireConfig{}","\tvar ok bool","\tif cfg.TrustDomain, ok = data[SpireTrustDomain]; !ok {","\t\tcfg.TrustDomain = SpireTrustDomainDefault","\t}","\tif cfg.SocketPath, ok = data[SpireSocketPath]; !ok {","\t\tcfg.SocketPath = SpireSocketPathDefault","\t}","\tif cfg.ServerAddr, ok = data[SpireServerAddr]; !ok {","\t\tcfg.ServerAddr = SpireServerAddrDefault","\t}","\tif cfg.NodeAliasPrefix, ok = data[SpireNodeAliasPrefix]; !ok {","\t\tcfg.NodeAliasPrefix = SpireNodeAliasPrefixDefault","\t}","\tif err := cfg.Validate(); err != nil {","\t\treturn nil, fmt.Errorf(\"failed to parse SPIRE configmap: %w\", err)","\t}","\treturn cfg, nil","}","","// NewSpireConfigFromConfigMap creates a Config from the supplied ConfigMap","func NewSpireConfigFromConfigMap(configMap *corev1.ConfigMap) (*sc.SpireConfig, error) {","\treturn NewSpireConfigFromMap(configMap.Data)","}","","// GetSpireConfigName returns the name of Spire ConfigMap","func GetSpireConfigName() string {","\tif e := os.Getenv(\"CONFIG_SPIRE\"); e != \"\" {","\t\treturn e","\t}","\treturn SpireConfigMapName","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,0,0,0,2,2,2,0,0,2,2,1,1,2,0]},{"id":10,"path":"pkg/apis/config/store.go","lines":["//go:build !disable_tls","","/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package config","","import (","\t\"context\"","","\tsc \"github.com/tektoncd/pipeline/pkg/spire/config\"","\t\"knative.dev/pkg/configmap\"",")","","type cfgKey struct{}","","// Config holds the collection of configurations that we attach to contexts.","// +k8s:deepcopy-gen=false","type Config struct {","\tDefaults               *Defaults","\tFeatureFlags           *FeatureFlags","\tMetrics                *Metrics","\tSpireConfig            *sc.SpireConfig","\tEvents                 *Events","\tTracing                *Tracing","\tWaitExponentialBackoff *WaitExponentialBackoff","}","","// FromContext extracts a Config from the provided context.","func FromContext(ctx context.Context) *Config {","\tx, ok := ctx.Value(cfgKey{}).(*Config)","\tif ok {","\t\treturn x","\t}","\treturn nil","}","","// FromContextOrDefaults is like FromContext, but when no Config is attached it","// returns a Config populated with the defaults for each of the Config fields.","func FromContextOrDefaults(ctx context.Context) *Config {","\tif cfg := FromContext(ctx); cfg != nil {","\t\treturn cfg","\t}","","\treturn \u0026Config{","\t\tDefaults:               DefaultConfig.DeepCopy(),","\t\tFeatureFlags:           DefaultFeatureFlags.DeepCopy(),","\t\tMetrics:                DefaultMetrics.DeepCopy(),","\t\tSpireConfig:            DefaultSpire.DeepCopy(),","\t\tEvents:                 DefaultEvents.DeepCopy(),","\t\tTracing:                DefaultTracing.DeepCopy(),","\t\tWaitExponentialBackoff: DefaultWaitExponentialBackoff.DeepCopy(),","\t}","}","","// ToContext attaches the provided Config to the provided context, returning the","// new context with the Config attached.","func ToContext(ctx context.Context, c *Config) context.Context {","\treturn context.WithValue(ctx, cfgKey{}, c)","}","","// Store is a typed wrapper around configmap.Untyped store to handle our configmaps.","// +k8s:deepcopy-gen=false","type Store struct {","\t*configmap.UntypedStore","}","","// NewStore creates a new store of Configs and optionally calls functions when ConfigMaps are updated.","func NewStore(logger configmap.Logger, onAfterStore ...func(name string, value interface{})) *Store {","\tstore := \u0026Store{","\t\tUntypedStore: configmap.NewUntypedStore(","\t\t\t\"defaults/features/artifacts\",","\t\t\tlogger,","\t\t\tconfigmap.Constructors{","\t\t\t\tGetDefaultsConfigName():               NewDefaultsFromConfigMap,","\t\t\t\tGetFeatureFlagsConfigName():           NewFeatureFlagsFromConfigMap,","\t\t\t\tGetMetricsConfigName():                NewMetricsFromConfigMap,","\t\t\t\tGetSpireConfigName():                  NewSpireConfigFromConfigMap,","\t\t\t\tGetEventsConfigName():                 NewEventsFromConfigMap,","\t\t\t\tGetTracingConfigName():                NewTracingFromConfigMap,","\t\t\t\tGetWaitExponentialBackoffConfigName(): NewWaitExponentialBackoffFromConfigMap,","\t\t\t},","\t\t\tonAfterStore...,","\t\t),","\t}","","\treturn store","}","","// ToContext attaches the current Config state to the provided context.","func (s *Store) ToContext(ctx context.Context) context.Context {","\treturn ToContext(ctx, s.Load())","}","","// Load creates a Config from the current config state of the Store.","func (s *Store) Load() *Config {","\tdefaults := s.UntypedLoad(GetDefaultsConfigName())","\tif defaults == nil {","\t\tdefaults = DefaultConfig.DeepCopy()","\t}","\tfeatureFlags := s.UntypedLoad(GetFeatureFlagsConfigName())","\tif featureFlags == nil {","\t\tfeatureFlags = DefaultFeatureFlags.DeepCopy()","\t}","\tmetrics := s.UntypedLoad(GetMetricsConfigName())","\tif metrics == nil {","\t\tmetrics = DefaultMetrics.DeepCopy()","\t}","\ttracing := s.UntypedLoad(GetTracingConfigName())","\tif tracing == nil {","\t\ttracing = DefaultTracing.DeepCopy()","\t}","","\tspireconfig := s.UntypedLoad(GetSpireConfigName())","\tif spireconfig == nil {","\t\tspireconfig = DefaultSpire.DeepCopy()","\t}","\tevents := s.UntypedLoad(GetEventsConfigName())","\tif events == nil {","\t\tevents = DefaultEvents.DeepCopy()","\t}","\twaitExponentialBackoff := s.UntypedLoad(GetWaitExponentialBackoffConfigName())","\tif waitExponentialBackoff == nil {","\t\twaitExponentialBackoff = DefaultWaitExponentialBackoff.DeepCopy()","\t}","","\treturn \u0026Config{","\t\tDefaults:               defaults.(*Defaults).DeepCopy(),","\t\tFeatureFlags:           featureFlags.(*FeatureFlags).DeepCopy(),","\t\tMetrics:                metrics.(*Metrics).DeepCopy(),","\t\tTracing:                tracing.(*Tracing).DeepCopy(),","\t\tSpireConfig:            spireconfig.(*sc.SpireConfig).DeepCopy(),","\t\tEvents:                 events.(*Events).DeepCopy(),","\t\tWaitExponentialBackoff: waitExponentialBackoff.(*WaitExponentialBackoff).DeepCopy(),","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,1,0,0,0,0,2,2,2,2,0,1,1,1,1,1,1,1,1,1,0,0,0,0,2,2,2,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,0]},{"id":11,"path":"pkg/apis/config/testing/defaults.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package testing","","import (","\t\"context\"","\t\"testing\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\tlogtesting \"knative.dev/pkg/logging/testing\"",")","","// SetDefaults sets the default ConfigMap values in an existing context (for use in testing)","func SetDefaults(ctx context.Context, t *testing.T, data map[string]string) context.Context {","\tt.Helper()","\ts := config.NewStore(logtesting.TestLogger(t))","\ts.OnConfigChanged(\u0026corev1.ConfigMap{","\t\tObjectMeta: metav1.ObjectMeta{","\t\t\tName: config.GetDefaultsConfigName(),","\t\t},","\t\tData: data,","\t})","\treturn s.ToContext(ctx)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1]},{"id":12,"path":"pkg/apis/config/testing/featureflags.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package testing","","import (","\t\"context\"","\t\"testing\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"knative.dev/pkg/logging\"",")","","// SetFeatureFlags sets the feature-flags ConfigMap values in an existing context (for use in testing)","func SetFeatureFlags(ctx context.Context, t *testing.T, data map[string]string) context.Context {","\tt.Helper()","\ts := config.NewStore(logging.FromContext(ctx).Named(\"config-store\"))","\ts.OnConfigChanged(\u0026corev1.ConfigMap{","\t\tObjectMeta: metav1.ObjectMeta{","\t\t\tName: config.GetFeatureFlagsConfigName(),","\t\t},","\t\tData: data,","\t})","\treturn s.ToContext(ctx)","}","","// EnableAlphaAPIFields enables alpha features in an existing context (for use in testing)","func EnableAlphaAPIFields(ctx context.Context) context.Context {","\treturn setEnableAPIFields(ctx, config.AlphaAPIFields)","}","","// EnableBetaAPIFields enables beta features in an existing context (for use in testing)","func EnableBetaAPIFields(ctx context.Context) context.Context {","\treturn setEnableAPIFields(ctx, config.BetaAPIFields)","}","","// EnableStableAPIFields enables stable features in an existing context (for use in testing)","func EnableStableAPIFields(ctx context.Context) context.Context {","\treturn setEnableAPIFields(ctx, config.StableAPIFields)","}","","func setEnableAPIFields(ctx context.Context, want string) context.Context {","\tfeatureFlags, _ := config.NewFeatureFlagsFromMap(map[string]string{","\t\t\"enable-api-fields\": want,","\t})","\tcfg := \u0026config.Config{","\t\tDefaults: \u0026config.Defaults{","\t\t\tDefaultTimeoutMinutes: 60,","\t\t},","\t\tFeatureFlags: featureFlags,","\t}","\treturn config.ToContext(ctx, cfg)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1]},{"id":13,"path":"pkg/apis/config/tracing.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package config","","import (","\t\"fmt\"","\t\"os\"","\t\"strconv\"","","\tcorev1 \"k8s.io/api/core/v1\"",")","","const (","\t// tracingEnabledKey is the configmap key which determines if tracing is enabled","\ttracingEnabledKey = \"enabled\"","\t// tracingEndpintKey is the configmap key for tracing api endpoint","\ttracingEndpointKey = \"endpoint\"","","\t// tracingCredentialsSecretKey is the name of the secret which contains credentials for tracing endpoint","\ttracingCredentialsSecretKey = \"credentialsSecret\"","","\t// DefaultEndpoint is the default destination for sending traces","\tDefaultEndpoint = \"http://jaeger-collector.jaeger.svc.cluster.local:14268/api/traces\"",")","","// DefaultTracing holds all the default configurations for tracing","var DefaultTracing, _ = newTracingFromMap(map[string]string{})","","// Tracing holds the configurations for tracing","// +k8s:deepcopy-gen=true","type Tracing struct {","\tEnabled           bool","\tEndpoint          string","\tCredentialsSecret string","}","","// Equals returns true if two Configs are identical","func (cfg *Tracing) Equals(other *Tracing) bool {","\tif cfg == nil \u0026\u0026 other == nil {","\t\treturn true","\t}","","\tif cfg == nil || other == nil {","\t\treturn false","\t}","","\treturn other.Enabled == cfg.Enabled \u0026\u0026","\t\tother.Endpoint == cfg.Endpoint \u0026\u0026","\t\tother.CredentialsSecret == cfg.CredentialsSecret","}","","// GetTracingConfigName returns the name of the configmap containing all","// customizations for tracing","func GetTracingConfigName() string {","\tif e := os.Getenv(\"CONFIG_TRACING_NAME\"); e != \"\" {","\t\treturn e","\t}","\treturn \"config-tracing\"","}","","// newTracingFromMap returns a Config given a map from ConfigMap","func newTracingFromMap(config map[string]string) (*Tracing, error) {","\tt := Tracing{","\t\tEnabled:  false,","\t\tEndpoint: DefaultEndpoint,","\t}","","\tif endpoint, ok := config[tracingEndpointKey]; ok {","\t\tt.Endpoint = endpoint","\t}","","\tif secret, ok := config[tracingCredentialsSecretKey]; ok {","\t\tt.CredentialsSecret = secret","\t}","","\tif enabled, ok := config[tracingEnabledKey]; ok {","\t\te, err := strconv.ParseBool(enabled)","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed parsing tracing config %q: %w\", enabled, err)","\t\t}","\t\tt.Enabled = e","\t}","\treturn \u0026t, nil","}","","// NewTracingFromConfigMap returns a Config given a ConfigMap","func NewTracingFromConfigMap(config *corev1.ConfigMap) (*Tracing, error) {","\treturn newTracingFromMap(config.Data)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,2,2,2,0,2,2,2,0,0,0,0,2,2,1,1,2,0,0,0,2,2,2,2,2,2,2,2,2,0,2,1,1,0,2,2,2,1,1,2,0,2,0,0,0,2,2,2]},{"id":14,"path":"pkg/apis/config/wait_exponential_backoff.go","lines":["/*","Copyright 2025 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package config","","import (","\t\"fmt\"","\t\"os\"","\t\"strconv\"","\t\"time\"","","\tcorev1 \"k8s.io/api/core/v1\"",")","","const (","\twaitExponentialBackoffDurationKey = \"duration\"","\twaitExponentialBackoffFactorKey   = \"factor\"","\twaitExponentialBackoffJitterKey   = \"jitter\"","\twaitExponentialBackoffStepsKey    = \"steps\"","\twaitExponentialBackoffCapKey      = \"cap\"","","\tDefaultWaitExponentialBackoffDuration = \"1s\"","\tDefaultWaitExponentialBackoffFactor   = 2.0","\tDefaultWaitExponentialBackoffJitter   = 0.0","\tDefaultWaitExponentialBackoffSteps    = 10","\tDefaultWaitExponentialBackoffCap      = \"60s\"",")","","// DefaultWaitExponentialBackoff holds all the default configurations for wait-exponential-backoff","var DefaultWaitExponentialBackoff, _ = newWaitExponentialBackoffFromMap(map[string]string{})","","// WaitExponentialBackoff holds the configurations for exponential backoff","// +k8s:deepcopy-gen=true","type WaitExponentialBackoff struct {","\tDuration time.Duration","\tFactor   float64","\tJitter   float64","\tSteps    int","\tCap      time.Duration","}","","// Equals returns true if two Configs are identical","func (cfg *WaitExponentialBackoff) Equals(other *WaitExponentialBackoff) bool {","\tif cfg == nil \u0026\u0026 other == nil {","\t\treturn true","\t}","\tif cfg == nil || other == nil {","\t\treturn false","\t}","\treturn other.Duration == cfg.Duration \u0026\u0026","\t\tother.Factor == cfg.Factor \u0026\u0026","\t\tother.Jitter == cfg.Jitter \u0026\u0026","\t\tother.Steps == cfg.Steps \u0026\u0026","\t\tother.Cap == cfg.Cap","}","","// GetWaitExponentialBackoffConfigName returns the name of the configmap containing all customizations for wait-exponential-backoff","func GetWaitExponentialBackoffConfigName() string {","\tif e := os.Getenv(\"CONFIG_WAIT_EXPONENTIAL_BACKOFF_NAME\"); e != \"\" {","\t\treturn e","\t}","\treturn \"config-wait-exponential-backoff\"","}","","// newWaitExponentialBackoffFromMap returns a Config given a map from ConfigMap","func newWaitExponentialBackoffFromMap(config map[string]string) (*WaitExponentialBackoff, error) {","\tw := WaitExponentialBackoff{}","","\tdurationStr := DefaultWaitExponentialBackoffDuration","\tif v, ok := config[waitExponentialBackoffDurationKey]; ok {","\t\tdurationStr = v","\t}","\tdur, err := time.ParseDuration(durationStr)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"failed parsing duration %q: %w\", durationStr, err)","\t}","\tw.Duration = dur","","\tfactor := DefaultWaitExponentialBackoffFactor","\tif v, ok := config[waitExponentialBackoffFactorKey]; ok {","\t\tf, err := strconv.ParseFloat(v, 64)","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed parsing factor %q: %w\", v, err)","\t\t}","\t\tfactor = f","\t}","\tw.Factor = factor","","\tjitter := DefaultWaitExponentialBackoffJitter","\tif v, ok := config[waitExponentialBackoffJitterKey]; ok {","\t\tj, err := strconv.ParseFloat(v, 64)","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed parsing jitter %q: %w\", v, err)","\t\t}","\t\tjitter = j","\t}","\tw.Jitter = jitter","","\tsteps := DefaultWaitExponentialBackoffSteps","\tif v, ok := config[waitExponentialBackoffStepsKey]; ok {","\t\ts, err := strconv.Atoi(v)","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed parsing steps %q: %w\", v, err)","\t\t}","\t\tsteps = s","\t}","\tw.Steps = steps","","\tcapStr := DefaultWaitExponentialBackoffCap","\tif v, ok := config[waitExponentialBackoffCapKey]; ok {","\t\tcapStr = v","\t}","\tcapDur, err := time.ParseDuration(capStr)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"failed parsing cap %q: %w\", capStr, err)","\t}","\tw.Cap = capDur","","\treturn \u0026w, nil","}","","// NewWaitExponentialBackoffFromConfigMap returns a Config given a ConfigMap","func NewWaitExponentialBackoffFromConfigMap(config *corev1.ConfigMap) (*WaitExponentialBackoff, error) {","\treturn newWaitExponentialBackoffFromMap(config.Data)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,1,1,2,0,0,0,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,1,1,2,0,2,2,2,2,2,2,1,1,2,0,2,2,2,2,2,2,1,1,2,0,2,2,2,2,2,2,2,2,1,1,2,2,2,0,0,0,2,2,2]},{"id":15,"path":"pkg/apis/pipeline/errors/errors.go","lines":["/*","Copyright 2023 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package errors","","import (","\t\"errors\"","\t\"strings\"","","\tapierrors \"k8s.io/apimachinery/pkg/api/errors\"",")","","const UserErrorLabel = \"[User error] \"","","type UserError struct {","\tReason   string","\tOriginal error","}","","var _ error = \u0026UserError{}","","// Error returns the original error message. This implements the error.Error interface.","func (e *UserError) Error() string {","\treturn e.Original.Error()","}","","// Unwrap returns the original error without the Reason annotation. This is","// intended to support usage of errors.Is and errors.As with Errors.","func (e *UserError) Unwrap() error {","\treturn e.Original","}","","// newUserError returns a UserError with the given reason and underlying","// original error.","func newUserError(reason string, err error) *UserError {","\treturn \u0026UserError{","\t\tReason:   reason,","\t\tOriginal: err,","\t}","}","","// WrapUserError wraps the original error with the user error label","func WrapUserError(err error) error {","\treturn newUserError(UserErrorLabel, err)","}","","// LabelUserError labels the failure RunStatus message if any of its error messages has been","// wrapped as an UserError. It indicates that the user is responsible for an error.","// See github.com/tektoncd/pipeline/blob/main/docs/pipelineruns.md#marking-off-user-errors","// for more details.","func LabelUserError(messageFormat string, messageA []interface{}) string {","\tfor _, message := range messageA {","\t\tif ue, ok := message.(*UserError); ok {","\t\t\treturn ue.Reason + messageFormat","\t\t}","\t}","\treturn messageFormat","}","","// GetErrorMessage returns the error message with the user error label if it is of type user","// error","func GetErrorMessage(err error) string {","\tvar ue *UserError","\tif errors.As(err, \u0026ue) {","\t\treturn ue.Reason + err.Error()","\t}","\treturn err.Error()","}","","// IsImmutableTaskRunSpecError returns true if the error is the taskrun spec is immutable","func IsImmutableTaskRunSpecError(err error) bool {","\t// The TaskRun may have completed and the spec field is immutable.","\t// validation code: https://github.com/tektoncd/pipeline/blob/v0.62.0/pkg/apis/pipeline/v1/taskrun_validation.go#L136-L138","\treturn apierrors.IsBadRequest(err) \u0026\u0026 strings.Contains(err.Error(), \"no updates are allowed\")","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,2,2,2,0,0,0,2,2,2,2,2,2,0,0,2,2,2,0,0,0,0,0,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,0,0,0,1,1,1,1,1]},{"id":16,"path":"pkg/apis/pipeline/images.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pipeline","","import (","\t\"fmt\"","\t\"sort\"",")","","// Images holds the images reference for a number of container images used","// across tektoncd pipelines.","type Images struct {","\t// EntrypointImage is container image containing our entrypoint binary.","\tEntrypointImage string","\t// SidecarLogResultsImage is container image containing the binary that fetches results from the steps and logs it to stdout.","\tSidecarLogResultsImage string","\t// NopImage is the container image used to kill sidecars.","\tNopImage string","\t// ShellImage is the container image containing bash shell.","\tShellImage string","\t// ShellImageWin is the container image containing powershell.","\tShellImageWin string","\t// WorkingDirInitImage is the container image containing our working dir init binary.","\tWorkingDirInitImage string","","\t// NOTE: Make sure to add any new images to Validate below!","}","","// Validate returns an error if any image is not set.","func (i Images) Validate() error {","\tvar unset []string","\tfor _, f := range []struct {","\t\tv, name string","\t}{","\t\t{i.EntrypointImage, \"entrypoint-image\"},","\t\t{i.SidecarLogResultsImage, \"sidecarlogresults-image\"},","\t\t{i.NopImage, \"nop-image\"},","\t\t{i.ShellImage, \"shell-image\"},","\t\t{i.ShellImageWin, \"shell-image-win\"},","\t\t{i.WorkingDirInitImage, \"workingdirinit-image\"},","\t} {","\t\tif f.v == \"\" {","\t\t\tunset = append(unset, f.name)","\t\t}","\t}","\tif len(unset) \u003e 0 {","\t\tsort.Strings(unset)","\t\treturn fmt.Errorf(\"found unset image flags: %s\", unset)","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,0]},{"id":17,"path":"pkg/apis/pipeline/internal/checksum/checksum.go","lines":["package checksum","","import (","\t\"crypto/sha256\"","\t\"encoding/json\"","\t\"fmt\"","","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"",")","","const (","\t// SignatureAnnotation is the key of signature in annotation map","\tSignatureAnnotation = \"tekton.dev/signature\"",")","","// PrepareObjectMeta will remove annotations not configured from user side -- \"kubectl-client-side-apply\" and \"kubectl.kubernetes.io/last-applied-configuration\"","// (added when an object is created with `kubectl apply`) to avoid verification failure and extract the signature.","// Returns a copy of the input object metadata with the annotations removed and the object's signature,","// if it is present in the metadata.","func PrepareObjectMeta(in metav1.Object) metav1.ObjectMeta {","\toutMeta := metav1.ObjectMeta{}","","\t// exclude the fields populated by system.","\toutMeta.Name = in.GetName()","\toutMeta.GenerateName = in.GetGenerateName()","\toutMeta.Namespace = in.GetNamespace()","","\tif in.GetLabels() != nil {","\t\toutMeta.Labels = make(map[string]string)","\t\tfor k, v := range in.GetLabels() {","\t\t\toutMeta.Labels[k] = v","\t\t}","\t}","","\toutMeta.Annotations = make(map[string]string)","\tfor k, v := range in.GetAnnotations() {","\t\toutMeta.Annotations[k] = v","\t}","","\t// exclude the annotations added by other components","\tdelete(outMeta.Annotations, \"kubectl-client-side-apply\")","\tdelete(outMeta.Annotations, \"kubectl.kubernetes.io/last-applied-configuration\")","\tdelete(outMeta.Annotations, SignatureAnnotation)","","\treturn outMeta","}","","// ComputeSha256Checksum computes the sha256 checksum of the tekton object.","func ComputeSha256Checksum(obj interface{}) ([]byte, error) {","\tts, err := json.Marshal(obj)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"failed to marshal the object: %w\", err)","\t}","\th := sha256.New()","\th.Write(ts)","\treturn h.Sum(nil), nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,0,2,2,2,2,2,0,0,0,2,2,2,1,1,2,2,2,0]},{"id":18,"path":"pkg/apis/pipeline/pod/affinity_assitant_template.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pod","","import (","\t\"reflect\"","","\tcorev1 \"k8s.io/api/core/v1\"",")","","// AffinityAssistantTemplate holds pod specific configuration and is a subset","// of the generic pod Template","// +k8s:deepcopy-gen=true","// +k8s:openapi-gen=true","type AffinityAssistantTemplate struct {","\t// NodeSelector is a selector which must be true for the pod to fit on a node.","\t// Selector which must match a node's labels for the pod to be scheduled on that node.","\t// More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/","\t// +optional","\tNodeSelector map[string]string `json:\"nodeSelector,omitempty\"`","","\t// If specified, the pod's tolerations.","\t// +optional","\t// +listType=atomic","\tTolerations []corev1.Toleration `json:\"tolerations,omitempty\"`","","\t// ImagePullSecrets gives the name of the secret used by the pod to pull the image if specified","\t// +optional","\t// +listType=atomic","\tImagePullSecrets []corev1.LocalObjectReference `json:\"imagePullSecrets,omitempty\"`","","\t// SecurityContext sets the security context for the pod","\t// +optional","\tSecurityContext *corev1.PodSecurityContext `json:\"securityContext,omitempty\"`","","\t// If specified, indicates the pod's priority. \"system-node-critical\" and","\t// \"system-cluster-critical\" are two special keywords which indicate the","\t// highest priorities with the former being the highest priority. Any other","\t// name must be defined by creating a PriorityClass object with that name.","\t// If not specified, the pod priority will be default or zero if there is no","\t// default.","\t// +optional","\tPriorityClassName *string `json:\"priorityClassName,omitempty\"`","","\t// ServiceAccountName is the name of the ServiceAccount to use for the affinity assistant pod.","\t// If not specified, the affinity assistant will inherit the serviceAccountName from the","\t// PipelineRun's taskRunTemplate. If that is also not specified, the pod will use the","\t// namespace's default ServiceAccount.","\t// More info: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/","\t// +optional","\tServiceAccountName string `json:\"serviceAccountName,omitempty\"`","}","","// Equals checks if this Template is identical to the given Template.","func (tpl *AffinityAssistantTemplate) Equals(other *AffinityAssistantTemplate) bool {","\tif tpl == nil \u0026\u0026 other == nil {","\t\treturn true","\t}","","\tif tpl == nil || other == nil {","\t\treturn false","\t}","","\treturn reflect.DeepEqual(tpl, other)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,1,1,1,0,1,0]},{"id":19,"path":"pkg/apis/pipeline/pod/template.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pod","","import (","\t\"reflect\"","","\tcorev1 \"k8s.io/api/core/v1\"",")","","// +listType=atomic","type Volumes []corev1.Volume","","// Template holds pod specific configuration","// +k8s:deepcopy-gen=true","// +k8s:openapi-gen=true","type Template struct {","\t// NodeSelector is a selector which must be true for the pod to fit on a node.","\t// Selector which must match a node's labels for the pod to be scheduled on that node.","\t// More info: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/","\t// +optional","\tNodeSelector map[string]string `json:\"nodeSelector,omitempty\"`","","\t// List of environment variables that can be provided to the containers belonging to the pod.","\t// +optional","\t// +patchMergeKey=name","\t// +patchStrategy=merge","\t// +listType=atomic","\tEnv []corev1.EnvVar `json:\"env,omitempty\" patchMergeKey:\"name\" patchStrategy:\"merge\" protobuf:\"bytes,7,rep,name=env\"`","","\t// If specified, the pod's tolerations.","\t// +optional","\t// +listType=atomic","\tTolerations []corev1.Toleration `json:\"tolerations,omitempty\"`","","\t// If specified, the pod's scheduling constraints.","\t// See Pod.spec.affinity (API version: v1)","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tAffinity *corev1.Affinity `json:\"affinity,omitempty\"`","","\t// SecurityContext holds pod-level security attributes and common container settings.","\t// Optional: Defaults to empty.  See type description for default values of each field.","\t// See Pod.spec.securityContext (API version: v1)","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tSecurityContext *corev1.PodSecurityContext `json:\"securityContext,omitempty\"`","","\t// List of volumes that can be mounted by containers belonging to the pod.","\t// More info: https://kubernetes.io/docs/concepts/storage/volumes","\t// See Pod.spec.volumes (API version: v1)","\t// +optional","\t// +patchMergeKey=name","\t// +patchStrategy=merge,retainKeys","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tVolumes Volumes `json:\"volumes,omitempty\" patchMergeKey:\"name\" patchStrategy:\"merge,retainKeys\" protobuf:\"bytes,1,rep,name=volumes\"`","","\t// RuntimeClassName refers to a RuntimeClass object in the node.k8s.io","\t// group, which should be used to run this pod. If no RuntimeClass resource","\t// matches the named class, the pod will not be run. If unset or empty, the","\t// \"legacy\" RuntimeClass will be used, which is an implicit class with an","\t// empty definition that uses the default runtime handler.","\t// More info: https://git.k8s.io/enhancements/keps/sig-node/runtime-class.md","\t// This is a beta feature as of Kubernetes v1.14.","\t// +optional","\tRuntimeClassName *string `json:\"runtimeClassName,omitempty\" protobuf:\"bytes,2,opt,name=runtimeClassName\"`","","\t// AutomountServiceAccountToken indicates whether pods running as this","\t// service account should have an API token automatically mounted.","\t// +optional","\tAutomountServiceAccountToken *bool `json:\"automountServiceAccountToken,omitempty\" protobuf:\"varint,3,opt,name=automountServiceAccountToken\"`","","\t// Set DNS policy for the pod. Defaults to \"ClusterFirst\". Valid values are","\t// 'ClusterFirst', 'Default' or 'None'. DNS parameters given in DNSConfig","\t// will be merged with the policy selected with DNSPolicy.","\t// +optional","\tDNSPolicy *corev1.DNSPolicy `json:\"dnsPolicy,omitempty\" protobuf:\"bytes,4,opt,name=dnsPolicy,casttype=k8s.io/api/core/v1.DNSPolicy\"`","","\t// Specifies the DNS parameters of a pod.","\t// Parameters specified here will be merged to the generated DNS","\t// configuration based on DNSPolicy.","\t// +optional","\tDNSConfig *corev1.PodDNSConfig `json:\"dnsConfig,omitempty\" protobuf:\"bytes,5,opt,name=dnsConfig\"`","","\t// EnableServiceLinks indicates whether information about services should be injected into pod's","\t// environment variables, matching the syntax of Docker links.","\t// Optional: Defaults to true.","\t// +optional","\tEnableServiceLinks *bool `json:\"enableServiceLinks,omitempty\" protobuf:\"varint,6,opt,name=enableServiceLinks\"`","","\t// If specified, indicates the pod's priority. \"system-node-critical\" and","\t// \"system-cluster-critical\" are two special keywords which indicate the","\t// highest priorities with the former being the highest priority. Any other","\t// name must be defined by creating a PriorityClass object with that name.","\t// If not specified, the pod priority will be default or zero if there is no","\t// default.","\t// +optional","\tPriorityClassName *string `json:\"priorityClassName,omitempty\" protobuf:\"bytes,8,opt,name=priorityClassName\"`","\t// SchedulerName specifies the scheduler to be used to dispatch the Pod","\t// +optional","\tSchedulerName string `json:\"schedulerName,omitempty\"`","","\t// ImagePullSecrets gives the name of the secret used by the pod to pull the image if specified","\t// +optional","\t// +listType=atomic","\tImagePullSecrets []corev1.LocalObjectReference `json:\"imagePullSecrets,omitempty\"`","","\t// HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts","\t// file if specified. This is only valid for non-hostNetwork pods.","\t// +optional","\t// +listType=atomic","\tHostAliases []corev1.HostAlias `json:\"hostAliases,omitempty\"`","","\t// HostNetwork specifies whether the pod may use the node network namespace","\t// +optional","\tHostNetwork bool `json:\"hostNetwork,omitempty\"`","","\t// HostUsers indicates whether the pod will use the host's user namespace.","\t// Optional: Default to true.","\t// If set to true or not present, the pod will be run in the host user namespace, useful","\t// for when the pod needs a feature only available to the host user namespace, such as","\t// loading a kernel module with CAP_SYS_MODULE.","\t// When set to false, a new user namespace is created for the pod. Setting false","\t// is useful to mitigating container breakout vulnerabilities such as allowing","\t// containers to run as root without their user having root privileges on the host.","\t// This field depends on the kubernetes feature gate UserNamespacesSupport being enabled.","\t// +optional","\tHostUsers *bool `json:\"hostUsers,omitempty\"`","","\t// TopologySpreadConstraints controls how Pods are spread across your cluster among","\t// failure-domains such as regions, zones, nodes, and other user-defined topology domains.","\t// +optional","\t// +listType=atomic","\tTopologySpreadConstraints []corev1.TopologySpreadConstraint `json:\"topologySpreadConstraints,omitempty\"`","}","","// Equals checks if this Template is identical to the given Template.","func (tpl *Template) Equals(other *Template) bool {","\tif tpl == nil \u0026\u0026 other == nil {","\t\treturn true","\t}","","\tif tpl == nil || other == nil {","\t\treturn false","\t}","","\treturn reflect.DeepEqual(tpl, other)","}","","// ToAffinityAssistantTemplate converts to a affinity assistant pod Template","func (tpl *Template) ToAffinityAssistantTemplate() *AffinityAssistantTemplate {","\tif tpl == nil {","\t\treturn nil","\t}","","\treturn \u0026AffinityAssistantTemplate{","\t\tNodeSelector:      tpl.NodeSelector,","\t\tTolerations:       tpl.Tolerations,","\t\tImagePullSecrets:  tpl.ImagePullSecrets,","\t\tSecurityContext:   tpl.SecurityContext,","\t\tPriorityClassName: tpl.PriorityClassName,","\t}","}","","// PodTemplate holds pod specific configuration","//","//nolint:revive","type PodTemplate = Template","","// MergePodTemplateWithDefault merges 2 PodTemplates together. If the same","// field is set on both templates, the value from tpl will overwrite the value","// from defaultTpl.","func MergePodTemplateWithDefault(tpl, defaultTpl *PodTemplate) *PodTemplate {","\tswitch {","\tcase defaultTpl == nil:","\t\t// No configured default, just return the template","\t\treturn tpl","\tcase tpl == nil:","\t\t// No template, just return the default template","\t\treturn defaultTpl","\tdefault:","\t\t// Otherwise, merge fields","\t\tif tpl.NodeSelector == nil {","\t\t\ttpl.NodeSelector = defaultTpl.NodeSelector","\t\t}","\t\ttpl.Env = mergeByName(defaultTpl.Env, tpl.Env)","\t\tif tpl.Tolerations == nil {","\t\t\ttpl.Tolerations = defaultTpl.Tolerations","\t\t}","\t\tif tpl.Affinity == nil {","\t\t\ttpl.Affinity = defaultTpl.Affinity","\t\t}","\t\tif tpl.SecurityContext == nil {","\t\t\ttpl.SecurityContext = defaultTpl.SecurityContext","\t\t}","\t\ttpl.Volumes = mergeByName(defaultTpl.Volumes, tpl.Volumes)","\t\tif tpl.RuntimeClassName == nil {","\t\t\ttpl.RuntimeClassName = defaultTpl.RuntimeClassName","\t\t}","\t\tif tpl.AutomountServiceAccountToken == nil {","\t\t\ttpl.AutomountServiceAccountToken = defaultTpl.AutomountServiceAccountToken","\t\t}","\t\tif tpl.DNSPolicy == nil {","\t\t\ttpl.DNSPolicy = defaultTpl.DNSPolicy","\t\t}","\t\tif tpl.DNSConfig == nil {","\t\t\ttpl.DNSConfig = defaultTpl.DNSConfig","\t\t}","\t\tif tpl.EnableServiceLinks == nil {","\t\t\ttpl.EnableServiceLinks = defaultTpl.EnableServiceLinks","\t\t}","\t\tif tpl.PriorityClassName == nil {","\t\t\ttpl.PriorityClassName = defaultTpl.PriorityClassName","\t\t}","\t\tif tpl.SchedulerName == \"\" {","\t\t\ttpl.SchedulerName = defaultTpl.SchedulerName","\t\t}","\t\tif tpl.ImagePullSecrets == nil {","\t\t\ttpl.ImagePullSecrets = defaultTpl.ImagePullSecrets","\t\t}","\t\tif tpl.HostAliases == nil {","\t\t\ttpl.HostAliases = defaultTpl.HostAliases","\t\t}","\t\tif !tpl.HostNetwork \u0026\u0026 defaultTpl.HostNetwork {","\t\t\ttpl.HostNetwork = true","\t\t}","\t\tif tpl.HostUsers == nil {","\t\t\ttpl.HostUsers = defaultTpl.HostUsers","\t\t}","\t\tif tpl.TopologySpreadConstraints == nil {","\t\t\ttpl.TopologySpreadConstraints = defaultTpl.TopologySpreadConstraints","\t\t}","\t\treturn tpl","\t}","}","","// AAPodTemplate holds pod specific configuration for the affinity-assistant","type AAPodTemplate = AffinityAssistantTemplate","","// MergeAAPodTemplateWithDefault is the same as MergePodTemplateWithDefault but","// for AffinityAssistantPodTemplates.","func MergeAAPodTemplateWithDefault(tpl, defaultTpl *AAPodTemplate) *AAPodTemplate {","\tswitch {","\tcase defaultTpl == nil:","\t\t// No configured default, just return the template","\t\treturn tpl","\tcase tpl == nil:","\t\t// No template, just return the default template","\t\treturn defaultTpl","\tdefault:","\t\t// Otherwise, merge fields","\t\tif tpl.NodeSelector == nil {","\t\t\ttpl.NodeSelector = defaultTpl.NodeSelector","\t\t}","\t\tif tpl.Tolerations == nil {","\t\t\ttpl.Tolerations = defaultTpl.Tolerations","\t\t}","\t\tif tpl.ImagePullSecrets == nil {","\t\t\ttpl.ImagePullSecrets = defaultTpl.ImagePullSecrets","\t\t}","\t\tif tpl.SecurityContext == nil {","\t\t\ttpl.SecurityContext = defaultTpl.SecurityContext","\t\t}","\t\tif tpl.PriorityClassName == nil {","\t\t\ttpl.PriorityClassName = defaultTpl.PriorityClassName","\t\t}","\t\tif tpl.ServiceAccountName == \"\" {","\t\t\ttpl.ServiceAccountName = defaultTpl.ServiceAccountName","\t\t}","","\t\treturn tpl","\t}","}","","// mergeByName merges two slices of items with names based on the getName","// function, giving priority to the items in the override slice.","func mergeByName[T any](base, overrides []T) []T {","\tif len(overrides) == 0 {","\t\treturn base","\t}","","\t// create a map to store the exist names in the override slice","\texists := make(map[string]struct{})","\tmerged := make([]T, 0, len(base)+len(overrides))","","\t// append the items in the override slice","\tfor _, item := range overrides {","\t\tname := getName(item)","\t\tif name != \"\" { // name should not be empty, if empty, ignore","\t\t\tmerged = append(merged, item)","\t\t\texists[name] = struct{}{}","\t\t}","\t}","","\t// append the items in the base slice if they have a different name","\tfor _, item := range base {","\t\tname := getName(item)","\t\tif name != \"\" { // name should not be empty, if empty, ignore","\t\t\tif _, found := exists[name]; !found {","\t\t\t\tmerged = append(merged, item)","\t\t\t}","\t\t}","\t}","","\treturn merged","}","","// getName returns the name of the given item, or an empty string if the item","// is not a supported type.","func getName(item interface{}) string {","\tswitch item := item.(type) {","\tcase corev1.EnvVar:","\t\treturn item.Name","\tcase corev1.Volume:","\t\treturn item.Name","\tdefault:","\t\treturn \"\"","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,1,1,1,0,1,0,0,0,1,1,1,1,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,0,2,0,0,0,0,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,0,2,0,0,0,0,2,2,2,2,2,2,2,2,0,0]},{"id":20,"path":"pkg/apis/pipeline/v1/artifact_types.go","lines":["/*","Copyright 2024 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"github.com/google/go-cmp/cmp\"",")","","// Algorithm Standard cryptographic hash algorithm","type Algorithm string","","// Artifact represents an artifact within a system, potentially containing multiple values","// associated with it.","type Artifact struct {","\t// The artifact's identifying category name","\tName string `json:\"name,omitempty\"`","\t// A collection of values related to the artifact","\tValues []ArtifactValue `json:\"values,omitempty\"`","\t// Indicate if the artifact is a build output or a by-product","\tBuildOutput bool `json:\"buildOutput,omitempty\"`","}","","// ArtifactValue represents a specific value or data element within an Artifact.","type ArtifactValue struct {","\tDigest map[Algorithm]string `json:\"digest,omitempty\"` // Algorithm-specific digests for verifying the content (e.g., SHA256)","\tUri    string               `json:\"uri,omitempty\"`    // Location where the artifact value can be retrieved","}","","// TaskRunStepArtifact represents an artifact produced or used by a step within a task run.","// It directly uses the Artifact type for its structure.","type TaskRunStepArtifact = Artifact","","// Artifacts represents the collection of input and output artifacts associated with","// a task run or a similar process. Artifacts in this context are units of data or resources","// that the process either consumes as input or produces as output.","type Artifacts struct {","\t// +listType=atomic","\tInputs []Artifact `json:\"inputs,omitempty\"`","\t// +listType=atomic","\tOutputs []Artifact `json:\"outputs,omitempty\"`","}","","func (a *Artifacts) Merge(another *Artifacts) {","\tinputMap := make(map[string][]ArtifactValue)","\tvar newInputs []Artifact","","\tfor _, v := range a.Inputs {","\t\tinputMap[v.Name] = v.Values","\t}","\tif another != nil {","\t\tfor _, v := range another.Inputs {","\t\t\t_, ok := inputMap[v.Name]","\t\t\tif !ok {","\t\t\t\tinputMap[v.Name] = []ArtifactValue{}","\t\t\t}","\t\t\tfor _, vv := range v.Values {","\t\t\t\texists := false","\t\t\t\tfor _, av := range inputMap[v.Name] {","\t\t\t\t\tif cmp.Equal(vv, av) {","\t\t\t\t\t\texists = true","\t\t\t\t\t\tbreak","\t\t\t\t\t}","\t\t\t\t}","\t\t\t\tif !exists {","\t\t\t\t\tinputMap[v.Name] = append(inputMap[v.Name], vv)","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\tfor k, v := range inputMap {","\t\tnewInputs = append(newInputs, Artifact{","\t\t\tName:   k,","\t\t\tValues: v,","\t\t})","\t}","","\toutputMap := make(map[string]Artifact)","\tvar newOutputs []Artifact","\tfor _, v := range a.Outputs {","\t\toutputMap[v.Name] = v","\t}","","\tif another != nil {","\t\tfor _, v := range another.Outputs {","\t\t\t_, ok := outputMap[v.Name]","\t\t\tif !ok {","\t\t\t\toutputMap[v.Name] = Artifact{Name: v.Name, Values: []ArtifactValue{}, BuildOutput: v.BuildOutput}","\t\t\t}","\t\t\t// only update buildOutput to true.","\t\t\t// Do not convert to false if it was true before.","\t\t\tif v.BuildOutput {","\t\t\t\tart := outputMap[v.Name]","\t\t\t\tart.BuildOutput = v.BuildOutput","\t\t\t\toutputMap[v.Name] = art","\t\t\t}","\t\t\tfor _, vv := range v.Values {","\t\t\t\texists := false","\t\t\t\tfor _, av := range outputMap[v.Name].Values {","\t\t\t\t\tif cmp.Equal(vv, av) {","\t\t\t\t\t\texists = true","\t\t\t\t\t\tbreak","\t\t\t\t\t}","\t\t\t\t}","\t\t\t\tif !exists {","\t\t\t\t\tart := outputMap[v.Name]","\t\t\t\t\tart.Values = append(art.Values, vv)","\t\t\t\t\toutputMap[v.Name] = art","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\tfor _, v := range outputMap {","\t\tnewOutputs = append(newOutputs, Artifact{","\t\t\tName:        v.Name,","\t\t\tValues:      v.Values,","\t\t\tBuildOutput: v.BuildOutput,","\t\t})","\t}","\ta.Inputs = newInputs","\ta.Outputs = newOutputs","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,0,0,0,2,2,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,1,1,0,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,0]},{"id":21,"path":"pkg/apis/pipeline/v1/container_types.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","package v1","","import (","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"",")","","// Step runs a subcomponent of a Task","type Step struct {","\t// Name of the Step specified as a DNS_LABEL.","\t// Each Step in a Task must have a unique name.","\tName string `json:\"name\" protobuf:\"bytes,1,opt,name=name\"`","\t// DisplayName is a user-facing name of the step that may be","\t// used to populate a UI.","\t// +optional","\tDisplayName string `json:\"displayName,omitempty\"`","\t// Docker image name.","\t// More info: https://kubernetes.io/docs/concepts/containers/images","\t// +optional","\tImage string `json:\"image,omitempty\" protobuf:\"bytes,2,opt,name=image\"`","\t// Entrypoint array. Not executed within a shell.","\t// The image's ENTRYPOINT is used if this is not provided.","\t// Variable references $(VAR_NAME) are expanded using the container's environment. If a variable","\t// cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced","\t// to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$$(VAR_NAME)\" will","\t// produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless","\t// of whether the variable exists or not. Cannot be updated.","\t// More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell","\t// +optional","\t// +listType=atomic","\tCommand []string `json:\"command,omitempty\" protobuf:\"bytes,3,rep,name=command\"`","\t// Arguments to the entrypoint.","\t// The image's CMD is used if this is not provided.","\t// Variable references $(VAR_NAME) are expanded using the container's environment. If a variable","\t// cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced","\t// to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$$(VAR_NAME)\" will","\t// produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless","\t// of whether the variable exists or not. Cannot be updated.","\t// More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell","\t// +optional","\t// +listType=atomic","\tArgs []string `json:\"args,omitempty\" protobuf:\"bytes,4,rep,name=args\"`","\t// Step's working directory.","\t// If not specified, the container runtime's default will be used, which","\t// might be configured in the container image.","\t// Cannot be updated.","\t// +optional","\tWorkingDir string `json:\"workingDir,omitempty\" protobuf:\"bytes,5,opt,name=workingDir\"`","\t// List of sources to populate environment variables in the Step.","\t// The keys defined within a source must be a C_IDENTIFIER. All invalid keys","\t// will be reported as an event when the Step is starting. When a key exists in multiple","\t// sources, the value associated with the last source will take precedence.","\t// Values defined by an Env with a duplicate key will take precedence.","\t// Cannot be updated.","\t// +optional","\t// +listType=atomic","\tEnvFrom []corev1.EnvFromSource `json:\"envFrom,omitempty\" protobuf:\"bytes,19,rep,name=envFrom\"`","\t// List of environment variables to set in the Step.","\t// Cannot be updated.","\t// +optional","\t// +patchMergeKey=name","\t// +patchStrategy=merge","\t// +listType=atomic","\tEnv []corev1.EnvVar `json:\"env,omitempty\" patchMergeKey:\"name\" patchStrategy:\"merge\" protobuf:\"bytes,7,rep,name=env\"`","\t// ComputeResources required by this Step.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/","\t// +optional","\tComputeResources corev1.ResourceRequirements `json:\"computeResources,omitempty\" protobuf:\"bytes,8,opt,name=computeResources\"`","\t// Volumes to mount into the Step's filesystem.","\t// Cannot be updated.","\t// +optional","\t// +patchMergeKey=mountPath","\t// +patchStrategy=merge","\t// +listType=atomic","\tVolumeMounts []corev1.VolumeMount `json:\"volumeMounts,omitempty\" patchMergeKey:\"mountPath\" patchStrategy:\"merge\" protobuf:\"bytes,9,rep,name=volumeMounts\"`","\t// volumeDevices is the list of block devices to be used by the Step.","\t// +patchMergeKey=devicePath","\t// +patchStrategy=merge","\t// +optional","\t// +listType=atomic","\tVolumeDevices []corev1.VolumeDevice `json:\"volumeDevices,omitempty\" patchMergeKey:\"devicePath\" patchStrategy:\"merge\" protobuf:\"bytes,21,rep,name=volumeDevices\"`","\t// Image pull policy.","\t// One of Always, Never, IfNotPresent.","\t// Defaults to Always if :latest tag is specified, or IfNotPresent otherwise.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/containers/images#updating-images","\t// +optional","\tImagePullPolicy corev1.PullPolicy `json:\"imagePullPolicy,omitempty\" protobuf:\"bytes,14,opt,name=imagePullPolicy,casttype=PullPolicy\"`","\t// SecurityContext defines the security options the Step should be run with.","\t// If set, the fields of SecurityContext override the equivalent fields of PodSecurityContext.","\t// More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/","\t// +optional","\tSecurityContext *corev1.SecurityContext `json:\"securityContext,omitempty\" protobuf:\"bytes,15,opt,name=securityContext\"`","","\t// Script is the contents of an executable file to execute.","\t//","\t// If Script is not empty, the Step cannot have an Command and the Args will be passed to the Script.","\t// +optional","\tScript string `json:\"script,omitempty\"`","","\t// Timeout is the time after which the step times out. Defaults to never.","\t// Refer to Go's ParseDuration documentation for expected format: https://golang.org/pkg/time/#ParseDuration","\t// +optional","\tTimeout *metav1.Duration `json:\"timeout,omitempty\"`","","\t// This is an alpha field. You must set the \"enable-api-fields\" feature flag to \"alpha\"","\t// for this field to be supported.","\t//","\t// Workspaces is a list of workspaces from the Task that this Step wants","\t// exclusive access to. Adding a workspace to this list means that any","\t// other Step or Sidecar that does not also request this Workspace will","\t// not have access to it.","\t// +optional","\t// +listType=atomic","\tWorkspaces []WorkspaceUsage `json:\"workspaces,omitempty\"`","","\t// OnError defines the exiting behavior of a container on error","\t// can be set to [ continue | stopAndFail ]","\tOnError OnErrorType `json:\"onError,omitempty\"`","\t// Stores configuration for the stdout stream of the step.","\t// +optional","\tStdoutConfig *StepOutputConfig `json:\"stdoutConfig,omitempty\"`","\t// Stores configuration for the stderr stream of the step.","\t// +optional","\tStderrConfig *StepOutputConfig `json:\"stderrConfig,omitempty\"`","\t// Contains the reference to an existing StepAction.","\t//+optional","\tRef *Ref `json:\"ref,omitempty\"`","\t// Params declares parameters passed to this step action.","\t// +optional","\tParams Params `json:\"params,omitempty\"`","\t// Results declares StepResults produced by the Step.","\t//","\t// It can be used in an inlined Step when used to store Results to $(step.results.resultName.path).","\t// It cannot be used when referencing StepActions using [v1.Step.Ref].","\t// The Results declared by the StepActions will be stored here instead.","\t// +optional","\t// +listType=atomic","\tResults []StepResult `json:\"results,omitempty\"`","","\t// When is a list of when expressions that need to be true for the task to run","\t// +optional","\tWhen StepWhenExpressions `json:\"when,omitempty\"`","}","","// Ref can be used to refer to a specific instance of a StepAction.","type Ref struct {","\t// Name of the referenced step","\tName string `json:\"name,omitempty\"`","\t// ResolverRef allows referencing a StepAction in a remote location","\t// like a git repo.","\t// +optional","\tResolverRef `json:\",omitempty\"`","}","","// OnErrorType defines a list of supported exiting behavior of a container on error","type OnErrorType string","","const (","\t// StopAndFail indicates exit the taskRun if the container exits with non-zero exit code","\tStopAndFail OnErrorType = \"stopAndFail\"","\t// Continue indicates continue executing the rest of the steps irrespective of the container exit code","\tContinue OnErrorType = \"continue\"",")","","// StepOutputConfig stores configuration for a step output stream.","type StepOutputConfig struct {","\t// Path to duplicate stdout stream to on container's local filesystem.","\t// +optional","\tPath string `json:\"path,omitempty\"`","}","","// ToK8sContainer converts the Step to a Kubernetes Container struct","func (s *Step) ToK8sContainer() *corev1.Container {","\treturn \u0026corev1.Container{","\t\tName:            s.Name,","\t\tImage:           s.Image,","\t\tCommand:         s.Command,","\t\tArgs:            s.Args,","\t\tWorkingDir:      s.WorkingDir,","\t\tEnvFrom:         s.EnvFrom,","\t\tEnv:             s.Env,","\t\tResources:       s.ComputeResources,","\t\tVolumeMounts:    s.VolumeMounts,","\t\tVolumeDevices:   s.VolumeDevices,","\t\tImagePullPolicy: s.ImagePullPolicy,","\t\tSecurityContext: s.SecurityContext,","\t}","}","","// SetContainerFields sets the fields of the Step to the values of the corresponding fields in the Container","func (s *Step) SetContainerFields(c corev1.Container) {","\ts.Name = c.Name","\ts.Image = c.Image","\ts.Command = c.Command","\ts.Args = c.Args","\ts.WorkingDir = c.WorkingDir","\ts.EnvFrom = c.EnvFrom","\ts.Env = c.Env","\ts.ComputeResources = c.Resources","\ts.VolumeMounts = c.VolumeMounts","\ts.VolumeDevices = c.VolumeDevices","\ts.ImagePullPolicy = c.ImagePullPolicy","\ts.SecurityContext = c.SecurityContext","}","","// GetVarSubstitutionExpressions walks all the places a substitution reference can be used","func (s *Step) GetVarSubstitutionExpressions() []string {","\tvar allExpressions []string","\tallExpressions = append(allExpressions, validateString(s.Name)...)","\tallExpressions = append(allExpressions, validateString(s.Image)...)","\tallExpressions = append(allExpressions, validateString(string(s.ImagePullPolicy))...)","\tallExpressions = append(allExpressions, validateString(s.Script)...)","\tallExpressions = append(allExpressions, validateString(s.WorkingDir)...)","\tfor _, cmd := range s.Command {","\t\tallExpressions = append(allExpressions, validateString(cmd)...)","\t}","\tfor _, arg := range s.Args {","\t\tallExpressions = append(allExpressions, validateString(arg)...)","\t}","\tfor _, env := range s.Env {","\t\tallExpressions = append(allExpressions, validateString(env.Value)...)","\t\tif env.ValueFrom != nil {","\t\t\tif env.ValueFrom.SecretKeyRef != nil {","\t\t\t\tallExpressions = append(allExpressions, validateString(env.ValueFrom.SecretKeyRef.Key)...)","\t\t\t\tallExpressions = append(allExpressions, validateString(env.ValueFrom.SecretKeyRef.LocalObjectReference.Name)...)","\t\t\t}","\t\t\tif env.ValueFrom.ConfigMapKeyRef != nil {","\t\t\t\tallExpressions = append(allExpressions, validateString(env.ValueFrom.ConfigMapKeyRef.Key)...)","\t\t\t\tallExpressions = append(allExpressions, validateString(env.ValueFrom.ConfigMapKeyRef.LocalObjectReference.Name)...)","\t\t\t}","\t\t}","\t}","\treturn allExpressions","}","","// StepTemplate is a template for a Step","type StepTemplate struct {","\t// Image reference name.","\t// More info: https://kubernetes.io/docs/concepts/containers/images","\t// +optional","\tImage string `json:\"image,omitempty\" protobuf:\"bytes,2,opt,name=image\"`","\t// Entrypoint array. Not executed within a shell.","\t// The image's ENTRYPOINT is used if this is not provided.","\t// Variable references $(VAR_NAME) are expanded using the Step's environment. If a variable","\t// cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced","\t// to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$$(VAR_NAME)\" will","\t// produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless","\t// of whether the variable exists or not. Cannot be updated.","\t// More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell","\t// +optional","\t// +listType=atomic","\tCommand []string `json:\"command,omitempty\" protobuf:\"bytes,3,rep,name=command\"`","\t// Arguments to the entrypoint.","\t// The image's CMD is used if this is not provided.","\t// Variable references $(VAR_NAME) are expanded using the Step's environment. If a variable","\t// cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced","\t// to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$$(VAR_NAME)\" will","\t// produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless","\t// of whether the variable exists or not. Cannot be updated.","\t// More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell","\t// +optional","\t// +listType=atomic","\tArgs []string `json:\"args,omitempty\" protobuf:\"bytes,4,rep,name=args\"`","\t// Step's working directory.","\t// If not specified, the container runtime's default will be used, which","\t// might be configured in the container image.","\t// Cannot be updated.","\t// +optional","\tWorkingDir string `json:\"workingDir,omitempty\" protobuf:\"bytes,5,opt,name=workingDir\"`","\t// List of sources to populate environment variables in the Step.","\t// The keys defined within a source must be a C_IDENTIFIER. All invalid keys","\t// will be reported as an event when the Step is starting. When a key exists in multiple","\t// sources, the value associated with the last source will take precedence.","\t// Values defined by an Env with a duplicate key will take precedence.","\t// Cannot be updated.","\t// +optional","\t// +listType=atomic","\tEnvFrom []corev1.EnvFromSource `json:\"envFrom,omitempty\" protobuf:\"bytes,19,rep,name=envFrom\"`","\t// List of environment variables to set in the Step.","\t// Cannot be updated.","\t// +optional","\t// +patchMergeKey=name","\t// +patchStrategy=merge","\t// +listType=atomic","\tEnv []corev1.EnvVar `json:\"env,omitempty\" patchMergeKey:\"name\" patchStrategy:\"merge\" protobuf:\"bytes,7,rep,name=env\"`","\t// ComputeResources required by this Step.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/","\t// +optional","\tComputeResources corev1.ResourceRequirements `json:\"computeResources,omitempty\" protobuf:\"bytes,8,opt,name=computeResources\"`","\t// Volumes to mount into the Step's filesystem.","\t// Cannot be updated.","\t// +optional","\t// +patchMergeKey=mountPath","\t// +patchStrategy=merge","\t// +listType=atomic","\tVolumeMounts []corev1.VolumeMount `json:\"volumeMounts,omitempty\" patchMergeKey:\"mountPath\" patchStrategy:\"merge\" protobuf:\"bytes,9,rep,name=volumeMounts\"`","\t// volumeDevices is the list of block devices to be used by the Step.","\t// +patchMergeKey=devicePath","\t// +patchStrategy=merge","\t// +optional","\t// +listType=atomic","\tVolumeDevices []corev1.VolumeDevice `json:\"volumeDevices,omitempty\" patchMergeKey:\"devicePath\" patchStrategy:\"merge\" protobuf:\"bytes,21,rep,name=volumeDevices\"`","\t// Image pull policy.","\t// One of Always, Never, IfNotPresent.","\t// Defaults to Always if :latest tag is specified, or IfNotPresent otherwise.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/containers/images#updating-images","\t// +optional","\tImagePullPolicy corev1.PullPolicy `json:\"imagePullPolicy,omitempty\" protobuf:\"bytes,14,opt,name=imagePullPolicy,casttype=PullPolicy\"`","\t// SecurityContext defines the security options the Step should be run with.","\t// If set, the fields of SecurityContext override the equivalent fields of PodSecurityContext.","\t// More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/","\t// +optional","\tSecurityContext *corev1.SecurityContext `json:\"securityContext,omitempty\" protobuf:\"bytes,15,opt,name=securityContext\"`","}","","// SetContainerFields sets the fields of the Step to the values of the corresponding fields in the Container","func (s *StepTemplate) SetContainerFields(c corev1.Container) {","\ts.Image = c.Image","\ts.Command = c.Command","\ts.Args = c.Args","\ts.WorkingDir = c.WorkingDir","\ts.EnvFrom = c.EnvFrom","\ts.Env = c.Env","\ts.ComputeResources = c.Resources","\ts.VolumeMounts = c.VolumeMounts","\ts.VolumeDevices = c.VolumeDevices","\ts.ImagePullPolicy = c.ImagePullPolicy","\ts.SecurityContext = c.SecurityContext","}","","// ToK8sContainer converts the StepTemplate to a Kubernetes Container struct","func (s *StepTemplate) ToK8sContainer() *corev1.Container {","\treturn \u0026corev1.Container{","\t\tImage:           s.Image,","\t\tCommand:         s.Command,","\t\tArgs:            s.Args,","\t\tWorkingDir:      s.WorkingDir,","\t\tEnvFrom:         s.EnvFrom,","\t\tEnv:             s.Env,","\t\tResources:       s.ComputeResources,","\t\tVolumeMounts:    s.VolumeMounts,","\t\tVolumeDevices:   s.VolumeDevices,","\t\tImagePullPolicy: s.ImagePullPolicy,","\t\tSecurityContext: s.SecurityContext,","\t}","}","","// Sidecar has nearly the same data structure as Step but does not have the ability to timeout.","type Sidecar struct {","\t// Name of the Sidecar specified as a DNS_LABEL.","\t// Each Sidecar in a Task must have a unique name (DNS_LABEL).","\t// Cannot be updated.","\tName string `json:\"name\" protobuf:\"bytes,1,opt,name=name\"`","\t// Image reference name.","\t// More info: https://kubernetes.io/docs/concepts/containers/images","\t// +optional","\tImage string `json:\"image,omitempty\" protobuf:\"bytes,2,opt,name=image\"`","\t// Entrypoint array. Not executed within a shell.","\t// The image's ENTRYPOINT is used if this is not provided.","\t// Variable references $(VAR_NAME) are expanded using the Sidecar's environment. If a variable","\t// cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced","\t// to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$$(VAR_NAME)\" will","\t// produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless","\t// of whether the variable exists or not. Cannot be updated.","\t// More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell","\t// +optional","\t// +listType=atomic","\tCommand []string `json:\"command,omitempty\" protobuf:\"bytes,3,rep,name=command\"`","\t// Arguments to the entrypoint.","\t// The image's CMD is used if this is not provided.","\t// Variable references $(VAR_NAME) are expanded using the Sidecar's environment. If a variable","\t// cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced","\t// to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$$(VAR_NAME)\" will","\t// produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless","\t// of whether the variable exists or not. Cannot be updated.","\t// More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell","\t// +optional","\t// +listType=atomic","\tArgs []string `json:\"args,omitempty\" protobuf:\"bytes,4,rep,name=args\"`","\t// Sidecar's working directory.","\t// If not specified, the container runtime's default will be used, which","\t// might be configured in the container image.","\t// Cannot be updated.","\t// +optional","\tWorkingDir string `json:\"workingDir,omitempty\" protobuf:\"bytes,5,opt,name=workingDir\"`","\t// List of ports to expose from the Sidecar. Exposing a port here gives","\t// the system additional information about the network connections a","\t// container uses, but is primarily informational. Not specifying a port here","\t// DOES NOT prevent that port from being exposed. Any port which is","\t// listening on the default \"0.0.0.0\" address inside a container will be","\t// accessible from the network.","\t// Cannot be updated.","\t// +optional","\t// +patchMergeKey=containerPort","\t// +patchStrategy=merge","\t// +listType=map","\t// +listMapKey=containerPort","\t// +listMapKey=protocol","\tPorts []corev1.ContainerPort `json:\"ports,omitempty\" patchMergeKey:\"containerPort\" patchStrategy:\"merge\" protobuf:\"bytes,6,rep,name=ports\"`","\t// List of sources to populate environment variables in the Sidecar.","\t// The keys defined within a source must be a C_IDENTIFIER. All invalid keys","\t// will be reported as an event when the container is starting. When a key exists in multiple","\t// sources, the value associated with the last source will take precedence.","\t// Values defined by an Env with a duplicate key will take precedence.","\t// Cannot be updated.","\t// +optional","\t// +listType=atomic","\tEnvFrom []corev1.EnvFromSource `json:\"envFrom,omitempty\" protobuf:\"bytes,19,rep,name=envFrom\"`","\t// List of environment variables to set in the Sidecar.","\t// Cannot be updated.","\t// +optional","\t// +patchMergeKey=name","\t// +patchStrategy=merge","\t// +listType=atomic","\tEnv []corev1.EnvVar `json:\"env,omitempty\" patchMergeKey:\"name\" patchStrategy:\"merge\" protobuf:\"bytes,7,rep,name=env\"`","\t// ComputeResources required by this Sidecar.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/","\t// +optional","\tComputeResources corev1.ResourceRequirements `json:\"computeResources,omitempty\" protobuf:\"bytes,8,opt,name=computeResources\"`","\t// Volumes to mount into the Sidecar's filesystem.","\t// Cannot be updated.","\t// +optional","\t// +patchMergeKey=mountPath","\t// +patchStrategy=merge","\t// +listType=atomic","\tVolumeMounts []corev1.VolumeMount `json:\"volumeMounts,omitempty\" patchMergeKey:\"mountPath\" patchStrategy:\"merge\" protobuf:\"bytes,9,rep,name=volumeMounts\"`","\t// volumeDevices is the list of block devices to be used by the Sidecar.","\t// +patchMergeKey=devicePath","\t// +patchStrategy=merge","\t// +optional","\t// +listType=atomic","\tVolumeDevices []corev1.VolumeDevice `json:\"volumeDevices,omitempty\" patchMergeKey:\"devicePath\" patchStrategy:\"merge\" protobuf:\"bytes,21,rep,name=volumeDevices\"`","\t// Periodic probe of Sidecar liveness.","\t// Container will be restarted if the probe fails.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes","\t// +optional","\tLivenessProbe *corev1.Probe `json:\"livenessProbe,omitempty\" protobuf:\"bytes,10,opt,name=livenessProbe\"`","\t// Periodic probe of Sidecar service readiness.","\t// Container will be removed from service endpoints if the probe fails.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes","\t// +optional","\tReadinessProbe *corev1.Probe `json:\"readinessProbe,omitempty\" protobuf:\"bytes,11,opt,name=readinessProbe\"`","\t// StartupProbe indicates that the Pod the Sidecar is running in has successfully initialized.","\t// If specified, no other probes are executed until this completes successfully.","\t// If this probe fails, the Pod will be restarted, just as if the livenessProbe failed.","\t// This can be used to provide different probe parameters at the beginning of a Pod's lifecycle,","\t// when it might take a long time to load data or warm a cache, than during steady-state operation.","\t// This cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes","\t// +optional","\tStartupProbe *corev1.Probe `json:\"startupProbe,omitempty\" protobuf:\"bytes,22,opt,name=startupProbe\"`","\t// Actions that the management system should take in response to Sidecar lifecycle events.","\t// Cannot be updated.","\t// +optional","\tLifecycle *corev1.Lifecycle `json:\"lifecycle,omitempty\" protobuf:\"bytes,12,opt,name=lifecycle\"`","\t// Optional: Path at which the file to which the Sidecar's termination message","\t// will be written is mounted into the Sidecar's filesystem.","\t// Message written is intended to be brief final status, such as an assertion failure message.","\t// Will be truncated by the node if greater than 4096 bytes. The total message length across","\t// all containers will be limited to 12kb.","\t// Defaults to /dev/termination-log.","\t// Cannot be updated.","\t// +optional","\tTerminationMessagePath string `json:\"terminationMessagePath,omitempty\" protobuf:\"bytes,13,opt,name=terminationMessagePath\"`","\t// Indicate how the termination message should be populated. File will use the contents of","\t// terminationMessagePath to populate the Sidecar status message on both success and failure.","\t// FallbackToLogsOnError will use the last chunk of Sidecar log output if the termination","\t// message file is empty and the Sidecar exited with an error.","\t// The log output is limited to 2048 bytes or 80 lines, whichever is smaller.","\t// Defaults to File.","\t// Cannot be updated.","\t// +optional","\tTerminationMessagePolicy corev1.TerminationMessagePolicy `json:\"terminationMessagePolicy,omitempty\" protobuf:\"bytes,20,opt,name=terminationMessagePolicy,casttype=TerminationMessagePolicy\"`","\t// Image pull policy.","\t// One of Always, Never, IfNotPresent.","\t// Defaults to Always if :latest tag is specified, or IfNotPresent otherwise.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/containers/images#updating-images","\t// +optional","\tImagePullPolicy corev1.PullPolicy `json:\"imagePullPolicy,omitempty\" protobuf:\"bytes,14,opt,name=imagePullPolicy,casttype=PullPolicy\"`","\t// SecurityContext defines the security options the Sidecar should be run with.","\t// If set, the fields of SecurityContext override the equivalent fields of PodSecurityContext.","\t// More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/","\t// +optional","\tSecurityContext *corev1.SecurityContext `json:\"securityContext,omitempty\" protobuf:\"bytes,15,opt,name=securityContext\"`","","\t// Variables for interactive containers, these have very specialized use-cases (e.g. debugging)","\t// and shouldn't be used for general purpose containers.","","\t// Whether this Sidecar should allocate a buffer for stdin in the container runtime. If this","\t// is not set, reads from stdin in the Sidecar will always result in EOF.","\t// Default is false.","\t// +optional","\tStdin bool `json:\"stdin,omitempty\" protobuf:\"varint,16,opt,name=stdin\"`","\t// Whether the container runtime should close the stdin channel after it has been opened by","\t// a single attach. When stdin is true the stdin stream will remain open across multiple attach","\t// sessions. If stdinOnce is set to true, stdin is opened on Sidecar start, is empty until the","\t// first client attaches to stdin, and then remains open and accepts data until the client disconnects,","\t// at which time stdin is closed and remains closed until the Sidecar is restarted. If this","\t// flag is false, a container processes that reads from stdin will never receive an EOF.","\t// Default is false","\t// +optional","\tStdinOnce bool `json:\"stdinOnce,omitempty\" protobuf:\"varint,17,opt,name=stdinOnce\"`","\t// Whether this Sidecar should allocate a TTY for itself, also requires 'stdin' to be true.","\t// Default is false.","\t// +optional","\tTTY bool `json:\"tty,omitempty\" protobuf:\"varint,18,opt,name=tty\"`","","\t// Script is the contents of an executable file to execute.","\t//","\t// If Script is not empty, the Step cannot have an Command or Args.","\t// +optional","\tScript string `json:\"script,omitempty\"`","","\t// This is an alpha field. You must set the \"enable-api-fields\" feature flag to \"alpha\"","\t// for this field to be supported.","\t//","\t// Workspaces is a list of workspaces from the Task that this Sidecar wants","\t// exclusive access to. Adding a workspace to this list means that any","\t// other Step or Sidecar that does not also request this Workspace will","\t// not have access to it.","\t// +optional","\t// +listType=atomic","\tWorkspaces []WorkspaceUsage `json:\"workspaces,omitempty\"`","","\t// RestartPolicy refers to kubernetes RestartPolicy. It can only be set for an","\t// initContainer and must have it's policy set to \"Always\". It is currently","\t// left optional to help support Kubernetes versions prior to 1.29 when this feature","\t// was introduced.","\t// +optional","\tRestartPolicy *corev1.ContainerRestartPolicy `json:\"restartPolicy,omitempty\"`","}","","// ToK8sContainer converts the Sidecar to a Kubernetes Container struct","func (s *Sidecar) ToK8sContainer() *corev1.Container {","\tif s.RestartPolicy == nil {","\t\treturn \u0026corev1.Container{","\t\t\tName:                     s.Name,","\t\t\tImage:                    s.Image,","\t\t\tCommand:                  s.Command,","\t\t\tArgs:                     s.Args,","\t\t\tWorkingDir:               s.WorkingDir,","\t\t\tPorts:                    s.Ports,","\t\t\tEnvFrom:                  s.EnvFrom,","\t\t\tEnv:                      s.Env,","\t\t\tResources:                s.ComputeResources,","\t\t\tVolumeMounts:             s.VolumeMounts,","\t\t\tVolumeDevices:            s.VolumeDevices,","\t\t\tLivenessProbe:            s.LivenessProbe,","\t\t\tReadinessProbe:           s.ReadinessProbe,","\t\t\tStartupProbe:             s.StartupProbe,","\t\t\tLifecycle:                s.Lifecycle,","\t\t\tTerminationMessagePath:   s.TerminationMessagePath,","\t\t\tTerminationMessagePolicy: s.TerminationMessagePolicy,","\t\t\tImagePullPolicy:          s.ImagePullPolicy,","\t\t\tSecurityContext:          s.SecurityContext,","\t\t\tStdin:                    s.Stdin,","\t\t\tStdinOnce:                s.StdinOnce,","\t\t\tTTY:                      s.TTY,","\t\t}","\t}","\treturn \u0026corev1.Container{","\t\tName:                     s.Name,","\t\tImage:                    s.Image,","\t\tCommand:                  s.Command,","\t\tArgs:                     s.Args,","\t\tWorkingDir:               s.WorkingDir,","\t\tPorts:                    s.Ports,","\t\tEnvFrom:                  s.EnvFrom,","\t\tEnv:                      s.Env,","\t\tResources:                s.ComputeResources,","\t\tVolumeMounts:             s.VolumeMounts,","\t\tVolumeDevices:            s.VolumeDevices,","\t\tLivenessProbe:            s.LivenessProbe,","\t\tReadinessProbe:           s.ReadinessProbe,","\t\tRestartPolicy:            s.RestartPolicy,","\t\tStartupProbe:             s.StartupProbe,","\t\tLifecycle:                s.Lifecycle,","\t\tTerminationMessagePath:   s.TerminationMessagePath,","\t\tTerminationMessagePolicy: s.TerminationMessagePolicy,","\t\tImagePullPolicy:          s.ImagePullPolicy,","\t\tSecurityContext:          s.SecurityContext,","\t\tStdin:                    s.Stdin,","\t\tStdinOnce:                s.StdinOnce,","\t\tTTY:                      s.TTY,","\t}","}","","// SetContainerFields sets the fields of the Sidecar to the values of the corresponding fields in the Container","func (s *Sidecar) SetContainerFields(c corev1.Container) {","\ts.Name = c.Name","\ts.Image = c.Image","\ts.Command = c.Command","\ts.Args = c.Args","\ts.WorkingDir = c.WorkingDir","\ts.Ports = c.Ports","\ts.EnvFrom = c.EnvFrom","\ts.Env = c.Env","\ts.ComputeResources = c.Resources","\ts.VolumeMounts = c.VolumeMounts","\ts.VolumeDevices = c.VolumeDevices","\ts.LivenessProbe = c.LivenessProbe","\ts.ReadinessProbe = c.ReadinessProbe","\ts.StartupProbe = c.StartupProbe","\ts.Lifecycle = c.Lifecycle","\ts.TerminationMessagePath = c.TerminationMessagePath","\ts.TerminationMessagePolicy = c.TerminationMessagePolicy","\ts.ImagePullPolicy = c.ImagePullPolicy","\ts.SecurityContext = c.SecurityContext","\ts.Stdin = c.Stdin","\ts.StdinOnce = c.StdinOnce","\ts.TTY = c.TTY","\ts.RestartPolicy = c.RestartPolicy","}","","// GetVarSubstitutionExpressions walks all the places a substitution reference can be used","func (s *Sidecar) GetVarSubstitutionExpressions() []string {","\tvar allExpressions []string","\tallExpressions = append(allExpressions, validateString(s.Name)...)","\tallExpressions = append(allExpressions, validateString(s.Image)...)","\tallExpressions = append(allExpressions, validateString(string(s.ImagePullPolicy))...)","\tallExpressions = append(allExpressions, validateString(s.Script)...)","\tallExpressions = append(allExpressions, validateString(s.WorkingDir)...)","\tfor _, cmd := range s.Command {","\t\tallExpressions = append(allExpressions, validateString(cmd)...)","\t}","\tfor _, arg := range s.Args {","\t\tallExpressions = append(allExpressions, validateString(arg)...)","\t}","\tfor _, env := range s.Env {","\t\tallExpressions = append(allExpressions, validateString(env.Value)...)","\t\tif env.ValueFrom != nil {","\t\t\tif env.ValueFrom.SecretKeyRef != nil {","\t\t\t\tallExpressions = append(allExpressions, validateString(env.ValueFrom.SecretKeyRef.Key)...)","\t\t\t\tallExpressions = append(allExpressions, validateString(env.ValueFrom.SecretKeyRef.LocalObjectReference.Name)...)","\t\t\t}","\t\t\tif env.ValueFrom.ConfigMapKeyRef != nil {","\t\t\t\tallExpressions = append(allExpressions, validateString(env.ValueFrom.ConfigMapKeyRef.Key)...)","\t\t\t\tallExpressions = append(allExpressions, validateString(env.ValueFrom.ConfigMapKeyRef.LocalObjectReference.Name)...)","\t\t\t}","\t\t}","\t}","\treturn allExpressions","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0]},{"id":22,"path":"pkg/apis/pipeline/v1/container_validation.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","\t\"regexp\"","\t\"slices\"","\t\"strings\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/internal/artifactref\"","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\t\"github.com/tektoncd/pipeline/pkg/internal/resultref\"","\t\"k8s.io/apimachinery/pkg/util/validation\"","\t\"knative.dev/pkg/apis\"",")","","// Validate ensures that a supplied Ref field is populated","// correctly. No errors are returned for a nil Ref.","func (ref *Ref) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif ref == nil {","\t\treturn errs","\t}","\treturn validateRef(ctx, ref.Name, ref.Resolver, ref.Params)","}","","func validateRef(ctx context.Context, refName string, refResolver ResolverName, refParams Params) (errs *apis.FieldError) {","\tswitch {","\tcase refResolver != \"\" || refParams != nil:","\t\tif refParams != nil {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"resolver params\", config.BetaAPIFields).ViaField(\"params\"))","\t\t\tif refName != \"\" {","\t\t\t\terrs = errs.Also(apis.ErrMultipleOneOf(\"name\", \"params\"))","\t\t\t}","\t\t\tif refResolver == \"\" {","\t\t\t\terrs = errs.Also(apis.ErrMissingField(\"resolver\"))","\t\t\t}","\t\t\terrs = errs.Also(ValidateParameters(ctx, refParams))","\t\t}","\t\tif refResolver != \"\" {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"resolver\", config.BetaAPIFields).ViaField(\"resolver\"))","\t\t\tif refName != \"\" {","\t\t\t\t// make sure that the name is url-like.","\t\t\t\terr := RefNameLikeUrl(refName)","\t\t\t\tif err == nil \u0026\u0026 !config.FromContextOrDefaults(ctx).FeatureFlags.EnableConciseResolverSyntax {","\t\t\t\t\t// If name is url-like then concise resolver syntax must be enabled","\t\t\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"feature flag %s should be set to true to use concise resolver syntax\", config.EnableConciseResolverSyntax), \"\"))","\t\t\t\t}","\t\t\t\tif err != nil {","\t\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(err, \"name\"))","\t\t\t\t}","\t\t\t}","\t\t}","\tcase refName != \"\":","\t\t// ref name can be a Url-like format.","\t\tif err := RefNameLikeUrl(refName); err == nil {","\t\t\t// If name is url-like then concise resolver syntax must be enabled","\t\t\tif !config.FromContextOrDefaults(ctx).FeatureFlags.EnableConciseResolverSyntax {","\t\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"feature flag %s should be set to true to use concise resolver syntax\", config.EnableConciseResolverSyntax), \"\"))","\t\t\t}","\t\t\t// In stage1 of concise remote resolvers syntax, this is a required field.","\t\t\t// TODO: remove this check when implementing stage 2 where this is optional.","\t\t\tif refResolver == \"\" {","\t\t\t\terrs = errs.Also(apis.ErrMissingField(\"resolver\"))","\t\t\t}","\t\t\t// Or, it must be a valid k8s name","\t\t} else {","\t\t\t// ref name must be a valid k8s name","\t\t\tif errSlice := validation.IsQualifiedName(refName); len(errSlice) != 0 {","\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(strings.Join(errSlice, \",\"), \"name\"))","\t\t\t}","\t\t}","\tdefault:","\t\terrs = errs.Also(apis.ErrMissingField(\"name\"))","\t}","\treturn errs","}","","// RefNameLikeUrl checks if the name is url parsable and returns an error if it isn't.","func RefNameLikeUrl(name string) error {","\tschemeRegex := regexp.MustCompile(`[\\w-]+:\\/\\/*`)","\tif !schemeRegex.MatchString(name) {","\t\treturn errors.New(\"invalid URI for request\")","\t}","\treturn nil","}","","// Validate implements apis.Validatable","func (s *Step) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif err := validateArtifactsReferencesInStep(ctx, s); err != nil {","\t\treturn err","\t}","","\tif s.Ref != nil {","\t\terrs = errs.Also(s.Ref.Validate(ctx))","\t\tif s.Image != \"\" {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"image cannot be used with Ref\",","\t\t\t\tPaths:   []string{\"image\"},","\t\t\t})","\t\t}","\t\tif len(s.Command) \u003e 0 {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"command cannot be used with Ref\",","\t\t\t\tPaths:   []string{\"command\"},","\t\t\t})","\t\t}","\t\tif len(s.Args) \u003e 0 {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"args cannot be used with Ref\",","\t\t\t\tPaths:   []string{\"args\"},","\t\t\t})","\t\t}","\t\tif s.Script != \"\" {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"script cannot be used with Ref\",","\t\t\t\tPaths:   []string{\"script\"},","\t\t\t})","\t\t}","\t\tif s.WorkingDir != \"\" {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"working dir cannot be used with Ref\",","\t\t\t\tPaths:   []string{\"workingDir\"},","\t\t\t})","\t\t}","\t\tif s.Env != nil {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"env cannot be used with Ref\",","\t\t\t\tPaths:   []string{\"env\"},","\t\t\t})","\t\t}","\t\tif len(s.VolumeMounts) \u003e 0 {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"volumeMounts cannot be used with Ref\",","\t\t\t\tPaths:   []string{\"volumeMounts\"},","\t\t\t})","\t\t}","\t\tif len(s.Results) \u003e 0 {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"results cannot be used with Ref\",","\t\t\t\tPaths:   []string{\"results\"},","\t\t\t})","\t\t}","\t} else {","\t\tif len(s.Params) \u003e 0 {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"params cannot be used without Ref\",","\t\t\t\tPaths:   []string{\"params\"},","\t\t\t})","\t\t}","\t\tif s.Image == \"\" {","\t\t\terrs = errs.Also(apis.ErrMissingField(\"Image\"))","\t\t}","","\t\tif s.Script != \"\" {","\t\t\tif len(s.Command) \u003e 0 {","\t\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\t\tMessage: \"script cannot be used with command\",","\t\t\t\t\tPaths:   []string{\"script\"},","\t\t\t\t})","\t\t\t}","\t\t}","\t}","","\tif s.Name != \"\" {","\t\tif e := validation.IsDNS1123Label(s.Name); len(e) \u003e 0 {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: fmt.Sprintf(\"invalid value %q\", s.Name),","\t\t\t\tPaths:   []string{\"name\"},","\t\t\t\tDetails: \"Task step name must be a valid DNS Label, For more info refer to https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names\",","\t\t\t})","\t\t}","\t}","","\tif s.Timeout != nil {","\t\tif s.Timeout.Duration \u003c time.Duration(0) {","\t\t\treturn apis.ErrInvalidValue(s.Timeout.Duration, \"negative timeout\")","\t\t}","\t}","","\tfor j, vm := range s.VolumeMounts {","\t\tif strings.HasPrefix(vm.MountPath, \"/tekton/\") \u0026\u0026","\t\t\t!strings.HasPrefix(vm.MountPath, \"/tekton/home\") {","\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"volumeMount cannot be mounted under /tekton/ (volumeMount %q mounted at %q)\", vm.Name, vm.MountPath), \"mountPath\").ViaFieldIndex(\"volumeMounts\", j))","\t\t}","\t\tif strings.HasPrefix(vm.Name, \"tekton-internal-\") {","\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(`volumeMount name %q cannot start with \"tekton-internal-\"`, vm.Name), \"name\").ViaFieldIndex(\"volumeMounts\", j))","\t\t}","\t}","","\tif s.OnError != \"\" {","\t\tif !isParamRefs(string(s.OnError)) \u0026\u0026 s.OnError != Continue \u0026\u0026 s.OnError != StopAndFail {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: fmt.Sprintf(\"invalid value: \\\"%v\\\"\", s.OnError),","\t\t\t\tPaths:   []string{\"onError\"},","\t\t\t\tDetails: \"Task step onError must be either \\\"continue\\\" or \\\"stopAndFail\\\"\",","\t\t\t})","\t\t}","\t}","","\tif s.Script != \"\" {","\t\tcleaned := strings.TrimSpace(s.Script)","\t\tif strings.HasPrefix(cleaned, \"#!win\") {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"windows script support\", config.AlphaAPIFields).ViaField(\"script\"))","\t\t}","\t}","","\t// StdoutConfig is an alpha feature and will fail validation if it's used in a task spec","\t// when the enable-api-fields feature gate is not \"alpha\".","\tif s.StdoutConfig != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"step stdout stream support\", config.AlphaAPIFields).ViaField(\"stdoutconfig\"))","\t}","\t// StderrConfig is an alpha feature and will fail validation if it's used in a task spec","\t// when the enable-api-fields feature gate is not \"alpha\".","\tif s.StderrConfig != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"step stderr stream support\", config.AlphaAPIFields).ViaField(\"stderrconfig\"))","\t}","","\t// Validate usage of step result reference.","\t// Referencing previous step's results are only allowed in `env`, `command` and `args`.","\terrs = errs.Also(validateStepResultReference(s))","","\t// Validate usage of step artifacts output reference","\t// Referencing previous step's results are only allowed in `env`, `command` and `args`, `script`.","\terrs = errs.Also(validateStepArtifactsReference(s))","\treturn errs","}","","// isParamRefs attempts to check if a specified string looks like it contains any parameter reference","// This is useful to make sure the specified value looks like a Parameter Reference before performing any strict validation","func isParamRefs(s string) bool {","\treturn strings.HasPrefix(s, \"$(\"+ParamsPrefix)","}","","func validateArtifactsReferencesInStep(ctx context.Context, s *Step) *apis.FieldError {","\tcfg := config.FromContextOrDefaults(ctx)","\tif cfg == nil || cfg.FeatureFlags == nil {","\t\tcfg = \u0026config.Config{","\t\t\tFeatureFlags: \u0026config.FeatureFlags{},","\t\t}","\t}","","\tif !cfg.FeatureFlags.EnableArtifacts {","\t\tvar t []string","\t\tif s.Script != \"\" {","\t\t\tt = append(t, s.Script)","\t\t}","\t\tif len(s.Command) \u003e 0 {","\t\t\tt = append(t, s.Command...)","\t\t}","\t\tif len(s.Args) \u003e 0 {","\t\t\tt = append(t, s.Args...)","\t\t}","\t\tif s.Env != nil {","\t\t\tfor _, e := range s.Env {","\t\t\t\tif e.Value != \"\" {","\t\t\t\t\tt = append(t, e.Value)","\t\t\t\t}","\t\t\t}","\t\t}","\t\tif slices.ContainsFunc(t, stepArtifactReferenceExists) || slices.ContainsFunc(t, taskArtifactReferenceExists) {","\t\t\treturn apis.ErrGeneric(fmt.Sprintf(\"feature flag %s should be set to true to use artifacts feature.\", config.EnableArtifacts), \"\")","\t\t}","\t}","\treturn nil","}","","func stepArtifactReferenceExists(src string) bool {","\treturn len(artifactref.StepArtifactRegex.FindAllStringSubmatch(src, -1)) \u003e 0 || strings.Contains(src, \"$(\"+artifactref.StepArtifactPathPattern+\")\")","}","","func taskArtifactReferenceExists(src string) bool {","\treturn len(artifactref.TaskArtifactRegex.FindAllStringSubmatch(src, -1)) \u003e 0 || strings.Contains(src, \"$(\"+artifactref.TaskArtifactPathPattern+\")\")","}","","func validateStepResultReference(s *Step) (errs *apis.FieldError) {","\terrs = errs.Also(errorIfStepResultReferencedInField(s.Name, \"name\"))","\terrs = errs.Also(errorIfStepResultReferencedInField(s.Image, \"image\"))","\terrs = errs.Also(errorIfStepResultReferencedInField(s.Script, \"script\"))","\terrs = errs.Also(errorIfStepResultReferencedInField(string(s.ImagePullPolicy), \"imagePullPolicy\"))","\terrs = errs.Also(errorIfStepResultReferencedInField(s.WorkingDir, \"workingDir\"))","\tfor _, e := range s.EnvFrom {","\t\terrs = errs.Also(errorIfStepResultReferencedInField(e.Prefix, \"envFrom.prefix\"))","\t\tif e.ConfigMapRef != nil {","\t\t\terrs = errs.Also(errorIfStepResultReferencedInField(e.ConfigMapRef.LocalObjectReference.Name, \"envFrom.configMapRef\"))","\t\t}","\t\tif e.SecretRef != nil {","\t\t\terrs = errs.Also(errorIfStepResultReferencedInField(e.SecretRef.LocalObjectReference.Name, \"envFrom.secretRef\"))","\t\t}","\t}","\tfor _, v := range s.VolumeMounts {","\t\terrs = errs.Also(errorIfStepResultReferencedInField(v.Name, \"volumeMounts.name\"))","\t\terrs = errs.Also(errorIfStepResultReferencedInField(v.MountPath, \"volumeMounts.mountPath\"))","\t\terrs = errs.Also(errorIfStepResultReferencedInField(v.SubPath, \"volumeMounts.subPath\"))","\t}","\tfor _, v := range s.VolumeDevices {","\t\terrs = errs.Also(errorIfStepResultReferencedInField(v.Name, \"volumeDevices.name\"))","\t\terrs = errs.Also(errorIfStepResultReferencedInField(v.DevicePath, \"volumeDevices.devicePath\"))","\t}","\treturn errs","}","","func errorIfStepResultReferencedInField(value, fieldName string) (errs *apis.FieldError) {","\tmatches := resultref.StepResultRegex.FindAllStringSubmatch(value, -1)","\tif len(matches) \u003e 0 {","\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\tMessage: \"stepResult substitutions are only allowed in env, command and args. Found usage in\",","\t\t\tPaths:   []string{fieldName},","\t\t})","\t}","\treturn errs","}","","func validateStepArtifactsReference(s *Step) (errs *apis.FieldError) {","\terrs = errs.Also(errorIfStepArtifactReferencedInField(s.Name, \"name\"))","\terrs = errs.Also(errorIfStepArtifactReferencedInField(s.Image, \"image\"))","\terrs = errs.Also(errorIfStepArtifactReferencedInField(string(s.ImagePullPolicy), \"imagePullPolicy\"))","\terrs = errs.Also(errorIfStepArtifactReferencedInField(s.WorkingDir, \"workingDir\"))","\tfor _, e := range s.EnvFrom {","\t\terrs = errs.Also(errorIfStepArtifactReferencedInField(e.Prefix, \"envFrom.prefix\"))","\t\tif e.ConfigMapRef != nil {","\t\t\terrs = errs.Also(errorIfStepArtifactReferencedInField(e.ConfigMapRef.LocalObjectReference.Name, \"envFrom.configMapRef\"))","\t\t}","\t\tif e.SecretRef != nil {","\t\t\terrs = errs.Also(errorIfStepArtifactReferencedInField(e.SecretRef.LocalObjectReference.Name, \"envFrom.secretRef\"))","\t\t}","\t}","\tfor _, v := range s.VolumeMounts {","\t\terrs = errs.Also(errorIfStepArtifactReferencedInField(v.Name, \"volumeMounts.name\"))","\t\terrs = errs.Also(errorIfStepArtifactReferencedInField(v.MountPath, \"volumeMounts.mountPath\"))","\t\terrs = errs.Also(errorIfStepArtifactReferencedInField(v.SubPath, \"volumeMounts.subPath\"))","\t}","\tfor _, v := range s.VolumeDevices {","\t\terrs = errs.Also(errorIfStepArtifactReferencedInField(v.Name, \"volumeDevices.name\"))","\t\terrs = errs.Also(errorIfStepArtifactReferencedInField(v.DevicePath, \"volumeDevices.devicePath\"))","\t}","\treturn errs","}","","func errorIfStepArtifactReferencedInField(value, fieldName string) (errs *apis.FieldError) {","\tif stepArtifactReferenceExists(value) {","\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\tMessage: \"stepArtifact substitutions are only allowed in env, command, args and script. Found usage in\",","\t\t\tPaths:   []string{fieldName},","\t\t})","\t}","\treturn errs","}","","func (sc *Sidecar) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif sc.Name == pipeline.ReservedResultsSidecarName {","\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(\"Invalid: cannot use reserved sidecar name %v \", sc.Name),","\t\t\tPaths:   []string{\"name\"},","\t\t})","\t}","","\tif sc.Image == \"\" {","\t\terrs = errs.Also(apis.ErrMissingField(\"image\"))","\t}","","\tif sc.Script != \"\" {","\t\tif len(sc.Command) \u003e 0 {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"script cannot be used with command\",","\t\t\t\tPaths:   []string{\"script\"},","\t\t\t})","\t\t}","\t}","\treturn errs","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,0,2,2,2,2,2,0,2,2,0,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,0,0,0,2,2,2,0,0,2,2,2,0,0,0,2,2,2,2,2,2,0,0,0,0,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,2,0,0,2,2,2,0,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,2,2,2,2,0,2,0]},{"id":23,"path":"pkg/apis/pipeline/v1/matrix_types.go","lines":["/*","Copyright 2023 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","\t\"fmt\"","\t\"maps\"","\t\"sort\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"k8s.io/utils/strings/slices\"","\t\"knative.dev/pkg/apis\"",")","","// Matrix is used to fan out Tasks in a Pipeline","type Matrix struct {","\t// Params is a list of parameters used to fan out the pipelineTask","\t// Params takes only `Parameters` of type `\"array\"`","\t// Each array element is supplied to the `PipelineTask` by substituting `params` of type `\"string\"` in the underlying `Task`.","\t// The names of the `params` in the `Matrix` must match the names of the `params` in the underlying `Task` that they will be substituting.","\tParams Params `json:\"params,omitempty\"`","","\t// Include is a list of IncludeParams which allows passing in specific combinations of Parameters into the Matrix.","\t// +optional","\tInclude IncludeParamsList `json:\"include,omitempty\"`","}","","// IncludeParamsList is a list of IncludeParams which allows passing in specific combinations of Parameters into the Matrix.","// +listType=atomic","type IncludeParamsList []IncludeParams","","// IncludeParams allows passing in a specific combinations of Parameters into the Matrix.","type IncludeParams struct {","\t// Name the specified combination","\tName string `json:\"name,omitempty\"`","","\t// Params takes only `Parameters` of type `\"string\"`","\t// The names of the `params` must match the names of the `params` in the underlying `Task`","\tParams Params `json:\"params,omitempty\"`","}","","// Combination is a map, mainly defined to hold a single combination from a Matrix with key as param.Name and value as param.Value","type Combination map[string]string","","// Combinations is a Combination list","type Combinations []Combination","","// FanOut returns an list of params that represent combinations","func (m *Matrix) FanOut() []Params {","\tvar combinations, includeCombinations Combinations","\tincludeCombinations = m.getIncludeCombinations()","\tif m.HasInclude() \u0026\u0026 !m.HasParams() {","\t\t// If there are only Matrix Include Parameters return explicit combinations","\t\treturn includeCombinations.toParams()","\t}","\t// Generate combinations from Matrix Parameters","\tfor _, parameter := range m.Params {","\t\tcombinations = combinations.fanOutMatrixParams(parameter)","\t}","\tcombinations.overwriteCombinations(includeCombinations)","\tcombinations = combinations.addNewCombinations(includeCombinations)","\treturn combinations.toParams()","}","","// overwriteCombinations replaces any missing include params in the initial","// matrix params combinations by overwriting the initial combinations with the","// include combinations","func (cs Combinations) overwriteCombinations(ics Combinations) {","\tfor _, paramCombination := range cs {","\t\tfor _, includeCombination := range ics {","\t\t\tif paramCombination.contains(includeCombination) {","\t\t\t\t// overwrite the parameter name and value in existing combination","\t\t\t\t// with the include combination","\t\t\t\tfor name, val := range includeCombination {","\t\t\t\t\tparamCombination[name] = val","\t\t\t\t}","\t\t\t}","\t\t}","\t}","}","","// addNewCombinations creates a new combination for any include parameter","// values that are missing entirely from the initial combinations and","// returns all combinations","func (cs Combinations) addNewCombinations(ics Combinations) Combinations {","\tfor _, includeCombination := range ics {","\t\tif cs.shouldAddNewCombination(includeCombination) {","\t\t\tcs = append(cs, includeCombination)","\t\t}","\t}","\treturn cs","}","","// contains returns true if the include parameter name and value exists in combinations","func (c Combination) contains(includeCombination Combination) bool {","\tfor name, val := range includeCombination {","\t\tif _, exist := c[name]; exist {","\t\t\tif c[name] != val {","\t\t\t\treturn false","\t\t\t}","\t\t}","\t}","\treturn true","}","","// shouldAddNewCombination returns true if the include parameter name exists but the value is","// missing from combinations","func (cs Combinations) shouldAddNewCombination(includeCombination map[string]string) bool {","\tif len(includeCombination) == 0 {","\t\treturn false","\t}","\tfor _, paramCombination := range cs {","\t\tfor name, val := range includeCombination {","\t\t\tif _, exist := paramCombination[name]; exist {","\t\t\t\tif paramCombination[name] == val {","\t\t\t\t\treturn false","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn true","}","","// toParams transforms Combinations from a slice of map[string]string to a slice of Params","// such that, these combinations can be directly consumed in creating taskRun/run object","func (cs Combinations) toParams() []Params {","\tlistOfParams := make([]Params, len(cs))","\tfor i := range cs {","\t\tvar params Params","\t\tcombination := cs[i]","\t\torder, _ := combination.sortCombination()","\t\tfor _, key := range order {","\t\t\tparams = append(params, Param{","\t\t\t\tName:  key,","\t\t\t\tValue: ParamValue{Type: ParamTypeString, StringVal: combination[key]},","\t\t\t})","\t\t}","\t\tlistOfParams[i] = params","\t}","\treturn listOfParams","}","","// fanOutMatrixParams generates new combinations based on Matrix Parameters.","func (cs Combinations) fanOutMatrixParams(param Param) Combinations {","\tif len(cs) == 0 {","\t\treturn initializeCombinations(param)","\t}","\treturn cs.distribute(param)","}","","// getIncludeCombinations generates combinations based on Matrix Include Parameters","func (m *Matrix) getIncludeCombinations() Combinations {","\tvar combinations Combinations","\tfor i := range m.Include {","\t\tincludeParams := m.Include[i].Params","\t\tnewCombination := make(Combination)","\t\tfor _, param := range includeParams {","\t\t\tnewCombination[param.Name] = param.Value.StringVal","\t\t}","\t\tcombinations = append(combinations, newCombination)","\t}","\treturn combinations","}","","// distribute generates a new Combination of Parameters by adding a new Parameter to an existing list of Combinations.","func (cs Combinations) distribute(param Param) Combinations {","\tvar expandedCombinations Combinations","\tfor _, value := range param.Value.ArrayVal {","\t\tfor _, combination := range cs {","\t\t\tnewCombination := make(Combination)","\t\t\tmaps.Copy(newCombination, combination)","\t\t\tnewCombination[param.Name] = value","\t\t\t_, orderedCombination := newCombination.sortCombination()","\t\t\texpandedCombinations = append(expandedCombinations, orderedCombination)","\t\t}","\t}","\treturn expandedCombinations","}","","// initializeCombinations generates a new Combination based on the first Parameter in the Matrix.","func initializeCombinations(param Param) Combinations {","\tvar combinations Combinations","\tfor _, value := range param.Value.ArrayVal {","\t\tcombinations = append(combinations, Combination{param.Name: value})","\t}","\treturn combinations","}","","// sortCombination sorts the given Combination based on the Parameter names to produce a deterministic ordering","func (c Combination) sortCombination() ([]string, Combination) {","\tsortedCombination := make(Combination, len(c))","\torder := make([]string, 0, len(c))","\tfor key := range c {","\t\torder = append(order, key)","\t}","\tsort.Slice(order, func(i, j int) bool {","\t\treturn order[i] \u003c= order[j]","\t})","\tfor _, key := range order {","\t\tsortedCombination[key] = c[key]","\t}","\treturn order, sortedCombination","}","","// CountCombinations returns the count of Combinations of Parameters generated from the Matrix in PipelineTask.","func (m *Matrix) CountCombinations() int {","\t// Iterate over Matrix Parameters and compute count of all generated Combinations","\tcount := m.countGeneratedCombinationsFromParams()","","\t// Add any additional Combinations generated from Matrix Include Parameters","\tcount += m.countNewCombinationsFromInclude()","","\treturn count","}","","// countGeneratedCombinationsFromParams returns the count of Combinations of Parameters generated from the Matrix","// Parameters","func (m *Matrix) countGeneratedCombinationsFromParams() int {","\tif !m.HasParams() {","\t\treturn 0","\t}","\tcount := 1","\tfor _, param := range m.Params {","\t\tif len(param.Value.ArrayVal) \u003e 0 {","\t\t\tcount *= len(param.Value.ArrayVal)","\t\t}","\t}","\treturn count","}","","// countNewCombinationsFromInclude returns the count of Combinations of Parameters generated from the Matrix","// Include Parameters","func (m *Matrix) countNewCombinationsFromInclude() int {","\tif !m.HasInclude() {","\t\treturn 0","\t}","\tif !m.HasParams() {","\t\treturn len(m.Include)","\t}","\tcount := 0","\tmatrixParamMap := m.Params.extractParamMapArrVals()","\tfor _, include := range m.Include {","\t\tfor _, param := range include.Params {","\t\t\tif val, exist := matrixParamMap[param.Name]; exist {","\t\t\t\t// If the Matrix Include param values does not exist, a new Combination will be generated","\t\t\t\tif !slices.Contains(val, param.Value.StringVal) {","\t\t\t\t\tcount++","\t\t\t\t} else {","\t\t\t\t\tbreak","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn count","}","","// HasInclude returns true if the Matrix has Include Parameters","func (m *Matrix) HasInclude() bool {","\treturn m != nil \u0026\u0026 m.Include != nil \u0026\u0026 len(m.Include) \u003e 0","}","","// HasParams returns true if the Matrix has Parameters","func (m *Matrix) HasParams() bool {","\treturn m != nil \u0026\u0026 m.Params != nil \u0026\u0026 len(m.Params) \u003e 0","}","","// GetAllParams returns a list of all Matrix Parameters","func (m *Matrix) GetAllParams() Params {","\tvar params Params","\tif m.HasParams() {","\t\tparams = append(params, m.Params...)","\t}","\tif m.HasInclude() {","\t\tfor _, include := range m.Include {","\t\t\tparams = append(params, include.Params...)","\t\t}","\t}","\treturn params","}","","func (m *Matrix) validateCombinationsCount(ctx context.Context) (errs *apis.FieldError) {","\tmatrixCombinationsCount := m.CountCombinations()","\tmaxMatrixCombinationsCount := config.FromContextOrDefaults(ctx).Defaults.DefaultMaxMatrixCombinationsCount","\tif matrixCombinationsCount \u003e maxMatrixCombinationsCount {","\t\terrs = errs.Also(apis.ErrOutOfBoundsValue(matrixCombinationsCount, 0, maxMatrixCombinationsCount, \"matrix\"))","\t}","\treturn errs","}","","// validateUniqueParams validates Matrix.Params for a unique list of params","// and a unique list of params in each Matrix.Include.Params specification","func (m *Matrix) validateUniqueParams() (errs *apis.FieldError) {","\tif m != nil {","\t\tif m.HasInclude() {","\t\t\tfor i, include := range m.Include {","\t\t\t\terrs = errs.Also(include.Params.validateDuplicateParameters().ViaField(fmt.Sprintf(\"matrix.include[%d].params\", i)))","\t\t\t}","\t\t}","\t\tif m.HasParams() {","\t\t\terrs = errs.Also(m.Params.validateDuplicateParameters().ViaField(\"matrix.params\"))","\t\t}","\t}","\treturn errs","}","","// validatePipelineParametersVariablesInMatrixParameters validates all pipeline parameter variables including Matrix.Params and Matrix.Include.Params","// that may contain the reference(s) to other params to make sure those references are used appropriately.","func (m *Matrix) validatePipelineParametersVariablesInMatrixParameters(prefix string, paramNames sets.String, arrayParamNames sets.String, objectParamNameKeys map[string][]string) (errs *apis.FieldError) {","\tif m.HasInclude() {","\t\tfor _, include := range m.Include {","\t\t\tfor idx, param := range include.Params {","\t\t\t\tstringElement := param.Value.StringVal","\t\t\t\t// Matrix Include Params must be of type string","\t\t\t\terrs = errs.Also(validateStringVariable(stringElement, prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaFieldIndex(\"\", idx).ViaField(\"matrix.include.params\", \"\"))","\t\t\t}","\t\t}","\t}","\tif m.HasParams() {","\t\tfor _, param := range m.Params {","\t\t\tfor idx, arrayElement := range param.Value.ArrayVal {","\t\t\t\t// Matrix Params must be of type array","\t\t\t\terrs = errs.Also(validateArrayVariable(arrayElement, prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaFieldIndex(\"value\", idx).ViaFieldKey(\"matrix.params\", param.Name))","\t\t\t}","\t\t}","\t}","\treturn errs","}","","func (m *Matrix) validateParameterInOneOfMatrixOrParams(params []Param) (errs *apis.FieldError) {","\tmatrixParamNames := m.GetAllParams().ExtractNames()","\tfor _, param := range params {","\t\tif matrixParamNames.Has(param.Name) {","\t\t\terrs = errs.Also(apis.ErrMultipleOneOf(\"matrix[\"+param.Name+\"]\", \"params[\"+param.Name+\"]\"))","\t\t}","\t}","\treturn errs","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,0,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,0,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,0,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,0,2,0]},{"id":24,"path":"pkg/apis/pipeline/v1/merge.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"encoding/json\"","","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/util/strategicpatch\"",")","","// mergeData is used to store the intermediate data needed to merge an object","// with a template. It's provided to avoid repeatedly re-serializing the template.","// +k8s:openapi-gen=false","type mergeData struct {","\temptyJSON    []byte","\ttemplateJSON []byte","\tpatchSchema  strategicpatch.PatchMetaFromStruct","}","","// MergeStepsWithStepTemplate takes a possibly nil container template and a","// list of steps, merging each of the steps with the container template, if","// it's not nil, and returning the resulting list.","func MergeStepsWithStepTemplate(template *StepTemplate, steps []Step) ([]Step, error) {","\tif template == nil {","\t\treturn steps, nil","\t}","","\tmd, err := getMergeData(template.ToK8sContainer(), \u0026corev1.Container{})","\tif err != nil {","\t\treturn nil, err","\t}","","\tfor i, s := range steps {","\t\t// If the stepaction has not been fetched yet then do not merge.","\t\t// Skip over to the next one","\t\tif s.Ref != nil {","\t\t\tcontinue","\t\t}","\t\tmerged := corev1.Container{}","\t\terr := mergeObjWithTemplateBytes(md, s.ToK8sContainer(), \u0026merged)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","","\t\t// If the container's args is nil, reset it to empty instead","\t\tif merged.Args == nil \u0026\u0026 s.Args != nil {","\t\t\tmerged.Args = []string{}","\t\t}","","\t\tamendConflictingContainerFields(\u0026merged, s)","","\t\t// Pass through original step Script, for later conversion.","\t\tnewStep := Step{","\t\t\tScript:       s.Script,","\t\t\tOnError:      s.OnError,","\t\t\tTimeout:      s.Timeout,","\t\t\tStdoutConfig: s.StdoutConfig,","\t\t\tStderrConfig: s.StderrConfig,","\t\t\tResults:      s.Results,","\t\t\tParams:       s.Params,","\t\t\tRef:          s.Ref,","\t\t\tWhen:         s.When,","\t\t\tWorkspaces:   s.Workspaces,","\t\t}","\t\tnewStep.SetContainerFields(merged)","\t\tsteps[i] = newStep","\t}","\treturn steps, nil","}","","// MergeStepsWithSpecs takes a possibly nil list of overrides and a","// list of steps, merging each of the steps with the overrides' resource requirements, if","// it's not nil, and returning the resulting list.","func MergeStepsWithSpecs(steps []Step, overrides []TaskRunStepSpec) ([]Step, error) {","\tstepNameToOverride := make(map[string]TaskRunStepSpec, len(overrides))","\tfor _, o := range overrides {","\t\tstepNameToOverride[o.Name] = o","\t}","\tfor i, s := range steps {","\t\to, found := stepNameToOverride[s.Name]","\t\tif !found {","\t\t\tcontinue","\t\t}","\t\tmerged := corev1.ResourceRequirements{}","\t\terr := mergeObjWithTemplate(\u0026s.ComputeResources, \u0026o.ComputeResources, \u0026merged)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tsteps[i].ComputeResources = merged","\t}","\treturn steps, nil","}","","// MergeSidecarsWithSpecs takes a possibly nil list of overrides and a","// list of sidecars, merging each of the sidecars with the overrides' resource requirements, if","// it's not nil, and returning the resulting list.","func MergeSidecarsWithSpecs(sidecars []Sidecar, overrides []TaskRunSidecarSpec) ([]Sidecar, error) {","\tif len(overrides) == 0 {","\t\treturn sidecars, nil","\t}","\tsidecarNameToOverride := make(map[string]TaskRunSidecarSpec, len(overrides))","\tfor _, o := range overrides {","\t\tsidecarNameToOverride[o.Name] = o","\t}","\tfor i, s := range sidecars {","\t\to, found := sidecarNameToOverride[s.Name]","\t\tif !found {","\t\t\tcontinue","\t\t}","\t\tmerged := corev1.ResourceRequirements{}","\t\terr := mergeObjWithTemplate(\u0026s.ComputeResources, \u0026o.ComputeResources, \u0026merged)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tsidecars[i].ComputeResources = merged","\t}","\treturn sidecars, nil","}","","// mergeObjWithTemplate merges obj with template and updates out to reflect the merged result.","// template, obj, and out should point to the same type. out points to the zero value of that type.","func mergeObjWithTemplate(template, obj, out interface{}) error {","\tmd, err := getMergeData(template, out)","\tif err != nil {","\t\treturn err","\t}","\treturn mergeObjWithTemplateBytes(md, obj, out)","}","","// getMergeData serializes the template and empty object to get the intermediate results necessary for","// merging an object of the same type with this template.","// This function is provided to avoid repeatedly serializing an identical template.","func getMergeData(template, empty interface{}) (*mergeData, error) {","\t// We need JSON bytes to generate a patch to merge the object","\t// onto the template, so marshal the template.","\ttemplateJSON, err := json.Marshal(template)","\tif err != nil {","\t\treturn nil, err","\t}","\t// We need to do a three-way merge to actually merge the template and","\t// object, so we need an empty object as the \"original\"","\temptyJSON, err := json.Marshal(empty)","\tif err != nil {","\t\treturn nil, err","\t}","\t// Get the patch meta, which is needed for generating and applying the merge patch.","\tpatchSchema, err := strategicpatch.NewPatchMetaFromStruct(template)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn \u0026mergeData{templateJSON: templateJSON, emptyJSON: emptyJSON, patchSchema: patchSchema}, nil","}","","// mergeObjWithTemplateBytes merges obj with md's template JSON and updates out to reflect the merged result.","// out is a pointer to the zero value of obj's type.","// This function is provided to avoid repeatedly serializing an identical template.","func mergeObjWithTemplateBytes(md *mergeData, obj, out interface{}) error {","\t// Marshal the object to JSON","\tobjAsJSON, err := json.Marshal(obj)","\tif err != nil {","\t\treturn err","\t}","\t// Create a merge patch, with the empty JSON as the original, the object JSON as the modified, and the template","\t// JSON as the current - this lets us do a deep merge of the template and object, with awareness of","\t// the \"patchMerge\" tags.","\tpatch, err := strategicpatch.CreateThreeWayMergePatch(md.emptyJSON, objAsJSON, md.templateJSON, md.patchSchema, true)","\tif err != nil {","\t\treturn err","\t}","","\t// Actually apply the merge patch to the template JSON.","\tmergedAsJSON, err := strategicpatch.StrategicMergePatchUsingLookupPatchMeta(md.templateJSON, patch, md.patchSchema)","\tif err != nil {","\t\treturn err","\t}","\t// Unmarshal the merged JSON to a pointer, and return it.","\treturn json.Unmarshal(mergedAsJSON, out)","}","","// amendConflictingContainerFields amends conflicting container fields after merge, and overrides conflicting fields","// by fields in step.","func amendConflictingContainerFields(container *corev1.Container, step Step) {","\tif container == nil || len(step.Env) == 0 {","\t\treturn","\t}","","\tenvNameToStepEnv := make(map[string]corev1.EnvVar, len(step.Env))","\tfor _, e := range step.Env {","\t\tenvNameToStepEnv[e.Name] = e","\t}","","\tfor index, env := range container.Env {","\t\tif env.ValueFrom != nil \u0026\u0026 len(env.Value) \u003e 0 {","\t\t\tif e, ok := envNameToStepEnv[env.Name]; ok {","\t\t\t\tcontainer.Env[index] = e","\t\t\t}","\t\t}","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,2,2,1,1,0,2,2,2,2,2,0,2,2,2,1,1,0,0,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,1,1,2,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,1,1,2,0,2,0,0,0,0,2,2,2,1,1,2,0,0,0,0,0,2,2,2,2,2,1,1,0,0,2,2,1,1,0,2,2,1,1,2,0,0,0,0,0,2,2,2,2,1,1,0,0,0,2,2,1,1,0,0,2,2,1,1,0,2,0,0,0,0,2,2,2,2,0,2,2,2,2,0,2,2,2,2,2,0,0,0]},{"id":25,"path":"pkg/apis/pipeline/v1/param_types.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","\t\"encoding/json\"","\t\"fmt\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"k8s.io/utils/strings/slices\"","\t\"knative.dev/pkg/apis\"",")","","// ParamsPrefix is the prefix used in $(...) expressions referring to parameters","const ParamsPrefix = \"params\"","","// ParamSpec defines arbitrary parameters needed beyond typed inputs (such as","// resources). Parameter values are provided by users as inputs on a TaskRun","// or PipelineRun.","type ParamSpec struct {","\t// Name declares the name by which a parameter is referenced.","\tName string `json:\"name\"`","\t// Type is the user-specified type of the parameter. The possible types","\t// are currently \"string\", \"array\" and \"object\", and \"string\" is the default.","\t// +optional","\tType ParamType `json:\"type,omitempty\"`","\t// Description is a user-facing description of the parameter that may be","\t// used to populate a UI.","\t// +optional","\tDescription string `json:\"description,omitempty\"`","\t// Properties is the JSON Schema properties to support key-value pairs parameter.","\t// +optional","\tProperties map[string]PropertySpec `json:\"properties,omitempty\"`","\t// Default is the value a parameter takes if no input value is supplied. If","\t// default is set, a Task may be executed without a supplied value for the","\t// parameter.","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tDefault *ParamValue `json:\"default,omitempty\"`","\t// Enum declares a set of allowed param input values for tasks/pipelines that can be validated.","\t// If Enum is not set, no input validation is performed for the param.","\t// +optional","\tEnum []string `json:\"enum,omitempty\"`","}","","// ParamSpecs is a list of ParamSpec","// +listType=atomic","type ParamSpecs []ParamSpec","","// PropertySpec defines the struct for object keys","type PropertySpec struct {","\tType ParamType `json:\"type,omitempty\"`","}","","// SetDefaults set the default type","func (pp *ParamSpec) SetDefaults(context.Context) {","\tif pp == nil {","\t\treturn","\t}","","\t// Propagate inferred type to the parent ParamSpec's type, and default type to the PropertySpec's type","\t// The sequence to look at is type in ParamSpec -\u003e properties -\u003e type in default -\u003e array/string/object value in default","\t// If neither `properties` or `default` section is provided, ParamTypeString will be the default type.","\tswitch {","\tcase pp.Type != \"\":","\t\t// If param type is provided by the author, do nothing but just set default type for PropertySpec in case `properties` section is provided.","\t\tpp.setDefaultsForProperties()","\tcase pp.Properties != nil:","\t\tpp.Type = ParamTypeObject","\t\t// Also set default type for PropertySpec","\t\tpp.setDefaultsForProperties()","\tcase pp.Default == nil:","\t\t// ParamTypeString is the default value (when no type can be inferred from the default value)","\t\tpp.Type = ParamTypeString","\tcase pp.Default.Type != \"\":","\t\tpp.Type = pp.Default.Type","\tcase pp.Default.ArrayVal != nil:","\t\tpp.Type = ParamTypeArray","\tcase pp.Default.ObjectVal != nil:","\t\tpp.Type = ParamTypeObject","\tdefault:","\t\tpp.Type = ParamTypeString","\t}","}","","// setDefaultsForProperties sets default type for PropertySpec (string) if it's not specified","func (pp *ParamSpec) setDefaultsForProperties() {","\tfor key, propertySpec := range pp.Properties {","\t\tif propertySpec.Type == \"\" {","\t\t\tpp.Properties[key] = PropertySpec{Type: ParamTypeString}","\t\t}","\t}","}","","// GetNames returns all the names of the declared parameters","func (ps ParamSpecs) GetNames() []string {","\tvar names []string","\tfor _, p := range ps {","\t\tnames = append(names, p.Name)","\t}","\treturn names","}","","// SortByType splits the input params into string params, array params, and object params, in that order","func (ps ParamSpecs) SortByType() (ParamSpecs, ParamSpecs, ParamSpecs) {","\tvar stringParams, arrayParams, objectParams ParamSpecs","\tfor _, p := range ps {","\t\tswitch p.Type {","\t\tcase ParamTypeArray:","\t\t\tarrayParams = append(arrayParams, p)","\t\tcase ParamTypeObject:","\t\t\tobjectParams = append(objectParams, p)","\t\tcase ParamTypeString:","\t\t\tfallthrough","\t\tdefault:","\t\t\tstringParams = append(stringParams, p)","\t\t}","\t}","\treturn stringParams, arrayParams, objectParams","}","","// ValidateNoDuplicateNames returns an error if any of the params have the same name","func (ps ParamSpecs) ValidateNoDuplicateNames() *apis.FieldError {","\tvar errs *apis.FieldError","\tnames := ps.GetNames()","\tfor dup := range findDups(names) {","\t\terrs = errs.Also(apis.ErrGeneric(\"parameter appears more than once\", \"\").ViaFieldKey(\"params\", dup))","\t}","\treturn errs","}","","// validateParamEnums validates feature flag, duplication and allowed types for Param Enum","func (ps ParamSpecs) validateParamEnums(ctx context.Context) *apis.FieldError {","\tvar errs *apis.FieldError","\tfor _, p := range ps {","\t\tif len(p.Enum) == 0 {","\t\t\tcontinue","\t\t}","\t\tif !config.FromContextOrDefaults(ctx).FeatureFlags.EnableParamEnum {","\t\t\terrs = errs.Also(errs, apis.ErrGeneric(fmt.Sprintf(\"feature flag `%s` should be set to true to use Enum\", config.EnableParamEnum), \"\").ViaKey(p.Name))","\t\t}","\t\tif p.Type != ParamTypeString {","\t\t\terrs = errs.Also(apis.ErrGeneric(\"enum can only be set with string type param\", \"\").ViaKey(p.Name))","\t\t}","\t\tfor dup := range findDups(p.Enum) {","\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"parameter enum value %v appears more than once\", dup), \"\").ViaKey(p.Name))","\t\t}","\t\tif p.Default != nil \u0026\u0026 p.Default.StringVal != \"\" {","\t\t\tif !slices.Contains(p.Enum, p.Default.StringVal) {","\t\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"param default value %v not in the enum list\", p.Default.StringVal), \"\").ViaKey(p.Name))","\t\t\t}","\t\t}","\t}","\treturn errs","}","","// findDups returns the duplicate element in the given slice","func findDups(vals []string) sets.String {","\tseen := sets.String{}","\tdups := sets.String{}","\tfor _, val := range vals {","\t\tif seen.Has(val) {","\t\t\tdups.Insert(val)","\t\t}","\t\tseen.Insert(val)","\t}","\treturn dups","}","","// Param declares an ParamValues to use for the parameter called name.","type Param struct {","\tName string `json:\"name\"`","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tValue ParamValue `json:\"value\"`","}","","// GetVarSubstitutionExpressions extracts all the value between \"$(\" and \")\"\" for a Parameter","func (p Param) GetVarSubstitutionExpressions() ([]string, bool) {","\tvar allExpressions []string","\tswitch p.Value.Type {","\tcase ParamTypeArray:","\t\t// array type","\t\tfor _, value := range p.Value.ArrayVal {","\t\t\tallExpressions = append(allExpressions, validateString(value)...)","\t\t}","\tcase ParamTypeString:","\t\t// string type","\t\tallExpressions = append(allExpressions, validateString(p.Value.StringVal)...)","\tcase ParamTypeObject:","\t\t// object type","\t\tfor _, value := range p.Value.ObjectVal {","\t\t\tallExpressions = append(allExpressions, validateString(value)...)","\t\t}","\tdefault:","\t\treturn nil, false","\t}","\treturn allExpressions, len(allExpressions) != 0","}","","// ExtractNames returns a set of unique names","func (ps Params) ExtractNames() sets.String {","\tnames := sets.String{}","\tfor _, p := range ps {","\t\tnames.Insert(p.Name)","\t}","\treturn names","}","","func (ps Params) extractValues() []string {","\tpvs := []string{}","\tfor i := range ps {","\t\tpvs = append(pvs, ps[i].Value.StringVal)","\t\tpvs = append(pvs, ps[i].Value.ArrayVal...)","\t\tfor _, v := range ps[i].Value.ObjectVal {","\t\t\tpvs = append(pvs, v)","\t\t}","\t}","\treturn pvs","}","","// extractParamMapArrVals creates a param map with the key: param.Name and","// val: param.Value.ArrayVal","func (ps Params) extractParamMapArrVals() map[string][]string {","\tparamsMap := make(map[string][]string)","\tfor _, p := range ps {","\t\tparamsMap[p.Name] = p.Value.ArrayVal","\t}","\treturn paramsMap","}","","// ParseTaskandResultName parses \"task name\", \"result name\" from a Matrix Context Variable","// Valid Example 1:","// - Input: tasks.myTask.matrix.length","// - Output: \"myTask\", \"\"","// Valid Example 2:","// - Input: tasks.myTask.matrix.ResultName.length","// - Output: \"myTask\", \"ResultName\"","func (p Param) ParseTaskandResultName() (string, string) {","\tif expressions, ok := p.GetVarSubstitutionExpressions(); ok {","\t\tfor _, expression := range expressions {","\t\t\tsubExpressions := strings.Split(expression, \".\")","\t\t\tpipelineTaskName := subExpressions[1]","\t\t\tif len(subExpressions) == 4 {","\t\t\t\treturn pipelineTaskName, \"\"","\t\t\t} else if len(subExpressions) == 5 {","\t\t\t\tresultName := subExpressions[3]","\t\t\t\treturn pipelineTaskName, resultName","\t\t\t}","\t\t}","\t}","\treturn \"\", \"\"","}","","// Params is a list of Param","// +listType=atomic","type Params []Param","","// ExtractParamArrayLengths extract and return the lengths of all array params","// Example of returned value: {\"a-array-params\": 2,\"b-array-params\": 2 }","func (ps Params) ExtractParamArrayLengths() map[string]int {","\t// Collect all array params","\tarrayParamsLengths := make(map[string]int)","","\t// Collect array params lengths from params","\tfor _, p := range ps {","\t\tif p.Value.Type == ParamTypeArray {","\t\t\tarrayParamsLengths[p.Name] = len(p.Value.ArrayVal)","\t\t}","\t}","\treturn arrayParamsLengths","}","","// validateDuplicateParameters checks if a parameter with the same name is defined more than once","func (ps Params) validateDuplicateParameters() (errs *apis.FieldError) {","\ttaskParamNames := sets.NewString()","\tfor i, param := range ps {","\t\tif taskParamNames.Has(param.Name) {","\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"parameter names must be unique,\"+","\t\t\t\t\" the parameter \\\"%s\\\" is also defined at\", param.Name), fmt.Sprintf(\"[%d].name\", i)))","\t\t}","\t\ttaskParamNames.Insert(param.Name)","\t}","\treturn errs","}","","// ReplaceVariables applies string, array and object replacements to variables in Params","func (ps Params) ReplaceVariables(stringReplacements map[string]string, arrayReplacements map[string][]string, objectReplacements map[string]map[string]string) Params {","\tparams := ps.DeepCopy()","\tfor i := range params {","\t\tparams[i].Value.ApplyReplacements(stringReplacements, arrayReplacements, objectReplacements)","\t}","\treturn params","}","","// ExtractDefaultParamArrayLengths extract and return the lengths of all array params","// Example of returned value: {\"a-array-params\": 2,\"b-array-params\": 2 }","func (ps ParamSpecs) ExtractDefaultParamArrayLengths() map[string]int {","\t// Collect all array params","\tarrayParamsLengths := make(map[string]int)","","\t// Collect array params lengths from defaults","\tfor _, p := range ps {","\t\tif p.Default != nil {","\t\t\tif p.Default.Type == ParamTypeArray {","\t\t\t\tarrayParamsLengths[p.Name] = len(p.Default.ArrayVal)","\t\t\t}","\t\t}","\t}","\treturn arrayParamsLengths","}","","// extractArrayIndexingParamRefs takes a string of the form `foo-$(params.array-param[1])-bar` and extracts the portions of the string that reference an element in an array param.","// For example, for the string â€œfoo-$(params.array-param[1])-bar-$(params.other-array-param[2])-$(params.string-param)`,","// it would return [\"$(params.array-param[1])\", \"$(params.other-array-param[2])\"].","func extractArrayIndexingParamRefs(paramReference string) []string {","\tl := []string{}","\tlist := substitution.ExtractArrayIndexingParamsExpressions(paramReference)","\tfor _, val := range list {","\t\tindexString := substitution.ExtractIndexString(val)","\t\tif indexString != \"\" {","\t\t\tl = append(l, val)","\t\t}","\t}","\treturn l","}","","// extractParamRefsFromSteps get all array indexing references from steps","func extractParamRefsFromSteps(steps []Step) []string {","\tparamsRefs := []string{}","\tfor _, step := range steps {","\t\tparamsRefs = append(paramsRefs, step.Script)","\t\tcontainer := step.ToK8sContainer()","\t\tparamsRefs = append(paramsRefs, extractParamRefsFromContainer(container)...)","\t}","\treturn paramsRefs","}","","// extractParamRefsFromStepTemplate get all array indexing references from StepsTemplate","func extractParamRefsFromStepTemplate(stepTemplate *StepTemplate) []string {","\tif stepTemplate == nil {","\t\treturn nil","\t}","\tcontainer := stepTemplate.ToK8sContainer()","\treturn extractParamRefsFromContainer(container)","}","","// extractParamRefsFromSidecars get all array indexing references from sidecars","func extractParamRefsFromSidecars(sidecars []Sidecar) []string {","\tparamsRefs := []string{}","\tfor _, s := range sidecars {","\t\tparamsRefs = append(paramsRefs, s.Script)","\t\tcontainer := s.ToK8sContainer()","\t\tparamsRefs = append(paramsRefs, extractParamRefsFromContainer(container)...)","\t}","\treturn paramsRefs","}","","// extractParamRefsFromVolumes get all array indexing references from volumes","func extractParamRefsFromVolumes(volumes []corev1.Volume) []string {","\tparamsRefs := []string{}","\tfor i, v := range volumes {","\t\tparamsRefs = append(paramsRefs, v.Name)","\t\tif v.VolumeSource.ConfigMap != nil {","\t\t\tparamsRefs = append(paramsRefs, v.ConfigMap.Name)","\t\t\tfor _, item := range v.ConfigMap.Items {","\t\t\t\tparamsRefs = append(paramsRefs, item.Key)","\t\t\t\tparamsRefs = append(paramsRefs, item.Path)","\t\t\t}","\t\t}","\t\tif v.VolumeSource.Secret != nil {","\t\t\tparamsRefs = append(paramsRefs, v.Secret.SecretName)","\t\t\tfor _, item := range v.Secret.Items {","\t\t\t\tparamsRefs = append(paramsRefs, item.Key)","\t\t\t\tparamsRefs = append(paramsRefs, item.Path)","\t\t\t}","\t\t}","\t\tif v.PersistentVolumeClaim != nil {","\t\t\tparamsRefs = append(paramsRefs, v.PersistentVolumeClaim.ClaimName)","\t\t}","\t\tif v.Projected != nil {","\t\t\tfor _, s := range volumes[i].Projected.Sources {","\t\t\t\tif s.ConfigMap != nil {","\t\t\t\t\tparamsRefs = append(paramsRefs, s.ConfigMap.Name)","\t\t\t\t}","\t\t\t\tif s.Secret != nil {","\t\t\t\t\tparamsRefs = append(paramsRefs, s.Secret.Name)","\t\t\t\t}","\t\t\t\tif s.ServiceAccountToken != nil {","\t\t\t\t\tparamsRefs = append(paramsRefs, s.ServiceAccountToken.Audience)","\t\t\t\t}","\t\t\t}","\t\t}","\t\tif v.CSI != nil {","\t\t\tif v.CSI.NodePublishSecretRef != nil {","\t\t\t\tparamsRefs = append(paramsRefs, v.CSI.NodePublishSecretRef.Name)","\t\t\t}","\t\t\tif v.CSI.VolumeAttributes != nil {","\t\t\t\tfor _, value := range v.CSI.VolumeAttributes {","\t\t\t\t\tparamsRefs = append(paramsRefs, value)","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn paramsRefs","}","","// extractParamRefsFromContainer get all array indexing references from container","func extractParamRefsFromContainer(c *corev1.Container) []string {","\tparamsRefs := []string{}","\tparamsRefs = append(paramsRefs, c.Name)","\tparamsRefs = append(paramsRefs, c.Image)","\tparamsRefs = append(paramsRefs, string(c.ImagePullPolicy))","\tparamsRefs = append(paramsRefs, c.Args...)","","\tfor ie, e := range c.Env {","\t\tparamsRefs = append(paramsRefs, e.Value)","\t\tif c.Env[ie].ValueFrom != nil {","\t\t\tif e.ValueFrom.SecretKeyRef != nil {","\t\t\t\tparamsRefs = append(paramsRefs, e.ValueFrom.SecretKeyRef.LocalObjectReference.Name)","\t\t\t\tparamsRefs = append(paramsRefs, e.ValueFrom.SecretKeyRef.Key)","\t\t\t}","\t\t\tif e.ValueFrom.ConfigMapKeyRef != nil {","\t\t\t\tparamsRefs = append(paramsRefs, e.ValueFrom.ConfigMapKeyRef.LocalObjectReference.Name)","\t\t\t\tparamsRefs = append(paramsRefs, e.ValueFrom.ConfigMapKeyRef.Key)","\t\t\t}","\t\t}","\t}","","\tfor _, e := range c.EnvFrom {","\t\tparamsRefs = append(paramsRefs, e.Prefix)","\t\tif e.ConfigMapRef != nil {","\t\t\tparamsRefs = append(paramsRefs, e.ConfigMapRef.LocalObjectReference.Name)","\t\t}","\t\tif e.SecretRef != nil {","\t\t\tparamsRefs = append(paramsRefs, e.SecretRef.LocalObjectReference.Name)","\t\t}","\t}","","\tparamsRefs = append(paramsRefs, c.WorkingDir)","\tparamsRefs = append(paramsRefs, c.Command...)","","\tfor _, v := range c.VolumeMounts {","\t\tparamsRefs = append(paramsRefs, v.Name)","\t\tparamsRefs = append(paramsRefs, v.MountPath)","\t\tparamsRefs = append(paramsRefs, v.SubPath)","\t}","\treturn paramsRefs","}","","// ParamType indicates the type of an input parameter;","// Used to distinguish between a single string and an array of strings.","type ParamType string","","// Valid ParamTypes:","const (","\tParamTypeString ParamType = \"string\"","\tParamTypeArray  ParamType = \"array\"","\tParamTypeObject ParamType = \"object\"",")","","// AllParamTypes can be used for ParamType validation.","var AllParamTypes = []ParamType{ParamTypeString, ParamTypeArray, ParamTypeObject}","","// ParamValues is modeled after IntOrString in kubernetes/apimachinery:","","// ParamValue is a type that can hold a single string, string array, or string map.","// Used in JSON unmarshalling so that a single JSON field can accept","// either an individual string or an array of strings.","type ParamValue struct {","\tType      ParamType // Represents the stored type of ParamValues.","\tStringVal string","\t// +listType=atomic","\tArrayVal  []string","\tObjectVal map[string]string","}","","// UnmarshalJSON implements the json.Unmarshaller interface.","func (paramValues *ParamValue) UnmarshalJSON(value []byte) error {","\t// ParamValues is used for Results Value as well, the results can be any kind of","\t// data so we need to check if it is empty.","\tif len(value) == 0 {","\t\tparamValues.Type = ParamTypeString","\t\treturn nil","\t}","\tif value[0] == '[' {","\t\t// We're trying to Unmarshal to []string, but for cases like []int or other types","\t\t// of nested array which we don't support yet, we should continue and Unmarshal","\t\t// it to String. If the Type being set doesn't match what it actually should be,","\t\t// it will be captured by validation in reconciler.","\t\t// if failed to unmarshal to array, we will convert the value to string and marshal it to string","\t\tvar a []string","\t\tif err := json.Unmarshal(value, \u0026a); err == nil {","\t\t\tparamValues.Type = ParamTypeArray","\t\t\tparamValues.ArrayVal = a","\t\t\treturn nil","\t\t}","\t}","\tif value[0] == '{' {","\t\t// if failed to unmarshal to map, we will convert the value to string and marshal it to string","\t\tvar m map[string]string","\t\tif err := json.Unmarshal(value, \u0026m); err == nil {","\t\t\tparamValues.Type = ParamTypeObject","\t\t\tparamValues.ObjectVal = m","\t\t\treturn nil","\t\t}","\t}","","\t// By default we unmarshal to string","\tparamValues.Type = ParamTypeString","\tif err := json.Unmarshal(value, \u0026paramValues.StringVal); err == nil {","\t\treturn nil","\t}","\tparamValues.StringVal = string(value)","","\treturn nil","}","","// MarshalJSON implements the json.Marshaller interface.","func (paramValues ParamValue) MarshalJSON() ([]byte, error) {","\tswitch paramValues.Type {","\tcase ParamTypeString:","\t\treturn json.Marshal(paramValues.StringVal)","\tcase ParamTypeArray:","\t\treturn json.Marshal(paramValues.ArrayVal)","\tcase ParamTypeObject:","\t\treturn json.Marshal(paramValues.ObjectVal)","\tdefault:","\t\treturn []byte{}, fmt.Errorf(\"impossible ParamValues.Type: %q\", paramValues.Type)","\t}","}","","// ApplyReplacements applyes replacements for ParamValues type","func (paramValues *ParamValue) ApplyReplacements(stringReplacements map[string]string, arrayReplacements map[string][]string, objectReplacements map[string]map[string]string) {","\tswitch paramValues.Type {","\tcase ParamTypeArray:","\t\tnewArrayVal := []string{}","\t\tfor _, v := range paramValues.ArrayVal {","\t\t\tnewArrayVal = append(newArrayVal, substitution.ApplyArrayReplacements(v, stringReplacements, arrayReplacements)...)","\t\t}","\t\tparamValues.ArrayVal = newArrayVal","\tcase ParamTypeObject:","\t\tnewObjectVal := map[string]string{}","\t\tfor k, v := range paramValues.ObjectVal {","\t\t\tnewObjectVal[k] = substitution.ApplyReplacements(v, stringReplacements)","\t\t}","\t\tparamValues.ObjectVal = newObjectVal","\tcase ParamTypeString:","\t\tfallthrough","\tdefault:","\t\tparamValues.applyOrCorrect(stringReplacements, arrayReplacements, objectReplacements)","\t}","}","","// applyOrCorrect deals with string param whose value can be string literal or a reference to a string/array/object param/result.","// If the value of paramValues is a reference to array or object, the type will be corrected from string to array/object.","func (paramValues *ParamValue) applyOrCorrect(stringReplacements map[string]string, arrayReplacements map[string][]string, objectReplacements map[string]map[string]string) {","\tstringVal := paramValues.StringVal","","\t// if the stringVal is a string literal or a string that mixed with var references","\t// just do the normal string replacement","\tif !exactVariableSubstitutionRegex.MatchString(stringVal) {","\t\tparamValues.StringVal = substitution.ApplyReplacements(paramValues.StringVal, stringReplacements)","\t\treturn","\t}","","\t// trim the head \"$(\" and the tail \")\" or \"[*])\"","\t// i.e. get \"params.name\" from \"$(params.name)\" or \"$(params.name[*])\"","\ttrimedStringVal := substitution.StripStarVarSubExpression(stringVal)","","\t// if the stringVal is a reference to a string param","\tif _, ok := stringReplacements[trimedStringVal]; ok {","\t\tparamValues.StringVal = substitution.ApplyReplacements(paramValues.StringVal, stringReplacements)","\t}","","\t// if the stringVal is a reference to an array param, we need to change the type other than apply replacement","\tif _, ok := arrayReplacements[trimedStringVal]; ok {","\t\tparamValues.StringVal = \"\"","\t\tparamValues.ArrayVal = substitution.ApplyArrayReplacements(stringVal, stringReplacements, arrayReplacements)","\t\tparamValues.Type = ParamTypeArray","\t}","","\t// if the stringVal is a reference an object param, we need to change the type other than apply replacement","\tif _, ok := objectReplacements[trimedStringVal]; ok {","\t\tparamValues.StringVal = \"\"","\t\tparamValues.ObjectVal = objectReplacements[trimedStringVal]","\t\tparamValues.Type = ParamTypeObject","\t}","}","","// NewStructuredValues creates an ParamValues of type ParamTypeString or ParamTypeArray, based on","// how many inputs are given (\u003e1 input will create an array, not string).","func NewStructuredValues(value string, values ...string) *ParamValue {","\tif len(values) \u003e 0 {","\t\treturn \u0026ParamValue{","\t\t\tType:     ParamTypeArray,","\t\t\tArrayVal: append([]string{value}, values...),","\t\t}","\t}","\treturn \u0026ParamValue{","\t\tType:      ParamTypeString,","\t\tStringVal: value,","\t}","}","","// NewObject creates an ParamValues of type ParamTypeObject using the provided key-value pairs","func NewObject(pairs map[string]string) *ParamValue {","\treturn \u0026ParamValue{","\t\tType:      ParamTypeObject,","\t\tObjectVal: pairs,","\t}","}","","// ArrayReference returns the name of the parameter from array parameter reference","// returns arrayParam from $(params.arrayParam[*])","func ArrayReference(a string) string {","\treturn strings.TrimSuffix(strings.TrimPrefix(a, \"$(\"+ParamsPrefix+\".\"), \"[*])\")","}","","// validatePipelineParametersVariablesInTaskParameters validates param value that","// may contain the reference(s) to other params to make sure those references are used appropriately.","func validatePipelineParametersVariablesInTaskParameters(params Params, prefix string, paramNames sets.String, arrayParamNames sets.String, objectParamNameKeys map[string][]string) (errs *apis.FieldError) {","\terrs = errs.Also(params.validateDuplicateParameters()).ViaField(\"params\")","\tfor _, param := range params {","\t\tswitch param.Value.Type {","\t\tcase ParamTypeArray:","\t\t\tfor idx, arrayElement := range param.Value.ArrayVal {","\t\t\t\terrs = errs.Also(validateArrayVariable(arrayElement, prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaFieldIndex(\"value\", idx).ViaFieldKey(\"params\", param.Name))","\t\t\t}","\t\tcase ParamTypeObject:","\t\t\tfor key, val := range param.Value.ObjectVal {","\t\t\t\terrs = errs.Also(validateStringVariable(val, prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaFieldKey(\"properties\", key).ViaFieldKey(\"params\", param.Name))","\t\t\t}","\t\tcase ParamTypeString:","\t\t\tfallthrough","\t\tdefault:","\t\t\terrs = errs.Also(validateParamStringValue(param, prefix, paramNames, arrayParamNames, objectParamNameKeys))","\t\t}","\t}","\treturn errs","}","","// validateParamStringValue validates the param value field of string type","// that may contain references to other isolated array/object params other than string param.","func validateParamStringValue(param Param, prefix string, paramNames sets.String, arrayVars sets.String, objectParamNameKeys map[string][]string) (errs *apis.FieldError) {","\tstringValue := param.Value.StringVal","","\t// if the provided param value is an isolated reference to the whole array/object, we just check if the param name exists.","\tisIsolated, errs := substitution.ValidateWholeArrayOrObjectRefInStringVariable(param.Name, stringValue, prefix, paramNames)","\tif isIsolated {","\t\treturn errs","\t}","","\t// if the provided param value is string literal and/or contains multiple variables","\t// valid example: \"$(params.myString) and another $(params.myObject.key1)\"","\t// invalid example: \"$(params.myString) and another $(params.myObject[*])\"","\treturn validateStringVariable(stringValue, prefix, paramNames, arrayVars, objectParamNameKeys).ViaFieldKey(\"params\", param.Name)","}","","// validateStringVariable validates the normal string fields that can only accept references to string param or individual keys of object param","func validateStringVariable(value, prefix string, stringVars sets.String, arrayVars sets.String, objectParamNameKeys map[string][]string) *apis.FieldError {","\terrs := substitution.ValidateNoReferencesToUnknownVariables(value, prefix, stringVars)","\terrs = errs.Also(validateObjectVariable(value, prefix, objectParamNameKeys))","\treturn errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(value, prefix, arrayVars))","}","","func validateArrayVariable(value, prefix string, stringVars sets.String, arrayVars sets.String, objectParamNameKeys map[string][]string) *apis.FieldError {","\terrs := substitution.ValidateNoReferencesToUnknownVariables(value, prefix, stringVars)","\terrs = errs.Also(validateObjectVariable(value, prefix, objectParamNameKeys))","\treturn errs.Also(substitution.ValidateVariableReferenceIsIsolated(value, prefix, arrayVars))","}","","func validateObjectVariable(value, prefix string, objectParamNameKeys map[string][]string) (errs *apis.FieldError) {","\tobjectNames := sets.NewString()","\tfor objectParamName, keys := range objectParamNameKeys {","\t\tobjectNames.Insert(objectParamName)","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(value, fmt.Sprintf(\"%s\\\\.%s\", prefix, objectParamName), sets.NewString(keys...)))","\t}","","\treturn errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(value, prefix, objectNames))","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,1,1,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,0,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,2,2,2,2,2,2,1,1,0,0,0,0,2,0,0,0,2,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,2,0,2,0]},{"id":26,"path":"pkg/apis/pipeline/v1/pipeline_conversion.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","\t\"fmt\"","","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Convertible = (*Pipeline)(nil)","","// ConvertTo implements apis.Convertible","func (p *Pipeline) ConvertTo(ctx context.Context, sink apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\treturn fmt.Errorf(\"v1 is the highest known version, got: %T\", sink)","}","","// ConvertFrom implements apis.Convertible","func (p *Pipeline) ConvertFrom(ctx context.Context, source apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\treturn fmt.Errorf(\"v1 is the highest known version, got: %T\", source)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,2,0,0,0,2,2,1,1,2,0]},{"id":27,"path":"pkg/apis/pipeline/v1/pipeline_defaults.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Defaultable = (*Pipeline)(nil)","","// SetDefaults sets default values on the Pipeline's Spec","func (p *Pipeline) SetDefaults(ctx context.Context) {","\tp.Spec.SetDefaults(ctx)","}","","// SetDefaults sets default values for the PipelineSpec's Params, Tasks, and Finally","func (ps *PipelineSpec) SetDefaults(ctx context.Context) {","\tfor i := range ps.Params {","\t\tps.Params[i].SetDefaults(ctx)","\t}","","\tfor _, pt := range ps.Tasks {","\t\tpt.SetDefaults(ctx)","\t}","","\tfor _, ft := range ps.Finally {","\t\tctx := ctx // Ensure local scoping per Task","\t\tft.SetDefaults(ctx)","\t}","}","","// SetDefaults sets default values for a PipelineTask","func (pt *PipelineTask) SetDefaults(ctx context.Context) {","\tcfg := config.FromContextOrDefaults(ctx)","\tif pt.TaskRef != nil {","\t\tif pt.TaskRef.Name == \"\" \u0026\u0026 pt.TaskRef.Resolver == \"\" {","\t\t\tpt.TaskRef.Resolver = ResolverName(cfg.Defaults.DefaultResolverType)","\t\t}","\t\tif pt.TaskRef.Kind == \"\" \u0026\u0026 pt.TaskRef.Resolver == \"\" {","\t\t\tpt.TaskRef.Kind = NamespacedTaskKind","\t\t}","\t}","\tif pt.TaskSpec != nil {","\t\tpt.TaskSpec.SetDefaults(ctx)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,2,2,2,2,0,2,2,2,0,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,0]},{"id":28,"path":"pkg/apis/pipeline/v1/pipeline_types.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/internal/checksum\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/pipeline/dag\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"knative.dev/pkg/kmeta\"",")","","// PipelineTaskOnErrorType defines a list of supported failure handling behaviors of a PipelineTask on error","type PipelineTaskOnErrorType string","","const (","\t// PipelineTasksAggregateStatus is a param representing aggregate status of all dag pipelineTasks","\tPipelineTasksAggregateStatus = \"tasks.status\"","\t// PipelineTasks is a value representing a task is a member of \"tasks\" section of the pipeline","\tPipelineTasks = \"tasks\"","\t// PipelineFinallyTasks is a value representing a task is a member of \"finally\" section of the pipeline","\tPipelineFinallyTasks = \"finally\"","\t// PipelineTaskStopAndFail indicates to stop and fail the PipelineRun if the PipelineTask fails","\tPipelineTaskStopAndFail PipelineTaskOnErrorType = \"stopAndFail\"","\t// PipelineTaskContinue indicates to continue executing the rest of the DAG when the PipelineTask fails","\tPipelineTaskContinue PipelineTaskOnErrorType = \"continue\"",")","","// +genclient","// +genclient:noStatus","// +genreconciler:krshapedlogic=false","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// Pipeline describes a list of Tasks to execute. It expresses how outputs","// of tasks feed into inputs of subsequent tasks.","// +k8s:openapi-gen=true","// +kubebuilder:storageversion","type Pipeline struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ObjectMeta `json:\"metadata,omitempty\"`","","\t// Spec holds the desired state of the Pipeline from the client","\t// +optional","\tSpec PipelineSpec `json:\"spec\"`","}","","var _ kmeta.OwnerRefable = (*Pipeline)(nil)","","// PipelineMetadata returns the Pipeline's ObjectMeta, implementing PipelineObject","func (p *Pipeline) PipelineMetadata() metav1.ObjectMeta {","\treturn p.ObjectMeta","}","","// PipelineSpec returns the Pipeline's Spec, implementing PipelineObject","func (p *Pipeline) PipelineSpec() PipelineSpec {","\treturn p.Spec","}","","// GetGroupVersionKind implements kmeta.OwnerRefable.","func (*Pipeline) GetGroupVersionKind() schema.GroupVersionKind {","\treturn SchemeGroupVersion.WithKind(pipeline.PipelineControllerName)","}","","// Checksum computes the sha256 checksum of the pipeline object.","// Prior to computing the checksum, it performs some preprocessing on the","// metadata of the object where it removes system provided annotations.","// Only the name, namespace, generateName, user-provided labels and annotations","// and the pipelineSpec are included for the checksum computation.","func (p *Pipeline) Checksum() ([]byte, error) {","\tobjectMeta := checksum.PrepareObjectMeta(p)","\tpreprocessedPipeline := Pipeline{","\t\tTypeMeta: metav1.TypeMeta{","\t\t\tAPIVersion: \"tekton.dev/v1\",","\t\t\tKind:       \"Pipeline\"},","\t\tObjectMeta: objectMeta,","\t\tSpec:       p.Spec,","\t}","\tsha256Checksum, err := checksum.ComputeSha256Checksum(preprocessedPipeline)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn sha256Checksum, nil","}","","// PipelineSpec defines the desired state of Pipeline.","type PipelineSpec struct {","\t// DisplayName is a user-facing name of the pipeline that may be","\t// used to populate a UI.","\t// +optional","\tDisplayName string `json:\"displayName,omitempty\"`","\t// Description is a user-facing description of the pipeline that may be","\t// used to populate a UI.","\t// +optional","\tDescription string `json:\"description,omitempty\"`","\t// Tasks declares the graph of Tasks that execute when this Pipeline is run.","\t// +listType=atomic","\tTasks []PipelineTask `json:\"tasks,omitempty\"`","\t// Params declares a list of input parameters that must be supplied when","\t// this Pipeline is run.","\tParams ParamSpecs `json:\"params,omitempty\"`","\t// Workspaces declares a set of named workspaces that are expected to be","\t// provided by a PipelineRun.","\t// +optional","\t// +listType=atomic","\tWorkspaces []PipelineWorkspaceDeclaration `json:\"workspaces,omitempty\"`","\t// Results are values that this pipeline can output once run","\t// +optional","\t// +listType=atomic","\tResults []PipelineResult `json:\"results,omitempty\"`","\t// Finally declares the list of Tasks that execute just before leaving the Pipeline","\t// i.e. either after all Tasks are finished executing successfully","\t// or after a failure which would result in ending the Pipeline","\t// +listType=atomic","\tFinally []PipelineTask `json:\"finally,omitempty\"`","}","","// PipelineResult used to describe the results of a pipeline","type PipelineResult struct {","\t// Name the given name","\tName string `json:\"name\"`","","\t// Type is the user-specified type of the result.","\t// The possible types are 'string', 'array', and 'object', with 'string' as the default.","\t// 'array' and 'object' types are alpha features.","\tType ResultsType `json:\"type,omitempty\"`","","\t// Description is a human-readable description of the result","\t// +optional","\tDescription string `json:\"description\"`","","\t// Value the expression used to retrieve the value","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tValue ResultValue `json:\"value\"`","}","","// PipelineTaskMetadata contains the labels or annotations for an EmbeddedTask","type PipelineTaskMetadata struct {","\t// +optional","\tLabels map[string]string `json:\"labels,omitempty\"`","","\t// +optional","\tAnnotations map[string]string `json:\"annotations,omitempty\"`","}","","// EmbeddedTask is used to define a Task inline within a Pipeline's PipelineTasks.","type EmbeddedTask struct {","\t// +optional","\truntime.TypeMeta `json:\",inline,omitempty\"`","","\t// Spec is a specification of a custom task","\t// +optional","\tSpec runtime.RawExtension `json:\"spec,omitempty\"`","","\t// +optional","\tMetadata PipelineTaskMetadata `json:\"metadata,omitempty\"`","","\t// TaskSpec is a specification of a task","\t// +optional","\tTaskSpec `json:\",inline,omitempty\"`","}","","// PipelineTask defines a task in a Pipeline, passing inputs from both","// Params and from the output of previous tasks.","type PipelineTask struct {","\t// Name is the name of this task within the context of a Pipeline. Name is","\t// used as a coordinate with the `from` and `runAfter` fields to establish","\t// the execution order of tasks relative to one another.","\tName string `json:\"name,omitempty\"`","","\t// DisplayName is the display name of this task within the context of a Pipeline.","\t// This display name may be used to populate a UI.","\t// +optional","\tDisplayName string `json:\"displayName,omitempty\"`","","\t// Description is the description of this task within the context of a Pipeline.","\t// This description may be used to populate a UI.","\t// +optional","\tDescription string `json:\"description,omitempty\"`","","\t// TaskRef is a reference to a task definition.","\t// +optional","\tTaskRef *TaskRef `json:\"taskRef,omitempty\"`","","\t// TaskSpec is a specification of a task","\t// Specifying TaskSpec can be disabled by setting","\t// `disable-inline-spec` feature flag.","\t// See Task.spec (API version: tekton.dev/v1)","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tTaskSpec *EmbeddedTask `json:\"taskSpec,omitempty\"`","","\t// When is a list of when expressions that need to be true for the task to run","\t// +optional","\tWhen WhenExpressions `json:\"when,omitempty\"`","","\t// Retries represents how many times this task should be retried in case of task failure: ConditionSucceeded set to False","\t// +optional","\tRetries int `json:\"retries,omitempty\"`","","\t// RunAfter is the list of PipelineTask names that should be executed before","\t// this Task executes. (Used to force a specific ordering in graph execution.)","\t// +optional","\t// +listType=atomic","\tRunAfter []string `json:\"runAfter,omitempty\"`","","\t// Parameters declares parameters passed to this task.","\t// +optional","\tParams Params `json:\"params,omitempty\"`","","\t// Matrix declares parameters used to fan out this task.","\t// +optional","\tMatrix *Matrix `json:\"matrix,omitempty\"`","","\t// Workspaces maps workspaces from the pipeline spec to the workspaces","\t// declared in the Task.","\t// +optional","\t// +listType=atomic","\tWorkspaces []WorkspacePipelineTaskBinding `json:\"workspaces,omitempty\"`","","\t// Duration after which the TaskRun times out. Defaults to 1 hour.","\t// Refer Go's ParseDuration documentation for expected format: https://golang.org/pkg/time/#ParseDuration","\t// +optional","\tTimeout *metav1.Duration `json:\"timeout,omitempty\"`","","\t// PipelineRef is a reference to a pipeline definition","\t// Note: PipelineRef is in preview mode and not yet supported","\t// +optional","\tPipelineRef *PipelineRef `json:\"pipelineRef,omitempty\"`","","\t// PipelineSpec is a specification of a pipeline","\t// Note: PipelineSpec is in preview mode and not yet supported","\t// Specifying PipelineSpec can be disabled by setting","\t// `disable-inline-spec` feature flag.","\t// See Pipeline.spec (API version: tekton.dev/v1)","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tPipelineSpec *PipelineSpec `json:\"pipelineSpec,omitempty\"`","","\t// OnError defines the exiting behavior of a PipelineRun on error","\t// can be set to [ continue | stopAndFail ]","\t// +optional","\tOnError PipelineTaskOnErrorType `json:\"onError,omitempty\"`","}","","// IsCustomTask checks whether an embedded TaskSpec is a Custom Task","func (et *EmbeddedTask) IsCustomTask() bool {","\t// Note that if `apiVersion` is set to `\"tekton.dev/v1beta1\"` and `kind` is set to `\"Task\"`,","\t// the reference will be considered a Custom Task - https://github.com/tektoncd/pipeline/issues/6457","\treturn et != nil \u0026\u0026 et.APIVersion != \"\" \u0026\u0026 et.Kind != \"\"","}","","// IsMatrixed return whether pipeline task is matrixed","func (pt *PipelineTask) IsMatrixed() bool {","\treturn pt.Matrix.HasParams() || pt.Matrix.HasInclude()","}","","// TaskSpecMetadata returns the metadata of the PipelineTask's EmbeddedTask spec.","func (pt *PipelineTask) TaskSpecMetadata() PipelineTaskMetadata {","\treturn pt.TaskSpec.Metadata","}","","// HashKey is the name of the PipelineTask, and is used as the key for this PipelineTask in the DAG","func (pt PipelineTask) HashKey() string {","\treturn pt.Name","}","","// Deps returns all other PipelineTask dependencies of this PipelineTask, based on resource usage or ordering","func (pt PipelineTask) Deps() []string {","\t// hold the list of dependencies in a set to avoid duplicates","\tdeps := sets.NewString()","","\t// add any new dependents from result references - resource dependency","\tfor _, ref := range PipelineTaskResultRefs(\u0026pt) {","\t\tdeps.Insert(ref.PipelineTask)","\t}","","\t// add any new dependents from runAfter - order dependency","\tfor _, runAfter := range pt.RunAfter {","\t\tdeps.Insert(runAfter)","\t}","","\treturn deps.List()","}","","// PipelineTaskList is a list of PipelineTasks","type PipelineTaskList []PipelineTask","","// Deps returns a map with key as name of a pipelineTask and value as a list of its dependencies","func (l PipelineTaskList) Deps() map[string][]string {","\tdeps := map[string][]string{}","\tfor _, pt := range l {","\t\t// get the list of deps for this pipelineTask","\t\td := pt.Deps()","\t\t// add the pipelineTask into the map if it has any deps","\t\tif len(d) \u003e 0 {","\t\t\tdeps[pt.HashKey()] = d","\t\t}","\t}","\treturn deps","}","","// Items returns a slice of all tasks in the PipelineTaskList, converted to dag.Tasks","func (l PipelineTaskList) Items() []dag.Task {","\ttasks := []dag.Task{}","\tfor _, t := range l {","\t\ttasks = append(tasks, dag.Task(t))","\t}","\treturn tasks","}","","// Names returns a set of pipeline task names from the given list of pipeline tasks","func (l PipelineTaskList) Names() sets.String {","\tnames := sets.String{}","\tfor _, pt := range l {","\t\tnames.Insert(pt.Name)","\t}","\treturn names","}","","// PipelineTaskParam is used to provide arbitrary string parameters to a Task.","type PipelineTaskParam struct {","\tName  string `json:\"name\"`","\tValue string `json:\"value\"`","}","","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// PipelineList contains a list of Pipeline","type PipelineList struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ListMeta `json:\"metadata,omitempty\"`","\tItems           []Pipeline `json:\"items\"`","}","","// GetVarSubstitutionExpressions extracts all the value between \"$(\" and \")\"\" for a PipelineResult","func (result PipelineResult) GetVarSubstitutionExpressions() ([]string, bool) {","\tallExpressions := validateString(result.Value.StringVal)","\tfor _, v := range result.Value.ArrayVal {","\t\tallExpressions = append(allExpressions, validateString(v)...)","\t}","\tfor _, v := range result.Value.ObjectVal {","\t\tallExpressions = append(allExpressions, validateString(v)...)","\t}","\treturn allExpressions, len(allExpressions) != 0","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,2,2,2,0,0,1,1,1,0,0,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,0,2,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0]},{"id":29,"path":"pkg/apis/pipeline/v1/pipeline_validation.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","\t\"fmt\"","\t\"slices\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/internal/artifactref\"","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/validate\"","\t\"github.com/tektoncd/pipeline/pkg/internal/resultref\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/pipeline/dag\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\tadmissionregistrationv1 \"k8s.io/api/admissionregistration/v1\"","\t\"k8s.io/apimachinery/pkg/api/equality\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"k8s.io/apimachinery/pkg/util/validation\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/webhook/resourcesemantics\"",")","","var (","\t_ apis.Validatable              = (*Pipeline)(nil)","\t_ resourcesemantics.VerbLimited = (*Pipeline)(nil)",")","","const (","\ttaskRef      = \"taskRef\"","\ttaskSpec     = \"taskSpec\"","\tpipelineRef  = \"pipelineRef\"","\tpipelineSpec = \"pipelineSpec\"",")","","// SupportedVerbs returns the operations that validation should be called for","func (p *Pipeline) SupportedVerbs() []admissionregistrationv1.OperationType {","\treturn []admissionregistrationv1.OperationType{admissionregistrationv1.Create, admissionregistrationv1.Update}","}","","// Validate checks that the Pipeline structure is valid but does not validate","// that any references resources exist, that is done at run time.","func (p *Pipeline) Validate(ctx context.Context) *apis.FieldError {","\terrs := validate.ObjectMetadata(p.GetObjectMeta()).ViaField(\"metadata\")","\terrs = errs.Also(p.Spec.Validate(apis.WithinSpec(ctx)).ViaField(\"spec\"))","\t// When a Pipeline is created directly, instead of declared inline in a PipelineRun,","\t// we do not support propagated parameters and workspaces.","\t// Validate that all params and workspaces it uses are declared.","\terrs = errs.Also(p.Spec.validatePipelineParameterUsage(ctx).ViaField(\"spec\"))","\terrs = errs.Also(p.Spec.validatePipelineWorkspacesUsage().ViaField(\"spec\"))","\treturn errs","}","","// Validate checks that taskNames in the Pipeline are valid and that the graph","// of Tasks expressed in the Pipeline makes sense.","func (ps *PipelineSpec) Validate(ctx context.Context) (errs *apis.FieldError) {","\terrs = errs.Also(ps.ValidateBetaFields(ctx))","\tif equality.Semantic.DeepEqual(ps, \u0026PipelineSpec{}) {","\t\terrs = errs.Also(apis.ErrGeneric(\"expected at least one, got none\", \"description\", \"params\", \"resources\", \"tasks\", \"workspaces\"))","\t}","\t// PipelineTask must have a valid unique label and at least one of taskRef or taskSpec should be specified","\terrs = errs.Also(ValidatePipelineTasks(ctx, ps.Tasks, ps.Finally))","\t// Validate the pipeline task graph","\terrs = errs.Also(validateGraph(ps.Tasks))","\t// The parameter variables should be valid","\terrs = errs.Also(ValidatePipelineParameterVariables(ctx, ps.Tasks, ps.Params).ViaField(\"tasks\"))","\terrs = errs.Also(ValidatePipelineParameterVariables(ctx, ps.Finally, ps.Params).ViaField(\"finally\"))","\terrs = errs.Also(validatePipelineContextVariables(ps.Tasks).ViaField(\"tasks\"))","\terrs = errs.Also(validatePipelineContextVariables(ps.Finally).ViaField(\"finally\"))","\terrs = errs.Also(validateExecutionStatusVariables(ps.Tasks, ps.Finally))","\t// Validate the pipeline's workspaces.","\terrs = errs.Also(validatePipelineWorkspacesDeclarations(ps.Workspaces))","\t// Validate the pipeline's results","\terrs = errs.Also(validatePipelineResults(ps.Results, ps.Tasks, ps.Finally))","\terrs = errs.Also(validateTasksAndFinallySection(ps))","\terrs = errs.Also(validateFinalTasks(ps.Tasks, ps.Finally))","\terrs = errs.Also(validateWhenExpressions(ctx, ps.Tasks, ps.Finally))","\terrs = errs.Also(validateArtifactReference(ctx, ps.Tasks, ps.Finally))","\terrs = errs.Also(validateMatrix(ctx, ps.Tasks).ViaField(\"tasks\"))","\terrs = errs.Also(validateMatrix(ctx, ps.Finally).ViaField(\"finally\"))","\treturn errs","}","","// ValidateBetaFields returns an error if the Pipeline spec uses beta features but does not","// have \"enable-api-fields\" set to \"alpha\" or \"beta\".","func (ps *PipelineSpec) ValidateBetaFields(ctx context.Context) *apis.FieldError {","\tvar errs *apis.FieldError","\tfor i, pt := range ps.Tasks {","\t\terrs = errs.Also(pt.validateBetaFields(ctx).ViaFieldIndex(\"tasks\", i))","\t}","\tfor i, pt := range ps.Finally {","\t\terrs = errs.Also(pt.validateBetaFields(ctx).ViaFieldIndex(\"tasks\", i))","\t}","","\treturn errs","}","","// validateBetaFields returns an error if the PipelineTask uses beta features but does not","// have \"enable-api-fields\" set to \"alpha\" or \"beta\".","func (pt *PipelineTask) validateBetaFields(ctx context.Context) *apis.FieldError {","\tvar errs *apis.FieldError","\tif pt.TaskRef != nil {","\t\t// Resolvers","\t\tif pt.TaskRef.Resolver != \"\" {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"taskref.resolver\", config.BetaAPIFields))","\t\t}","\t\tif len(pt.TaskRef.Params) \u003e 0 {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"taskref.params\", config.BetaAPIFields))","\t\t}","\t}","\treturn errs","}","","// ValidatePipelineTasks ensures that pipeline tasks has unique label, pipeline tasks has specified one of","// taskRef or taskSpec, and in case of a pipeline task with taskRef, it has a reference to a valid task (task name)","func ValidatePipelineTasks(ctx context.Context, tasks []PipelineTask, finalTasks []PipelineTask) *apis.FieldError {","\ttaskNames := sets.NewString()","\tvar errs *apis.FieldError","\terrs = errs.Also(PipelineTaskList(tasks).Validate(ctx, taskNames, \"tasks\"))","\terrs = errs.Also(PipelineTaskList(finalTasks).Validate(ctx, taskNames, \"finally\"))","\treturn errs","}","","// Validate a list of pipeline tasks including custom task","func (l PipelineTaskList) Validate(ctx context.Context, taskNames sets.String, path string) (errs *apis.FieldError) {","\tfor i, t := range l {","\t\t// validate pipeline task name","\t\terrs = errs.Also(t.ValidateName().ViaFieldIndex(path, i))","\t\t// names cannot be duplicated - checking that pipelineTask names are unique","\t\tif _, ok := taskNames[t.Name]; ok {","\t\t\terrs = errs.Also(apis.ErrMultipleOneOf(\"name\").ViaFieldIndex(path, i))","\t\t}","\t\ttaskNames.Insert(t.Name)","\t\t// validate custom task, dag, or final task","\t\terrs = errs.Also(t.Validate(ctx).ViaFieldIndex(path, i))","\t}","\treturn errs","}","","// validateUsageOfDeclaredPipelineTaskParameters validates that all parameters referenced in the pipeline Task are declared by the pipeline Task.","func (l PipelineTaskList) validateUsageOfDeclaredPipelineTaskParameters(ctx context.Context, additionalParams []ParamSpec, path string) (errs *apis.FieldError) {","\tfor i, t := range l {","\t\tif t.TaskSpec != nil {","\t\t\terrs = errs.Also(ValidateUsageOfDeclaredParameters(ctx, t.TaskSpec.Steps, append(t.TaskSpec.Params, additionalParams...)).ViaFieldIndex(path, i))","\t\t}","\t}","\treturn errs","}","","// ValidateName checks whether the PipelineTask's name is a valid DNS label","func (pt PipelineTask) ValidateName() *apis.FieldError {","\tif err := validation.IsDNS1123Label(pt.Name); len(err) \u003e 0 {","\t\treturn \u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(\"invalid value %q\", pt.Name),","\t\t\tPaths:   []string{\"name\"},","\t\t\tDetails: \"Pipeline Task name must be a valid DNS Label.\" +","\t\t\t\t\"For more info refer to https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names\",","\t\t}","\t}","\treturn nil","}","","// Validate classifies whether a task is a custom task or a regular task(dag/final)","// calls the validation routine based on the type of the task","func (pt PipelineTask) Validate(ctx context.Context) (errs *apis.FieldError) {","\terrs = errs.Also(pt.validateRefOrSpec(ctx))","","\terrs = errs.Also(pt.validateEnabledInlineSpec(ctx))","","\terrs = errs.Also(pt.validateEmbeddedOrType())","\t// taskKinds contains the kinds when the apiVersion is not set, they are not custom tasks,","\t// if apiVersion is set they are custom tasks.","\ttaskKinds := map[TaskKind]bool{","\t\t\"\":                 true,","\t\tNamespacedTaskKind: true,","\t}","","\terrs = errs.Also(pt.ValidateOnError(ctx))","","\t// Pipeline task having taskRef/taskSpec with APIVersion is classified as custom task","\tswitch {","\tcase pt.TaskRef != nil \u0026\u0026 !taskKinds[pt.TaskRef.Kind]:","\t\terrs = errs.Also(pt.validateCustomTask())","\tcase pt.TaskRef != nil \u0026\u0026 pt.TaskRef.APIVersion != \"\":","\t\terrs = errs.Also(pt.validateCustomTask())","\tcase pt.TaskSpec != nil \u0026\u0026 !taskKinds[TaskKind(pt.TaskSpec.Kind)]:","\t\terrs = errs.Also(pt.validateCustomTask())","\tcase pt.TaskSpec != nil \u0026\u0026 pt.TaskSpec.APIVersion != \"\":","\t\terrs = errs.Also(pt.validateCustomTask())","\tdefault:","\t\terrs = errs.Also(pt.validateTask(ctx))","\t}","\treturn errs","}","","// ValidateOnError validates the OnError field of a PipelineTask","func (pt PipelineTask) ValidateOnError(ctx context.Context) (errs *apis.FieldError) {","\tif pt.OnError != \"\" \u0026\u0026 !isParamRefs(string(pt.OnError)) {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"OnError\", config.BetaAPIFields))","\t\tif pt.OnError != PipelineTaskContinue \u0026\u0026 pt.OnError != PipelineTaskStopAndFail {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(pt.OnError, \"OnError\", \"PipelineTask OnError must be either \\\"continue\\\" or \\\"stopAndFail\\\"\"))","\t\t}","\t\tif pt.OnError == PipelineTaskContinue \u0026\u0026 pt.Retries \u003e 0 {","\t\t\terrs = errs.Also(apis.ErrGeneric(\"PipelineTask OnError cannot be set to \\\"continue\\\" when Retries is greater than 0\"))","\t\t}","\t}","\treturn errs","}","","func (pt *PipelineTask) validateMatrix(ctx context.Context) (errs *apis.FieldError) {","\tif pt.IsMatrixed() {","\t\t// This is a beta feature and will fail validation if it's used in a pipeline spec","\t\t// when the enable-api-fields feature gate is set to \"stable\".","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"matrix\", config.BetaAPIFields))","\t\terrs = errs.Also(pt.Matrix.validateCombinationsCount(ctx))","\t\terrs = errs.Also(pt.Matrix.validateUniqueParams())","\t}","\terrs = errs.Also(pt.Matrix.validateParameterInOneOfMatrixOrParams(pt.Params))","\treturn errs","}","","func (pt PipelineTask) validateEmbeddedOrType() (errs *apis.FieldError) {","\t// Reject cases where APIVersion and/or Kind are specified alongside an embedded Task.","\t// We determine if this is an embedded Task by checking of TaskSpec.TaskSpec.Steps has items.","\tif pt.TaskSpec != nil \u0026\u0026 len(pt.TaskSpec.TaskSpec.Steps) \u003e 0 {","\t\tif pt.TaskSpec.APIVersion != \"\" {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"taskSpec.apiVersion cannot be specified when using taskSpec.steps\",","\t\t\t\tPaths:   []string{\"taskSpec.apiVersion\"},","\t\t\t})","\t\t}","\t\tif pt.TaskSpec.Kind != \"\" {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"taskSpec.kind cannot be specified when using taskSpec.steps\",","\t\t\t\tPaths:   []string{\"taskSpec.kind\"},","\t\t\t})","\t\t}","\t}","\treturn","}","","func (pt *PipelineTask) validateWorkspaces(workspaceNames sets.String) (errs *apis.FieldError) {","\tworkspaceBindingNames := sets.NewString()","\tfor i, ws := range pt.Workspaces {","\t\tif workspaceBindingNames.Has(ws.Name) {","\t\t\terrs = errs.Also(apis.ErrGeneric(","\t\t\t\tfmt.Sprintf(\"workspace name %q must be unique\", ws.Name), \"\").ViaFieldIndex(\"workspaces\", i))","\t\t}","","\t\tif ws.Workspace == \"\" {","\t\t\tif !workspaceNames.Has(ws.Name) {","\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(","\t\t\t\t\tfmt.Sprintf(\"pipeline task %q expects workspace with name %q but none exists in pipeline spec\", pt.Name, ws.Name),","\t\t\t\t\t\"\",","\t\t\t\t).ViaFieldIndex(\"workspaces\", i))","\t\t\t}","\t\t} else if !workspaceNames.Has(ws.Workspace) {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(","\t\t\t\tfmt.Sprintf(\"pipeline task %q expects workspace with name %q but none exists in pipeline spec\", pt.Name, ws.Workspace),","\t\t\t\t\"\",","\t\t\t).ViaFieldIndex(\"workspaces\", i))","\t\t}","","\t\tworkspaceBindingNames.Insert(ws.Name)","\t}","\treturn errs","}","","// validateEnabledInlineSpec validates that pipelineSpec or taskSpec is allowed by checking","// disable-inline-spec field","func (pt PipelineTask) validateEnabledInlineSpec(ctx context.Context) (errs *apis.FieldError) {","\tif pt.TaskSpec != nil {","\t\tif slices.Contains(strings.Split(","\t\t\tconfig.FromContextOrDefaults(ctx).FeatureFlags.DisableInlineSpec, \",\"), \"pipeline\") {","\t\t\terrs = errs.Also(apis.ErrDisallowedFields(\"taskSpec\"))","\t\t}","\t}","\tif pt.PipelineSpec != nil {","\t\tif slices.Contains(strings.Split(","\t\t\tconfig.FromContextOrDefaults(ctx).FeatureFlags.DisableInlineSpec, \",\"), \"pipeline\") {","\t\t\terrs = errs.Also(apis.ErrDisallowedFields(\"pipelineSpec\"))","\t\t}","\t}","\treturn errs","}","","// validateRefOrSpec validates at least one of taskRef or taskSpec or pipelineRef or pipelineSpec is specified","func (pt PipelineTask) validateRefOrSpec(ctx context.Context) (errs *apis.FieldError) {","\t// collect all the specified specifications","\tnonNilFields := []string{}","\tif pt.TaskRef != nil {","\t\tnonNilFields = append(nonNilFields, taskRef)","\t}","\tif pt.TaskSpec != nil {","\t\tnonNilFields = append(nonNilFields, taskSpec)","\t}","\tif pt.PipelineRef != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, pipelineRef, config.AlphaAPIFields))","\t\tnonNilFields = append(nonNilFields, pipelineRef)","\t}","\tif pt.PipelineSpec != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, pipelineSpec, config.AlphaAPIFields))","\t\tnonNilFields = append(nonNilFields, pipelineSpec)","\t}","","\t// check the length of nonNilFields","\t// if one of taskRef or taskSpec or pipelineRef or pipelineSpec is specified,","\t// the length of nonNilFields should exactly be 1","\tif len(nonNilFields) \u003e 1 {","\t\terrs = errs.Also(apis.ErrGeneric(\"expected exactly one, got multiple\", nonNilFields...))","\t} else if len(nonNilFields) == 0 {","\t\tcfg := config.FromContextOrDefaults(ctx)","\t\t// check for TaskRef or TaskSpec or PipelineRef or PipelineSpec with alpha feature flag","\t\tif cfg.FeatureFlags.EnableAPIFields == config.AlphaAPIFields {","\t\t\terrs = errs.Also(apis.ErrMissingOneOf(taskRef, taskSpec, pipelineRef, pipelineSpec))","\t\t} else {","\t\t\t// check for taskRef and taskSpec with beta/stable feature flag","\t\t\terrs = errs.Also(apis.ErrMissingOneOf(taskRef, taskSpec))","\t\t}","\t}","\treturn errs","}","","// isValidAPIVersion validates the format of an apiVersion string.","// Valid formats are \"group/version\" where both group and version are non-empty.","// For custom tasks, apiVersion must always be in the \"group/version\" format.","func isValidAPIVersion(apiVersion string) bool {","\tparts := strings.Split(apiVersion, \"/\")","\tif len(parts) != 2 {","\t\treturn false","\t}","\tgroup := parts[0]","\tversion := parts[1]","\treturn group != \"\" \u0026\u0026 version != \"\"","}","","// validateCustomTask validates custom task specifications - checking kind and fail if not yet supported features specified","func (pt PipelineTask) validateCustomTask() (errs *apis.FieldError) {","\tif pt.TaskRef != nil \u0026\u0026 pt.TaskRef.Kind == \"\" {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"custom task ref must specify kind\", \"taskRef.kind\"))","\t}","\tif pt.TaskSpec != nil \u0026\u0026 pt.TaskSpec.Kind == \"\" {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"custom task spec must specify kind\", \"taskSpec.kind\"))","\t}","\t// Validate apiVersion format for custom tasks","\tif pt.TaskRef != nil \u0026\u0026 pt.TaskRef.APIVersion != \"\" {","\t\tif !isValidAPIVersion(pt.TaskRef.APIVersion) {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"invalid apiVersion format %q, must be in the format \\\"group/version\\\"\", pt.TaskRef.APIVersion), \"taskRef.apiVersion\"))","\t\t}","\t} else if pt.TaskRef != nil {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"custom task ref must specify apiVersion\", \"taskRef.apiVersion\"))","\t}","\tif pt.TaskSpec != nil \u0026\u0026 pt.TaskSpec.APIVersion != \"\" {","\t\tif !isValidAPIVersion(pt.TaskSpec.APIVersion) {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"invalid apiVersion format %q, must be in the format \\\"group/version\\\"\", pt.TaskSpec.APIVersion), \"taskSpec.apiVersion\"))","\t\t}","\t} else if pt.TaskSpec != nil {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"custom task spec must specify apiVersion\", \"taskSpec.apiVersion\"))","\t}","\treturn errs","}","","// validateTask validates a pipeline task or a final task for taskRef and taskSpec","func (pt PipelineTask) validateTask(ctx context.Context) (errs *apis.FieldError) {","\t// Validate TaskSpec if it's present","\tif pt.TaskSpec != nil {","\t\terrs = errs.Also(pt.TaskSpec.Validate(ctx).ViaField(taskSpec))","\t}","\tif pt.TaskRef != nil {","\t\terrs = errs.Also(pt.TaskRef.Validate(ctx).ViaField(taskRef))","\t}","\tif pt.PipelineRef != nil {","\t\terrs = errs.Also(pt.PipelineRef.Validate(ctx).ViaField(pipelineRef))","\t}","\tif pt.PipelineSpec != nil {","\t\terrs = errs.Also(pt.PipelineSpec.Validate(ctx).ViaField(pipelineSpec))","\t}","\treturn errs","}","","// validatePipelineWorkspacesDeclarations validates the specified workspaces, ensuring having unique name without any","// empty string,","func validatePipelineWorkspacesDeclarations(wss []PipelineWorkspaceDeclaration) (errs *apis.FieldError) {","\t// Workspace names must be non-empty and unique.","\twsTable := sets.NewString()","\tfor i, ws := range wss {","\t\tif ws.Name == \"\" {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"workspace %d has empty name\", i),","\t\t\t\t\"\").ViaFieldIndex(\"workspaces\", i))","\t\t}","\t\tif wsTable.Has(ws.Name) {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"workspace with name %q appears more than once\", ws.Name),","\t\t\t\t\"\").ViaFieldIndex(\"workspaces\", i))","\t\t}","\t\twsTable.Insert(ws.Name)","\t}","\treturn errs","}","","// validatePipelineParameterUsage validates that parameters referenced in the Pipeline are declared by the Pipeline","func (ps *PipelineSpec) validatePipelineParameterUsage(ctx context.Context) (errs *apis.FieldError) {","\terrs = errs.Also(PipelineTaskList(ps.Tasks).validateUsageOfDeclaredPipelineTaskParameters(ctx, ps.Params, \"tasks\"))","\terrs = errs.Also(PipelineTaskList(ps.Finally).validateUsageOfDeclaredPipelineTaskParameters(ctx, ps.Params, \"finally\"))","\terrs = errs.Also(validatePipelineTaskParameterUsage(ps.Tasks, ps.Params).ViaField(\"tasks\"))","\terrs = errs.Also(validatePipelineTaskParameterUsage(ps.Finally, ps.Params).ViaField(\"finally\"))","\treturn errs","}","","// validatePipelineTaskParameterUsage validates that parameters referenced in the Pipeline Tasks are declared by the Pipeline","func validatePipelineTaskParameterUsage(tasks []PipelineTask, params ParamSpecs) (errs *apis.FieldError) {","\tallParamNames := sets.NewString(params.GetNames()...)","\t_, arrayParams, objectParams := params.SortByType()","\tarrayParamNames := sets.NewString(arrayParams.GetNames()...)","\tobjectParameterNameKeys := map[string][]string{}","\tfor _, p := range objectParams {","\t\tfor k := range p.Properties {","\t\t\tobjectParameterNameKeys[p.Name] = append(objectParameterNameKeys[p.Name], k)","\t\t}","\t}","\terrs = errs.Also(validatePipelineParametersVariables(tasks, \"params\", allParamNames, arrayParamNames, objectParameterNameKeys))","\tfor i, task := range tasks {","\t\terrs = errs.Also(task.Params.validateDuplicateParameters().ViaField(\"params\").ViaIndex(i))","\t}","\treturn errs","}","","// validatePipelineWorkspacesUsage validates that workspaces referenced in the Pipeline are declared by the Pipeline","func (ps *PipelineSpec) validatePipelineWorkspacesUsage() (errs *apis.FieldError) {","\terrs = errs.Also(validatePipelineTasksWorkspacesUsage(ps.Workspaces, ps.Tasks).ViaField(\"tasks\"))","\terrs = errs.Also(validatePipelineTasksWorkspacesUsage(ps.Workspaces, ps.Finally).ViaField(\"finally\"))","\treturn errs","}","","// validatePipelineTasksWorkspacesUsage validates that all the referenced workspaces (by pipeline tasks) are specified in","// the pipeline","func validatePipelineTasksWorkspacesUsage(wss []PipelineWorkspaceDeclaration, pts []PipelineTask) (errs *apis.FieldError) {","\tworkspaceNames := sets.NewString()","\tfor _, ws := range wss {","\t\tworkspaceNames.Insert(ws.Name)","\t}","\t// Any workspaces used in PipelineTasks should have their name declared in the Pipeline's Workspaces list.","\tfor i, pt := range pts {","\t\terrs = errs.Also(pt.validateWorkspaces(workspaceNames).ViaIndex(i))","\t}","\treturn errs","}","","// ValidatePipelineParameterVariables validates parameters with those specified by each pipeline task,","// (1) it validates the type of parameter is either string or array (2) parameter default value matches","// with the type of that param (3) no duplication, feature flag and allowed param type when using param enum","func ValidatePipelineParameterVariables(ctx context.Context, tasks []PipelineTask, params ParamSpecs) (errs *apis.FieldError) {","\t// validates all the types within a slice of ParamSpecs","\terrs = errs.Also(ValidateParameterTypes(ctx, params).ViaField(\"params\"))","\terrs = errs.Also(params.ValidateNoDuplicateNames())","\terrs = errs.Also(params.validateParamEnums(ctx).ViaField(\"params\"))","\tfor i, task := range tasks {","\t\terrs = errs.Also(task.Params.validateDuplicateParameters().ViaField(\"params\").ViaIndex(i))","\t}","\treturn errs","}","","func validatePipelineParametersVariables(tasks []PipelineTask, prefix string, paramNames sets.String, arrayParamNames sets.String, objectParamNameKeys map[string][]string) (errs *apis.FieldError) {","\tfor idx, task := range tasks {","\t\terrs = errs.Also(validatePipelineParametersVariablesInTaskParameters(task.Params, prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaIndex(idx))","\t\tif task.IsMatrixed() {","\t\t\terrs = errs.Also(task.Matrix.validatePipelineParametersVariablesInMatrixParameters(prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaIndex(idx))","\t\t}","\t\terrs = errs.Also(task.When.validatePipelineParametersVariables(prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaIndex(idx))","\t}","\treturn errs","}","","func validatePipelineContextVariables(tasks []PipelineTask) *apis.FieldError {","\tpipelineRunContextNames := sets.NewString().Insert(","\t\t\"name\",","\t\t\"namespace\",","\t\t\"uid\",","\t)","\tpipelineContextNames := sets.NewString().Insert(","\t\t\"name\",","\t)","\tpipelineTaskContextNames := sets.NewString().Insert(","\t\t\"retries\",","\t)","\tvar paramValues []string","\tfor _, task := range tasks {","\t\tparamValues = task.extractAllParams().extractValues()","\t}","\terrs := validatePipelineContextVariablesInParamValues(paramValues, \"context\\\\.pipelineRun\", pipelineRunContextNames).","\t\tAlso(validatePipelineContextVariablesInParamValues(paramValues, \"context\\\\.pipeline\", pipelineContextNames)).","\t\tAlso(validatePipelineContextVariablesInParamValues(paramValues, \"context\\\\.pipelineTask\", pipelineTaskContextNames))","\treturn errs","}","","// extractAllParams extracts all the parameters in a PipelineTask:","// - pt.Params","// - pt.Matrix.Params","// - pt.Matrix.Include.Params","func (pt *PipelineTask) extractAllParams() Params {","\tallParams := pt.Params","\tif pt.Matrix.HasParams() {","\t\tallParams = append(allParams, pt.Matrix.Params...)","\t}","\tif pt.Matrix.HasInclude() {","\t\tfor _, include := range pt.Matrix.Include {","\t\t\tallParams = append(allParams, include.Params...)","\t\t}","\t}","\treturn allParams","}","","// GetVarSubstitutionExpressions extract all values between the parameters \"$(\" and \")\" of steps and sidecars","func (pt *PipelineTask) GetVarSubstitutionExpressions() []string {","\tvar allExpressions []string","\tif pt.TaskSpec != nil {","\t\tfor _, step := range pt.TaskSpec.Steps {","\t\t\tstepExpressions := step.GetVarSubstitutionExpressions()","\t\t\tallExpressions = append(allExpressions, stepExpressions...)","\t\t}","\t\tfor _, sidecar := range pt.TaskSpec.Sidecars {","\t\t\tsidecarExpressions := sidecar.GetVarSubstitutionExpressions()","\t\t\tallExpressions = append(allExpressions, sidecarExpressions...)","\t\t}","\t}","\treturn allExpressions","}","","// containsExecutionStatusRef checks if a specified param has a reference to execution status or reason","// $(tasks.\u003ctask-name\u003e.status), $(tasks.status), or $(tasks.\u003ctask-name\u003e.reason)","func containsExecutionStatusRef(p string) bool {","\tif strings.HasPrefix(p, \"tasks.\") {","\t\tif strings.HasSuffix(p, \".status\") || strings.HasSuffix(p, \".reason\") {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","func validateExecutionStatusVariables(tasks []PipelineTask, finallyTasks []PipelineTask) (errs *apis.FieldError) {","\terrs = errs.Also(validateExecutionStatusVariablesInTasks(tasks).ViaField(\"tasks\"))","\terrs = errs.Also(validateExecutionStatusVariablesInFinally(PipelineTaskList(tasks).Names(), finallyTasks).ViaField(\"finally\"))","\treturn errs","}","","// validate dag pipeline tasks, task params can not access execution status of any other task","// dag tasks cannot have param value as $(tasks.pipelineTask.status)","func validateExecutionStatusVariablesInTasks(tasks []PipelineTask) (errs *apis.FieldError) {","\tfor idx, t := range tasks {","\t\terrs = errs.Also(t.validateExecutionStatusVariablesDisallowed().ViaIndex(idx))","\t}","\treturn errs","}","","// validate finally tasks accessing execution status of a dag task specified in the pipeline","// $(tasks.pipelineTask.status) is invalid if pipelineTask is not defined as a dag task","func validateExecutionStatusVariablesInFinally(tasksNames sets.String, finally []PipelineTask) (errs *apis.FieldError) {","\tfor idx, t := range finally {","\t\terrs = errs.Also(t.validateExecutionStatusVariablesAllowed(tasksNames).ViaIndex(idx))","\t}","\treturn errs","}","","func (pt *PipelineTask) validateExecutionStatusVariablesDisallowed() (errs *apis.FieldError) {","\tfor _, param := range pt.Params {","\t\tif expressions, ok := param.GetVarSubstitutionExpressions(); ok {","\t\t\terrs = errs.Also(validateContainsExecutionStatusVariablesDisallowed(expressions, \"value\").","\t\t\t\tViaFieldKey(\"params\", param.Name))","\t\t}","\t}","\tfor i, we := range pt.When {","\t\tif expressions, ok := we.GetVarSubstitutionExpressions(); ok {","\t\t\terrs = errs.Also(validateContainsExecutionStatusVariablesDisallowed(expressions, \"\").","\t\t\t\tViaFieldIndex(\"when\", i))","\t\t}","\t}","\treturn errs","}","","func (pt *PipelineTask) validateExecutionStatusVariablesAllowed(ptNames sets.String) (errs *apis.FieldError) {","\tfor _, param := range pt.Params {","\t\tif expressions, ok := param.GetVarSubstitutionExpressions(); ok {","\t\t\terrs = errs.Also(validateExecutionStatusVariablesExpressions(expressions, ptNames, \"value\").","\t\t\t\tViaFieldKey(\"params\", param.Name))","\t\t}","\t}","\tfor i, we := range pt.When {","\t\tif expressions, ok := we.GetVarSubstitutionExpressions(); ok {","\t\t\terrs = errs.Also(validateExecutionStatusVariablesExpressions(expressions, ptNames, \"\").","\t\t\t\tViaFieldIndex(\"when\", i))","\t\t}","\t}","\treturn errs","}","","func validateContainsExecutionStatusVariablesDisallowed(expressions []string, path string) (errs *apis.FieldError) {","\tif containsExecutionStatusReferences(expressions) {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"pipeline tasks can not refer to execution status\"+","\t\t\t\" of any other pipeline task or aggregate status of tasks\", path))","\t}","\treturn errs","}","","func containsExecutionStatusReferences(expressions []string) bool {","\t// validate tasks.pipelineTask.status/tasks.status if this expression is not a result reference","\tif !LooksLikeContainsResultRefs(expressions) {","\t\tfor _, e := range expressions {","\t\t\t// check if it contains context variable accessing execution status - $(tasks.taskname.status)","\t\t\t// or an aggregate status - $(tasks.status) or reason - $(tasks.taskname.reason)","\t\t\tif containsExecutionStatusRef(e) {","\t\t\t\treturn true","\t\t\t}","\t\t}","\t}","\treturn false","}","","func validateExecutionStatusVariablesExpressions(expressions []string, ptNames sets.String, fieldPath string) (errs *apis.FieldError) {","\t// validate tasks.pipelineTask.status if this expression is not a result reference","\tif !LooksLikeContainsResultRefs(expressions) {","\t\tfor _, expression := range expressions {","\t\t\t// its a reference to aggregate status of dag tasks - $(tasks.status)","\t\t\tif expression == PipelineTasksAggregateStatus {","\t\t\t\tcontinue","\t\t\t}","\t\t\t// check if it contains context variable accessing execution status - $(tasks.taskname.status) | $(tasks.taskname.reason)","\t\t\tif containsExecutionStatusRef(expression) {","\t\t\t\tvar pt string","\t\t\t\tif strings.HasSuffix(expression, \".status\") {","\t\t\t\t\t// strip tasks. and .status from tasks.taskname.status to further verify task name","\t\t\t\t\tpt = strings.TrimSuffix(strings.TrimPrefix(expression, \"tasks.\"), \".status\")","\t\t\t\t}","\t\t\t\tif strings.HasSuffix(expression, \".reason\") {","\t\t\t\t\t// strip tasks. and .reason from tasks.taskname.reason to further verify task name","\t\t\t\t\tpt = strings.TrimSuffix(strings.TrimPrefix(expression, \"tasks.\"), \".reason\")","\t\t\t\t}","\t\t\t\t// report an error if the task name does not exist in the list of dag tasks","\t\t\t\tif !ptNames.Has(pt) {","\t\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"pipeline task %s is not defined in the pipeline\", pt), fieldPath))","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\treturn errs","}","","func validatePipelineContextVariablesInParamValues(paramValues []string, prefix string, contextNames sets.String) (errs *apis.FieldError) {","\tfor _, paramValue := range paramValues {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(paramValue, prefix, contextNames).ViaField(\"value\"))","\t}","\treturn errs","}","","func filter(arr []string, cond func(string) bool) []string {","\tresult := []string{}","\tfor i := range arr {","\t\tif cond(arr[i]) {","\t\t\tresult = append(result, arr[i])","\t\t}","\t}","\treturn result","}","","// validatePipelineResults ensure that pipeline result variables are properly configured","func validatePipelineResults(results []PipelineResult, tasks []PipelineTask, finally []PipelineTask) (errs *apis.FieldError) {","\tpipelineTaskNames := getPipelineTasksNames(tasks)","\tpipelineFinallyTaskNames := getPipelineTasksNames(finally)","\tfor idx, result := range results {","\t\texpressions, ok := result.GetVarSubstitutionExpressions()","\t\tif !ok {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(\"expected pipeline results to be task result expressions but no expressions were found\",","\t\t\t\t\"value\").ViaFieldIndex(\"results\", idx))","\t\t}","","\t\tif !LooksLikeContainsResultRefs(expressions) {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(\"expected pipeline results to be task result expressions but an invalid expressions was found\",","\t\t\t\t\"value\").ViaFieldIndex(\"results\", idx))","\t\t}","","\t\texpressions = filter(expressions, resultref.LooksLikeResultRef)","\t\tresultRefs := NewResultRefs(expressions)","\t\tif len(expressions) != len(resultRefs) {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"expected all of the expressions %v to be result expressions but only %v were\", expressions, resultRefs),","\t\t\t\t\"value\").ViaFieldIndex(\"results\", idx))","\t\t}","","\t\tif !taskContainsResult(result.Value.StringVal, pipelineTaskNames, pipelineFinallyTaskNames) {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(\"referencing a nonexistent task\",","\t\t\t\t\"value\").ViaFieldIndex(\"results\", idx))","\t\t}","\t}","","\treturn errs","}","","// put task names in a set","func getPipelineTasksNames(pipelineTasks []PipelineTask) sets.String {","\tpipelineTaskNames := make(sets.String)","\tfor _, pipelineTask := range pipelineTasks {","\t\tpipelineTaskNames.Insert(pipelineTask.Name)","\t}","","\treturn pipelineTaskNames","}","","// taskContainsResult ensures the result value is referenced within the","// task names","func taskContainsResult(resultExpression string, pipelineTaskNames sets.String, pipelineFinallyTaskNames sets.String) bool {","\t// split incase of multiple resultExpressions in the same result.Value string","\t// i.e \"$(task.\u003ctask-name).result.\u003cresult-name\u003e) - $(task2.\u003ctask2-name).result2.\u003cresult2-name\u003e)\"","\tsplit := strings.Split(resultExpression, \"$\")","\tfor _, expression := range split {","\t\tif expression != \"\" {","\t\t\tvalue := stripVarSubExpression(\"$\" + expression)","\t\t\tpr, err := resultref.ParseTaskExpression(value)","\t\t\tif err != nil {","\t\t\t\treturn false","\t\t\t}","","\t\t\tif strings.HasPrefix(value, \"tasks\") \u0026\u0026 !pipelineTaskNames.Has(pr.ResourceName) {","\t\t\t\treturn false","\t\t\t}","\t\t\tif strings.HasPrefix(value, \"finally\") \u0026\u0026 !pipelineFinallyTaskNames.Has(pr.ResourceName) {","\t\t\t\treturn false","\t\t\t}","\t\t}","\t}","\treturn true","}","","func validateTasksAndFinallySection(ps *PipelineSpec) *apis.FieldError {","\tif len(ps.Finally) != 0 \u0026\u0026 len(ps.Tasks) == 0 {","\t\treturn apis.ErrInvalidValue(fmt.Sprintf(\"spec.tasks is empty but spec.finally has %d tasks\", len(ps.Finally)), \"finally\")","\t}","\treturn nil","}","","func validateFinalTasks(tasks []PipelineTask, finalTasks []PipelineTask) (errs *apis.FieldError) {","\tfor idx, f := range finalTasks {","\t\tif len(f.RunAfter) != 0 {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"no runAfter allowed under spec.finally, final task %s has runAfter specified\", f.Name), \"\").ViaFieldIndex(\"finally\", idx))","\t\t}","\t}","","\tts := PipelineTaskList(tasks).Names()","\tfts := PipelineTaskList(finalTasks).Names()","","\terrs = errs.Also(validateTaskResultReferenceInFinallyTasks(finalTasks, ts, fts))","","\treturn errs","}","","func validateTaskResultReferenceInFinallyTasks(finalTasks []PipelineTask, ts sets.String, fts sets.String) (errs *apis.FieldError) {","\tfor idx, t := range finalTasks {","\t\tfor _, p := range t.Params {","\t\t\tif expressions, ok := p.GetVarSubstitutionExpressions(); ok {","\t\t\t\terrs = errs.Also(validateResultsVariablesExpressionsInFinally(expressions, ts, fts, \"value\").ViaFieldKey(","\t\t\t\t\t\"params\", p.Name).ViaFieldIndex(\"finally\", idx))","\t\t\t}","\t\t}","\t\tfor i, we := range t.When {","\t\t\tif expressions, ok := we.GetVarSubstitutionExpressions(); ok {","\t\t\t\terrs = errs.Also(validateResultsVariablesExpressionsInFinally(expressions, ts, fts, \"\").ViaFieldIndex(","\t\t\t\t\t\"when\", i).ViaFieldIndex(\"finally\", idx))","\t\t\t}","\t\t}","\t}","\treturn errs","}","","func validateResultsVariablesExpressionsInFinally(expressions []string, pipelineTasksNames sets.String, finalTasksNames sets.String, fieldPath string) (errs *apis.FieldError) {","\tif LooksLikeContainsResultRefs(expressions) {","\t\tresultRefs := NewResultRefs(expressions)","\t\tfor _, resultRef := range resultRefs {","\t\t\tpt := resultRef.PipelineTask","\t\t\tif finalTasksNames.Has(pt) {","\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"invalid task result reference, \"+","\t\t\t\t\t\"final task has task result reference from a final task %s\", pt), fieldPath))","\t\t\t} else if !pipelineTasksNames.Has(resultRef.PipelineTask) {","\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"invalid task result reference, \"+","\t\t\t\t\t\"final task has task result reference from a task %s which is not defined in the pipeline\", pt), fieldPath))","\t\t\t}","\t\t}","\t}","\treturn errs","}","","func validateWhenExpressions(ctx context.Context, tasks []PipelineTask, finalTasks []PipelineTask) (errs *apis.FieldError) {","\tfor i, t := range tasks {","\t\terrs = errs.Also(t.When.validate(ctx).ViaFieldIndex(\"tasks\", i))","\t}","\tfor i, t := range finalTasks {","\t\terrs = errs.Also(t.When.validate(ctx).ViaFieldIndex(\"finally\", i))","\t}","\treturn errs","}","","// validateGraph ensures the Pipeline's dependency Graph (DAG) make sense: that there is no dependency","// cycle or that they rely on values from Tasks that ran previously.","func validateGraph(tasks []PipelineTask) (errs *apis.FieldError) {","\tif _, err := dag.Build(PipelineTaskList(tasks), PipelineTaskList(tasks).Deps()); err != nil {","\t\terrs = errs.Also(apis.ErrInvalidValue(err.Error(), \"tasks\"))","\t}","\treturn errs","}","","func validateMatrix(ctx context.Context, tasks []PipelineTask) (errs *apis.FieldError) {","\tfor idx, task := range tasks {","\t\terrs = errs.Also(task.validateMatrix(ctx).ViaIndex(idx))","\t}","\terrs = errs.Also(validateTaskResultsFromMatrixedPipelineTasksConsumed(tasks))","\treturn errs","}","","// findAndValidateResultRefsForMatrix checks that any result references to Matrixed PipelineTasks if consumed","// by another PipelineTask that the entire array of results produced by a matrix is consumed in aggregate","// since consuming a singular result produced by a matrix is currently not supported","func findAndValidateResultRefsForMatrix(tasks []PipelineTask, taskMapping map[string]PipelineTask) (resultRefs []*ResultRef, errs *apis.FieldError) {","\tfor _, t := range tasks {","\t\tfor _, p := range t.Params {","\t\t\tif expressions, ok := p.GetVarSubstitutionExpressions(); ok {","\t\t\t\tif LooksLikeContainsResultRefs(expressions) {","\t\t\t\t\tresultRefs, errs = validateMatrixedPipelineTaskConsumed(expressions, taskMapping)","\t\t\t\t\tif errs != nil {","\t\t\t\t\t\treturn nil, errs","\t\t\t\t\t}","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn resultRefs, errs","}","","// validateMatrixedPipelineTaskConsumed checks that any Matrixed Pipeline Task that the is being consumed is consumed in","// aggregate [*] since consuming a singular result produced by a matrix is currently not supported","func validateMatrixedPipelineTaskConsumed(expressions []string, taskMapping map[string]PipelineTask) (resultRefs []*ResultRef, errs *apis.FieldError) {","\tvar filteredExpressions []string","\tfor _, expression := range expressions {","\t\t// if it is not matrix result ref expression, skip","\t\tif !resultref.LooksLikeResultRef(expression) {","\t\t\tcontinue","\t\t}","\t\t// ie. \"tasks.\u003cpipelineTaskName\u003e.results.\u003cresultName\u003e[*]\"","\t\tsubExpressions := strings.Split(expression, \".\")","\t\tpipelineTask := subExpressions[1] // pipelineTaskName","\t\ttaskConsumed := taskMapping[pipelineTask]","\t\tif taskConsumed.IsMatrixed() {","\t\t\tif !strings.HasSuffix(expression, \"[*]\") {","\t\t\t\terrs = errs.Also(apis.ErrGeneric(\"A matrixed pipelineTask can only be consumed in aggregate using [*] notation, but is currently set to \" + expression))","\t\t\t}","\t\t\tfilteredExpressions = append(filteredExpressions, expression)","\t\t}","\t}","\treturn NewResultRefs(filteredExpressions), errs","}","","// validateTaskResultsFromMatrixedPipelineTasksConsumed checks that any Matrixed Pipeline Task that the is being consumed","// is consumed in aggregate [*] since consuming a singular result produced by a matrix is currently not supported.","// It also validates that a matrix emitting results can only emit results with the underlying type string","// if those results are being consumed by another PipelineTask.","func validateTaskResultsFromMatrixedPipelineTasksConsumed(tasks []PipelineTask) (errs *apis.FieldError) {","\ttaskMapping := createTaskMapping(tasks)","\tresultRefs, errs := findAndValidateResultRefsForMatrix(tasks, taskMapping)","\tif errs != nil {","\t\treturn errs","\t}","","\terrs = errs.Also(validateMatrixEmittingStringResults(resultRefs, taskMapping))","\treturn errs","}","","// createTaskMapping maps the PipelineTaskName to the PipelineTask to easily access","// the pipelineTask by Name","func createTaskMapping(tasks []PipelineTask) (taskMap map[string]PipelineTask) {","\ttaskMapping := make(map[string]PipelineTask)","\tfor _, task := range tasks {","\t\ttaskMapping[task.Name] = task","\t}","\treturn taskMapping","}","","// validateMatrixEmittingStringResults checks a matrix emitting results can only emit results with the underlying type string","// if those results are being consumed by another PipelineTask. Note: It is not possible to validate remote tasks","func validateMatrixEmittingStringResults(resultRefs []*ResultRef, taskMapping map[string]PipelineTask) (errs *apis.FieldError) {","\tfor _, resultRef := range resultRefs {","\t\ttask := taskMapping[resultRef.PipelineTask]","\t\tresultName := resultRef.Result","\t\tif task.TaskRef != nil {","\t\t\treferencedTask := taskMapping[task.TaskRef.Name]","\t\t\tif referencedTask.TaskSpec != nil {","\t\t\t\terrs = errs.Also(validateStringResults(referencedTask.TaskSpec.Results, resultName))","\t\t\t}","\t\t} else if task.TaskSpec != nil {","\t\t\terrs = errs.Also(validateStringResults(task.TaskSpec.Results, resultName))","\t\t}","\t}","\treturn errs","}","","// validateStringResults ensure that the result type is string","func validateStringResults(results []TaskResult, resultName string) (errs *apis.FieldError) {","\tfor _, result := range results {","\t\tif result.Name == resultName {","\t\t\tif result.Type != ResultsTypeString {","\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(","\t\t\t\t\tfmt.Sprintf(\"Matrixed PipelineTasks emitting results must have an underlying type string, but result %s has type %s in pipelineTask\", resultName, string(result.Type)),","\t\t\t\t\t\"\",","\t\t\t\t))","\t\t\t}","\t\t}","\t}","\treturn errs","}","","// validateArtifactReference ensure that the feature flag enableArtifacts is set to true when using artifacts","func validateArtifactReference(ctx context.Context, tasks []PipelineTask, finalTasks []PipelineTask) (errs *apis.FieldError) {","\tif config.FromContextOrDefaults(ctx).FeatureFlags.EnableArtifacts {","\t\treturn errs","\t}","\tfor i, t := range tasks {","\t\tfor _, v := range t.Params.extractValues() {","\t\t\tif len(artifactref.TaskArtifactRegex.FindAllStringSubmatch(v, -1)) \u003e 0 {","\t\t\t\treturn errs.Also(apis.ErrGeneric(fmt.Sprintf(\"feature flag %s should be set to true to use artifacts feature.\", config.EnableArtifacts), \"\").ViaField(\"params\").ViaFieldIndex(\"tasks\", i))","\t\t\t}","\t\t}","\t}","\tfor i, t := range finalTasks {","\t\tfor _, v := range t.Params.extractValues() {","\t\t\tif len(artifactref.TaskArtifactRegex.FindAllStringSubmatch(v, -1)) \u003e 0 {","\t\t\t\treturn errs.Also(apis.ErrGeneric(fmt.Sprintf(\"feature flag %s should be set to true to use artifacts feature.\", config.EnableArtifacts), \"\").ViaField(\"params\").ViaFieldIndex(\"finally\", i))","\t\t\t}","\t\t}","\t}","\treturn errs","}","","// GetIndexingReferencesToArrayParams returns all strings referencing indices of PipelineRun array parameters","// from parameters, workspaces, and when expressions defined in the Pipeline's Tasks and Finally Tasks.","// For example, if a Task in the Pipeline has a parameter with a value \"$(params.array-param-name[1])\",","// this would be one of the strings returned.","func (ps *PipelineSpec) GetIndexingReferencesToArrayParams() sets.String {","\tparamsRefs := []string{}","\tfor i := range ps.Tasks {","\t\tparamsRefs = append(paramsRefs, ps.Tasks[i].Params.extractValues()...)","\t\tif ps.Tasks[i].IsMatrixed() {","\t\t\tparamsRefs = append(paramsRefs, ps.Tasks[i].Matrix.Params.extractValues()...)","\t\t}","\t\tfor j := range ps.Tasks[i].Workspaces {","\t\t\tparamsRefs = append(paramsRefs, ps.Tasks[i].Workspaces[j].SubPath)","\t\t}","\t\tfor _, wes := range ps.Tasks[i].When {","\t\t\tparamsRefs = append(paramsRefs, wes.Input)","\t\t\tparamsRefs = append(paramsRefs, wes.Values...)","\t\t}","\t}","\tfor i := range ps.Finally {","\t\tparamsRefs = append(paramsRefs, ps.Finally[i].Params.extractValues()...)","\t\tif ps.Finally[i].IsMatrixed() {","\t\t\tparamsRefs = append(paramsRefs, ps.Finally[i].Matrix.Params.extractValues()...)","\t\t}","\t\tfor _, wes := range ps.Finally[i].When {","\t\t\tparamsRefs = append(paramsRefs, wes.Input)","\t\t\tparamsRefs = append(paramsRefs, wes.Values...)","\t\t}","\t}","\t// extract all array indexing references, for example []{\"$(params.array-params[1])\"}","\tarrayIndexParamRefs := []string{}","\tfor _, p := range paramsRefs {","\t\tarrayIndexParamRefs = append(arrayIndexParamRefs, extractArrayIndexingParamRefs(p)...)","\t}","\treturn sets.NewString(arrayIndexParamRefs...)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,2,0,0,0,0,2,2,2,2,2,2,0,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,0,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,0,2,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,0,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,0,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,0,0,0,0,2,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,0,0,2,0,0,0,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,0,2,0,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,0,0,2,2,2,2,2,2,0,2,2,0,0,0,0,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,0,2,0,0,0,0,0,0,2,2,2,2,2,1,1,2,2,2,2,2,2,2,0,2,2,2,1,1,2,2,2,2,0,0,2,2,2,2,2,0]},{"id":30,"path":"pkg/apis/pipeline/v1/pipelineref_validation.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","","\t\"knative.dev/pkg/apis\"",")","","// Validate ensures that a supplied PipelineRef field is populated","// correctly. No errors are returned for a nil PipelineRef.","func (ref *PipelineRef) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif ref == nil {","\t\treturn errs","\t}","\treturn validateRef(ctx, ref.Name, ref.Resolver, ref.Params)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0]},{"id":31,"path":"pkg/apis/pipeline/v1/pipelinerun_conversion.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","\t\"fmt\"","","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Convertible = (*PipelineRun)(nil)","","// ConvertTo implements apis.Convertible","func (pr *PipelineRun) ConvertTo(ctx context.Context, sink apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\treturn fmt.Errorf(\"v1 is the highest known version, got: %T\", sink)","}","","// ConvertFrom implements apis.Convertible","func (pr *PipelineRun) ConvertFrom(ctx context.Context, source apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\treturn fmt.Errorf(\"v1 is the highest known version, got: %T\", source)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,2,0,0,0,2,2,1,1,2,0]},{"id":32,"path":"pkg/apis/pipeline/v1/pipelinerun_defaults.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","\t\"regexp\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/pod\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/kmap\"",")","","var (","\t_                              apis.Defaultable = (*PipelineRun)(nil)","\tfilterReservedAnnotationRegexp                  = regexp.MustCompile(pipeline.TektonReservedAnnotationExpr)",")","","// SetDefaults implements apis.Defaultable","func (pr *PipelineRun) SetDefaults(ctx context.Context) {","\tpr.Spec.SetDefaults(ctx)","","\t// Silently filtering out Tekton Reserved annotations at creation","\tif apis.IsInCreate(ctx) {","\t\tpr.ObjectMeta.Annotations = kmap.Filter(pr.ObjectMeta.Annotations, func(s string) bool {","\t\t\treturn filterReservedAnnotationRegexp.MatchString(s)","\t\t})","\t}","}","","// SetDefaults implements apis.Defaultable","func (prs *PipelineRunSpec) SetDefaults(ctx context.Context) {","\tcfg := config.FromContextOrDefaults(ctx)","\tif prs.PipelineRef != nil \u0026\u0026 prs.PipelineRef.Name == \"\" \u0026\u0026 prs.PipelineRef.Resolver == \"\" {","\t\tprs.PipelineRef.Resolver = ResolverName(cfg.Defaults.DefaultResolverType)","\t}","","\tif prs.Timeouts == nil {","\t\tprs.Timeouts = \u0026TimeoutFields{}","\t}","","\tif prs.Timeouts.Pipeline == nil {","\t\tprs.Timeouts.Pipeline = \u0026metav1.Duration{Duration: time.Duration(cfg.Defaults.DefaultTimeoutMinutes) * time.Minute}","\t}","","\tdefaultSA := cfg.Defaults.DefaultServiceAccount","\tif prs.TaskRunTemplate.ServiceAccountName == \"\" \u0026\u0026 defaultSA != \"\" {","\t\tprs.TaskRunTemplate.ServiceAccountName = defaultSA","\t}","","\tdefaultPodTemplate := cfg.Defaults.DefaultPodTemplate","\tprs.TaskRunTemplate.PodTemplate = pod.MergePodTemplateWithDefault(prs.TaskRunTemplate.PodTemplate, defaultPodTemplate)","","\tif prs.PipelineSpec != nil {","\t\tprs.PipelineSpec.SetDefaults(ctx)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,0,2,2,2,0,2,2,2,0,2,2,2,2,0,2,2,2,2,2,2,0]},{"id":33,"path":"pkg/apis/pipeline/v1/pipelinerun_types.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","\t\"fmt\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tpipelineErrors \"github.com/tektoncd/pipeline/pkg/apis/pipeline/errors\"","\tpod \"github.com/tektoncd/pipeline/pkg/apis/pipeline/pod\"","\trunv1beta1 \"github.com/tektoncd/pipeline/pkg/apis/run/v1beta1\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"","\t\"k8s.io/apimachinery/pkg/types\"","\t\"k8s.io/utils/clock\"","\t\"knative.dev/pkg/apis\"","\tduckv1 \"knative.dev/pkg/apis/duck/v1\"",")","","// +genclient","// +genreconciler:krshapedlogic=false","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// PipelineRun represents a single execution of a Pipeline. PipelineRuns are how","// the graph of Tasks declared in a Pipeline are executed; they specify inputs","// to Pipelines such as parameter values and capture operational aspects of the","// Tasks execution such as service account and tolerations. Creating a","// PipelineRun creates TaskRuns for Tasks in the referenced Pipeline.","//","// +k8s:openapi-gen=true","// +kubebuilder:storageversion","type PipelineRun struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ObjectMeta `json:\"metadata,omitempty\"`","","\t// +optional","\tSpec PipelineRunSpec `json:\"spec,omitempty\"`","\t// +optional","\tStatus PipelineRunStatus `json:\"status,omitempty\"`","}","","// GetName Returns the name of the PipelineRun","func (pr *PipelineRun) GetName() string {","\treturn pr.ObjectMeta.GetName()","}","","// GetStatusCondition returns the task run status as a ConditionAccessor","func (pr *PipelineRun) GetStatusCondition() apis.ConditionAccessor {","\treturn \u0026pr.Status","}","","// GetGroupVersionKind implements kmeta.OwnerRefable.","func (*PipelineRun) GetGroupVersionKind() schema.GroupVersionKind {","\treturn SchemeGroupVersion.WithKind(pipeline.PipelineRunControllerName)","}","","// IsDone returns true if the PipelineRun's status indicates that it is done.","func (pr *PipelineRun) IsDone() bool {","\treturn !pr.Status.GetCondition(apis.ConditionSucceeded).IsUnknown()","}","","// HasStarted function check whether pipelinerun has valid start time set in its status","func (pr *PipelineRun) HasStarted() bool {","\treturn pr.Status.StartTime != nil \u0026\u0026 !pr.Status.StartTime.IsZero()","}","","// IsSuccessful returns true if the PipelineRun's status indicates that it has succeeded.","func (pr *PipelineRun) IsSuccessful() bool {","\treturn pr != nil \u0026\u0026 pr.Status.GetCondition(apis.ConditionSucceeded).IsTrue()","}","","// IsFailure returns true if the PipelineRun's status indicates that it has failed.","func (pr *PipelineRun) IsFailure() bool {","\treturn pr != nil \u0026\u0026 pr.Status.GetCondition(apis.ConditionSucceeded).IsFalse()","}","","// IsCancelled returns true if the PipelineRun's spec status is set to Cancelled state","func (pr *PipelineRun) IsCancelled() bool {","\treturn pr.Spec.Status == PipelineRunSpecStatusCancelled","}","","// IsGracefullyCancelled returns true if the PipelineRun's spec status is set to CancelledRunFinally state","func (pr *PipelineRun) IsGracefullyCancelled() bool {","\treturn pr.Spec.Status == PipelineRunSpecStatusCancelledRunFinally","}","","// IsGracefullyStopped returns true if the PipelineRun's spec status is set to StoppedRunFinally state","func (pr *PipelineRun) IsGracefullyStopped() bool {","\treturn pr.Spec.Status == PipelineRunSpecStatusStoppedRunFinally","}","","// PipelineTimeout returns the applicable timeout for the PipelineRun","func (pr *PipelineRun) PipelineTimeout(ctx context.Context) time.Duration {","\tif pr.Spec.Timeouts != nil \u0026\u0026 pr.Spec.Timeouts.Pipeline != nil {","\t\treturn pr.Spec.Timeouts.Pipeline.Duration","\t}","\treturn time.Duration(config.FromContextOrDefaults(ctx).Defaults.DefaultTimeoutMinutes) * time.Minute","}","","// TasksTimeout returns the tasks timeout for the PipelineRun, if set,","// or the tasks timeout computed from the Pipeline and Finally timeouts, if those are set.","func (pr *PipelineRun) TasksTimeout() *metav1.Duration {","\tt := pr.Spec.Timeouts","\tif t == nil {","\t\treturn nil","\t}","\tif t.Tasks != nil {","\t\treturn t.Tasks","\t}","\tif t.Pipeline != nil \u0026\u0026 t.Finally != nil {","\t\tif t.Pipeline.Duration == config.NoTimeoutDuration || t.Finally.Duration == config.NoTimeoutDuration {","\t\t\treturn nil","\t\t}","\t\treturn \u0026metav1.Duration{Duration: (t.Pipeline.Duration - t.Finally.Duration)}","\t}","\treturn nil","}","","// FinallyTimeout returns the finally timeout for the PipelineRun, if set,","// or the finally timeout computed from the Pipeline and Tasks timeouts, if those are set.","func (pr *PipelineRun) FinallyTimeout() *metav1.Duration {","\tt := pr.Spec.Timeouts","\tif t == nil {","\t\treturn nil","\t}","\tif t.Finally != nil {","\t\treturn t.Finally","\t}","\tif t.Pipeline != nil \u0026\u0026 t.Tasks != nil {","\t\tif t.Pipeline.Duration == config.NoTimeoutDuration || t.Tasks.Duration == config.NoTimeoutDuration {","\t\t\treturn nil","\t\t}","\t\treturn \u0026metav1.Duration{Duration: (t.Pipeline.Duration - t.Tasks.Duration)}","\t}","\treturn nil","}","","// IsPending returns true if the PipelineRun's spec status is set to Pending state","func (pr *PipelineRun) IsPending() bool {","\treturn pr.Spec.Status == PipelineRunSpecStatusPending","}","","// GetNamespacedName returns a k8s namespaced name that identifies this PipelineRun","func (pr *PipelineRun) GetNamespacedName() types.NamespacedName {","\treturn types.NamespacedName{Namespace: pr.Namespace, Name: pr.Name}","}","","// IsTimeoutConditionSet returns true when the pipelinerun has the pipelinerun timed out reason","func (pr *PipelineRun) IsTimeoutConditionSet() bool {","\tcondition := pr.Status.GetCondition(apis.ConditionSucceeded)","\treturn condition.IsFalse() \u0026\u0026 condition.Reason == PipelineRunReasonTimedOut.String()","}","","// SetTimeoutCondition sets the status of the PipelineRun to timed out.","func (pr *PipelineRun) SetTimeoutCondition(ctx context.Context) {","\tpr.Status.SetCondition(\u0026apis.Condition{","\t\tType:    apis.ConditionSucceeded,","\t\tStatus:  corev1.ConditionFalse,","\t\tReason:  PipelineRunReasonTimedOut.String(),","\t\tMessage: fmt.Sprintf(\"PipelineRun %q failed to finish within %q\", pr.Name, pr.PipelineTimeout(ctx).String()),","\t})","}","","// HasTimedOut returns true if a pipelinerun has exceeded its spec.Timeout based on its status.Timeout","func (pr *PipelineRun) HasTimedOut(ctx context.Context, c clock.PassiveClock) bool {","\ttimeout := pr.PipelineTimeout(ctx)","\tstartTime := pr.Status.StartTime","","\tif !startTime.IsZero() {","\t\tif timeout == config.NoTimeoutDuration {","\t\t\treturn false","\t\t}","\t\truntime := c.Since(startTime.Time)","\t\tif runtime \u003e timeout {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// HasTimedOutForALongTime returns true if a pipelinerun has exceeed its spec.Timeout based its status.StartTime","// by a large margin","func (pr *PipelineRun) HasTimedOutForALongTime(ctx context.Context, c clock.PassiveClock) bool {","\tif !pr.HasTimedOut(ctx, c) {","\t\treturn false","\t}","\ttimeout := pr.PipelineTimeout(ctx)","\tstartTime := pr.Status.StartTime","\truntime := c.Since(startTime.Time)","\t// We are arbitrarily defining large margin as doubling the spec.timeout","\treturn runtime \u003e= 2*timeout","}","","// HaveTasksTimedOut returns true if a pipelinerun has exceeded its spec.Timeouts.Tasks","func (pr *PipelineRun) HaveTasksTimedOut(ctx context.Context, c clock.PassiveClock) bool {","\ttimeout := pr.TasksTimeout()","\tstartTime := pr.Status.StartTime","","\tif !startTime.IsZero() \u0026\u0026 timeout != nil {","\t\tif timeout.Duration == config.NoTimeoutDuration {","\t\t\treturn false","\t\t}","\t\truntime := c.Since(startTime.Time)","\t\tif runtime \u003e timeout.Duration {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// HasFinallyTimedOut returns true if a pipelinerun has exceeded its spec.Timeouts.Finally, based on status.FinallyStartTime","func (pr *PipelineRun) HasFinallyTimedOut(ctx context.Context, c clock.PassiveClock) bool {","\ttimeout := pr.FinallyTimeout()","\tstartTime := pr.Status.FinallyStartTime","","\tif startTime != nil \u0026\u0026 !startTime.IsZero() \u0026\u0026 timeout != nil {","\t\tif timeout.Duration == config.NoTimeoutDuration {","\t\t\treturn false","\t\t}","\t\truntime := c.Since(startTime.Time)","\t\tif runtime \u003e timeout.Duration {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// HasVolumeClaimTemplate returns true if PipelineRun contains volumeClaimTemplates that is","// used for creating PersistentVolumeClaims with an OwnerReference for each run","func (pr *PipelineRun) HasVolumeClaimTemplate() bool {","\tfor _, ws := range pr.Spec.Workspaces {","\t\tif ws.VolumeClaimTemplate != nil {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// PipelineRunSpec defines the desired state of PipelineRun","type PipelineRunSpec struct {","\t// +optional","\tPipelineRef *PipelineRef `json:\"pipelineRef,omitempty\"`","\t// Specifying PipelineSpec can be disabled by setting","\t// `disable-inline-spec` feature flag.","\t// See Pipeline.spec (API version: tekton.dev/v1)","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tPipelineSpec *PipelineSpec `json:\"pipelineSpec,omitempty\"`","\t// Params is a list of parameter names and values.","\tParams Params `json:\"params,omitempty\"`","","\t// Used for cancelling a pipelinerun (and maybe more later on)","\t// +optional","\tStatus PipelineRunSpecStatus `json:\"status,omitempty\"`","\t// Time after which the Pipeline times out.","\t// Currently three keys are accepted in the map","\t// pipeline, tasks and finally","\t// with Timeouts.pipeline \u003e= Timeouts.tasks + Timeouts.finally","\t// +optional","\tTimeouts *TimeoutFields `json:\"timeouts,omitempty\"`","","\t// TaskRunTemplate represent template of taskrun","\t// +optional","\tTaskRunTemplate PipelineTaskRunTemplate `json:\"taskRunTemplate,omitempty\"`","","\t// Workspaces holds a set of workspace bindings that must match names","\t// with those declared in the pipeline.","\t// +optional","\t// +listType=atomic","\tWorkspaces []WorkspaceBinding `json:\"workspaces,omitempty\"`","\t// TaskRunSpecs holds a set of runtime specs","\t// +optional","\t// +listType=atomic","\tTaskRunSpecs []PipelineTaskRunSpec `json:\"taskRunSpecs,omitempty\"`","\t// ManagedBy indicates which controller is responsible for reconciling","\t// this resource. If unset or set to \"tekton.dev/pipeline\", the default","\t// Tekton controller will manage this resource.","\t// This field is immutable.","\t// +optional","\tManagedBy *string `json:\"managedBy,omitempty\"`","}","","// TimeoutFields allows granular specification of pipeline, task, and finally timeouts","type TimeoutFields struct {","\t// Pipeline sets the maximum allowed duration for execution of the entire pipeline. The sum of individual timeouts for tasks and finally must not exceed this value.","\tPipeline *metav1.Duration `json:\"pipeline,omitempty\"`","\t// Tasks sets the maximum allowed duration of this pipeline's tasks","\tTasks *metav1.Duration `json:\"tasks,omitempty\"`","\t// Finally sets the maximum allowed duration of this pipeline's finally","\tFinally *metav1.Duration `json:\"finally,omitempty\"`","}","","// PipelineRunSpecStatus defines the pipelinerun spec status the user can provide","type PipelineRunSpecStatus string","","const (","\t// PipelineRunSpecStatusCancelled indicates that the user wants to cancel the task,","\t// if not already cancelled or terminated","\tPipelineRunSpecStatusCancelled = \"Cancelled\"","","\t// PipelineRunSpecStatusCancelledRunFinally indicates that the user wants to cancel the pipeline run,","\t// if not already cancelled or terminated, but ensure finally is run normally","\tPipelineRunSpecStatusCancelledRunFinally = \"CancelledRunFinally\"","","\t// PipelineRunSpecStatusStoppedRunFinally indicates that the user wants to stop the pipeline run,","\t// wait for already running tasks to be completed and run finally","\t// if not already cancelled or terminated","\tPipelineRunSpecStatusStoppedRunFinally = \"StoppedRunFinally\"","","\t// PipelineRunSpecStatusPending indicates that the user wants to postpone starting a PipelineRun","\t// until some condition is met","\tPipelineRunSpecStatusPending = \"PipelineRunPending\"",")","","// PipelineRunStatus defines the observed state of PipelineRun","type PipelineRunStatus struct {","\tduckv1.Status `json:\",inline\"`","","\t// PipelineRunStatusFields inlines the status fields.","\tPipelineRunStatusFields `json:\",inline\"`","}","","// PipelineRunReason represents a reason for the pipeline run \"Succeeded\" condition","type PipelineRunReason string","","const (","\t// PipelineRunReasonStarted is the reason set when the PipelineRun has just started","\tPipelineRunReasonStarted PipelineRunReason = \"Started\"","\t// PipelineRunReasonRunning is the reason set when the PipelineRun is running","\tPipelineRunReasonRunning PipelineRunReason = \"Running\"","\t// PipelineRunReasonSuccessful is the reason set when the PipelineRun completed successfully","\tPipelineRunReasonSuccessful PipelineRunReason = \"Succeeded\"","\t// PipelineRunReasonCompleted is the reason set when the PipelineRun completed successfully with one or more skipped Tasks","\tPipelineRunReasonCompleted PipelineRunReason = \"Completed\"","\t// PipelineRunReasonFailed is the reason set when the PipelineRun completed with a failure","\tPipelineRunReasonFailed PipelineRunReason = \"Failed\"","\t// PipelineRunReasonCancelled is the reason set when the PipelineRun cancelled by the user","\t// This reason may be found with a corev1.ConditionFalse status, if the cancellation was processed successfully","\t// This reason may be found with a corev1.ConditionUnknown status, if the cancellation is being processed or failed","\tPipelineRunReasonCancelled PipelineRunReason = \"Cancelled\"","\t// PipelineRunReasonPending is the reason set when the PipelineRun is in the pending state","\tPipelineRunReasonPending PipelineRunReason = \"PipelineRunPending\"","\t// PipelineRunReasonTimedOut is the reason set when the PipelineRun has timed out","\tPipelineRunReasonTimedOut PipelineRunReason = \"PipelineRunTimeout\"","\t// PipelineRunReasonStopping indicates that no new Tasks will be scheduled by the controller, and the","\t// pipeline will stop once all running tasks complete their work","\tPipelineRunReasonStopping PipelineRunReason = \"PipelineRunStopping\"","\t// PipelineRunReasonCancelledRunningFinally indicates that pipeline has been gracefully cancelled","\t// and no new Tasks will be scheduled by the controller, but final tasks are now running","\tPipelineRunReasonCancelledRunningFinally PipelineRunReason = \"CancelledRunningFinally\"","\t// PipelineRunReasonStoppedRunningFinally indicates that pipeline has been gracefully stopped","\t// and no new Tasks will be scheduled by the controller, but final tasks are now running","\tPipelineRunReasonStoppedRunningFinally PipelineRunReason = \"StoppedRunningFinally\"","\t// ReasonCouldntGetPipeline indicates that the reason for the failure status is that the","\t// associated Pipeline couldn't be retrieved","\tPipelineRunReasonCouldntGetPipeline PipelineRunReason = \"CouldntGetPipeline\"","\t// ReasonInvalidBindings indicates that the reason for the failure status is that the","\t// PipelineResources bound in the PipelineRun didn't match those declared in the Pipeline","\tPipelineRunReasonInvalidBindings PipelineRunReason = \"InvalidPipelineResourceBindings\"","\t// ReasonInvalidWorkspaceBinding indicates that a Pipeline expects a workspace but a","\t// PipelineRun has provided an invalid binding.","\tPipelineRunReasonInvalidWorkspaceBinding PipelineRunReason = \"InvalidWorkspaceBindings\"","\t// ReasonInvalidTaskRunSpec indicates that PipelineRun.Spec.TaskRunSpecs[].PipelineTaskName is defined with","\t// a not exist taskName in pipelineSpec.","\tPipelineRunReasonInvalidTaskRunSpec PipelineRunReason = \"InvalidTaskRunSpecs\"","\t// ReasonParameterTypeMismatch indicates that the reason for the failure status is that","\t// parameter(s) declared in the PipelineRun do not have the some declared type as the","\t// parameters(s) declared in the Pipeline that they are supposed to override.","\tPipelineRunReasonParameterTypeMismatch PipelineRunReason = \"ParameterTypeMismatch\"","\t// ReasonObjectParameterMissKeys indicates that the object param value provided from PipelineRun spec","\t// misses some keys required for the object param declared in Pipeline spec.","\tPipelineRunReasonObjectParameterMissKeys PipelineRunReason = \"ObjectParameterMissKeys\"","\t// ReasonParamArrayIndexingInvalid indicates that the use of param array indexing is out of bound.","\tPipelineRunReasonParamArrayIndexingInvalid PipelineRunReason = \"ParamArrayIndexingInvalid\"","\t// ReasonCouldntGetTask indicates that the reason for the failure status is that the","\t// associated Pipeline's Tasks couldn't all be retrieved","\tPipelineRunReasonCouldntGetTask PipelineRunReason = \"CouldntGetTask\"","\t// ReasonParameterMissing indicates that the reason for the failure status is that the","\t// associated PipelineRun didn't provide all the required parameters","\tPipelineRunReasonParameterMissing PipelineRunReason = \"ParameterMissing\"","\t// ReasonFailedValidation indicates that the reason for failure status is","\t// that pipelinerun failed runtime validation","\tPipelineRunReasonFailedValidation PipelineRunReason = \"PipelineValidationFailed\"","\t// PipelineRunReasonCouldntGetPipelineResult indicates that the pipeline fails to retrieve the","\t// referenced result. This could be due to failed TaskRuns or Runs that were supposed to produce","\t// the results","\tPipelineRunReasonCouldntGetPipelineResult PipelineRunReason = \"CouldntGetPipelineResult\"","\t// ReasonInvalidGraph indicates that the reason for the failure status is that the","\t// associated Pipeline is an invalid graph (a.k.a wrong order, cycle, â€¦)","\tPipelineRunReasonInvalidGraph PipelineRunReason = \"PipelineInvalidGraph\"","\t// ReasonCouldntCancel indicates that a PipelineRun was cancelled but attempting to update","\t// all of the running TaskRuns as cancelled failed.","\tPipelineRunReasonCouldntCancel PipelineRunReason = \"PipelineRunCouldntCancel\"","\t// ReasonCouldntTimeOut indicates that a PipelineRun was timed out but attempting to update","\t// all of the running TaskRuns as timed out failed.","\tPipelineRunReasonCouldntTimeOut PipelineRunReason = \"PipelineRunCouldntTimeOut\"","\t// ReasonInvalidMatrixParameterTypes indicates a matrix contains invalid parameter types","\tPipelineRunReasonInvalidMatrixParameterTypes PipelineRunReason = \"InvalidMatrixParameterTypes\"","\t// ReasonInvalidTaskResultReference indicates a task result was declared","\t// but was not initialized by that task","\tPipelineRunReasonInvalidTaskResultReference PipelineRunReason = \"InvalidTaskResultReference\"","\t// PipelineRunReasonInvalidPipelineResultReference indicates a pipeline result was declared","\t// by the pipeline but not initialized in the pipelineTask","\tPipelineRunReasonInvalidPipelineResultReference PipelineRunReason = \"InvalidPipelineResultReference\"","\t// ReasonRequiredWorkspaceMarkedOptional indicates an optional workspace","\t// has been passed to a Task that is expecting a non-optional workspace","\tPipelineRunReasonRequiredWorkspaceMarkedOptional PipelineRunReason = \"RequiredWorkspaceMarkedOptional\"","\t// ReasonResolvingPipelineRef indicates that the PipelineRun is waiting for","\t// its pipelineRef to be asynchronously resolved.","\tPipelineRunReasonResolvingPipelineRef PipelineRunReason = \"ResolvingPipelineRef\"","\t// ReasonResourceVerificationFailed indicates that the pipeline fails the trusted resource verification,","\t// it could be the content has changed, signature is invalid or public key is invalid","\tPipelineRunReasonResourceVerificationFailed PipelineRunReason = \"ResourceVerificationFailed\"","\t// ReasonCreateRunFailed indicates that the pipeline fails to create the taskrun or other run resources","\tPipelineRunReasonCreateRunFailed PipelineRunReason = \"CreateRunFailed\"","\t// ReasonCELEvaluationFailed indicates the pipeline fails the CEL evaluation","\tPipelineRunReasonCELEvaluationFailed PipelineRunReason = \"CELEvaluationFailed\"","\t// PipelineRunReasonInvalidParamValue indicates that the PipelineRun Param input value is not allowed.","\tPipelineRunReasonInvalidParamValue PipelineRunReason = \"InvalidParamValue\"",")","","// PipelineTaskOnErrorAnnotation is used to pass the failure strategy to TaskRun pods from PipelineTask OnError field","const PipelineTaskOnErrorAnnotation = \"pipeline.tekton.dev/pipeline-task-on-error\"","","func (t PipelineRunReason) String() string {","\treturn string(t)","}","","var pipelineRunCondSet = apis.NewBatchConditionSet()","","// GetCondition returns the Condition matching the given type.","func (pr *PipelineRunStatus) GetCondition(t apis.ConditionType) *apis.Condition {","\treturn pipelineRunCondSet.Manage(pr).GetCondition(t)","}","","// InitializeConditions will set all conditions in pipelineRunCondSet to unknown for the PipelineRun","// and set the started time to the current time","func (pr *PipelineRunStatus) InitializeConditions(c clock.PassiveClock) {","\tstarted := false","\tif pr.StartTime.IsZero() {","\t\tpr.StartTime = \u0026metav1.Time{Time: c.Now()}","\t\tstarted = true","\t}","\tconditionManager := pipelineRunCondSet.Manage(pr)","\tconditionManager.InitializeConditions()","\t// Ensure the started reason is set for the \"Succeeded\" condition","\tif started {","\t\tinitialCondition := conditionManager.GetCondition(apis.ConditionSucceeded)","\t\tinitialCondition.Reason = PipelineRunReasonStarted.String()","\t\tconditionManager.SetCondition(*initialCondition)","\t}","}","","// SetCondition sets the condition, unsetting previous conditions with the same","// type as necessary.","func (pr *PipelineRunStatus) SetCondition(newCond *apis.Condition) {","\tif newCond != nil {","\t\tpipelineRunCondSet.Manage(pr).SetCondition(*newCond)","\t}","}","","// MarkSucceeded changes the Succeeded condition to True with the provided reason and message.","func (pr *PipelineRunStatus) MarkSucceeded(reason, messageFormat string, messageA ...interface{}) {","\tpipelineRunCondSet.Manage(pr).MarkTrueWithReason(apis.ConditionSucceeded, reason, messageFormat, messageA...)","\tsucceeded := pr.GetCondition(apis.ConditionSucceeded)","\tpr.CompletionTime = \u0026succeeded.LastTransitionTime.Inner","}","","// MarkFailed changes the Succeeded condition to False with the provided reason and message.","func (pr *PipelineRunStatus) MarkFailed(reason, messageFormat string, messageA ...interface{}) {","\tmessageFormat = pipelineErrors.LabelUserError(messageFormat, messageA)","\tpipelineRunCondSet.Manage(pr).MarkFalse(apis.ConditionSucceeded, reason, messageFormat, messageA...)","\tsucceeded := pr.GetCondition(apis.ConditionSucceeded)","\tpr.CompletionTime = \u0026succeeded.LastTransitionTime.Inner","}","","// MarkRunning changes the Succeeded condition to Unknown with the provided reason and message.","func (pr *PipelineRunStatus) MarkRunning(reason, messageFormat string, messageA ...interface{}) {","\tpipelineRunCondSet.Manage(pr).MarkUnknown(apis.ConditionSucceeded, reason, messageFormat, messageA...)","}","","// ChildStatusReference is used to point to the statuses of individual TaskRuns and Runs within this PipelineRun.","type ChildStatusReference struct {","\truntime.TypeMeta `json:\",inline\"`","\t// Name is the name of the TaskRun or Run this is referencing.","\tName string `json:\"name,omitempty\"`","\t// DisplayName is a user-facing name of the pipelineTask that may be","\t// used to populate a UI.","\tDisplayName string `json:\"displayName,omitempty\"`","\t// PipelineTaskName is the name of the PipelineTask this is referencing.","\tPipelineTaskName string `json:\"pipelineTaskName,omitempty\"`","","\t// WhenExpressions is the list of checks guarding the execution of the PipelineTask","\t// +optional","\t// +listType=atomic","\tWhenExpressions []WhenExpression `json:\"whenExpressions,omitempty\"`","}","","// PipelineRunStatusFields holds the fields of PipelineRunStatus' status.","// This is defined separately and inlined so that other types can readily","// consume these fields via duck typing.","type PipelineRunStatusFields struct {","\t// StartTime is the time the PipelineRun is actually started.","\tStartTime *metav1.Time `json:\"startTime,omitempty\"`","","\t// CompletionTime is the time the PipelineRun completed.","\tCompletionTime *metav1.Time `json:\"completionTime,omitempty\"`","","\t// Results are the list of results written out by the pipeline task's containers","\t// +optional","\t// +listType=atomic","\tResults []PipelineRunResult `json:\"results,omitempty\"`","","\t// PipelineSpec contains the exact spec used to instantiate the run.","\t// See Pipeline.spec (API version: tekton.dev/v1)","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tPipelineSpec *PipelineSpec `json:\"pipelineSpec,omitempty\"`","","\t// list of tasks that were skipped due to when expressions evaluating to false","\t// +optional","\t// +listType=atomic","\tSkippedTasks []SkippedTask `json:\"skippedTasks,omitempty\"`","","\t// list of TaskRun and Run names, PipelineTask names, and API versions/kinds for children of this PipelineRun.","\t// +optional","\t// +listType=atomic","\tChildReferences []ChildStatusReference `json:\"childReferences,omitempty\"`","","\t// FinallyStartTime is when all non-finally tasks have been completed and only finally tasks are being executed.","\t// +optional","\tFinallyStartTime *metav1.Time `json:\"finallyStartTime,omitempty\"`","","\t// Provenance contains some key authenticated metadata about how a software artifact was built (what sources, what inputs/outputs, etc.).","\t// +optional","\tProvenance *Provenance `json:\"provenance,omitempty\"`","","\t// SpanContext contains tracing span context fields","\tSpanContext map[string]string `json:\"spanContext,omitempty\"`","}","","// SkippedTask is used to describe the Tasks that were skipped due to their When Expressions","// evaluating to False. This is a struct because we are looking into including more details","// about the When Expressions that caused this Task to be skipped.","type SkippedTask struct {","\t// Name is the Pipeline Task name","\tName string `json:\"name\"`","\t// Reason is the cause of the PipelineTask being skipped.","\tReason SkippingReason `json:\"reason\"`","\t// WhenExpressions is the list of checks guarding the execution of the PipelineTask","\t// +optional","\t// +listType=atomic","\tWhenExpressions []WhenExpression `json:\"whenExpressions,omitempty\"`","}","","// SkippingReason explains why a PipelineTask was skipped.","type SkippingReason string","","const (","\t// WhenExpressionsSkip means the task was skipped due to at least one of its when expressions evaluating to false","\tWhenExpressionsSkip SkippingReason = \"When Expressions evaluated to false\"","\t// ParentTasksSkip means the task was skipped because its parent was skipped","\tParentTasksSkip SkippingReason = \"Parent Tasks were skipped\"","\t// StoppingSkip means the task was skipped because the pipeline run is stopping","\tStoppingSkip SkippingReason = \"PipelineRun was stopping\"","\t// GracefullyCancelledSkip means the task was skipped because the pipeline run has been gracefully cancelled","\tGracefullyCancelledSkip SkippingReason = \"PipelineRun was gracefully cancelled\"","\t// GracefullyStoppedSkip means the task was skipped because the pipeline run has been gracefully stopped","\tGracefullyStoppedSkip SkippingReason = \"PipelineRun was gracefully stopped\"","\t// MissingResultsSkip means the task was skipped because it's missing necessary results","\tMissingResultsSkip SkippingReason = \"Results were missing\"","\t// PipelineTimedOutSkip means the task was skipped because the PipelineRun has passed its overall timeout.","\tPipelineTimedOutSkip SkippingReason = \"PipelineRun timeout has been reached\"","\t// TasksTimedOutSkip means the task was skipped because the PipelineRun has passed its Timeouts.Tasks.","\tTasksTimedOutSkip SkippingReason = \"PipelineRun Tasks timeout has been reached\"","\t// FinallyTimedOutSkip means the task was skipped because the PipelineRun has passed its Timeouts.Finally.","\tFinallyTimedOutSkip SkippingReason = \"PipelineRun Finally timeout has been reached\"","\t// EmptyArrayInMatrixParams means the task was skipped because Matrix parameters contain empty array.","\tEmptyArrayInMatrixParams SkippingReason = \"Matrix Parameters have an empty array\"","\t// None means the task was not skipped","\tNone SkippingReason = \"None\"",")","","// PipelineRunResult used to describe the results of a pipeline","type PipelineRunResult struct {","\t// Name is the result's name as declared by the Pipeline","\tName string `json:\"name\"`","","\t// Value is the result returned from the execution of this PipelineRun","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tValue ResultValue `json:\"value\"`","}","","// PipelineRunTaskRunStatus contains the name of the PipelineTask for this TaskRun and the TaskRun's Status","type PipelineRunTaskRunStatus struct {","\t// PipelineTaskName is the name of the PipelineTask.","\tPipelineTaskName string `json:\"pipelineTaskName,omitempty\"`","\t// Status is the TaskRunStatus for the corresponding TaskRun","\t// +optional","\tStatus *TaskRunStatus `json:\"status,omitempty\"`","\t// WhenExpressions is the list of checks guarding the execution of the PipelineTask","\t// +optional","\t// +listType=atomic","\tWhenExpressions []WhenExpression `json:\"whenExpressions,omitempty\"`","}","","// PipelineRunRunStatus contains the name of the PipelineTask for this Run and the Run's Status","type PipelineRunRunStatus struct {","\t// PipelineTaskName is the name of the PipelineTask.","\tPipelineTaskName string `json:\"pipelineTaskName,omitempty\"`","\t// Status is the RunStatus for the corresponding Run","\t// +optional","\tStatus *runv1beta1.CustomRunStatus `json:\"status,omitempty\"`","\t// WhenExpressions is the list of checks guarding the execution of the PipelineTask","\t// +optional","\t// +listType=atomic","\tWhenExpressions []WhenExpression `json:\"whenExpressions,omitempty\"`","}","","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// PipelineRunList contains a list of PipelineRun","type PipelineRunList struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ListMeta `json:\"metadata,omitempty\"`","\tItems           []PipelineRun `json:\"items\"`","}","","// PipelineTaskRun reports the results of running a step in the Task. Each","// task has the potential to succeed or fail (based on the exit code)","// and produces logs.","type PipelineTaskRun struct {","\tName string `json:\"name,omitempty\"`","}","","// PipelineTaskRunSpec  can be used to configure specific","// specs for a concrete Task","type PipelineTaskRunSpec struct {","\tPipelineTaskName   string           `json:\"pipelineTaskName,omitempty\"`","\tServiceAccountName string           `json:\"serviceAccountName,omitempty\"`","\tPodTemplate        *pod.PodTemplate `json:\"podTemplate,omitempty\"`","\t// +listType=atomic","\tStepSpecs []TaskRunStepSpec `json:\"stepSpecs,omitempty\"`","\t// +listType=atomic","\tSidecarSpecs []TaskRunSidecarSpec `json:\"sidecarSpecs,omitempty\"`","","\t// +optional","\tMetadata *PipelineTaskMetadata `json:\"metadata,omitempty\"`","","\t// Compute resources to use for this TaskRun","\tComputeResources *corev1.ResourceRequirements `json:\"computeResources,omitempty\"`","","\t// Duration after which the TaskRun times out. Overrides the timeout specified","\t// on the Task's spec if specified. Takes lower precedence to PipelineRun's","\t// `spec.timeouts.tasks`","\t// Refer Go's ParseDuration documentation for expected format: https://golang.org/pkg/time/#ParseDuration","\t// +optional","\tTimeout *metav1.Duration `json:\"timeout,omitempty\"`","}","","// GetTaskRunSpec returns the task specific spec for a given","// PipelineTask if configured, otherwise it returns the PipelineRun's default.","func (pr *PipelineRun) GetTaskRunSpec(pipelineTaskName string) PipelineTaskRunSpec {","\ts := PipelineTaskRunSpec{","\t\tPipelineTaskName:   pipelineTaskName,","\t\tServiceAccountName: pr.Spec.TaskRunTemplate.ServiceAccountName,","\t\tPodTemplate:        pr.Spec.TaskRunTemplate.PodTemplate,","\t}","\tfor _, task := range pr.Spec.TaskRunSpecs {","\t\tif task.PipelineTaskName == pipelineTaskName {","\t\t\t// merge podTemplates specified in pipelineRun.spec.taskRunSpecs[].podTemplate and pipelineRun.spec.podTemplate","\t\t\t// with taskRunSpecs taking higher precedence","\t\t\ts.PodTemplate = pod.MergePodTemplateWithDefault(task.PodTemplate, s.PodTemplate)","\t\t\tif task.ServiceAccountName != \"\" {","\t\t\t\ts.ServiceAccountName = task.ServiceAccountName","\t\t\t}","\t\t\ts.StepSpecs = task.StepSpecs","\t\t\ts.SidecarSpecs = task.SidecarSpecs","\t\t\ts.Metadata = task.Metadata","\t\t\ts.ComputeResources = task.ComputeResources","\t\t\ts.Timeout = task.Timeout","\t\t}","\t}","\treturn s","}","","// PipelineTaskRunTemplate is used to specify run specifications for all Task in pipelinerun.","type PipelineTaskRunTemplate struct {","\t// +optional","\tPodTemplate *pod.PodTemplate `json:\"podTemplate,omitempty\"`","\t// +optional","\tServiceAccountName string `json:\"serviceAccountName,omitempty\"`","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,0,0,0,1,1,1,1,1,0,0,2,2,2,2,2,2,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,0,0,0,0,0]},{"id":34,"path":"pkg/apis/pipeline/v1/pipelinerun_validation.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","\t\"fmt\"","\t\"slices\"","\t\"strings\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/validate\"","\t\"github.com/tektoncd/pipeline/pkg/internal/resultref\"","\tadmissionregistrationv1 \"k8s.io/api/admissionregistration/v1\"","\t\"k8s.io/apimachinery/pkg/api/equality\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/webhook/resourcesemantics\"",")","","var (","\t_ apis.Validatable              = (*PipelineRun)(nil)","\t_ resourcesemantics.VerbLimited = (*PipelineRun)(nil)",")","","// SupportedVerbs returns the operations that validation should be called for","func (pr *PipelineRun) SupportedVerbs() []admissionregistrationv1.OperationType {","\treturn []admissionregistrationv1.OperationType{admissionregistrationv1.Create, admissionregistrationv1.Update}","}","","// Validate pipelinerun","func (pr *PipelineRun) Validate(ctx context.Context) *apis.FieldError {","\terrs := validate.ObjectMetadata(pr.GetObjectMeta()).ViaField(\"metadata\")","","\tif pr.IsPending() \u0026\u0026 pr.HasStarted() {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"PipelineRun cannot be Pending after it is started\", \"spec.status\"))","\t}","","\treturn errs.Also(pr.Spec.Validate(apis.WithinSpec(ctx)).ViaField(\"spec\"))","}","","// Validate pipelinerun spec","func (ps *PipelineRunSpec) Validate(ctx context.Context) (errs *apis.FieldError) {","\t// Validate the spec changes","\terrs = errs.Also(ps.ValidateUpdate(ctx))","","\t// Must have exactly one of pipelineRef and pipelineSpec.","\tif ps.PipelineRef == nil \u0026\u0026 ps.PipelineSpec == nil {","\t\terrs = errs.Also(apis.ErrMissingOneOf(\"pipelineRef\", \"pipelineSpec\"))","\t}","\tif ps.PipelineRef != nil \u0026\u0026 ps.PipelineSpec != nil {","\t\terrs = errs.Also(apis.ErrMultipleOneOf(\"pipelineRef\", \"pipelineSpec\"))","\t}","","\t// Validate PipelineRef if it's present","\tif ps.PipelineRef != nil {","\t\terrs = errs.Also(ps.PipelineRef.Validate(ctx).ViaField(\"pipelineRef\"))","\t}","","\t// Validate PipelineSpec if it's present","\tif ps.PipelineSpec != nil {","\t\tif slices.Contains(strings.Split(","\t\t\tconfig.FromContextOrDefaults(ctx).FeatureFlags.DisableInlineSpec, \",\"), \"pipelinerun\") {","\t\t\terrs = errs.Also(apis.ErrDisallowedFields(\"pipelineSpec\"))","\t\t}","\t\terrs = errs.Also(ps.PipelineSpec.Validate(ctx).ViaField(\"pipelineSpec\"))","\t}","","\t// Validate PipelineRun parameters","\terrs = errs.Also(ps.validatePipelineRunParameters(ctx))","","\t// Validate propagated parameters","\terrs = errs.Also(ps.validateInlineParameters(ctx))","","\tif ps.Timeouts != nil {","\t\t// tasks timeout should be a valid duration of at least 0.","\t\terrs = errs.Also(validateTimeoutDuration(\"tasks\", ps.Timeouts.Tasks))","","\t\t// finally timeout should be a valid duration of at least 0.","\t\terrs = errs.Also(validateTimeoutDuration(\"finally\", ps.Timeouts.Finally))","","\t\t// pipeline timeout should be a valid duration of at least 0.","\t\terrs = errs.Also(validateTimeoutDuration(\"pipeline\", ps.Timeouts.Pipeline))","","\t\tif ps.Timeouts.Pipeline != nil {","\t\t\terrs = errs.Also(ps.validatePipelineTimeout(ps.Timeouts.Pipeline.Duration, \"should be \u003c= pipeline duration\"))","\t\t} else {","\t\t\tdefaultTimeout := time.Duration(config.FromContextOrDefaults(ctx).Defaults.DefaultTimeoutMinutes)","\t\t\terrs = errs.Also(ps.validatePipelineTimeout(defaultTimeout, \"should be \u003c= default timeout duration\"))","\t\t}","\t}","","\t// Validate individual TaskRunSpecs with timeout context","\tfor idx, trs := range ps.TaskRunSpecs {","\t\terrs = errs.Also(validateTaskRunSpec(ctx, trs, ps.Timeouts).ViaIndex(idx).ViaField(\"taskRunSpecs\"))","\t}","\terrs = errs.Also(validateSpecStatus(ps.Status))","","\tif ps.Workspaces != nil {","\t\twsNames := make(map[string]int)","\t\tfor idx, ws := range ps.Workspaces {","\t\t\terrs = errs.Also(ws.Validate(ctx).ViaFieldIndex(\"workspaces\", idx))","\t\t\tif prevIdx, alreadyExists := wsNames[ws.Name]; alreadyExists {","\t\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"workspace %q provided by pipelinerun more than once, at index %d and %d\", ws.Name, prevIdx, idx), \"name\").ViaFieldIndex(\"workspaces\", idx))","\t\t\t}","\t\t\twsNames[ws.Name] = idx","\t\t}","\t}","","\tif ps.TaskRunTemplate.PodTemplate != nil {","\t\terrs = errs.Also(validatePodTemplateEnv(ctx, *ps.TaskRunTemplate.PodTemplate).ViaField(\"taskRunTemplate\"))","\t}","","\treturn errs","}","","// ValidateUpdate validates the update of a PipelineRunSpec","func (ps *PipelineRunSpec) ValidateUpdate(ctx context.Context) (errs *apis.FieldError) {","\tif !apis.IsInUpdate(ctx) {","\t\treturn","\t}","\toldObj, ok := apis.GetBaseline(ctx).(*PipelineRun)","\tif !ok || oldObj == nil {","\t\treturn","\t}","","\tif (oldObj.Spec.ManagedBy == nil) != (ps.ManagedBy == nil) || (oldObj.Spec.ManagedBy != nil \u0026\u0026 *oldObj.Spec.ManagedBy != *ps.ManagedBy) {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"managedBy is immutable\", \"spec.managedBy\"))","\t}","","\tif oldObj.IsDone() {","\t\t// try comparing without any copying first","\t\t// this handles the common case where only finalizers changed","\t\tif equality.Semantic.DeepEqual(\u0026oldObj.Spec, ps) {","\t\t\treturn nil // Specs identical, allow update","\t\t}","","\t\t// Specs differ, this could be due to different defaults after upgrade","\t\t// Apply current defaults to old spec to normalize","\t\toldCopy := oldObj.Spec.DeepCopy()","\t\toldCopy.SetDefaults(ctx)","","\t\tif equality.Semantic.DeepEqual(oldCopy, ps) {","\t\t\treturn nil // Difference was only defaults, allow update","\t\t}","","\t\t// Real spec changes detected, reject update","\t\terrs = errs.Also(apis.ErrInvalidValue(\"Once the PipelineRun is complete, no updates are allowed\", \"\"))","\t\treturn errs","\t}","","\t// Handle started but not done case","\told := oldObj.Spec.DeepCopy()","\told.Status = ps.Status","\told.ManagedBy = ps.ManagedBy // Already tested before","\tif !equality.Semantic.DeepEqual(old, ps) {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"Once the PipelineRun has started, only status updates are allowed\", \"\"))","\t}","\treturn","}","","func (ps *PipelineRunSpec) validatePipelineRunParameters(ctx context.Context) (errs *apis.FieldError) {","\tif len(ps.Params) == 0 {","\t\treturn errs","\t}","","\t// Validate parameter types and uniqueness","\terrs = errs.Also(ValidateParameters(ctx, ps.Params).ViaField(\"params\"))","","\t// Validate that task results aren't used in param values","\tfor _, param := range ps.Params {","\t\texpressions, ok := param.GetVarSubstitutionExpressions()","\t\tif ok {","\t\t\tif LooksLikeContainsResultRefs(expressions) {","\t\t\t\texpressions = filter(expressions, resultref.LooksLikeResultRef)","\t\t\t\tresultRefs := NewResultRefs(expressions)","\t\t\t\tif len(resultRefs) \u003e 0 {","\t\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"cannot use result expressions in %v as PipelineRun parameter values\", expressions),","\t\t\t\t\t\t\"value\").ViaFieldKey(\"params\", param.Name))","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\treturn errs","}","","// validateInlineParameters validates parameters that are defined inline.","// This is crucial for propagated parameters since the parameters could","// be defined under pipelineRun and then called directly in the task steps.","// In this case, parameters cannot be validated by the underlying pipelineSpec","// or taskSpec since they may not have the parameters declared because of propagation.","func (ps *PipelineRunSpec) validateInlineParameters(ctx context.Context) (errs *apis.FieldError) {","\tif ps.PipelineSpec == nil {","\t\treturn errs","\t}","\tparamSpecForValidation := make(map[string]ParamSpec)","\tfor _, p := range ps.Params {","\t\tparamSpecForValidation = createParamSpecFromParam(p, paramSpecForValidation)","\t}","\tfor _, p := range ps.PipelineSpec.Params {","\t\tvar err *apis.FieldError","\t\tparamSpecForValidation, err = combineParamSpec(p, paramSpecForValidation)","\t\tif err != nil {","\t\t\terrs = errs.Also(err)","\t\t}","\t}","\tfor _, pt := range ps.PipelineSpec.Tasks {","\t\tparamSpecForValidation = appendPipelineTaskParams(paramSpecForValidation, pt.Params)","\t\tif pt.TaskSpec != nil \u0026\u0026 pt.TaskSpec.Params != nil {","\t\t\tfor _, p := range pt.TaskSpec.Params {","\t\t\t\tvar err *apis.FieldError","\t\t\t\tparamSpecForValidation, err = combineParamSpec(p, paramSpecForValidation)","\t\t\t\tif err != nil {","\t\t\t\t\terrs = errs.Also(err)","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\tvar paramSpec []ParamSpec","\tfor _, v := range paramSpecForValidation {","\t\tparamSpec = append(paramSpec, v)","\t}","\tif ps.PipelineSpec != nil \u0026\u0026 ps.PipelineSpec.Tasks != nil {","\t\tfor _, pt := range ps.PipelineSpec.Tasks {","\t\t\tif pt.TaskSpec != nil \u0026\u0026 pt.TaskSpec.Steps != nil {","\t\t\t\terrs = errs.Also(ValidateParameterTypes(ctx, paramSpec))","\t\t\t\terrs = errs.Also(ValidateParameterVariables(ctx, pt.TaskSpec.Steps, paramSpec))","\t\t\t\terrs = errs.Also(ValidateUsageOfDeclaredParameters(ctx, pt.TaskSpec.Steps, paramSpec))","\t\t\t}","\t\t}","\t\terrs = errs.Also(ValidatePipelineParameterVariables(ctx, ps.PipelineSpec.Tasks, paramSpec))","\t\terrs = errs.Also(validatePipelineTaskParameterUsage(ps.PipelineSpec.Tasks, paramSpec))","\t}","\treturn errs","}","","func appendPipelineTaskParams(paramSpecForValidation map[string]ParamSpec, params Params) map[string]ParamSpec {","\tfor _, p := range params {","\t\tif pSpec, ok := paramSpecForValidation[p.Name]; ok {","\t\t\tif p.Value.ObjectVal != nil {","\t\t\t\tfor k, v := range p.Value.ObjectVal {","\t\t\t\t\tpSpec.Default.ObjectVal[k] = v","\t\t\t\t\tpSpec.Properties[k] = PropertySpec{Type: ParamTypeString}","\t\t\t\t}","\t\t\t}","\t\t\tparamSpecForValidation[p.Name] = pSpec","\t\t} else {","\t\t\tparamSpecForValidation = createParamSpecFromParam(p, paramSpecForValidation)","\t\t}","\t}","\treturn paramSpecForValidation","}","","func validateSpecStatus(status PipelineRunSpecStatus) *apis.FieldError {","\tswitch status {","\tcase \"\":","\t\treturn nil","\tcase PipelineRunSpecStatusPending:","\t\treturn nil","\tcase PipelineRunSpecStatusCancelled,","\t\tPipelineRunSpecStatusCancelledRunFinally,","\t\tPipelineRunSpecStatusStoppedRunFinally:","\t\treturn nil","\t}","","\treturn apis.ErrInvalidValue(fmt.Sprintf(\"%s should be %s, %s, %s or %s\", status,","\t\tPipelineRunSpecStatusCancelled,","\t\tPipelineRunSpecStatusCancelledRunFinally,","\t\tPipelineRunSpecStatusStoppedRunFinally,","\t\tPipelineRunSpecStatusPending), \"status\")","}","","func validateTimeoutDuration(field string, d *metav1.Duration) (errs *apis.FieldError) {","\tif d != nil \u0026\u0026 d.Duration \u003c 0 {","\t\tfieldPath := \"timeouts.\" + field","\t\treturn errs.Also(apis.ErrInvalidValue(d.Duration.String()+\" should be \u003e= 0\", fieldPath))","\t}","\treturn nil","}","","func (ps *PipelineRunSpec) validatePipelineTimeout(timeout time.Duration, errorMsg string) (errs *apis.FieldError) {","\tif ps.Timeouts.Tasks != nil {","\t\ttasksTimeoutErr := false","\t\ttasksTimeoutStr := ps.Timeouts.Tasks.Duration.String()","\t\tif ps.Timeouts.Tasks.Duration \u003e timeout \u0026\u0026 timeout != config.NoTimeoutDuration {","\t\t\ttasksTimeoutErr = true","\t\t}","\t\tif ps.Timeouts.Tasks.Duration == config.NoTimeoutDuration \u0026\u0026 timeout != config.NoTimeoutDuration {","\t\t\ttasksTimeoutErr = true","\t\t\ttasksTimeoutStr += \" (no timeout)\"","\t\t}","\t\tif tasksTimeoutErr {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"%s %s\", tasksTimeoutStr, errorMsg), \"timeouts.tasks\"))","\t\t}","\t}","","\tif ps.Timeouts.Finally != nil {","\t\tfinallyTimeoutErr := false","\t\tfinallyTimeoutStr := ps.Timeouts.Finally.Duration.String()","\t\tif ps.Timeouts.Finally.Duration \u003e timeout \u0026\u0026 timeout != config.NoTimeoutDuration {","\t\t\tfinallyTimeoutErr = true","\t\t}","\t\tif ps.Timeouts.Finally.Duration == config.NoTimeoutDuration \u0026\u0026 timeout != config.NoTimeoutDuration {","\t\t\tfinallyTimeoutErr = true","\t\t\tfinallyTimeoutStr += \" (no timeout)\"","\t\t}","\t\tif finallyTimeoutErr {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"%s %s\", finallyTimeoutStr, errorMsg), \"timeouts.finally\"))","\t\t}","\t}","","\tif ps.Timeouts.Tasks != nil \u0026\u0026 ps.Timeouts.Finally != nil {","\t\tif ps.Timeouts.Tasks.Duration+ps.Timeouts.Finally.Duration \u003e timeout {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"%s + %s %s\", ps.Timeouts.Tasks.Duration.String(), ps.Timeouts.Finally.Duration.String(), errorMsg), \"timeouts.tasks\"))","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"%s + %s %s\", ps.Timeouts.Tasks.Duration.String(), ps.Timeouts.Finally.Duration.String(), errorMsg), \"timeouts.finally\"))","\t\t}","\t}","\treturn errs","}","","func validateTaskRunSpec(ctx context.Context, trs PipelineTaskRunSpec, pipelineTimeouts *TimeoutFields) (errs *apis.FieldError) {","\tif trs.StepSpecs != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"stepSpecs\", config.BetaAPIFields).ViaField(\"stepSpecs\"))","\t\terrs = errs.Also(validateStepSpecs(trs.StepSpecs).ViaField(\"stepSpecs\"))","\t}","\tif trs.SidecarSpecs != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"sidecarSpecs\", config.BetaAPIFields).ViaField(\"sidecarSpecs\"))","\t\terrs = errs.Also(validateSidecarSpecs(trs.SidecarSpecs).ViaField(\"sidecarSpecs\"))","\t}","\tif trs.ComputeResources != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"computeResources\", config.BetaAPIFields).ViaField(\"computeResources\"))","\t\terrs = errs.Also(validateTaskRunComputeResources(trs.ComputeResources, trs.StepSpecs))","\t}","\tif trs.PodTemplate != nil {","\t\terrs = errs.Also(validatePodTemplateEnv(ctx, *trs.PodTemplate))","\t}","","\terrs = errs.Also(validateTaskRunSpecTimeout(ctx, trs.Timeout, pipelineTimeouts))","","\treturn errs","}","","// validateTaskRunSpecTimeout validates a TaskRunSpec's timeout against pipeline timeouts.","// This function works in isolation and doesn't rely on previous validation steps.","func validateTaskRunSpecTimeout(ctx context.Context, timeout *metav1.Duration, pipelineTimeouts *TimeoutFields) *apis.FieldError {","\tif timeout == nil {","\t\treturn nil","\t}","","\tcfg := config.FromContextOrDefaults(ctx)","","\t// Validate basic timeout (negative values)","\tif _, err := validateTimeout(timeout, cfg.Defaults.DefaultTimeoutMinutes); err != nil {","\t\treturn err","\t}","","\t// Find applicable timeout limit: Tasks -\u003e Pipeline -\u003e Default (60min)","\tvar maxTimeout *metav1.Duration","\tvar timeoutSource string","","\tswitch {","\tcase pipelineTimeouts != nil \u0026\u0026 pipelineTimeouts.Tasks != nil:","\t\tif validatedTimeout, err := validateTimeout(pipelineTimeouts.Tasks, cfg.Defaults.DefaultTimeoutMinutes); err != nil {","\t\t\t// Return error if Tasks timeout is invalid (prevents silent failures)","\t\t\treturn err","\t\t} else {","\t\t\tmaxTimeout = validatedTimeout","\t\t\ttimeoutSource = \"pipeline tasks duration\"","\t\t}","\tcase pipelineTimeouts != nil \u0026\u0026 pipelineTimeouts.Pipeline != nil:","\t\tif validatedTimeout, err := validateTimeout(pipelineTimeouts.Pipeline, cfg.Defaults.DefaultTimeoutMinutes); err != nil {","\t\t\t// Return error if Pipeline timeout is invalid (prevents silent failures)","\t\t\treturn err","\t\t} else {","\t\t\tmaxTimeout = validatedTimeout","\t\t\ttimeoutSource = \"pipeline duration\"","\t\t}","\tdefault:","\t\tmaxTimeout = \u0026metav1.Duration{Duration: time.Duration(cfg.Defaults.DefaultTimeoutMinutes) * time.Minute}","\t\ttimeoutSource = \"default pipeline duration\"","\t}","","\t// always check against max timeout","\tif maxTimeout != nil \u0026\u0026 maxTimeout.Duration != config.NoTimeoutDuration {","\t\tif taskRunTimeout, _ := validateTimeout(timeout, cfg.Defaults.DefaultTimeoutMinutes); taskRunTimeout.Duration \u003e maxTimeout.Duration { // We know this won't error from above","\t\t\treturn apis.ErrInvalidValue(","\t\t\t\tfmt.Sprintf(\"%s should be \u003c= %s %s\", taskRunTimeout.Duration, timeoutSource, maxTimeout.Duration),","\t\t\t\t\"timeout\")","\t\t}","\t}","","\treturn nil","}","","// validateTimeout validates a timeout field and returns the validated timeout with defaults applied.","// If timeout is nil, returns default timeout. If timeout is negative, returns an error.","func validateTimeout(timeout *metav1.Duration, defaultTimeoutMinutes int) (*metav1.Duration, *apis.FieldError) {","\tif timeout == nil {","\t\treturn \u0026metav1.Duration{Duration: time.Duration(defaultTimeoutMinutes) * time.Minute}, nil","\t}","\tif timeout.Duration \u003c 0 {","\t\treturn nil, apis.ErrInvalidValue(timeout.Duration.String()+\" should be \u003e= 0\", \"timeout\")","\t}","\treturn timeout, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,2,2,2,0,0,0,2,2,2,2,1,1,0,0,2,2,0,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,0,0,2,2,2,2,2,2,1,1,1,1,1,1,1,0,0,0,0,2,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,1,1,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,0,2,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,0,2,0,0,2,2,2,2,2,2,0,0,2,2,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,0,0,0,0,2,2,2,2,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,1,1,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,2,0,0,0,0,2,2,1,1,2,2,2,2,0]},{"id":35,"path":"pkg/apis/pipeline/v1/register.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"",")","","// SchemeGroupVersion is group version used to register these objects","var SchemeGroupVersion = schema.GroupVersion{Group: pipeline.GroupName, Version: \"v1\"}","","// Kind takes an unqualified kind and returns back a Group qualified GroupKind","func Kind(kind string) schema.GroupKind {","\treturn SchemeGroupVersion.WithKind(kind).GroupKind()","}","","// Resource takes an unqualified resource and returns a Group qualified GroupResource","func Resource(resource string) schema.GroupResource {","\treturn SchemeGroupVersion.WithResource(resource).GroupResource()","}","","var (","\tschemeBuilder = runtime.NewSchemeBuilder(addKnownTypes)","","\t// AddToScheme adds Build types to the scheme.","\tAddToScheme = schemeBuilder.AddToScheme",")","","// Adds the list of known types to Scheme.","func addKnownTypes(scheme *runtime.Scheme) error {","\tscheme.AddKnownTypes(SchemeGroupVersion,","\t\t\u0026Task{},","\t\t\u0026TaskList{},","\t\t\u0026Pipeline{},","\t\t\u0026PipelineList{},","\t\t\u0026TaskRun{},","\t\t\u0026TaskRunList{},","\t\t\u0026PipelineRun{},","\t\t\u0026PipelineRunList{},","\t)","\tmetav1.AddToGroupVersion(scheme, SchemeGroupVersion)","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1]},{"id":36,"path":"pkg/apis/pipeline/v1/result_defaults.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import \"context\"","","// SetDefaults set the default type for TaskResult","func (tr *TaskResult) SetDefaults(context.Context) {","\tif tr == nil {","\t\treturn","\t}","\tif tr.Type == \"\" {","\t\tif tr.Properties != nil {","\t\t\t// Set type to object if `properties` is given","\t\t\ttr.Type = ResultsTypeObject","\t\t} else {","\t\t\t// ResultsTypeString is the default value","\t\t\ttr.Type = ResultsTypeString","\t\t}","\t}","","\t// Set default type of object values to string","\tfor key, propertySpec := range tr.Properties {","\t\tif propertySpec.Type == \"\" {","\t\t\ttr.Properties[key] = PropertySpec{Type: ParamType(ResultsTypeString)}","\t\t}","\t}","}","","// SetDefaults set the default type for StepResult","func (sr *StepResult) SetDefaults(context.Context) {","\tif sr == nil {","\t\treturn","\t}","\tif sr.Type == \"\" {","\t\tif sr.Properties != nil {","\t\t\t// Set type to object if `properties` is given","\t\t\tsr.Type = ResultsTypeObject","\t\t} else {","\t\t\t// ResultsTypeString is the default value","\t\t\tsr.Type = ResultsTypeString","\t\t}","\t}","","\t// Set default type of object values to string","\tfor key, propertySpec := range sr.Properties {","\t\tif propertySpec.Type == \"\" {","\t\t\tsr.Properties[key] = PropertySpec{Type: ParamType(ResultsTypeString)}","\t\t}","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,0,0]},{"id":37,"path":"pkg/apis/pipeline/v1/result_types.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import \"strings\"","","// TaskResult used to describe the results of a task","type TaskResult struct {","\t// Name the given name","\tName string `json:\"name\"`","","\t// Type is the user-specified type of the result. The possible type","\t// is currently \"string\" and will support \"array\" in following work.","\t// +optional","\tType ResultsType `json:\"type,omitempty\"`","","\t// Properties is the JSON Schema properties to support key-value pairs results.","\t// +optional","\tProperties map[string]PropertySpec `json:\"properties,omitempty\"`","","\t// Description is a human-readable description of the result","\t// +optional","\tDescription string `json:\"description,omitempty\"`","","\t// Value the expression used to retrieve the value of the result from an underlying Step.","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tValue *ResultValue `json:\"value,omitempty\"`","}","","// StepResult used to describe the Results of a Step.","type StepResult struct {","\t// Name the given name","\tName string `json:\"name\"`","","\t// The possible types are 'string', 'array', and 'object', with 'string' as the default.","\t// +optional","\tType ResultsType `json:\"type,omitempty\"`","","\t// Properties is the JSON Schema properties to support key-value pairs results.","\t// +optional","\tProperties map[string]PropertySpec `json:\"properties,omitempty\"`","","\t// Description is a human-readable description of the result","\t// +optional","\tDescription string `json:\"description,omitempty\"`","}","","// TaskRunResult used to describe the results of a task","type TaskRunResult struct {","\t// Name the given name","\tName string `json:\"name\"`","","\t// Type is the user-specified type of the result. The possible type","\t// is currently \"string\" and will support \"array\" in following work.","\t// +optional","\tType ResultsType `json:\"type,omitempty\"`","","\t// Value the given value of the result","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tValue ResultValue `json:\"value\"`","}","","// TaskRunStepResult is a type alias of TaskRunResult","type TaskRunStepResult = TaskRunResult","","// ResultValue is a type alias of ParamValue","type ResultValue = ParamValue","","// ResultsType indicates the type of a result;","// Used to distinguish between a single string and an array of strings.","// Note that there is ResultType used to find out whether a","// RunResult is from a task result or not, which is different from","// this ResultsType.","type ResultsType string","","// Valid ResultsType:","const (","\tResultsTypeString ResultsType = \"string\"","\tResultsTypeArray  ResultsType = \"array\"","\tResultsTypeObject ResultsType = \"object\"",")","","// AllResultsTypes can be used for ResultsTypes validation.","var AllResultsTypes = []ResultsType{ResultsTypeString, ResultsTypeArray, ResultsTypeObject}","","// ResultsArrayReference returns the reference of the result. e.g. results.resultname from $(results.resultname[*])","func ResultsArrayReference(a string) string {","\treturn strings.TrimSuffix(strings.TrimSuffix(strings.TrimPrefix(a, \"$(\"), \")\"), \"[*]\")","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2]},{"id":38,"path":"pkg/apis/pipeline/v1/result_validation.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","\t\"fmt\"","\t\"regexp\"","","\t\"k8s.io/apimachinery/pkg/util/validation\"","\t\"knative.dev/pkg/apis\"",")","","// Validate implements apis.Validatable","func (tr TaskResult) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif !resultNameFormatRegex.MatchString(tr.Name) {","\t\treturn apis.ErrInvalidKeyName(tr.Name, \"name\", fmt.Sprintf(\"Name must consist of alphanumeric characters, '-', '_', and must start and end with an alphanumeric character (e.g. 'MyName',  or 'my-name',  or 'my_name', regex used for validation is '%s')\", ResultNameFormat))","\t}","","\tswitch {","\tcase tr.Type == ResultsTypeObject:","\t\terrs = errs.Also(validateObjectResult(tr))","\tcase tr.Type == ResultsTypeArray:","\t// Resources created before the result. Type was introduced may not have Type set","\t// and should be considered valid","\tcase tr.Type == \"\":","\t// By default, the result type is string","\tcase tr.Type != ResultsTypeString:","\t\terrs = errs.Also(apis.ErrInvalidValue(tr.Type, \"type\", \"type must be string\"))","\t}","\treturn errs.Also(tr.validateValue(ctx))","}","","// validateObjectResult validates the object result and check if the Properties is missing","// for Properties values it will check if the type is string.","func validateObjectResult(tr TaskResult) (errs *apis.FieldError) {","\tif ParamType(tr.Type) == ParamTypeObject \u0026\u0026 tr.Properties == nil {","\t\treturn apis.ErrMissingField(tr.Name + \".properties\")","\t}","","\tinvalidKeys := []string{}","\tfor key, propertySpec := range tr.Properties {","\t\tif propertySpec.Type != ParamTypeString {","\t\t\tinvalidKeys = append(invalidKeys, key)","\t\t}","\t}","","\tif len(invalidKeys) != 0 {","\t\treturn \u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(\"The value type specified for these keys %v is invalid, the type must be string\", invalidKeys),","\t\t\tPaths:   []string{tr.Name + \".properties\"},","\t\t}","\t}","\treturn nil","}","","// validateValue validates the value of the TaskResult.","// It requires that the value is of type string","// and format $(steps.\u003cstepName\u003e.results.\u003cresultName\u003e)","func (tr TaskResult) validateValue(ctx context.Context) (errs *apis.FieldError) {","\tif tr.Value == nil {","\t\treturn nil","\t}","\tif tr.Value.Type != ParamTypeString {","\t\treturn \u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(","\t\t\t\t\"Invalid Type. Wanted string but got: \\\"%v\\\"\", tr.Value.Type),","\t\t\tPaths: []string{","\t\t\t\ttr.Name + \".type\",","\t\t\t},","\t\t}","\t}","\tif tr.Value.StringVal != \"\" {","\t\tstepName, resultName, err := ExtractStepResultName(tr.Value.StringVal)","\t\tif err != nil {","\t\t\treturn \u0026apis.FieldError{","\t\t\t\tMessage: fmt.Sprintf(\"%v\", err),","\t\t\t\tPaths:   []string{tr.Name + \".value\"},","\t\t\t}","\t\t}","\t\tif e := validation.IsDNS1123Label(stepName); len(e) \u003e 0 {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: fmt.Sprintf(\"invalid extracted step name %q\", stepName),","\t\t\t\tPaths:   []string{tr.Name + \".value\"},","\t\t\t\tDetails: \"stepName in $(steps.\u003cstepName\u003e.results.\u003cresultName\u003e) must be a valid DNS Label, For more info refer to https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names\",","\t\t\t})","\t\t}","\t\tif !resultNameFormatRegex.MatchString(resultName) {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: fmt.Sprintf(\"invalid extracted result name %q\", resultName),","\t\t\t\tPaths:   []string{tr.Name + \".value\"},","\t\t\t\tDetails: fmt.Sprintf(\"resultName in $(steps.\u003cstepName\u003e.results.\u003cresultName\u003e) must consist of alphanumeric characters, '-', '_', and must start and end with an alphanumeric character (e.g. 'MyName',  or 'my-name',  or 'my_name', regex used for validation is '%s')\", ResultNameFormat),","\t\t\t})","\t\t}","\t}","\treturn errs","}","","// Validate implements apis.Validatable","func (sr StepResult) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif !resultNameFormatRegex.MatchString(sr.Name) {","\t\treturn apis.ErrInvalidKeyName(sr.Name, \"name\", fmt.Sprintf(\"Name must consist of alphanumeric characters, '-', '_', and must start and end with an alphanumeric character (e.g. 'MyName',  or 'my-name',  or 'my_name', regex used for validation is '%s')\", ResultNameFormat))","\t}","","\tswitch {","\tcase sr.Type == ResultsTypeObject:","\t\treturn validateObjectStepResult(sr)","\tcase sr.Type == ResultsTypeArray:","\t\treturn nil","\t// The Type is string by default if it is empty.","\tcase sr.Type == \"\":","\t\treturn nil","\tcase sr.Type == ResultsTypeString:","\t\treturn nil","\tdefault:","\t\treturn apis.ErrInvalidValue(sr.Type, \"type\", fmt.Sprintf(\"invalid type %s\", sr.Type))","\t}","}","","// validateObjectStepResult validates the object result and check if the Properties is missing","// for Properties values it will check if the type is string.","func validateObjectStepResult(sr StepResult) (errs *apis.FieldError) {","\tif ParamType(sr.Type) == ParamTypeObject \u0026\u0026 sr.Properties == nil {","\t\treturn apis.ErrMissingField(sr.Name + \".properties\")","\t}","","\tinvalidKeys := []string{}","\tfor key, propertySpec := range sr.Properties {","\t\t// In case we need to support other types in the future like the nested objects #7069","\t\tif propertySpec.Type != ParamTypeString {","\t\t\tinvalidKeys = append(invalidKeys, key)","\t\t}","\t}","","\tif len(invalidKeys) != 0 {","\t\treturn \u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(\"the value type specified for these keys %v is invalid, the type must be string\", invalidKeys),","\t\t\tPaths:   []string{sr.Name + \".properties\"},","\t\t}","\t}","\treturn nil","}","","// ExtractStepResultName extracts the step name and result name from a string matching","// formtat $(steps.\u003cstepName\u003e.results.\u003cresultName\u003e).","// If a match is not found, an error is retured.","func ExtractStepResultName(value string) (string, string, error) {","\tre := regexp.MustCompile(`\\$\\(steps\\.(.*?)\\.results\\.(.*?)\\)`)","\trs := re.FindStringSubmatch(value)","\tif len(rs) != 3 {","\t\treturn \"\", \"\", fmt.Errorf(\"Could not extract step name and result name. Expected value to look like $(steps.\u003cstepName\u003e.results.\u003cresultName\u003e) but got \\\"%v\\\"\", value)","\t}","\treturn rs[1], rs[2], nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,2,2,2,0,0,0,0,0,2,2,0,2,0,0,0,0,2,2,2,2,0,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,0]},{"id":39,"path":"pkg/apis/pipeline/v1/resultref.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"regexp\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/internal/resultref\"",")","","// ResultRef is a type that represents a reference to a task run result","type ResultRef struct {","\tPipelineTask string `json:\"pipelineTask\"`","\tResult       string `json:\"result\"`","\tResultsIndex *int   `json:\"resultsIndex\"`","\tProperty     string `json:\"property\"`","}","","const (","\t// ResultTaskPart Constant used to define the \"tasks\" part of a pipeline result reference","\t// retained because of backwards compatibility","\tResultTaskPart = resultref.ResultTaskPart","\t// ResultFinallyPart Constant used to define the \"finally\" part of a pipeline result reference","\t// retained because of backwards compatibility","\tResultFinallyPart = resultref.ResultFinallyPart","\t// ResultResultPart Constant used to define the \"results\" part of a pipeline result reference","\t// retained because of backwards compatibility","\tResultResultPart = resultref.ResultResultPart","\t// TODO(#2462) use one regex across all substitutions","\t// variableSubstitutionFormat matches format like $result.resultname, $result.resultname[int] and $result.resultname[*]","\tvariableSubstitutionFormat = `\\$\\([_a-zA-Z0-9.-]+(\\.[_a-zA-Z0-9.-]+)*(\\[([0-9]+|\\*)\\])?\\)`","\t// exactVariableSubstitutionFormat matches strings that only contain a single reference to result or param variables, but nothing else","\t// i.e. `$(result.resultname)` is a match, but `foo $(result.resultname)` is not.","\texactVariableSubstitutionFormat = `^\\$\\([_a-zA-Z0-9.-]+(\\.[_a-zA-Z0-9.-]+)*(\\[([0-9]+|\\*)\\])?\\)$`","\t// ResultNameFormat Constant used to define the regex Result.Name should follow","\tResultNameFormat = `^([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9]$`",")","","// VariableSubstitutionRegex is a regex to find all result matching substitutions","var VariableSubstitutionRegex = regexp.MustCompile(variableSubstitutionFormat)","var exactVariableSubstitutionRegex = regexp.MustCompile(exactVariableSubstitutionFormat)","var resultNameFormatRegex = regexp.MustCompile(ResultNameFormat)","","// NewResultRefs extracts all ResultReferences from a param or a pipeline result.","// If the ResultReference can be extracted, they are returned. Expressions which are not","// results are ignored.","func NewResultRefs(expressions []string) []*ResultRef {","\tvar resultRefs []*ResultRef","\tfor _, expression := range expressions {","\t\tpr, err := resultref.ParseTaskExpression(expression)","\t\t// If the expression isn't a result but is some other expression,","\t\t// parseTaskExpression will return an error, in which case we just skip that expression,","\t\t// since although it's not a result ref, it might be some other kind of reference","\t\tif err == nil {","\t\t\tresultRefs = append(resultRefs, \u0026ResultRef{","\t\t\t\tPipelineTask: pr.ResourceName,","\t\t\t\tResult:       pr.ResultName,","\t\t\t\tResultsIndex: pr.ArrayIdx,","\t\t\t\tProperty:     pr.ObjectKey,","\t\t\t})","\t\t}","\t}","\treturn resultRefs","}","","// LooksLikeContainsResultRefs attempts to check if param or a pipeline result looks like it contains any","// result references.","// This is useful if we want to make sure the param looks like a ResultReference before","// performing strict validation","func LooksLikeContainsResultRefs(expressions []string) bool {","\tfor _, expression := range expressions {","\t\tif resultref.LooksLikeResultRef(expression) {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","func validateString(value string) []string {","\texpressions := VariableSubstitutionRegex.FindAllString(value, -1)","\tif expressions == nil {","\t\treturn nil","\t}","\tvar result []string","\tfor _, expression := range expressions {","\t\tresult = append(result, stripVarSubExpression(expression))","\t}","\treturn result","}","","func stripVarSubExpression(expression string) string {","\treturn strings.TrimSuffix(strings.TrimPrefix(expression, \"$(\"), \")\")","}","","// ParseResultName parse the input string to extract resultName and result index.","// Array indexing:","// Input:  anArrayResult[1]","// Output: anArrayResult, \"1\"","// Array star reference:","// Input:  anArrayResult[*]","// Output: anArrayResult, \"*\"","// retained for backwards compatibility","func ParseResultName(resultName string) (string, string) {","\treturn resultref.ParseResultName(resultName)","}","","// PipelineTaskResultRefs walks all the places a result reference can be used","// in a PipelineTask and returns a list of any references that are found.","func PipelineTaskResultRefs(pt *PipelineTask) []*ResultRef {","\trefs := []*ResultRef{}","\t// TODO move the whenExpression.GetVarSubstitutionExpressions() and GetVarSubstitutionExpressionsForParam(p) as well","\t// separate cleanup, reference https://github.com/tektoncd/pipeline/pull/7121","\tfor _, p := range pt.extractAllParams() {","\t\texpressions, _ := p.GetVarSubstitutionExpressions()","\t\trefs = append(refs, NewResultRefs(expressions)...)","\t}","\tfor _, whenExpression := range pt.When {","\t\texpressions, _ := whenExpression.GetVarSubstitutionExpressions()","\t\trefs = append(refs, NewResultRefs(expressions)...)","\t}","\ttaskSubExpressions := pt.GetVarSubstitutionExpressions()","\trefs = append(refs, NewResultRefs(taskSubExpressions)...)","\treturn refs","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,0,0,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0]},{"id":40,"path":"pkg/apis/pipeline/v1/task_conversion.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","\t\"fmt\"","","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Convertible = (*Task)(nil)","","// ConvertTo implements apis.Convertible","func (t *Task) ConvertTo(ctx context.Context, sink apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\treturn fmt.Errorf(\"v1 is the highest known version, got: %T\", sink)","}","","// ConvertFrom implements apis.Convertible","func (t *Task) ConvertFrom(ctx context.Context, source apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\treturn fmt.Errorf(\"v1 is the highest known version, got: %T\", source)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,2,0,0,0,2,2,1,1,2,0]},{"id":41,"path":"pkg/apis/pipeline/v1/task_defaults.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Defaultable = (*Task)(nil)","","// SetDefaults implements apis.Defaultable","func (t *Task) SetDefaults(ctx context.Context) {","\tt.Spec.SetDefaults(ctx)","}","","// SetDefaults set any defaults for the task spec","func (ts *TaskSpec) SetDefaults(ctx context.Context) {","\tcfg := config.FromContextOrDefaults(ctx)","\tfor _, s := range ts.Steps {","\t\tif s.Ref != nil \u0026\u0026 s.Ref.Name == \"\" \u0026\u0026 s.Ref.Resolver == \"\" {","\t\t\ts.Ref.Resolver = ResolverName(cfg.Defaults.DefaultResolverType)","\t\t}","\t}","\tfor i := range ts.Params {","\t\tts.Params[i].SetDefaults(ctx)","\t}","\tfor i := range ts.Results {","\t\tts.Results[i].SetDefaults(ctx)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,2,2,2,2,2,2,0,2,2,2,2,2,2,0]},{"id":42,"path":"pkg/apis/pipeline/v1/task_types.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/internal/checksum\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"","\t\"knative.dev/pkg/kmeta\"",")","","// +genclient","// +genclient:noStatus","// +genreconciler:krshapedlogic=false","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// Task represents a collection of sequential steps that are run as part of a","// Pipeline using a set of inputs and producing a set of outputs. Tasks execute","// when TaskRuns are created that provide the input parameters and resources and","// output resources the Task requires.","//","// +k8s:openapi-gen=true","// +kubebuilder:storageversion","type Task struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ObjectMeta `json:\"metadata\"`","","\t// Spec holds the desired state of the Task from the client","\t// +optional","\tSpec TaskSpec `json:\"spec\"`","}","","var _ kmeta.OwnerRefable = (*Task)(nil)","","// GetGroupVersionKind implements kmeta.OwnerRefable.","func (*Task) GetGroupVersionKind() schema.GroupVersionKind {","\treturn SchemeGroupVersion.WithKind(pipeline.TaskControllerName)","}","","// Checksum computes the sha256 checksum of the task object.","// Prior to computing the checksum, it performs some preprocessing on the","// metadata of the object where it removes system provided annotations.","// Only the name, namespace, generateName, user-provided labels and annotations","// and the taskSpec are included for the checksum computation.","func (t *Task) Checksum() ([]byte, error) {","\tobjectMeta := checksum.PrepareObjectMeta(t)","\tpreprocessedTask := Task{","\t\tTypeMeta: metav1.TypeMeta{","\t\t\tAPIVersion: \"tekton.dev/v1\",","\t\t\tKind:       \"Task\"},","\t\tObjectMeta: objectMeta,","\t\tSpec:       t.Spec,","\t}","\tsha256Checksum, err := checksum.ComputeSha256Checksum(preprocessedTask)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn sha256Checksum, nil","}","","// +listType=atomic","type Volumes []corev1.Volume","","// TaskSpec defines the desired state of Task.","type TaskSpec struct {","\t// Params is a list of input parameters required to run the task. Params","\t// must be supplied as inputs in TaskRuns unless they declare a default","\t// value.","\t// +optional","\tParams ParamSpecs `json:\"params,omitempty\"`","","\t// DisplayName is a user-facing name of the task that may be","\t// used to populate a UI.","\t// +optional","\tDisplayName string `json:\"displayName,omitempty\"`","","\t// Description is a user-facing description of the task that may be","\t// used to populate a UI.","\t// +optional","\tDescription string `json:\"description,omitempty\"`","","\t// Steps are the steps of the build; each step is run sequentially with the","\t// source mounted into /workspace.","\t// +listType=atomic","\tSteps []Step `json:\"steps,omitempty\"`","","\t// Volumes is a collection of volumes that are available to mount into the","\t// steps of the build.","\t// See Pod.spec.volumes (API version: v1)","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tVolumes Volumes `json:\"volumes,omitempty\"`","","\t// StepTemplate can be used as the basis for all step containers within the","\t// Task, so that the steps inherit settings on the base container.","\tStepTemplate *StepTemplate `json:\"stepTemplate,omitempty\"`","","\t// Sidecars are run alongside the Task's step containers. They begin before","\t// the steps start and end after the steps complete.","\t// +listType=atomic","\tSidecars []Sidecar `json:\"sidecars,omitempty\"`","","\t// Workspaces are the volumes that this Task requires.","\t// +listType=atomic","\tWorkspaces []WorkspaceDeclaration `json:\"workspaces,omitempty\"`","","\t// Results are values that this Task can output","\t// +listType=atomic","\tResults []TaskResult `json:\"results,omitempty\"`","}","","// TaskList contains a list of Task","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","type TaskList struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ListMeta `json:\"metadata,omitempty\"`","\tItems           []Task `json:\"items\"`","}","","// StepList is a list of Steps","type StepList []Step","","// SidecarList is a list of Sidecars","type SidecarList []Sidecar"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]},{"id":43,"path":"pkg/apis/pipeline/v1/task_validation.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","\t\"fmt\"","\t\"path/filepath\"","\t\"regexp\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/validate\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","","\tadmissionregistrationv1 \"k8s.io/api/admissionregistration/v1\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/webhook/resourcesemantics\"",")","","const (","\t// stringAndArrayVariableNameFormat is the regex to validate if string/array variable name format follows the following rules.","\t// - Must only contain alphanumeric characters, hyphens (-), underscores (_), and dots (.)","\t// - Must begin with a letter or an underscore (_)","\tstringAndArrayVariableNameFormat = \"^[_a-zA-Z][_a-zA-Z0-9.-]*$\"","","\t// objectVariableNameFormat is the regex used to validate object name and key names format","\t// The difference with the array or string name format is that object variable names shouldn't contain dots.","\tobjectVariableNameFormat = \"^[_a-zA-Z][_a-zA-Z0-9-]*$\"",")","","var (","\t_ apis.Validatable              = (*Task)(nil)","\t_ resourcesemantics.VerbLimited = (*Task)(nil)",")","","// SupportedVerbs returns the operations that validation should be called for","func (t *Task) SupportedVerbs() []admissionregistrationv1.OperationType {","\treturn []admissionregistrationv1.OperationType{admissionregistrationv1.Create, admissionregistrationv1.Update}","}","","var (","\tstringAndArrayVariableNameFormatRegex = regexp.MustCompile(stringAndArrayVariableNameFormat)","\tobjectVariableNameFormatRegex         = regexp.MustCompile(objectVariableNameFormat)",")","","// Validate implements apis.Validatable","func (t *Task) Validate(ctx context.Context) *apis.FieldError {","\terrs := validate.ObjectMetadata(t.GetObjectMeta()).ViaField(\"metadata\")","\terrs = errs.Also(t.Spec.Validate(apis.WithinSpec(ctx)).ViaField(\"spec\"))","\t// When a Task is created directly, instead of declared inline in a TaskRun or PipelineRun,","\t// we do not support propagated parameters. Validate that all params it uses are declared.","\terrs = errs.Also(ValidateUsageOfDeclaredParameters(ctx, t.Spec.Steps, t.Spec.Params).ViaField(\"spec\"))","\treturn errs","}","","// Validate implements apis.Validatable","func (ts *TaskSpec) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif len(ts.Steps) == 0 {","\t\terrs = errs.Also(apis.ErrMissingField(\"steps\"))","\t}","","\terrs = errs.Also(ValidateVolumes(ts.Volumes).ViaField(\"volumes\"))","\terrs = errs.Also(validateDeclaredWorkspaces(ts.Workspaces, ts.Steps, ts.StepTemplate).ViaField(\"workspaces\"))","\terrs = errs.Also(validateWorkspaceUsages(ctx, ts))","\tmergedSteps, err := MergeStepsWithStepTemplate(ts.StepTemplate, ts.Steps)","\tif err != nil {","\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(\"error merging step template and steps: %s\", err),","\t\t\tPaths:   []string{\"stepTemplate\"},","\t\t\tDetails: err.Error(),","\t\t})","\t}","","\terrs = errs.Also(StepList(mergedSteps).Validate(ctx).ViaField(\"steps\"))","\terrs = errs.Also(SidecarList(ts.Sidecars).Validate(ctx).ViaField(\"sidecars\"))","\terrs = errs.Also(ValidateParameterTypes(ctx, ts.Params).ViaField(\"params\"))","\terrs = errs.Also(ValidateParameterVariables(ctx, ts.Steps, ts.Params))","\terrs = errs.Also(validateTaskContextVariables(ctx, ts.Steps))","\terrs = errs.Also(validateTaskResultsVariables(ctx, ts.Steps, ts.Results))","\terrs = errs.Also(validateResults(ctx, ts.Results).ViaField(\"results\"))","\treturn errs","}","","// ValidateUsageOfDeclaredParameters validates that all parameters referenced in the Task are declared by the Task.","func ValidateUsageOfDeclaredParameters(ctx context.Context, steps []Step, params ParamSpecs) *apis.FieldError {","\tvar errs *apis.FieldError","\t_, _, objectParams := params.SortByType()","\tallParameterNames := sets.NewString(params.GetNames()...)","\terrs = errs.Also(validateVariables(ctx, steps, \"params\", allParameterNames))","\terrs = errs.Also(validateObjectUsage(ctx, steps, objectParams))","\terrs = errs.Also(ValidateObjectParamsHaveProperties(ctx, params))","\treturn errs","}","","// ValidateObjectParamsHaveProperties returns an error if any declared object params are missing properties","func ValidateObjectParamsHaveProperties(ctx context.Context, params ParamSpecs) *apis.FieldError {","\tvar errs *apis.FieldError","\tfor _, p := range params {","\t\tif p.Type == ParamTypeObject \u0026\u0026 p.Properties == nil {","\t\t\terrs = errs.Also(apis.ErrMissingField(p.Name + \".properties\"))","\t\t}","\t}","\treturn errs","}","","func validateResults(ctx context.Context, results []TaskResult) (errs *apis.FieldError) {","\tfor index, result := range results {","\t\terrs = errs.Also(result.Validate(ctx).ViaIndex(index))","\t}","\treturn errs","}","","// a mount path which conflicts with any other declared workspaces, with the explicitly","// declared volume mounts, or with the stepTemplate. The names must also be unique.","func validateDeclaredWorkspaces(workspaces []WorkspaceDeclaration, steps []Step, stepTemplate *StepTemplate) (errs *apis.FieldError) {","\tmountPaths := sets.NewString()","\tfor _, step := range steps {","\t\tfor _, vm := range step.VolumeMounts {","\t\t\tmountPaths.Insert(filepath.Clean(vm.MountPath))","\t\t}","\t}","\tif stepTemplate != nil {","\t\tfor _, vm := range stepTemplate.VolumeMounts {","\t\t\tmountPaths.Insert(filepath.Clean(vm.MountPath))","\t\t}","\t}","","\twsNames := sets.NewString()","\tfor idx, w := range workspaces {","\t\t// Workspace names must be unique","\t\tif wsNames.Has(w.Name) {","\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"workspace name %q must be unique\", w.Name), \"name\").ViaIndex(idx))","\t\t} else {","\t\t\twsNames.Insert(w.Name)","\t\t}","\t\t// Workspaces must not try to use mount paths that are already used","\t\tmountPath := filepath.Clean(w.GetMountPath())","\t\tif _, ok := mountPaths[mountPath]; ok {","\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"workspace mount path %q must be unique\", mountPath), \"mountpath\").ViaIndex(idx))","\t\t}","\t\tmountPaths[mountPath] = struct{}{}","\t}","\treturn errs","}","","// validateWorkspaceUsages checks that all WorkspaceUsage objects in Steps","// refer to workspaces that are defined in the Task.","//","// This is a beta feature and will fail validation if it's used by a step","// or sidecar when the enable-api-fields feature gate is anything but \"beta\".","func validateWorkspaceUsages(ctx context.Context, ts *TaskSpec) (errs *apis.FieldError) {","\tworkspaces := ts.Workspaces","\tsteps := ts.Steps","\tsidecars := ts.Sidecars","","\twsNames := sets.NewString()","\tfor _, w := range workspaces {","\t\twsNames.Insert(w.Name)","\t}","","\tfor stepIdx, step := range steps {","\t\tif len(step.Workspaces) != 0 {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"step workspaces\", config.BetaAPIFields).ViaIndex(stepIdx).ViaField(\"steps\"))","\t\t}","\t\tfor workspaceIdx, w := range step.Workspaces {","\t\t\tif !wsNames.Has(w.Name) {","\t\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"undefined workspace %q\", w.Name), \"name\").ViaIndex(workspaceIdx).ViaField(\"workspaces\").ViaIndex(stepIdx).ViaField(\"steps\"))","\t\t\t}","\t\t}","\t}","","\tfor sidecarIdx, sidecar := range sidecars {","\t\tif len(sidecar.Workspaces) != 0 {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"sidecar workspaces\", config.BetaAPIFields).ViaIndex(sidecarIdx).ViaField(\"sidecars\"))","\t\t}","\t\tfor workspaceIdx, w := range sidecar.Workspaces {","\t\t\tif !wsNames.Has(w.Name) {","\t\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"undefined workspace %q\", w.Name), \"name\").ViaIndex(workspaceIdx).ViaField(\"workspaces\").ViaIndex(sidecarIdx).ViaField(\"sidecars\"))","\t\t\t}","\t\t}","\t}","","\treturn errs","}","","// ValidateVolumes validates a slice of volumes to make sure there are no duplicate names","func ValidateVolumes(volumes []corev1.Volume) (errs *apis.FieldError) {","\t// Task must not have duplicate volume names.","\tvols := sets.NewString()","\tfor idx, v := range volumes {","\t\tif vols.Has(v.Name) {","\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"multiple volumes with same name %q\", v.Name), \"name\").ViaIndex(idx))","\t\t} else {","\t\t\tvols.Insert(v.Name)","\t\t}","\t}","\treturn errs","}","","// Validate implements apis.Validatable","func (l StepList) Validate(ctx context.Context) (errs *apis.FieldError) {","\t// Task must not have duplicate step names.","\tnames := sets.NewString()","\tfor idx, s := range l {","\t\t// names cannot be duplicated - checking that Step names are unique","\t\tif s.Name != \"\" {","\t\t\tif names.Has(s.Name) {","\t\t\t\terrs = errs.Also(apis.ErrMultipleOneOf(\"name\").ViaIndex(idx))","\t\t\t}","\t\t\tnames.Insert(s.Name)","\t\t}","","\t\terrs = errs.Also(s.Validate(ctx).ViaIndex(idx))","\t\tif s.Results != nil {","\t\t\terrs = errs.Also(ValidateStepResultsVariables(ctx, s.Results, s.Script).ViaIndex(idx))","\t\t\terrs = errs.Also(ValidateStepResults(ctx, s.Results).ViaIndex(idx).ViaField(\"results\"))","\t\t}","\t\tif len(s.When) \u003e 0 {","\t\t\terrs = errs.Also(s.When.validate(ctx).ViaIndex(idx))","\t\t}","\t}","\treturn errs","}","","// ValidateStepResults validates that all of the declared StepResults are valid.","func ValidateStepResults(ctx context.Context, results []StepResult) (errs *apis.FieldError) {","\tfor index, result := range results {","\t\terrs = errs.Also(result.Validate(ctx).ViaIndex(index))","\t}","\treturn errs","}","","// ValidateStepResultsVariables validates if the StepResults referenced in step script are defined in step's results.","func ValidateStepResultsVariables(ctx context.Context, results []StepResult, script string) (errs *apis.FieldError) {","\tresultsNames := sets.NewString()","\tfor _, r := range results {","\t\tresultsNames.Insert(r.Name)","\t}","\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(script, \"step.results\", resultsNames).ViaField(\"script\"))","\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(script, \"results\", resultsNames).ViaField(\"script\"))","\treturn errs","}","","func (l SidecarList) Validate(ctx context.Context) (errs *apis.FieldError) {","\tfor _, sc := range l {","\t\terrs = errs.Also(sc.Validate(ctx))","\t}","\treturn errs","}","","// ValidateParameterTypes validates all the types within a slice of ParamSpecs","func ValidateParameterTypes(ctx context.Context, params []ParamSpec) (errs *apis.FieldError) {","\tfor _, p := range params {","\t\terrs = errs.Also(p.ValidateType(ctx))","\t}","\treturn errs","}","","// ValidateType checks that the type of a ParamSpec is allowed and its default value matches that type","func (p ParamSpec) ValidateType(ctx context.Context) *apis.FieldError {","\t// Ensure param has a valid type.","\tvalidType := false","\tfor _, allowedType := range AllParamTypes {","\t\tif p.Type == allowedType {","\t\t\tvalidType = true","\t\t}","\t}","\tif !validType {","\t\treturn apis.ErrInvalidValue(p.Type, p.Name+\".type\")","\t}","","\t// If a default value is provided, ensure its type matches param's declared type.","\tif (p.Default != nil) \u0026\u0026 (p.Default.Type != p.Type) {","\t\treturn \u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(","\t\t\t\t\"\\\"%v\\\" type does not match default value's type: \\\"%v\\\"\", p.Type, p.Default.Type),","\t\t\tPaths: []string{","\t\t\t\tp.Name + \".type\",","\t\t\t\tp.Name + \".default.type\",","\t\t\t},","\t\t}","\t}","","\t// Check object type and its PropertySpec type","\treturn p.ValidateObjectType(ctx)","}","","// ValidateObjectType checks that object type parameter does not miss the","// definition of `properties` section and the type of a PropertySpec is allowed.","// (Currently, only string is allowed)","func (p ParamSpec) ValidateObjectType(ctx context.Context) *apis.FieldError {","\tinvalidKeys := []string{}","\tfor key, propertySpec := range p.Properties {","\t\tif propertySpec.Type != ParamTypeString {","\t\t\tinvalidKeys = append(invalidKeys, key)","\t\t}","\t}","","\tif len(invalidKeys) != 0 {","\t\treturn \u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(\"The value type specified for these keys %v is invalid\", invalidKeys),","\t\t\tPaths:   []string{p.Name + \".properties\"},","\t\t}","\t}","","\treturn nil","}","","// ValidateParameterVariables validates all variables within a slice of ParamSpecs against a slice of Steps","func ValidateParameterVariables(ctx context.Context, steps []Step, params ParamSpecs) *apis.FieldError {","\tvar errs *apis.FieldError","\terrs = errs.Also(params.ValidateNoDuplicateNames())","\terrs = errs.Also(params.validateParamEnums(ctx).ViaField(\"params\"))","\tstringParams, arrayParams, objectParams := params.SortByType()","\tstringParameterNames := sets.NewString(stringParams.GetNames()...)","\tarrayParameterNames := sets.NewString(arrayParams.GetNames()...)","\terrs = errs.Also(ValidateNameFormat(stringParameterNames.Insert(arrayParameterNames.List()...), objectParams))","\treturn errs.Also(validateArrayUsage(steps, \"params\", arrayParameterNames))","}","","// validateTaskContextVariables returns an error if any Steps reference context variables that don't exist.","func validateTaskContextVariables(ctx context.Context, steps []Step) *apis.FieldError {","\ttaskRunContextNames := sets.NewString().Insert(","\t\t\"name\",","\t\t\"namespace\",","\t\t\"uid\",","\t)","\ttaskContextNames := sets.NewString().Insert(","\t\t\"name\",","\t\t\"retry-count\",","\t)","\terrs := validateVariables(ctx, steps, \"context\\\\.taskRun\", taskRunContextNames)","\treturn errs.Also(validateVariables(ctx, steps, \"context\\\\.task\", taskContextNames))","}","","// validateTaskResultsVariables validates if the results referenced in step script are defined in task results","func validateTaskResultsVariables(ctx context.Context, steps []Step, results []TaskResult) (errs *apis.FieldError) {","\tresultsNames := sets.NewString()","\tfor _, r := range results {","\t\tresultsNames.Insert(r.Name)","\t}","\tfor idx, step := range steps {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(step.Script, \"results\", resultsNames).ViaField(\"script\").ViaFieldIndex(\"steps\", idx))","\t}","\treturn errs","}","","// validateObjectUsage validates the usage of individual attributes of an object param and the usage of the entire object","func validateObjectUsage(ctx context.Context, steps []Step, params []ParamSpec) (errs *apis.FieldError) {","\tobjectParameterNames := sets.NewString()","\tfor _, p := range params {","\t\t// collect all names of object type params","\t\tobjectParameterNames.Insert(p.Name)","","\t\t// collect all keys for this object param","\t\tobjectKeys := sets.NewString()","\t\tfor key := range p.Properties {","\t\t\tobjectKeys.Insert(key)","\t\t}","","\t\t// check if the object's key names are referenced correctly i.e. param.objectParam.key1","\t\terrs = errs.Also(validateVariables(ctx, steps, \"params\\\\.\"+p.Name, objectKeys))","\t}","","\treturn errs.Also(validateObjectUsageAsWhole(steps, \"params\", objectParameterNames))","}","","// validateObjectUsageAsWhole returns an error if the Steps contain references to the entire input object params in fields where these references are prohibited","func validateObjectUsageAsWhole(steps []Step, prefix string, vars sets.String) (errs *apis.FieldError) {","\tfor idx, step := range steps {","\t\terrs = errs.Also(validateStepObjectUsageAsWhole(step, prefix, vars)).ViaFieldIndex(\"steps\", idx)","\t}","\treturn errs","}","","// validateStepObjectUsageAsWhole returns an error if the Step contains references to the entire input object params in fields where these references are prohibited","func validateStepObjectUsageAsWhole(step Step, prefix string, vars sets.String) *apis.FieldError {","\terrs := substitution.ValidateNoReferencesToEntireProhibitedVariables(step.Name, prefix, vars).ViaField(\"name\")","\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(step.Image, prefix, vars).ViaField(\"image\"))","\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(step.WorkingDir, prefix, vars).ViaField(\"workingDir\"))","\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(step.Script, prefix, vars).ViaField(\"script\"))","\tfor i, cmd := range step.Command {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(cmd, prefix, vars).ViaFieldIndex(\"command\", i))","\t}","\tfor i, arg := range step.Args {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(arg, prefix, vars).ViaFieldIndex(\"args\", i))","\t}","\tfor _, env := range step.Env {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(env.Value, prefix, vars).ViaFieldKey(\"env\", env.Name))","\t}","\tfor i, v := range step.VolumeMounts {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(v.Name, prefix, vars).ViaField(\"name\").ViaFieldIndex(\"volumeMount\", i))","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(v.MountPath, prefix, vars).ViaField(\"mountPath\").ViaFieldIndex(\"volumeMount\", i))","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(v.SubPath, prefix, vars).ViaField(\"subPath\").ViaFieldIndex(\"volumeMount\", i))","\t}","\treturn errs","}","","// validateArrayUsage returns an error if the Steps contain references to the input array params in fields where these references are prohibited","func validateArrayUsage(steps []Step, prefix string, arrayParamNames sets.String) (errs *apis.FieldError) {","\tfor idx, step := range steps {","\t\terrs = errs.Also(validateStepArrayUsage(step, prefix, arrayParamNames)).ViaFieldIndex(\"steps\", idx)","\t}","\treturn errs","}","","// validateStepArrayUsage returns an error if the Step contains references to the input array params in fields where these references are prohibited","func validateStepArrayUsage(step Step, prefix string, arrayParamNames sets.String) *apis.FieldError {","\terrs := substitution.ValidateNoReferencesToProhibitedVariables(step.Name, prefix, arrayParamNames).ViaField(\"name\")","\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(step.Image, prefix, arrayParamNames).ViaField(\"image\"))","\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(step.WorkingDir, prefix, arrayParamNames).ViaField(\"workingDir\"))","\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(step.Script, prefix, arrayParamNames).ViaField(\"script\"))","\tfor i, cmd := range step.Command {","\t\terrs = errs.Also(substitution.ValidateVariableReferenceIsIsolated(cmd, prefix, arrayParamNames).ViaFieldIndex(\"command\", i))","\t}","\tfor i, arg := range step.Args {","\t\terrs = errs.Also(substitution.ValidateVariableReferenceIsIsolated(arg, prefix, arrayParamNames).ViaFieldIndex(\"args\", i))","\t}","\tfor _, env := range step.Env {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(env.Value, prefix, arrayParamNames).ViaFieldKey(\"env\", env.Name))","\t}","\tfor i, v := range step.VolumeMounts {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(v.Name, prefix, arrayParamNames).ViaField(\"name\").ViaFieldIndex(\"volumeMount\", i))","\t\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(v.MountPath, prefix, arrayParamNames).ViaField(\"mountPath\").ViaFieldIndex(\"volumeMount\", i))","\t\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(v.SubPath, prefix, arrayParamNames).ViaField(\"subPath\").ViaFieldIndex(\"volumeMount\", i))","\t}","\treturn errs","}","","// validateVariables returns an error if the Steps contain references to any unknown variables","func validateVariables(ctx context.Context, steps []Step, prefix string, vars sets.String) (errs *apis.FieldError) {","\tfor idx, step := range steps {","\t\terrs = errs.Also(validateStepVariables(ctx, step, prefix, vars).ViaFieldIndex(\"steps\", idx))","\t}","\treturn errs","}","","// ValidateNameFormat validates that the name format of all param types follows the rules","func ValidateNameFormat(stringAndArrayParams sets.String, objectParams []ParamSpec) (errs *apis.FieldError) {","\t// checking string or array name format","\t// ----","\tinvalidStringAndArrayNames := []string{}","\t// Converting to sorted list here rather than just looping map keys","\t// because we want the order of items in vars to be deterministic for purpose of unit testing","\tfor _, name := range stringAndArrayParams.List() {","\t\tif !stringAndArrayVariableNameFormatRegex.MatchString(name) {","\t\t\tinvalidStringAndArrayNames = append(invalidStringAndArrayNames, name)","\t\t}","\t}","","\tif len(invalidStringAndArrayNames) != 0 {","\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(\"The format of following array and string variable names is invalid: %s\", invalidStringAndArrayNames),","\t\t\tPaths:   []string{\"params\"},","\t\t\tDetails: \"String/Array Names: \\nMust only contain alphanumeric characters, hyphens (-), underscores (_), and dots (.)\\nMust begin with a letter or an underscore (_)\",","\t\t})","\t}","","\t// checking object name and key name format","\t// -----","\tinvalidObjectNames := map[string][]string{}","\tfor _, obj := range objectParams {","\t\t// check object param name","\t\tif !objectVariableNameFormatRegex.MatchString(obj.Name) {","\t\t\tinvalidObjectNames[obj.Name] = []string{}","\t\t}","","\t\t// check key names","\t\tfor k := range obj.Properties {","\t\t\tif !objectVariableNameFormatRegex.MatchString(k) {","\t\t\t\tinvalidObjectNames[obj.Name] = append(invalidObjectNames[obj.Name], k)","\t\t\t}","\t\t}","\t}","","\tif len(invalidObjectNames) != 0 {","\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(\"Object param name and key name format is invalid: %s\", invalidObjectNames),","\t\t\tPaths:   []string{\"params\"},","\t\t\tDetails: \"Object Names: \\nMust only contain alphanumeric characters, hyphens (-), underscores (_) \\nMust begin with a letter or an underscore (_)\",","\t\t})","\t}","","\treturn errs","}","","// validateStepVariables returns an error if the Step contains references to any unknown variables","func validateStepVariables(ctx context.Context, step Step, prefix string, vars sets.String) *apis.FieldError {","\terrs := substitution.ValidateNoReferencesToUnknownVariables(step.Name, prefix, vars).ViaField(\"name\")","\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(step.Image, prefix, vars).ViaField(\"image\"))","\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(step.WorkingDir, prefix, vars).ViaField(\"workingDir\"))","\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(step.Script, prefix, vars).ViaField(\"script\"))","\tfor i, cmd := range step.Command {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(cmd, prefix, vars).ViaFieldIndex(\"command\", i))","\t}","\tfor i, arg := range step.Args {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(arg, prefix, vars).ViaFieldIndex(\"args\", i))","\t}","\tfor _, env := range step.Env {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(env.Value, prefix, vars).ViaFieldKey(\"env\", env.Name))","\t}","\tfor i, v := range step.VolumeMounts {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(v.Name, prefix, vars).ViaField(\"name\").ViaFieldIndex(\"volumeMount\", i))","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(v.MountPath, prefix, vars).ViaField(\"MountPath\").ViaFieldIndex(\"volumeMount\", i))","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(v.SubPath, prefix, vars).ViaField(\"SubPath\").ViaFieldIndex(\"volumeMount\", i))","\t}","\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(string(step.OnError), prefix, vars).ViaField(\"onError\"))","\treturn errs","}","","// GetIndexingReferencesToArrayParams returns all strings referencing indices of TaskRun array parameters","// from parameters, workspaces, and when expressions defined in the Task.","// For example, if a Task has a parameter with a value \"$(params.array-param-name[1])\",","// this would be one of the strings returned.","func (ts *TaskSpec) GetIndexingReferencesToArrayParams() sets.String {","\t// collect all the possible places to use param references","\tparamsRefs := []string{}","\tparamsRefs = append(paramsRefs, extractParamRefsFromSteps(ts.Steps)...)","\tparamsRefs = append(paramsRefs, extractParamRefsFromStepTemplate(ts.StepTemplate)...)","\tparamsRefs = append(paramsRefs, extractParamRefsFromVolumes(ts.Volumes)...)","\tfor _, v := range ts.Workspaces {","\t\tparamsRefs = append(paramsRefs, v.MountPath)","\t}","\tparamsRefs = append(paramsRefs, extractParamRefsFromSidecars(ts.Sidecars)...)","\t// extract all array indexing references, for example []{\"$(params.array-params[1])\"}","\tarrayIndexParamRefs := []string{}","\tfor _, p := range paramsRefs {","\t\tarrayIndexParamRefs = append(arrayIndexParamRefs, extractArrayIndexingParamRefs(p)...)","\t}","\treturn sets.NewString(arrayIndexParamRefs...)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,2,2,2,2,2,1,1,1,1,1,1,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,0,2,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0]},{"id":44,"path":"pkg/apis/pipeline/v1/taskref_types.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","// TaskRef can be used to refer to a specific instance of a task.","type TaskRef struct {","\t// Name of the referent; More info: http://kubernetes.io/docs/user-guide/identifiers#names","\tName string `json:\"name,omitempty\"`","\t// TaskKind indicates the Kind of the Task:","\t// 1. Namespaced Task when Kind is set to \"Task\". If Kind is \"\", it defaults to \"Task\".","\t// 2. Custom Task when Kind is non-empty and APIVersion is non-empty","\tKind TaskKind `json:\"kind,omitempty\"`","\t// API version of the referent","\t// Note: A Task with non-empty APIVersion and Kind is considered a Custom Task","\t// +optional","\tAPIVersion string `json:\"apiVersion,omitempty\"`","","\t// ResolverRef allows referencing a Task in a remote location","\t// like a git repo. This field is only supported when the alpha","\t// feature gate is enabled.","\t// +optional","\tResolverRef `json:\",omitempty\"`","}","","// TaskKind defines the type of Task used by the pipeline.","type TaskKind string","","const (","\t// NamespacedTaskKind indicates that the task type has a namespaced scope.","\tNamespacedTaskKind TaskKind = \"Task\"",")","","// IsCustomTask checks whether the reference is to a Custom Task","func (tr *TaskRef) IsCustomTask() bool {","\t// Note that if `apiVersion` is set to `\"tekton.dev/v1beta1\"` and `kind` is set to `\"Task\"`,","\t// the reference will be considered a Custom Task - https://github.com/tektoncd/pipeline/issues/6457","\treturn tr != nil \u0026\u0026 tr.APIVersion != \"\" \u0026\u0026 tr.Kind != \"\"","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2]},{"id":45,"path":"pkg/apis/pipeline/v1/taskref_validation.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","","\t\"knative.dev/pkg/apis\"",")","","// Validate ensures that a supplied TaskRef field is populated","// correctly. No errors are returned for a nil TaskRef.","func (ref *TaskRef) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif ref == nil {","\t\treturn errs","\t}","\treturn validateRef(ctx, ref.Name, ref.Resolver, ref.Params)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0]},{"id":46,"path":"pkg/apis/pipeline/v1/taskrun_conversion.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","\t\"fmt\"","","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Convertible = (*TaskRun)(nil)","","// ConvertTo implements apis.Convertible","func (tr *TaskRun) ConvertTo(ctx context.Context, sink apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\treturn fmt.Errorf(\"v1 is the highest known version, got: %T\", sink)","}","","// ConvertFrom implements apis.Convertible","func (tr *TaskRun) ConvertFrom(ctx context.Context, source apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\treturn fmt.Errorf(\"v1 is the highest known version, got: %T\", source)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,2,0,0,0,2,2,1,1,2,0]},{"id":47,"path":"pkg/apis/pipeline/v1/taskrun_defaults.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\tpod \"github.com/tektoncd/pipeline/pkg/apis/pipeline/pod\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/kmap\"",")","","var _ apis.Defaultable = (*TaskRun)(nil)","","// ManagedByLabelKey is the label key used to mark what is managing this resource","const ManagedByLabelKey = \"app.kubernetes.io/managed-by\"","","// SetDefaults implements apis.Defaultable","func (tr *TaskRun) SetDefaults(ctx context.Context) {","\tctx = apis.WithinParent(ctx, tr.ObjectMeta)","\ttr.Spec.SetDefaults(ctx)","","\t// Silently filtering out Tekton Reserved annotations at creation","\tif apis.IsInCreate(ctx) {","\t\ttr.ObjectMeta.Annotations = kmap.Filter(tr.ObjectMeta.Annotations, func(s string) bool {","\t\t\treturn filterReservedAnnotationRegexp.MatchString(s)","\t\t})","\t}","","\t// If the TaskRun doesn't have a managed-by label, apply the default","\t// specified in the config.","\tcfg := config.FromContextOrDefaults(ctx)","\tif tr.ObjectMeta.Labels == nil {","\t\ttr.ObjectMeta.Labels = map[string]string{}","\t}","\tif _, found := tr.ObjectMeta.Labels[ManagedByLabelKey]; !found {","\t\ttr.ObjectMeta.Labels[ManagedByLabelKey] = cfg.Defaults.DefaultManagedByLabelValue","\t}","}","","// SetDefaults implements apis.Defaultable","func (trs *TaskRunSpec) SetDefaults(ctx context.Context) {","\tcfg := config.FromContextOrDefaults(ctx)","\tif trs.TaskRef != nil {","\t\tif trs.TaskRef.Name == \"\" \u0026\u0026 trs.TaskRef.Resolver == \"\" {","\t\t\ttrs.TaskRef.Resolver = ResolverName(cfg.Defaults.DefaultResolverType)","\t\t}","\t\tif trs.TaskRef.Kind == \"\" \u0026\u0026 trs.TaskRef.Resolver == \"\" {","\t\t\ttrs.TaskRef.Kind = NamespacedTaskKind","\t\t}","\t}","","\tif trs.Timeout == nil {","\t\ttrs.Timeout = \u0026metav1.Duration{Duration: time.Duration(cfg.Defaults.DefaultTimeoutMinutes) * time.Minute}","\t}","","\tdefaultSA := cfg.Defaults.DefaultServiceAccount","\tif trs.ServiceAccountName == \"\" \u0026\u0026 defaultSA != \"\" {","\t\ttrs.ServiceAccountName = defaultSA","\t}","","\tdefaultPodTemplate := cfg.Defaults.DefaultPodTemplate","\ttrs.PodTemplate = pod.MergePodTemplateWithDefault(trs.PodTemplate, defaultPodTemplate)","","\t// If this taskrun has an embedded task, apply the usual task defaults","\tif trs.TaskSpec != nil {","\t\ttrs.TaskSpec.SetDefaults(ctx)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,2,2,2,2,0,2,2,2,2,2,2,2,0]},{"id":48,"path":"pkg/apis/pipeline/v1/taskrun_types.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\tapisconfig \"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tpipelineErrors \"github.com/tektoncd/pipeline/pkg/apis/pipeline/errors\"","\tpod \"github.com/tektoncd/pipeline/pkg/apis/pipeline/pod\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"","\t\"k8s.io/apimachinery/pkg/types\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"k8s.io/utils/clock\"","\t\"knative.dev/pkg/apis\"","\tduckv1 \"knative.dev/pkg/apis/duck/v1\"",")","","// TaskRunSpec defines the desired state of TaskRun","type TaskRunSpec struct {","\t// +optional","\tDebug *TaskRunDebug `json:\"debug,omitempty\"`","\t// +optional","\tParams Params `json:\"params,omitempty\"`","\t// +optional","\tServiceAccountName string `json:\"serviceAccountName\"`","\t// no more than one of the TaskRef and TaskSpec may be specified.","\t// +optional","\tTaskRef *TaskRef `json:\"taskRef,omitempty\"`","\t// Specifying TaskSpec can be disabled by setting","\t// `disable-inline-spec` feature flag.","\t// See Task.spec (API version: tekton.dev/v1)","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tTaskSpec *TaskSpec `json:\"taskSpec,omitempty\"`","\t// Used for cancelling a TaskRun (and maybe more later on)","\t// +optional","\tStatus TaskRunSpecStatus `json:\"status,omitempty\"`","\t// Status message for cancellation.","\t// +optional","\tStatusMessage TaskRunSpecStatusMessage `json:\"statusMessage,omitempty\"`","\t// Retries represents how many times this TaskRun should be retried in the event of task failure.","\t// +optional","\tRetries int `json:\"retries,omitempty\"`","\t// Time after which one retry attempt times out. Defaults to 1 hour.","\t// Refer Go's ParseDuration documentation for expected format: https://golang.org/pkg/time/#ParseDuration","\t// +optional","\tTimeout *metav1.Duration `json:\"timeout,omitempty\"`","\t// PodTemplate holds pod specific configuration","\tPodTemplate *pod.PodTemplate `json:\"podTemplate,omitempty\"`","\t// Workspaces is a list of WorkspaceBindings from volumes to workspaces.","\t// +optional","\t// +listType=atomic","\tWorkspaces []WorkspaceBinding `json:\"workspaces,omitempty\"`","\t// Specs to apply to Steps in this TaskRun.","\t// If a field is specified in both a Step and a StepSpec,","\t// the value from the StepSpec will be used.","\t// This field is only supported when the alpha feature gate is enabled.","\t// +optional","\t// +listType=atomic","\tStepSpecs []TaskRunStepSpec `json:\"stepSpecs,omitempty\"`","\t// Specs to apply to Sidecars in this TaskRun.","\t// If a field is specified in both a Sidecar and a SidecarSpec,","\t// the value from the SidecarSpec will be used.","\t// This field is only supported when the alpha feature gate is enabled.","\t// +optional","\t// +listType=atomic","\tSidecarSpecs []TaskRunSidecarSpec `json:\"sidecarSpecs,omitempty\"`","\t// Compute resources to use for this TaskRun","\tComputeResources *corev1.ResourceRequirements `json:\"computeResources,omitempty\"`","\t// ManagedBy indicates which controller is responsible for reconciling","\t// this resource. If unset or set to \"tekton.dev/pipeline\", the default","\t// Tekton controller will manage this resource.","\t// This field is immutable.","\t// +optional","\tManagedBy *string `json:\"managedBy,omitempty\"`","}","","// TaskRunSpecStatus defines the TaskRun spec status the user can provide","type TaskRunSpecStatus string","","const (","\t// TaskRunSpecStatusCancelled indicates that the user wants to cancel the task,","\t// if not already cancelled or terminated","\tTaskRunSpecStatusCancelled = \"TaskRunCancelled\"",")","","// TaskRunSpecStatusMessage defines human readable status messages for the TaskRun.","type TaskRunSpecStatusMessage string","","const (","\t// TaskRunCancelledByPipelineMsg indicates that the PipelineRun of which this","\t// TaskRun was a part of has been cancelled.","\tTaskRunCancelledByPipelineMsg TaskRunSpecStatusMessage = \"TaskRun cancelled as the PipelineRun it belongs to has been cancelled.\"","\t// TaskRunCancelledByPipelineTimeoutMsg indicates that the TaskRun was cancelled because the PipelineRun running it timed out.","\tTaskRunCancelledByPipelineTimeoutMsg TaskRunSpecStatusMessage = \"TaskRun cancelled as the PipelineRun it belongs to has timed out.\"",")","","const (","\t// EnabledOnFailureBreakpoint is the value for TaskRunDebug.Breakpoints.OnFailure that means the breakpoint onFailure is enabled","\tEnabledOnFailureBreakpoint = \"enabled\"",")","","// TaskRunDebug defines the breakpoint config for a particular TaskRun","type TaskRunDebug struct {","\t// +optional","\tBreakpoints *TaskBreakpoints `json:\"breakpoints,omitempty\"`","}","","// TaskBreakpoints defines the breakpoint config for a particular Task","type TaskBreakpoints struct {","\t// if enabled, pause TaskRun on failure of a step","\t// failed step will not exit","\t// +optional","\tOnFailure string `json:\"onFailure,omitempty\"`","\t// +optional","\t// +listType=atomic","\tBeforeSteps []string `json:\"beforeSteps,omitempty\"`","}","","// NeedsDebugOnFailure return true if the TaskRun is configured to debug on failure","func (trd *TaskRunDebug) NeedsDebugOnFailure() bool {","\tif trd.Breakpoints == nil {","\t\treturn false","\t}","\treturn trd.Breakpoints.OnFailure == EnabledOnFailureBreakpoint","}","","// NeedsDebugBeforeStep return true if the step is configured to debug before execution","func (trd *TaskRunDebug) NeedsDebugBeforeStep(stepName string) bool {","\tif trd.Breakpoints == nil {","\t\treturn false","\t}","\tbeforeStepSets := sets.NewString(trd.Breakpoints.BeforeSteps...)","\treturn beforeStepSets.Has(stepName)","}","","// StepNeedsDebug return true if the step is configured to debug","func (trd *TaskRunDebug) StepNeedsDebug(stepName string) bool {","\treturn trd.NeedsDebugOnFailure() || trd.NeedsDebugBeforeStep(stepName)","}","","// NeedsDebug return true if defined onfailure or have any before, after steps","func (trd *TaskRunDebug) NeedsDebug() bool {","\treturn trd.NeedsDebugOnFailure() || trd.HaveBeforeSteps()","}","","// HaveBeforeSteps return true if have any before steps","func (trd *TaskRunDebug) HaveBeforeSteps() bool {","\treturn trd.Breakpoints != nil \u0026\u0026 len(trd.Breakpoints.BeforeSteps) \u003e 0","}","","// TaskRunInputs holds the input values that this task was invoked with.","type TaskRunInputs struct {","\t// +optional","\t// +listType=atomic","\tParams Params `json:\"params,omitempty\"`","}","","var taskRunCondSet = apis.NewBatchConditionSet()","","// TaskRunStatus defines the observed state of TaskRun","type TaskRunStatus struct {","\tduckv1.Status `json:\",inline\"`","","\t// TaskRunStatusFields inlines the status fields.","\tTaskRunStatusFields `json:\",inline\"`","}","","// TaskRunReason is an enum used to store all TaskRun reason for","// the Succeeded condition that are controlled by the TaskRun itself. Failure","// reasons that emerge from underlying resources are not included here","type TaskRunReason string","","const (","\t// TaskRunReasonStarted is the reason set when the TaskRun has just started","\tTaskRunReasonStarted TaskRunReason = \"Started\"","\t// TaskRunReasonRunning is the reason set when the TaskRun is running","\tTaskRunReasonRunning TaskRunReason = \"Running\"","\t// TaskRunReasonSuccessful is the reason set when the TaskRun completed successfully","\tTaskRunReasonSuccessful TaskRunReason = \"Succeeded\"","\t// TaskRunReasonFailed is the reason set when the TaskRun completed with a failure","\tTaskRunReasonFailed TaskRunReason = \"Failed\"","\t// TaskRunReasonToBeRetried is the reason set when the last TaskRun execution failed, and will be retried","\tTaskRunReasonToBeRetried TaskRunReason = \"ToBeRetried\"","\t// TaskRunReasonCancelled is the reason set when the TaskRun is cancelled by the user","\tTaskRunReasonCancelled TaskRunReason = \"TaskRunCancelled\"","\t// TaskRunReasonTimedOut is the reason set when one TaskRun execution has timed out","\tTaskRunReasonTimedOut TaskRunReason = \"TaskRunTimeout\"","\t// TaskRunReasonResolvingTaskRef indicates that the TaskRun is waiting for","\t// its taskRef to be asynchronously resolved.","\tTaskRunReasonResolvingTaskRef = \"ResolvingTaskRef\"","\t// TaskRunReasonResolvingStepActionRef indicates that the TaskRun is waiting for","\t// its StepAction's Ref to be asynchronously resolved.","\tTaskRunReasonResolvingStepActionRef = \"ResolvingStepActionRef\"","\t// TaskRunReasonImagePullFailed is the reason set when the step of a task fails due to image not being pulled","\tTaskRunReasonImagePullFailed TaskRunReason = \"TaskRunImagePullFailed\"","\t// TaskRunReasonCreateContainerConfigError is the reason set when the step of a task fails due to config error (e.g., missing ConfigMap or Secret)","\tTaskRunReasonCreateContainerConfigError TaskRunReason = \"CreateContainerConfigError\"","\t// TaskRunReasonPodCreationFailed is the reason set when the pod backing the TaskRun fails to be created (e.g., CreateContainerError)","\tTaskRunReasonPodCreationFailed TaskRunReason = \"PodCreationFailed\"","\t// TaskRunReasonResultLargerThanAllowedLimit is the reason set when one of the results exceeds its maximum allowed limit of 1 KB","\tTaskRunReasonResultLargerThanAllowedLimit TaskRunReason = \"TaskRunResultLargerThanAllowedLimit\"","\t// TaskRunReasonStopSidecarFailed indicates that the sidecar is not properly stopped.","\tTaskRunReasonStopSidecarFailed TaskRunReason = \"TaskRunStopSidecarFailed\"","\t// TaskRunReasonInvalidParamValue indicates that the TaskRun Param input value is not allowed.","\tTaskRunReasonInvalidParamValue TaskRunReason = \"InvalidParamValue\"","\t// TaskRunReasonFailedResolution indicated that the reason for failure status is","\t// that references within the TaskRun could not be resolved","\tTaskRunReasonFailedResolution TaskRunReason = \"TaskRunResolutionFailed\"","\t// TaskRunReasonFailedValidation indicated that the reason for failure status is","\t// that taskrun failed runtime validation","\tTaskRunReasonFailedValidation TaskRunReason = \"TaskRunValidationFailed\"","\t// TaskRunReasonTaskFailedValidation indicated that the reason for failure status is","\t// that task failed runtime validation","\tTaskRunReasonTaskFailedValidation TaskRunReason = \"TaskValidationFailed\"","\t// TaskRunReasonResourceVerificationFailed indicates that the task fails the trusted resource verification,","\t// it could be the content has changed, signature is invalid or public key is invalid","\tTaskRunReasonResourceVerificationFailed TaskRunReason = \"ResourceVerificationFailed\"","\t// TaskRunReasonFailureIgnored is the reason set when the Taskrun has failed due to pod execution error and the failure is ignored for the owning PipelineRun.","\t// TaskRuns failed due to reconciler/validation error should not use this reason.","\tTaskRunReasonFailureIgnored TaskRunReason = \"FailureIgnored\"",")","","func (t TaskRunReason) String() string {","\treturn string(t)","}","","// GetStartedReason returns the reason set to the \"Succeeded\" condition when","// InitializeConditions is invoked","func (trs *TaskRunStatus) GetStartedReason() string {","\treturn TaskRunReasonStarted.String()","}","","// GetRunningReason returns the reason set to the \"Succeeded\" condition when","// the TaskRun starts running. This is used indicate that the resource","// could be validated is starting to perform its job.","func (trs *TaskRunStatus) GetRunningReason() string {","\treturn TaskRunReasonRunning.String()","}","","// MarkResourceOngoing sets the ConditionSucceeded condition to ConditionUnknown","// with the reason and message.","func (trs *TaskRunStatus) MarkResourceOngoing(reason TaskRunReason, message string) {","\ttaskRunCondSet.Manage(trs).SetCondition(apis.Condition{","\t\tType:    apis.ConditionSucceeded,","\t\tStatus:  corev1.ConditionUnknown,","\t\tReason:  reason.String(),","\t\tMessage: message,","\t})","}","","// MarkResourceFailed sets the ConditionSucceeded condition to ConditionFalse","// based on an error that occurred and a reason","func (trs *TaskRunStatus) MarkResourceFailed(reason TaskRunReason, err error) {","\ttaskRunCondSet.Manage(trs).SetCondition(apis.Condition{","\t\tType:    apis.ConditionSucceeded,","\t\tStatus:  corev1.ConditionFalse,","\t\tReason:  reason.String(),","\t\tMessage: pipelineErrors.GetErrorMessage(err),","\t})","\tsucceeded := trs.GetCondition(apis.ConditionSucceeded)","\ttrs.CompletionTime = \u0026succeeded.LastTransitionTime.Inner","}","","// +listType=atomic","type RetriesStatus []TaskRunStatus","","// TaskRunStatusFields holds the fields of TaskRun's status.  This is defined","// separately and inlined so that other types can readily consume these fields","// via duck typing.","type TaskRunStatusFields struct {","\t// PodName is the name of the pod responsible for executing this task's steps.","\tPodName string `json:\"podName\"`","","\t// StartTime is the time the build is actually started.","\tStartTime *metav1.Time `json:\"startTime,omitempty\"`","","\t// CompletionTime is the time the build completed.","\tCompletionTime *metav1.Time `json:\"completionTime,omitempty\"`","","\t// Steps describes the state of each build step container.","\t// +optional","\t// +listType=atomic","\tSteps []StepState `json:\"steps,omitempty\"`","","\t// RetriesStatus contains the history of TaskRunStatus in case of a retry in order to keep record of failures.","\t// All TaskRunStatus stored in RetriesStatus will have no date within the RetriesStatus as is redundant.","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tRetriesStatus RetriesStatus `json:\"retriesStatus,omitempty\"`","","\t// Results are the list of results written out by the task's containers","\t// +optional","\t// +listType=atomic","\tResults []TaskRunResult `json:\"results,omitempty\"`","","\t// Artifacts are the list of artifacts written out by the task's containers","\t// +optional","\tArtifacts *Artifacts `json:\"artifacts,omitempty\"`","","\t// The list has one entry per sidecar in the manifest. Each entry is","\t// represents the imageid of the corresponding sidecar.","\t// +listType=atomic","\tSidecars []SidecarState `json:\"sidecars,omitempty\"`","","\t// TaskSpec contains the Spec from the dereferenced Task definition used to instantiate this TaskRun.","\tTaskSpec *TaskSpec `json:\"taskSpec,omitempty\"`","","\t// Provenance contains some key authenticated metadata about how a software artifact was built (what sources, what inputs/outputs, etc.).","\t// +optional","\tProvenance *Provenance `json:\"provenance,omitempty\"`","","\t// SpanContext contains tracing span context fields","\tSpanContext map[string]string `json:\"spanContext,omitempty\"`","}","","// TaskRunStepSpec is used to override the values of a Step in the corresponding Task.","type TaskRunStepSpec struct {","\t// The name of the Step to override.","\tName string `json:\"name\"`","\t// The resource requirements to apply to the Step.","\tComputeResources corev1.ResourceRequirements `json:\"computeResources\"`","}","","// TaskRunSidecarSpec is used to override the values of a Sidecar in the corresponding Task.","type TaskRunSidecarSpec struct {","\t// The name of the Sidecar to override.","\tName string `json:\"name\"`","\t// The resource requirements to apply to the Sidecar.","\tComputeResources corev1.ResourceRequirements `json:\"computeResources\"`","}","","// GetGroupVersionKind implements kmeta.OwnerRefable.","func (*TaskRun) GetGroupVersionKind() schema.GroupVersionKind {","\treturn SchemeGroupVersion.WithKind(pipeline.TaskRunControllerName)","}","","// GetStatusCondition returns the task run status as a ConditionAccessor","func (tr *TaskRun) GetStatusCondition() apis.ConditionAccessor {","\treturn \u0026tr.Status","}","","// GetCondition returns the Condition matching the given type.","func (trs *TaskRunStatus) GetCondition(t apis.ConditionType) *apis.Condition {","\treturn taskRunCondSet.Manage(trs).GetCondition(t)","}","","// InitializeConditions will set all conditions in taskRunCondSet to unknown for the TaskRun","// and set the started time to the current time","func (trs *TaskRunStatus) InitializeConditions() {","\tstarted := false","\tif trs.StartTime.IsZero() {","\t\ttrs.StartTime = \u0026metav1.Time{Time: time.Now()}","\t\tstarted = true","\t}","\tconditionManager := taskRunCondSet.Manage(trs)","\tconditionManager.InitializeConditions()","\t// Ensure the started reason is set for the \"Succeeded\" condition","\tif started {","\t\tinitialCondition := conditionManager.GetCondition(apis.ConditionSucceeded)","\t\tinitialCondition.Reason = TaskRunReasonStarted.String()","\t\tconditionManager.SetCondition(*initialCondition)","\t}","}","","// SetCondition sets the condition, unsetting previous conditions with the same","// type as necessary.","func (trs *TaskRunStatus) SetCondition(newCond *apis.Condition) {","\tif newCond != nil {","\t\ttaskRunCondSet.Manage(trs).SetCondition(*newCond)","\t}","}","","// StepState reports the results of running a step in a Task.","type StepState struct {","\tcorev1.ContainerState `json:\",inline\"`","\tName                  string                `json:\"name,omitempty\"`","\tContainer             string                `json:\"container,omitempty\"`","\tImageID               string                `json:\"imageID,omitempty\"`","\tResults               []TaskRunStepResult   `json:\"results,omitempty\"`","\tProvenance            *Provenance           `json:\"provenance,omitempty\"`","\tTerminationReason     string                `json:\"terminationReason,omitempty\"`","\tInputs                []TaskRunStepArtifact `json:\"inputs,omitempty\"`","\tOutputs               []TaskRunStepArtifact `json:\"outputs,omitempty\"`","}","","// SidecarState reports the results of running a sidecar in a Task.","type SidecarState struct {","\tcorev1.ContainerState `json:\",inline\"`","\tName                  string `json:\"name,omitempty\"`","\tContainer             string `json:\"container,omitempty\"`","\tImageID               string `json:\"imageID,omitempty\"`","}","","// +genclient","// +genreconciler:krshapedlogic=false","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// TaskRun represents a single execution of a Task. TaskRuns are how the steps","// specified in a Task are executed; they specify the parameters and resources","// used to run the steps in a Task.","//","// +k8s:openapi-gen=true","// +kubebuilder:storageversion","type TaskRun struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ObjectMeta `json:\"metadata,omitempty\"`","","\t// +optional","\tSpec TaskRunSpec `json:\"spec,omitempty\"`","\t// +optional","\tStatus TaskRunStatus `json:\"status,omitempty\"`","}","","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// TaskRunList contains a list of TaskRun","type TaskRunList struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ListMeta `json:\"metadata,omitempty\"`","\tItems           []TaskRun `json:\"items\"`","}","","// GetPipelineRunPVCName for TaskRun gets pipelinerun","func (tr *TaskRun) GetPipelineRunPVCName() string {","\tif tr == nil {","\t\treturn \"\"","\t}","\tfor _, ref := range tr.GetOwnerReferences() {","\t\tif ref.Kind == pipeline.PipelineRunControllerName {","\t\t\treturn ref.Name + \"-pvc\"","\t\t}","\t}","\treturn \"\"","}","","// HasPipelineRunOwnerReference returns true of TaskRun has","// owner reference of type PipelineRun","func (tr *TaskRun) HasPipelineRunOwnerReference() bool {","\tfor _, ref := range tr.GetOwnerReferences() {","\t\tif ref.Kind == pipeline.PipelineRunControllerName {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// IsDone returns true if the TaskRun's status indicates that it is done.","func (tr *TaskRun) IsDone() bool {","\treturn !tr.Status.GetCondition(apis.ConditionSucceeded).IsUnknown()","}","","// HasStarted function check whether TaskRun has valid start time set in its status","func (tr *TaskRun) HasStarted() bool {","\treturn tr.Status.StartTime != nil \u0026\u0026 !tr.Status.StartTime.IsZero()","}","","// IsSuccessful returns true if the TaskRun's status indicates that it has succeeded.","func (tr *TaskRun) IsSuccessful() bool {","\treturn tr != nil \u0026\u0026 tr.Status.GetCondition(apis.ConditionSucceeded).IsTrue()","}","","// IsFailure returns true if the TaskRun's status indicates that it has failed.","func (tr *TaskRun) IsFailure() bool {","\treturn tr != nil \u0026\u0026 tr.Status.GetCondition(apis.ConditionSucceeded).IsFalse()","}","","// IsCancelled returns true if the TaskRun's spec status is set to Cancelled state","func (tr *TaskRun) IsCancelled() bool {","\treturn tr.Spec.Status == TaskRunSpecStatusCancelled","}","","// IsRetriable returns true if the TaskRun's Retries is not exhausted.","func (tr *TaskRun) IsRetriable() bool {","\treturn len(tr.Status.RetriesStatus) \u003c tr.Spec.Retries","}","","// HasTimedOut returns true if the TaskRun runtime is beyond the allowed timeout","func (tr *TaskRun) HasTimedOut(ctx context.Context, c clock.PassiveClock) bool {","\tif tr.Status.StartTime.IsZero() {","\t\treturn false","\t}","\ttimeout := tr.GetTimeout(ctx)","\t// If timeout is set to 0 or defaulted to 0, there is no timeout.","\tif timeout == apisconfig.NoTimeoutDuration {","\t\treturn false","\t}","\truntime := c.Since(tr.Status.StartTime.Time)","\treturn runtime \u003e timeout","}","","// GetTimeout returns the timeout for the TaskRun, or the default if not specified","func (tr *TaskRun) GetTimeout(ctx context.Context) time.Duration {","\t// Use the platform default is no timeout is set","\tif tr.Spec.Timeout == nil {","\t\tdefaultTimeout := time.Duration(config.FromContextOrDefaults(ctx).Defaults.DefaultTimeoutMinutes)","\t\treturn defaultTimeout * time.Minute //nolint:durationcheck","\t}","\treturn tr.Spec.Timeout.Duration","}","","// GetNamespacedName returns a k8s namespaced name that identifies this TaskRun","func (tr *TaskRun) GetNamespacedName() types.NamespacedName {","\treturn types.NamespacedName{Namespace: tr.Namespace, Name: tr.Name}","}","","// HasVolumeClaimTemplate returns true if TaskRun contains volumeClaimTemplates that is","// used for creating PersistentVolumeClaims with an OwnerReference for each run","func (tr *TaskRun) HasVolumeClaimTemplate() bool {","\tfor _, ws := range tr.Spec.Workspaces {","\t\tif ws.VolumeClaimTemplate != nil {","\t\t\treturn true","\t\t}","\t}","\treturn false","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,1,1,1,0,0,0,0,1,1,1,0,0,0,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,0,2,0,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,1,1,1,2,0,0,0,2,2,2,0,0,0,2,2,2,2,2,0,1,0]},{"id":49,"path":"pkg/apis/pipeline/v1/taskrun_validation.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","\t\"fmt\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/pod\"","\t\"github.com/tektoncd/pipeline/pkg/apis/validate\"","\tadmissionregistrationv1 \"k8s.io/api/admissionregistration/v1\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/api/equality\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"k8s.io/utils/strings/slices\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/webhook/resourcesemantics\"",")","","var (","\t_ apis.Validatable              = (*TaskRun)(nil)","\t_ resourcesemantics.VerbLimited = (*TaskRun)(nil)",")","","// SupportedVerbs returns the operations that validation should be called for","func (tr *TaskRun) SupportedVerbs() []admissionregistrationv1.OperationType {","\treturn []admissionregistrationv1.OperationType{admissionregistrationv1.Create, admissionregistrationv1.Update}","}","","// Validate taskrun","func (tr *TaskRun) Validate(ctx context.Context) *apis.FieldError {","\terrs := validate.ObjectMetadata(tr.GetObjectMeta()).ViaField(\"metadata\")","\treturn errs.Also(tr.Spec.Validate(apis.WithinSpec(ctx)).ViaField(\"spec\"))","}","","// Validate taskrun spec","func (ts *TaskRunSpec) Validate(ctx context.Context) (errs *apis.FieldError) {","\t// Validate the spec changes","\terrs = errs.Also(ts.ValidateUpdate(ctx))","","\t// Must have exactly one of taskRef and taskSpec.","\tif ts.TaskRef == nil \u0026\u0026 ts.TaskSpec == nil {","\t\terrs = errs.Also(apis.ErrMissingOneOf(\"taskRef\", \"taskSpec\"))","\t}","\tif ts.TaskRef != nil \u0026\u0026 ts.TaskSpec != nil {","\t\terrs = errs.Also(apis.ErrMultipleOneOf(\"taskRef\", \"taskSpec\"))","\t}","\t// Validate TaskRef if it's present.","\tif ts.TaskRef != nil {","\t\terrs = errs.Also(ts.TaskRef.Validate(ctx).ViaField(\"taskRef\"))","\t}","\t// Validate TaskSpec if it's present.","\tif ts.TaskSpec != nil {","\t\tif slices.Contains(strings.Split(","\t\t\tconfig.FromContextOrDefaults(ctx).FeatureFlags.DisableInlineSpec, \",\"), \"taskrun\") {","\t\t\terrs = errs.Also(apis.ErrDisallowedFields(\"taskSpec\"))","\t\t}","\t\terrs = errs.Also(ts.TaskSpec.Validate(ctx).ViaField(\"taskSpec\"))","\t}","","\terrs = errs.Also(ValidateParameters(ctx, ts.Params).ViaField(\"params\"))","","\t// Validate propagated parameters","\terrs = errs.Also(ts.validateInlineParameters(ctx))","\terrs = errs.Also(ValidateWorkspaceBindings(ctx, ts.Workspaces).ViaField(\"workspaces\"))","\tif ts.Debug != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"debug\", config.AlphaAPIFields).ViaField(\"debug\"))","\t\terrs = errs.Also(validateDebug(ts.Debug).ViaField(\"debug\"))","\t}","\tif ts.StepSpecs != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"stepSpecs\", config.BetaAPIFields).ViaField(\"stepSpecs\"))","\t\terrs = errs.Also(validateStepSpecs(ts.StepSpecs).ViaField(\"stepSpecs\"))","\t}","\tif ts.SidecarSpecs != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"sidecarSpecs\", config.BetaAPIFields).ViaField(\"sidecarSpecs\"))","\t\terrs = errs.Also(validateSidecarSpecs(ts.SidecarSpecs).ViaField(\"sidecarSpecs\"))","\t}","\tif ts.ComputeResources != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"computeResources\", config.BetaAPIFields).ViaField(\"computeResources\"))","\t\terrs = errs.Also(validateTaskRunComputeResources(ts.ComputeResources, ts.StepSpecs))","\t}","","\tif ts.Status != \"\" {","\t\tif ts.Status != TaskRunSpecStatusCancelled {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"%s should be %s\", ts.Status, TaskRunSpecStatusCancelled), \"status\"))","\t\t}","\t}","\tif ts.Status == \"\" {","\t\tif ts.StatusMessage != \"\" {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"statusMessage should not be set if status is not set, but it is currently set to %s\", ts.StatusMessage), \"statusMessage\"))","\t\t}","\t}","\tif ts.Retries \u003c 0 {","\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"%d should be \u003e= 0\", ts.Retries), \"retries\"))","\t}","","\tif ts.PodTemplate != nil {","\t\terrs = errs.Also(validatePodTemplateEnv(ctx, *ts.PodTemplate))","\t}","","\tif ts.Timeout != nil \u0026\u0026 ts.Timeout.Duration \u003c 0 {","\t\terrs = errs.Also(apis.ErrInvalidValue(ts.Timeout.Duration.String()+\" should be \u003e= 0\", \"timeout\"))","\t}","","\treturn errs","}","","// ValidateUpdate validates the update of a TaskRunSpec","func (ts *TaskRunSpec) ValidateUpdate(ctx context.Context) (errs *apis.FieldError) {","\tif !apis.IsInUpdate(ctx) {","\t\treturn","\t}","","\toldObj, ok := apis.GetBaseline(ctx).(*TaskRun)","\tif !ok || oldObj == nil {","\t\treturn","\t}","","\tif (oldObj.Spec.ManagedBy == nil) != (ts.ManagedBy == nil) || (oldObj.Spec.ManagedBy != nil \u0026\u0026 *oldObj.Spec.ManagedBy != *ts.ManagedBy) {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"managedBy is immutable\", \"spec.managedBy\"))","\t}","","\tif oldObj.IsDone() {","\t\t// try comparing without any copying first","\t\t// this handles the common case where only finalizers changed","\t\tif equality.Semantic.DeepEqual(\u0026oldObj.Spec, ts) {","\t\t\treturn nil // Specs identical, allow update","\t\t}","\t\t// Specs differ, this could be due to different defaults after upgrade","\t\t// Apply current defaults to old spec to normalize","\t\toldCopy := oldObj.Spec.DeepCopy()","\t\toldCopy.SetDefaults(ctx)","","\t\tif equality.Semantic.DeepEqual(oldCopy, ts) {","\t\t\treturn nil // Difference was only defaults, allow update","\t\t}","","\t\t// Real spec changes detected, reject update","\t\terrs = errs.Also(apis.ErrInvalidValue(\"Once the TaskRun is complete, no updates are allowed\", \"\"))","\t\treturn errs","\t}","","\t// Handle started but not done case","\told := oldObj.Spec.DeepCopy()","\told.Status = ts.Status","\told.StatusMessage = ts.StatusMessage","\told.ManagedBy = ts.ManagedBy // Already tested before","\tif !equality.Semantic.DeepEqual(old, ts) {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"Once the TaskRun has started, only status and statusMessage updates are allowed\", \"\"))","\t}","\treturn","}","","// validateInlineParameters validates that any parameters called in the","// Task spec are declared in the TaskRun.","// This is crucial for propagated parameters because the parameters could","// be defined under taskRun and then called directly in the task steps.","// In this case, parameters cannot be validated by the underlying taskSpec","// since they may not have the parameters declared because of propagation.","func (ts *TaskRunSpec) validateInlineParameters(ctx context.Context) (errs *apis.FieldError) {","\tif ts.TaskSpec == nil {","\t\treturn errs","\t}","\tparamSpecForValidation := make(map[string]ParamSpec)","\tfor _, p := range ts.Params {","\t\tparamSpecForValidation = createParamSpecFromParam(p, paramSpecForValidation)","\t}","","\tfor _, p := range ts.TaskSpec.Params {","\t\tvar err *apis.FieldError","\t\tparamSpecForValidation, err = combineParamSpec(p, paramSpecForValidation)","\t\tif err != nil {","\t\t\terrs = errs.Also(err)","\t\t}","\t}","\tvar paramSpec []ParamSpec","\tfor _, v := range paramSpecForValidation {","\t\tparamSpec = append(paramSpec, v)","\t}","\tif ts.TaskSpec != nil \u0026\u0026 ts.TaskSpec.Steps != nil {","\t\terrs = errs.Also(ValidateParameterTypes(ctx, paramSpec))","\t\terrs = errs.Also(ValidateParameterVariables(ctx, ts.TaskSpec.Steps, paramSpec))","\t\terrs = errs.Also(ValidateUsageOfDeclaredParameters(ctx, ts.TaskSpec.Steps, paramSpec))","\t}","\treturn errs","}","","func validatePodTemplateEnv(ctx context.Context, podTemplate pod.Template) (errs *apis.FieldError) {","\tforbiddenEnvsConfigured := config.FromContextOrDefaults(ctx).Defaults.DefaultForbiddenEnv","\tif len(forbiddenEnvsConfigured) == 0 {","\t\treturn errs","\t}","\tfor _, pEnv := range podTemplate.Env {","\t\tif slices.Contains(forbiddenEnvsConfigured, pEnv.Name) {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(\"PodTemplate cannot update a forbidden env: \"+pEnv.Name, \"PodTemplate.Env\"))","\t\t}","\t}","\treturn errs","}","","func createParamSpecFromParam(p Param, paramSpecForValidation map[string]ParamSpec) map[string]ParamSpec {","\tvalue := p.Value","\tpSpec := ParamSpec{","\t\tName:    p.Name,","\t\tDefault: \u0026value,","\t\tType:    p.Value.Type,","\t}","\tif p.Value.ObjectVal != nil {","\t\tpSpec.Properties = make(map[string]PropertySpec)","\t\tprop := make(map[string]PropertySpec)","\t\tfor k := range p.Value.ObjectVal {","\t\t\tprop[k] = PropertySpec{Type: ParamTypeString}","\t\t}","\t\tpSpec.Properties = prop","\t}","\tparamSpecForValidation[p.Name] = pSpec","\treturn paramSpecForValidation","}","","func combineParamSpec(p ParamSpec, paramSpecForValidation map[string]ParamSpec) (map[string]ParamSpec, *apis.FieldError) {","\tif pSpec, ok := paramSpecForValidation[p.Name]; ok {","\t\t// Merge defaults with provided values in the taskrun.","\t\tif p.Default != nil \u0026\u0026 p.Default.ObjectVal != nil {","\t\t\tfor k, v := range p.Default.ObjectVal {","\t\t\t\tif pSpec.Default.ObjectVal == nil {","\t\t\t\t\tpSpec.Default.ObjectVal = map[string]string{k: v}","\t\t\t\t} else {","\t\t\t\t\tpSpec.Default.ObjectVal[k] = v","\t\t\t\t}","\t\t\t}","\t\t\t// If Default values of object type are provided then Properties must also be fully declared.","\t\t\tif p.Properties == nil {","\t\t\t\treturn paramSpecForValidation, apis.ErrMissingField(p.Name + \".properties\")","\t\t\t}","\t\t}","","\t\t// Properties must be defined if paramSpec is of object Type","\t\tif pSpec.Type == ParamTypeObject {","\t\t\tif p.Properties == nil {","\t\t\t\treturn paramSpecForValidation, apis.ErrMissingField(p.Name + \".properties\")","\t\t\t}","\t\t\t// Expect Properties to be complete","\t\t\tpSpec.Properties = p.Properties","\t\t}","\t\tparamSpecForValidation[p.Name] = pSpec","\t} else {","\t\t// No values provided by task run but found a paramSpec declaration.","\t\t// Expect it to be fully speced out.","\t\tparamSpecForValidation[p.Name] = p","\t}","\treturn paramSpecForValidation, nil","}","","// validateDebug validates the debug section of the TaskRun.","// if set, onFailure breakpoint must be \"enabled\"","func validateDebug(db *TaskRunDebug) (errs *apis.FieldError) {","\tif db == nil || db.Breakpoints == nil {","\t\treturn errs","\t}","","\tif db.Breakpoints.OnFailure == \"\" {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"onFailure breakpoint is empty, it is only allowed to be set as enabled\", \"breakpoints.onFailure\"))","\t}","","\tif db.Breakpoints.OnFailure != \"\" \u0026\u0026 db.Breakpoints.OnFailure != EnabledOnFailureBreakpoint {","\t\terrs = errs.Also(apis.ErrInvalidValue(db.Breakpoints.OnFailure+\" is not a valid onFailure breakpoint value, onFailure breakpoint is only allowed to be set as enabled\", \"breakpoints.onFailure\"))","\t}","\tbeforeSteps := sets.NewString()","\tfor i, step := range db.Breakpoints.BeforeSteps {","\t\tif beforeSteps.Has(step) {","\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"before step must be unique, the same step: %s is defined multiple times at\", step), fmt.Sprintf(\"breakpoints.beforeSteps[%d]\", i)))","\t\t}","\t\tbeforeSteps.Insert(step)","\t}","\treturn errs","}","","// ValidateWorkspaceBindings makes sure the volumes provided for the Task's declared workspaces make sense.","func ValidateWorkspaceBindings(ctx context.Context, wb []WorkspaceBinding) (errs *apis.FieldError) {","\tvar names []string","\tfor idx, w := range wb {","\t\tnames = append(names, w.Name)","\t\terrs = errs.Also(w.Validate(ctx).ViaIndex(idx))","\t}","\terrs = errs.Also(validateNoDuplicateNames(names, true))","\treturn errs","}","","// ValidateParameters makes sure the params for the Task are valid.","func ValidateParameters(ctx context.Context, params Params) (errs *apis.FieldError) {","\tvar names []string","\tfor _, p := range params {","\t\tnames = append(names, p.Name)","\t}","\treturn errs.Also(validateNoDuplicateNames(names, false))","}","","func validateStepSpecs(specs []TaskRunStepSpec) (errs *apis.FieldError) {","\tvar names []string","\tfor i, o := range specs {","\t\tif o.Name == \"\" {","\t\t\terrs = errs.Also(apis.ErrMissingField(\"name\").ViaIndex(i))","\t\t} else {","\t\t\tnames = append(names, o.Name)","\t\t}","\t}","\terrs = errs.Also(validateNoDuplicateNames(names, true))","\treturn errs","}","","// validateTaskRunComputeResources ensures that compute resources are not configured at both the step level and the task level","func validateTaskRunComputeResources(computeResources *corev1.ResourceRequirements, specs []TaskRunStepSpec) (errs *apis.FieldError) {","\tfor _, spec := range specs {","\t\tif spec.ComputeResources.Size() != 0 \u0026\u0026 computeResources != nil {","\t\t\treturn apis.ErrMultipleOneOf(","\t\t\t\t\"stepSpecs.resources\",","\t\t\t\t\"computeResources\",","\t\t\t)","\t\t}","\t}","\treturn nil","}","","func validateSidecarSpecs(specs []TaskRunSidecarSpec) (errs *apis.FieldError) {","\tvar names []string","\tfor i, o := range specs {","\t\tif o.Name == \"\" {","\t\t\terrs = errs.Also(apis.ErrMissingField(\"name\").ViaIndex(i))","\t\t} else {","\t\t\tnames = append(names, o.Name)","\t\t}","\t}","\terrs = errs.Also(validateNoDuplicateNames(names, true))","\treturn errs","}","","// validateNoDuplicateNames returns an error for each name that is repeated in names.","// Case insensitive.","// If byIndex is true, the error will be reported by index instead of by key.","func validateNoDuplicateNames(names []string, byIndex bool) (errs *apis.FieldError) {","\tseen := sets.NewString()","\tfor i, n := range names {","\t\tif seen.Has(strings.ToLower(n)) {","\t\t\tif byIndex {","\t\t\t\terrs = errs.Also(apis.ErrMultipleOneOf(\"name\").ViaIndex(i))","\t\t\t} else {","\t\t\t\terrs = errs.Also(apis.ErrMultipleOneOf(\"name\").ViaKey(n))","\t\t\t}","\t\t}","\t\tseen.Insert(strings.ToLower(n))","\t}","\treturn errs","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,2,2,2,2,0,2,2,2,0,2,2,2,0,2,2,2,0,2,0,0,0,2,2,2,2,0,2,2,2,2,0,2,2,2,0,2,2,2,2,2,2,0,0,2,2,2,2,1,1,0,0,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,1,1,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,0,0,2,2,1,1,0,2,0,2,2,2,2,2,2,2,0,0,0,0,2,2,1,1,0,2,2,2,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,2,2,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,0,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,0,2,0]},{"id":50,"path":"pkg/apis/pipeline/v1/types/artifacts_types.go","lines":["/*","Copyright 2025 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package types","","import (","\t\"github.com/google/go-cmp/cmp\"",")","","// Algorithm Standard cryptographic hash algorithm","type Algorithm string","","// Artifact represents an artifact within a system, potentially containing multiple values","// associated with it.","type Artifact struct {","\t// The artifact's identifying category name","\tName string `json:\"name,omitempty\"`","\t// A collection of values related to the artifact","\tValues []ArtifactValue `json:\"values,omitempty\"`","\t// Indicate if the artifact is a build output or a by-product","\tBuildOutput bool `json:\"buildOutput,omitempty\"`","}","","// ArtifactValue represents a specific value or data element within an Artifact.","type ArtifactValue struct {","\tDigest map[Algorithm]string `json:\"digest,omitempty\"` // Algorithm-specific digests for verifying the content (e.g., SHA256)","\tUri    string               `json:\"uri,omitempty\"`    // Location where the artifact value can be retrieved","}","","// TaskRunStepArtifact represents an artifact produced or used by a step within a task run.","// It directly uses the Artifact type for its structure.","type TaskRunStepArtifact = Artifact","","// Artifacts represents the collection of input and output artifacts associated with","// a task run or a similar process. Artifacts in this context are units of data or resources","// that the process either consumes as input or produces as output.","type Artifacts struct {","\tInputs  []Artifact `json:\"inputs,omitempty\"`","\tOutputs []Artifact `json:\"outputs,omitempty\"`","}","","func (a *Artifacts) Merge(another *Artifacts) {","\tinputMap := make(map[string][]ArtifactValue)","\tvar newInputs []Artifact","","\tfor _, v := range a.Inputs {","\t\tinputMap[v.Name] = v.Values","\t}","\tif another != nil {","\t\tfor _, v := range another.Inputs {","\t\t\t_, ok := inputMap[v.Name]","\t\t\tif !ok {","\t\t\t\tinputMap[v.Name] = []ArtifactValue{}","\t\t\t}","\t\t\tfor _, vv := range v.Values {","\t\t\t\texists := false","\t\t\t\tfor _, av := range inputMap[v.Name] {","\t\t\t\t\tif cmp.Equal(vv, av) {","\t\t\t\t\t\texists = true","\t\t\t\t\t\tbreak","\t\t\t\t\t}","\t\t\t\t}","\t\t\t\tif !exists {","\t\t\t\t\tinputMap[v.Name] = append(inputMap[v.Name], vv)","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\tfor k, v := range inputMap {","\t\tnewInputs = append(newInputs, Artifact{","\t\t\tName:   k,","\t\t\tValues: v,","\t\t})","\t}","","\toutputMap := make(map[string]Artifact)","\tvar newOutputs []Artifact","\tfor _, v := range a.Outputs {","\t\toutputMap[v.Name] = v","\t}","","\tif another != nil {","\t\tfor _, v := range another.Outputs {","\t\t\t_, ok := outputMap[v.Name]","\t\t\tif !ok {","\t\t\t\toutputMap[v.Name] = Artifact{Name: v.Name, Values: []ArtifactValue{}, BuildOutput: v.BuildOutput}","\t\t\t}","\t\t\t// only update buildOutput to true.","\t\t\t// Do not convert to false if it was true before.","\t\t\tif v.BuildOutput {","\t\t\t\tart := outputMap[v.Name]","\t\t\t\tart.BuildOutput = v.BuildOutput","\t\t\t\toutputMap[v.Name] = art","\t\t\t}","\t\t\tfor _, vv := range v.Values {","\t\t\t\texists := false","\t\t\t\tfor _, av := range outputMap[v.Name].Values {","\t\t\t\t\tif cmp.Equal(vv, av) {","\t\t\t\t\t\texists = true","\t\t\t\t\t\tbreak","\t\t\t\t\t}","\t\t\t\t}","\t\t\t\tif !exists {","\t\t\t\t\tart := outputMap[v.Name]","\t\t\t\t\tart.Values = append(art.Values, vv)","\t\t\t\t\toutputMap[v.Name] = art","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\tfor _, v := range outputMap {","\t\tnewOutputs = append(newOutputs, Artifact{","\t\t\tName:        v.Name,","\t\t\tValues:      v.Values,","\t\t\tBuildOutput: v.BuildOutput,","\t\t})","\t}","\ta.Inputs = newInputs","\ta.Outputs = newOutputs","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,0,0,0,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,1,1,1,0]},{"id":51,"path":"pkg/apis/pipeline/v1/types/param_types.go","lines":["/*","Copyright 2025 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package types","","import (","\t\"encoding/json\"","\t\"strings\"",")","","// ParamType indicates the type of an input parameter;","// Used to distinguish between a single string and an array of strings.","type ParamType string","","// Valid ParamTypes:","const (","\tParamTypeString ParamType = \"string\"","\tParamTypeArray  ParamType = \"array\"","\tParamTypeObject ParamType = \"object\"",")","","// AllParamTypes can be used for ParamType validation.","var AllParamTypes = []ParamType{ParamTypeString, ParamTypeArray, ParamTypeObject}","","// ParamValues is modeled after IntOrString in kubernetes/apimachinery:","","// ParamValue is a type that can hold a single string, string array, or string map.","// Used in JSON unmarshalling so that a single JSON field can accept","// either an individual string or an array of strings.","type ParamValue struct {","\tType      ParamType // Represents the stored type of ParamValues.","\tStringVal string","\t// +listType=atomic","\tArrayVal  []string","\tObjectVal map[string]string","}","","// PropertySpec defines the struct for object keys","type PropertySpec struct {","\tType ParamType `json:\"type,omitempty\"`","}","","// ParamsPrefix is the prefix used in $(...) expressions referring to parameters","const ParamsPrefix = \"params\"","","// ArrayReference returns the name of the parameter from array parameter reference","// returns arrayParam from $(params.arrayParam[*])","func ArrayReference(a string) string {","\treturn strings.TrimSuffix(strings.TrimPrefix(a, \"$(\"+ParamsPrefix+\".\"), \"[*])\")","}","","// UnmarshalJSON implements the json.Unmarshaller interface.","func (paramValues *ParamValue) UnmarshalJSON(value []byte) error {","\t// ParamValues is used for Results Value as well, the results can be any kind of","\t// data so we need to check if it is empty.","\tif len(value) == 0 {","\t\tparamValues.Type = ParamTypeString","\t\treturn nil","\t}","\tif value[0] == '[' {","\t\t// We're trying to Unmarshal to []string, but for cases like []int or other types","\t\t// of nested array which we don't support yet, we should continue and Unmarshal","\t\t// it to String. If the Type being set doesn't match what it actually should be,","\t\t// it will be captured by validation in reconciler.","\t\t// if failed to unmarshal to array, we will convert the value to string and marshal it to string","\t\tvar a []string","\t\tif err := json.Unmarshal(value, \u0026a); err == nil {","\t\t\tparamValues.Type = ParamTypeArray","\t\t\tparamValues.ArrayVal = a","\t\t\treturn nil","\t\t}","\t}","\tif value[0] == '{' {","\t\t// if failed to unmarshal to map, we will convert the value to string and marshal it to string","\t\tvar m map[string]string","\t\tif err := json.Unmarshal(value, \u0026m); err == nil {","\t\t\tparamValues.Type = ParamTypeObject","\t\t\tparamValues.ObjectVal = m","\t\t\treturn nil","\t\t}","\t}","","\t// By default we unmarshal to string","\tparamValues.Type = ParamTypeString","\tif err := json.Unmarshal(value, \u0026paramValues.StringVal); err == nil {","\t\treturn nil","\t}","\tparamValues.StringVal = string(value)","","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,1,0]},{"id":52,"path":"pkg/apis/pipeline/v1/types/result_types.go","lines":["/*","Copyright 2025 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package types","","import \"strings\"","","// TaskResult used to describe the results of a task","type TaskResult struct {","\t// Name the given name","\tName string `json:\"name\"`","","\t// Type is the user-specified type of the result. The possible type","\t// is currently \"string\" and will support \"array\" in following work.","\t// +optional","\tType ResultsType `json:\"type,omitempty\"`","","\t// Properties is the JSON Schema properties to support key-value pairs results.","\t// +optional","\tProperties map[string]PropertySpec `json:\"properties,omitempty\"`","","\t// Description is a human-readable description of the result","\t// +optional","\tDescription string `json:\"description,omitempty\"`","","\t// Value the expression used to retrieve the value of the result from an underlying Step.","\t// +optional","\tValue *ResultValue `json:\"value,omitempty\"`","}","","// StepResult used to describe the Results of a Step.","type StepResult struct {","\t// Name the given name","\tName string `json:\"name\"`","","\t// The possible types are 'string', 'array', and 'object', with 'string' as the default.","\t// +optional","\tType ResultsType `json:\"type,omitempty\"`","","\t// Properties is the JSON Schema properties to support key-value pairs results.","\t// +optional","\tProperties map[string]PropertySpec `json:\"properties,omitempty\"`","","\t// Description is a human-readable description of the result","\t// +optional","\tDescription string `json:\"description,omitempty\"`","}","","// TaskRunResult used to describe the results of a task","type TaskRunResult struct {","\t// Name the given name","\tName string `json:\"name\"`","","\t// Type is the user-specified type of the result. The possible type","\t// is currently \"string\" and will support \"array\" in following work.","\t// +optional","\tType ResultsType `json:\"type,omitempty\"`","","\t// Value the given value of the result","\tValue ResultValue `json:\"value\"`","}","","// TaskRunStepResult is a type alias of TaskRunResult","type TaskRunStepResult = TaskRunResult","","// ResultValue is a type alias of ParamValue","type ResultValue = ParamValue","","// ResultsType indicates the type of a result;","// Used to distinguish between a single string and an array of strings.","// Note that there is ResultType used to find out whether a","// RunResult is from a task result or not, which is different from","// this ResultsType.","type ResultsType string","","// Valid ResultsType:","const (","\tResultsTypeString ResultsType = \"string\"","\tResultsTypeArray  ResultsType = \"array\"","\tResultsTypeObject ResultsType = \"object\"",")","","// AllResultsTypes can be used for ResultsTypes validation.","var AllResultsTypes = []ResultsType{ResultsTypeString, ResultsTypeArray, ResultsTypeObject}","","// ResultsArrayReference returns the reference of the result. e.g. results.resultname from $(results.resultname[*])","func ResultsArrayReference(a string) string {","\treturn strings.TrimSuffix(strings.TrimSuffix(strings.TrimPrefix(a, \"$(\"), \")\"), \"[*]\")","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1]},{"id":53,"path":"pkg/apis/pipeline/v1/types/resultsref.go","lines":["/*","Copyright 2025 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package types","","import (","\t\"regexp\"","\t\"strings\"",")","","const (","\t// TODO(#2462) use one regex across all substitutions","\t// variableSubstitutionFormat matches format like $result.resultname, $result.resultname[int] and $result.resultname[*]","\tvariableSubstitutionFormat = `\\$\\([_a-zA-Z0-9.-]+(\\.[_a-zA-Z0-9.-]+)*(\\[([0-9]+|\\*)\\])?\\)`",")","","// VariableSubstitutionRegex is a regex to find all result matching substitutions","var VariableSubstitutionRegex = regexp.MustCompile(variableSubstitutionFormat)","","func stripVarSubExpression(expression string) string {","\treturn strings.TrimSuffix(strings.TrimPrefix(expression, \"$(\"), \")\")","}","","func validateString(value string) []string {","\texpressions := VariableSubstitutionRegex.FindAllString(value, -1)","\tif expressions == nil {","\t\treturn nil","\t}","\tvar result []string","\tfor _, expression := range expressions {","\t\tresult = append(result, stripVarSubExpression(expression))","\t}","\treturn result","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0]},{"id":54,"path":"pkg/apis/pipeline/v1/types/when_types.go","lines":["/*","Copyright 2025 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package types","","import (","\t\"fmt\"","","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\t\"k8s.io/apimachinery/pkg/selection\"",")","","// WhenExpression allows a PipelineTask to declare expressions to be evaluated before the Task is run","// to determine whether the Task should be executed or skipped","type WhenExpression struct {","\t// Input is the string for guard checking which can be a static input or an output from a parent Task","\tInput string `json:\"input,omitempty\"`","","\t// Operator that represents an Input's relationship to the values","\tOperator selection.Operator `json:\"operator,omitempty\"`","","\t// Values is an array of strings, which is compared against the input, for guard checking","\t// It must be non-empty","\t// +listType=atomic","\tValues []string `json:\"values,omitempty\"`","","\t// CEL is a string of Common Language Expression, which can be used to conditionally execute","\t// the task based on the result of the expression evaluation","\t// More info about CEL syntax: https://github.com/google/cel-spec/blob/master/doc/langdef.md","\t// +optional","\tCEL string `json:\"cel,omitempty\"`","}","","func (we *WhenExpression) isInputInValues() bool {","\tfor i := range we.Values {","\t\tif we.Values[i] == we.Input {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","func (we *WhenExpression) isTrue() bool {","\tif we.Operator == selection.In {","\t\treturn we.isInputInValues()","\t}","\t// selection.NotIn","\treturn !we.isInputInValues()","}","","func (we *WhenExpression) applyReplacements(replacements map[string]string, arrayReplacements map[string][]string) WhenExpression {","\treplacedInput := substitution.ApplyReplacements(we.Input, replacements)","\treplacedCEL := substitution.ApplyReplacements(we.CEL, replacements)","","\tvar replacedValues []string","\tfor _, val := range we.Values {","\t\t// arrayReplacements holds a list of array parameters with a pattern - params.arrayParam1","\t\t// array params are referenced using $(params.arrayParam1[*])","\t\t// array results are referenced using $(results.resultname[*])","\t\t// check if the param exist in the arrayReplacements to replace it with a list of values","\t\tif _, ok := arrayReplacements[fmt.Sprintf(\"%s.%s\", ParamsPrefix, ArrayReference(val))]; ok {","\t\t\treplacedValues = append(replacedValues, substitution.ApplyArrayReplacements(val, replacements, arrayReplacements)...)","\t\t} else if _, ok := arrayReplacements[ResultsArrayReference(val)]; ok {","\t\t\treplacedValues = append(replacedValues, substitution.ApplyArrayReplacements(val, replacements, arrayReplacements)...)","\t\t} else {","\t\t\treplacedValues = append(replacedValues, substitution.ApplyReplacements(val, replacements))","\t\t}","\t}","","\treturn WhenExpression{Input: replacedInput, Operator: we.Operator, Values: replacedValues, CEL: replacedCEL}","}","","// GetVarSubstitutionExpressions extracts all the values between \"$(\" and \")\" in a When Expression","func (we *WhenExpression) GetVarSubstitutionExpressions() ([]string, bool) {","\tvar allExpressions []string","\tallExpressions = append(allExpressions, validateString(we.Input)...)","\tallExpressions = append(allExpressions, validateString(we.CEL)...)","\tfor _, value := range we.Values {","\t\tallExpressions = append(allExpressions, validateString(value)...)","\t}","\treturn allExpressions, len(allExpressions) != 0","}","","// WhenExpressions are used to specify whether a Task should be executed or skipped","// All of them need to evaluate to True for a guarded Task to be executed.","type WhenExpressions []WhenExpression","","type StepWhenExpressions = WhenExpressions","","// AllowsExecution evaluates an Input's relationship to an array of Values, based on the Operator,","// to determine whether all the When Expressions are True. If they are all True, the guarded Task is","// executed, otherwise it is skipped.","// If CEL expression exists, AllowsExecution will get the evaluated results from evaluatedCEL and determine","// if the Task should be skipped.","func (wes WhenExpressions) AllowsExecution(evaluatedCEL map[string]bool) bool {","\tfor _, we := range wes {","\t\tif !we.isTrue() || (we.CEL != \"\" \u0026\u0026 !evaluatedCEL[we.CEL]) {","\t\t\treturn false","\t\t}","\t}","\treturn true","}","","// ReplaceVariables interpolates variables, such as Parameters and Results, in","// the Input and Values.","func (wes WhenExpressions) ReplaceVariables(replacements map[string]string, arrayReplacements map[string][]string) WhenExpressions {","\treplaced := wes","\tfor i := range wes {","\t\treplaced[i] = wes[i].applyReplacements(replacements, arrayReplacements)","\t}","\treturn replaced","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,1,0,0,1,1,1,1,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,1,0,0,0,0,1,1,1,1,1,1,0]},{"id":55,"path":"pkg/apis/pipeline/v1/when_types.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"encoding/json\"","\t\"fmt\"","","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\t\"k8s.io/apimachinery/pkg/selection\"",")","","// WhenExpression allows a PipelineTask to declare expressions to be evaluated before the Task is run","// to determine whether the Task should be executed or skipped","type WhenExpression struct {","\t// Input is the string for guard checking which can be a static input or an output from a parent Task","\tInput string `json:\"input,omitempty\"`","","\t// Operator that represents an Input's relationship to the values","\tOperator selection.Operator `json:\"operator,omitempty\"`","","\t// Values is an array of strings, which is compared against the input, for guard checking","\t// It must be non-empty","\t// +listType=atomic","\tValues []string `json:\"values,omitempty\"`","","\t// CEL is a string of Common Language Expression, which can be used to conditionally execute","\t// the task based on the result of the expression evaluation","\t// More info about CEL syntax: https://github.com/google/cel-spec/blob/master/doc/langdef.md","\t// +optional","\tCEL string `json:\"cel,omitempty\"`","}","","func (we *WhenExpression) isInputInValues() bool {","\tfor i := range we.Values {","\t\tif we.Values[i] == we.Input {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","func (we *WhenExpression) isTrue() bool {","\tif we.Operator == selection.In {","\t\treturn we.isInputInValues()","\t}","\t// selection.NotIn","\treturn !we.isInputInValues()","}","","func (we *WhenExpression) applyReplacements(replacements map[string]string, arrayReplacements map[string][]string) WhenExpression {","\treplacedInput := applyReplacementsAsString(we.Input, replacements, arrayReplacements)","\treplacedCEL := substitution.ApplyReplacements(we.CEL, replacements)","","\tvar replacedValues []string","\tfor _, val := range we.Values {","\t\t// arrayReplacements holds a list of array parameters with a pattern - params.arrayParam1","\t\t// array params are referenced using $(params.arrayParam1[*])","\t\t// array results are referenced using $(results.resultname[*])","\t\t// check if the param exist in the arrayReplacements to replace it with a list of values","\t\tif _, ok := arrayReplacements[fmt.Sprintf(\"%s.%s\", ParamsPrefix, ArrayReference(val))]; ok {","\t\t\treplacedValues = append(replacedValues, substitution.ApplyArrayReplacements(val, replacements, arrayReplacements)...)","\t\t} else if _, ok := arrayReplacements[ResultsArrayReference(val)]; ok {","\t\t\treplacedValues = append(replacedValues, substitution.ApplyArrayReplacements(val, replacements, arrayReplacements)...)","\t\t} else {","\t\t\treplacedValues = append(replacedValues, substitution.ApplyReplacements(val, replacements))","\t\t}","\t}","","\treturn WhenExpression{Input: replacedInput, Operator: we.Operator, Values: replacedValues, CEL: replacedCEL}","}","","func applyReplacementsAsString(s string, replacements map[string]string, arrayReplacements map[string][]string) string {","\tif _, ok := arrayReplacements[fmt.Sprintf(\"%s.%s\", ParamsPrefix, ArrayReference(s))]; ok {","\t\tb, err := json.Marshal(substitution.ApplyArrayReplacements(s, replacements, arrayReplacements))","\t\tif err != nil {","\t\t\treturn s","\t\t}","\t\treturn string(b)","\t}","","\tif _, ok := arrayReplacements[ResultsArrayReference(s)]; ok {","\t\tb, err := json.Marshal(substitution.ApplyArrayReplacements(s, replacements, arrayReplacements))","\t\tif err != nil {","\t\t\treturn s","\t\t}","\t\treturn string(b)","\t}","","\treturn substitution.ApplyReplacements(s, replacements)","}","","// GetVarSubstitutionExpressions extracts all the values between \"$(\" and \")\" in a When Expression","func (we *WhenExpression) GetVarSubstitutionExpressions() ([]string, bool) {","\tvar allExpressions []string","\tallExpressions = append(allExpressions, validateString(we.Input)...)","\tallExpressions = append(allExpressions, validateString(we.CEL)...)","\tfor _, value := range we.Values {","\t\tallExpressions = append(allExpressions, validateString(value)...)","\t}","\treturn allExpressions, len(allExpressions) != 0","}","","// WhenExpressions are used to specify whether a Task should be executed or skipped","// All of them need to evaluate to True for a guarded Task to be executed.","type WhenExpressions []WhenExpression","","type StepWhenExpressions = WhenExpressions","","// AllowsExecution evaluates an Input's relationship to an array of Values, based on the Operator,","// to determine whether all the When Expressions are True. If they are all True, the guarded Task is","// executed, otherwise it is skipped.","// If CEL expression exists, AllowsExecution will get the evaluated results from evaluatedCEL and determine","// if the Task should be skipped.","func (wes WhenExpressions) AllowsExecution(evaluatedCEL map[string]bool) bool {","\tfor _, we := range wes {","\t\tif !we.isTrue() || (we.CEL != \"\" \u0026\u0026 !evaluatedCEL[we.CEL]) {","\t\t\treturn false","\t\t}","\t}","\treturn true","}","","// ReplaceVariables interpolates variables, such as Parameters and Results, in","// the Input and Values.","func (wes WhenExpressions) ReplaceVariables(replacements map[string]string, arrayReplacements map[string][]string) WhenExpressions {","\treplaced := wes","\tfor i := range wes {","\t\treplaced[i] = wes[i].applyReplacements(replacements, arrayReplacements)","\t}","\treturn replaced","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,2,0,0,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,1,1,2,0,0,2,2,2,1,1,2,0,0,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,0]},{"id":56,"path":"pkg/apis/pipeline/v1/when_validation.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","\t\"fmt\"","\t\"strings\"","","\t\"github.com/google/cel-go/cel\"","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"k8s.io/apimachinery/pkg/api/equality\"","\t\"k8s.io/apimachinery/pkg/selection\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"knative.dev/pkg/apis\"",")","","var validWhenOperators = []string{","\tstring(selection.In),","\tstring(selection.NotIn),","}","","func (wes WhenExpressions) validate(ctx context.Context) *apis.FieldError {","\treturn wes.validateWhenExpressionsFields(ctx).ViaField(\"when\")","}","","func (wes WhenExpressions) validateWhenExpressionsFields(ctx context.Context) (errs *apis.FieldError) {","\tfor idx, we := range wes {","\t\terrs = errs.Also(we.validateWhenExpressionFields(ctx).ViaIndex(idx))","\t}","\treturn errs","}","","func (we *WhenExpression) validateWhenExpressionFields(ctx context.Context) *apis.FieldError {","\tif we.CEL != \"\" {","\t\tif !config.FromContextOrDefaults(ctx).FeatureFlags.EnableCELInWhenExpression {","\t\t\treturn apis.ErrGeneric(fmt.Sprintf(\"feature flag %s should be set to true to use CEL: %s in WhenExpression\", config.EnableCELInWhenExpression, we.CEL), \"\")","\t\t}","\t\tif we.Input != \"\" || we.Operator != \"\" || len(we.Values) != 0 {","\t\t\treturn apis.ErrGeneric(fmt.Sprintf(\"cel and input+operator+values cannot be set in one WhenExpression: %v\", we))","\t\t}","","\t\t// We need to compile the CEL expression and check if it is a valid expression","\t\t// note that at the validation webhook, Tekton's variables are not substituted,","\t\t// so they need to be wrapped with single quotes.","\t\t// e.g.  This is a valid CEL expression: '$(params.foo)' == 'foo';","\t\t//       But this is not a valid expression since CEL cannot recognize: $(params.foo) == 'foo';","\t\t//       This is not valid since we don't pass params to CEL's environment: params.foo == 'foo';","\t\tenv, _ := cel.NewEnv()","\t\t_, iss := env.Compile(we.CEL)","\t\tif iss.Err() != nil {","\t\t\treturn apis.ErrGeneric(\"invalid cel expression: %s with err: %s\", we.CEL, iss.Err().Error())","\t\t}","\t\treturn nil","\t}","","\tif equality.Semantic.DeepEqual(we, \u0026WhenExpression{}) || we == nil {","\t\treturn apis.ErrMissingField(apis.CurrentField)","\t}","\tif !sets.NewString(validWhenOperators...).Has(string(we.Operator)) {","\t\tmessage := fmt.Sprintf(\"operator %q is not recognized. valid operators: %s\", we.Operator, strings.Join(validWhenOperators, \",\"))","\t\treturn apis.ErrInvalidValue(message, apis.CurrentField)","\t}","\tif len(we.Values) == 0 {","\t\treturn apis.ErrInvalidValue(\"expecting non-empty values field\", apis.CurrentField)","\t}","\treturn nil","}","","func (wes WhenExpressions) validatePipelineParametersVariables(prefix string, paramNames sets.String, arrayParamNames sets.String, objectParamNameKeys map[string][]string) (errs *apis.FieldError) {","\tfor idx, we := range wes {","\t\terrs = errs.Also(validateStringVariable(we.Input, prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaField(\"input\").ViaFieldIndex(\"when\", idx))","\t\tfor _, val := range we.Values {","\t\t\t// one of the values could be a reference to an array param, such as, $(params.foo[*])","\t\t\t// extract the variable name from the pattern $(params.foo[*]), if the variable name matches with one of the array params","\t\t\t// validate the param as an array variable otherwise, validate it as a string variable","\t\t\tif arrayParamNames.Has(ArrayReference(val)) {","\t\t\t\terrs = errs.Also(validateArrayVariable(val, prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaField(\"values\").ViaFieldIndex(\"when\", idx))","\t\t\t} else {","\t\t\t\terrs = errs.Also(validateStringVariable(val, prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaField(\"values\").ViaFieldIndex(\"when\", idx))","\t\t\t}","\t\t}","\t}","\treturn errs","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0]},{"id":57,"path":"pkg/apis/pipeline/v1/workspace_types.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"path/filepath\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tcorev1 \"k8s.io/api/core/v1\"",")","","// WorkspaceDeclaration is a declaration of a volume that a Task requires.","type WorkspaceDeclaration struct {","\t// Name is the name by which you can bind the volume at runtime.","\tName string `json:\"name\"`","\t// Description is an optional human readable description of this volume.","\t// +optional","\tDescription string `json:\"description,omitempty\"`","\t// MountPath overrides the directory that the volume will be made available at.","\t// +optional","\tMountPath string `json:\"mountPath,omitempty\"`","\t// ReadOnly dictates whether a mounted volume is writable. By default this","\t// field is false and so mounted volumes are writable.","\tReadOnly bool `json:\"readOnly,omitempty\"`","\t// Optional marks a Workspace as not being required in TaskRuns. By default","\t// this field is false and so declared workspaces are required.","\tOptional bool `json:\"optional,omitempty\"`","}","","// GetMountPath returns the mountPath for w which is the MountPath if provided or the","// default if not.","func (w *WorkspaceDeclaration) GetMountPath() string {","\tif w.MountPath != \"\" {","\t\treturn w.MountPath","\t}","\treturn filepath.Join(pipeline.WorkspaceDir, w.Name)","}","","// WorkspaceBinding maps a Task's declared workspace to a Volume.","type WorkspaceBinding struct {","\t// Name is the name of the workspace populated by the volume.","\tName string `json:\"name\"`","\t// SubPath is optionally a directory on the volume which should be used","\t// for this binding (i.e. the volume will be mounted at this sub directory).","\t// +optional","\tSubPath string `json:\"subPath,omitempty\"`","\t// VolumeClaimTemplate is a template for a claim that will be created in the same namespace.","\t// The PipelineRun controller is responsible for creating a unique claim for each instance of PipelineRun.","\t// See PersistentVolumeClaim (API version: v1)","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tVolumeClaimTemplate *corev1.PersistentVolumeClaim `json:\"volumeClaimTemplate,omitempty\"`","\t// PersistentVolumeClaimVolumeSource represents a reference to a","\t// PersistentVolumeClaim in the same namespace. Either this OR EmptyDir can be used.","\t// +optional","\tPersistentVolumeClaim *corev1.PersistentVolumeClaimVolumeSource `json:\"persistentVolumeClaim,omitempty\"`","\t// EmptyDir represents a temporary directory that shares a Task's lifetime.","\t// More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir","\t// Either this OR PersistentVolumeClaim can be used.","\t// +optional","\tEmptyDir *corev1.EmptyDirVolumeSource `json:\"emptyDir,omitempty\"`","\t// ConfigMap represents a configMap that should populate this workspace.","\t// +optional","\tConfigMap *corev1.ConfigMapVolumeSource `json:\"configMap,omitempty\"`","\t// Secret represents a secret that should populate this workspace.","\t// +optional","\tSecret *corev1.SecretVolumeSource `json:\"secret,omitempty\"`","\t// Projected represents a projected volume that should populate this workspace.","\t// +optional","\tProjected *corev1.ProjectedVolumeSource `json:\"projected,omitempty\"`","\t// CSI (Container Storage Interface) represents ephemeral storage that is handled by certain external CSI drivers.","\t// +optional","\tCSI *corev1.CSIVolumeSource `json:\"csi,omitempty\"`","}","","// WorkspacePipelineDeclaration creates a named slot in a Pipeline that a PipelineRun","// is expected to populate with a workspace binding.","//","// Deprecated: use PipelineWorkspaceDeclaration type instead","type WorkspacePipelineDeclaration = PipelineWorkspaceDeclaration","","// PipelineWorkspaceDeclaration creates a named slot in a Pipeline that a PipelineRun","// is expected to populate with a workspace binding.","type PipelineWorkspaceDeclaration struct {","\t// Name is the name of a workspace to be provided by a PipelineRun.","\tName string `json:\"name\"`","\t// Description is a human readable string describing how the workspace will be","\t// used in the Pipeline. It can be useful to include a bit of detail about which","\t// tasks are intended to have access to the data on the workspace.","\t// +optional","\tDescription string `json:\"description,omitempty\"`","\t// Optional marks a Workspace as not being required in PipelineRuns. By default","\t// this field is false and so declared workspaces are required.","\tOptional bool `json:\"optional,omitempty\"`","}","","// WorkspacePipelineTaskBinding describes how a workspace passed into the pipeline should be","// mapped to a task's declared workspace.","type WorkspacePipelineTaskBinding struct {","\t// Name is the name of the workspace as declared by the task","\tName string `json:\"name\"`","\t// Workspace is the name of the workspace declared by the pipeline","\t// +optional","\tWorkspace string `json:\"workspace,omitempty\"`","\t// SubPath is optionally a directory on the volume which should be used","\t// for this binding (i.e. the volume will be mounted at this sub directory).","\t// +optional","\tSubPath string `json:\"subPath,omitempty\"`","}","","// WorkspaceUsage is used by a Step or Sidecar to declare that it wants isolated access","// to a Workspace defined in a Task.","type WorkspaceUsage struct {","\t// Name is the name of the workspace this Step or Sidecar wants access to.","\tName string `json:\"name\"`","\t// MountPath is the path that the workspace should be mounted to inside the Step or Sidecar,","\t// overriding any MountPath specified in the Task's WorkspaceDeclaration.","\tMountPath string `json:\"mountPath\"`","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]},{"id":58,"path":"pkg/apis/pipeline/v1/workspace_validation.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1","","import (","\t\"context\"","","\t\"k8s.io/apimachinery/pkg/api/equality\"","\t\"knative.dev/pkg/apis\"",")","","// allVolumeSourceFields is a list of all the volume source field paths that a","// WorkspaceBinding may include.","var allVolumeSourceFields = []string{","\t\"persistentvolumeclaim\",","\t\"volumeclaimtemplate\",","\t\"emptydir\",","\t\"configmap\",","\t\"secret\",","}","","// Validate looks at the Volume provided in wb and makes sure that it is valid.","// This means that only one VolumeSource can be specified, and also that the","// supported VolumeSource is itself valid.","func (b *WorkspaceBinding) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif equality.Semantic.DeepEqual(b, \u0026WorkspaceBinding{}) || b == nil {","\t\treturn apis.ErrMissingField(apis.CurrentField)","\t}","","\tnumSources := b.numSources()","","\tif numSources \u003e 1 {","\t\treturn apis.ErrMultipleOneOf(allVolumeSourceFields...)","\t}","","\tif numSources == 0 {","\t\treturn apis.ErrMissingOneOf(allVolumeSourceFields...)","\t}","","\t// For a PersistentVolumeClaim to work, you must at least provide the name of the PVC to use.","\tif b.PersistentVolumeClaim != nil \u0026\u0026 b.PersistentVolumeClaim.ClaimName == \"\" {","\t\treturn apis.ErrMissingField(\"persistentvolumeclaim.claimname\")","\t}","","\t// For a ConfigMap to work, you must provide the name of the ConfigMap to use.","\tif b.ConfigMap != nil \u0026\u0026 b.ConfigMap.LocalObjectReference.Name == \"\" {","\t\treturn apis.ErrMissingField(\"configmap.name\")","\t}","","\t// For a Secret to work, you must provide the name of the Secret to use.","\tif b.Secret != nil \u0026\u0026 b.Secret.SecretName == \"\" {","\t\treturn apis.ErrMissingField(\"secret.secretName\")","\t}","","\t// For a Projected volume to work, you must provide at least one source.","\tif b.Projected != nil \u0026\u0026 len(b.Projected.Sources) == 0 {","\t\tif len(b.Projected.Sources) == 0 {","\t\t\treturn apis.ErrMissingField(\"projected.sources\")","\t\t}","\t}","","\t// For a CSI to work, you must provide and have installed the driver to use.","\tif b.CSI != nil {","\t\tif b.CSI.Driver == \"\" {","\t\t\treturn apis.ErrMissingField(\"csi.driver\")","\t\t}","\t}","","\treturn nil","}","","// numSources returns the total number of volume sources that this WorkspaceBinding","// has been configured with.","func (b *WorkspaceBinding) numSources() int {","\tn := 0","\tif b.VolumeClaimTemplate != nil {","\t\tn++","\t}","\tif b.PersistentVolumeClaim != nil {","\t\tn++","\t}","\tif b.EmptyDir != nil {","\t\tn++","\t}","\tif b.ConfigMap != nil {","\t\tn++","\t}","\tif b.Secret != nil {","\t\tn++","\t}","\tif b.Projected != nil {","\t\tn++","\t}","\tif b.CSI != nil {","\t\tn++","\t}","\treturn n","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,2,2,2,2,2,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,2,0,0,0,2,2,2,2,0,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0]},{"id":59,"path":"pkg/apis/pipeline/v1alpha1/register.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1alpha1","","import (","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"",")","","// SchemeGroupVersion is group version used to register these objects","var SchemeGroupVersion = schema.GroupVersion{Group: pipeline.GroupName, Version: \"v1alpha1\"}","","// Kind takes an unqualified kind and returns back a Group qualified GroupKind","func Kind(kind string) schema.GroupKind {","\treturn SchemeGroupVersion.WithKind(kind).GroupKind()","}","","// Resource takes an unqualified resource and returns a Group qualified GroupResource","func Resource(resource string) schema.GroupResource {","\treturn SchemeGroupVersion.WithResource(resource).GroupResource()","}","","var (","\tschemeBuilder = runtime.NewSchemeBuilder(addKnownTypes)","","\t// AddToScheme adds Build types to the scheme.","\tAddToScheme = schemeBuilder.AddToScheme",")","","// Adds the list of known types to Scheme.","func addKnownTypes(scheme *runtime.Scheme) error {","\tscheme.AddKnownTypes(SchemeGroupVersion,","\t\t\u0026Run{},","\t\t\u0026RunList{},","\t\t\u0026VerificationPolicy{},","\t\t\u0026VerificationPolicyList{},","\t\t\u0026StepAction{},","\t\t\u0026StepActionList{},","\t)","\tmetav1.AddToGroupVersion(scheme, SchemeGroupVersion)","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2]},{"id":60,"path":"pkg/apis/pipeline/v1alpha1/run_defaults.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1alpha1","","import (","\t\"context\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Defaultable = (*Run)(nil)","","// SetDefaults implements apis.Defaultable","func (r *Run) SetDefaults(ctx context.Context) {","\tctx = apis.WithinParent(ctx, r.ObjectMeta)","\tr.Spec.SetDefaults(apis.WithinSpec(ctx))","}","","// SetDefaults implements apis.Defaultable","func (rs *RunSpec) SetDefaults(ctx context.Context) {","\tcfg := config.FromContextOrDefaults(ctx)","\tdefaultSA := cfg.Defaults.DefaultServiceAccount","\tif rs.ServiceAccountName == \"\" \u0026\u0026 defaultSA != \"\" {","\t\trs.ServiceAccountName = defaultSA","\t}","\tdefaultPodTemplate := cfg.Defaults.DefaultPodTemplate","\tif rs.PodTemplate == nil {","\t\trs.PodTemplate = defaultPodTemplate","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,0]},{"id":61,"path":"pkg/apis/pipeline/v1alpha1/run_types.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1alpha1","","import (","\t\"fmt\"","\t\"time\"","","\tapisconfig \"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tpod \"github.com/tektoncd/pipeline/pkg/apis/pipeline/pod\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\trunv1alpha1 \"github.com/tektoncd/pipeline/pkg/apis/run/v1alpha1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"","\t\"k8s.io/utils/clock\"","\t\"knative.dev/pkg/apis\"","\tduckv1 \"knative.dev/pkg/apis/duck/v1\"",")","","// EmbeddedRunSpec allows custom task definitions to be embedded","type EmbeddedRunSpec struct {","\truntime.TypeMeta `json:\",inline\"`","","\t// +optional","\tMetadata v1beta1.PipelineTaskMetadata `json:\"metadata,omitempty\"`","","\t// Spec is a specification of a custom task","\t// +optional","\tSpec runtime.RawExtension `json:\"spec,omitempty\"`","}","","// RunSpec defines the desired state of Run","type RunSpec struct {","\t// +optional","\tRef *v1beta1.TaskRef `json:\"ref,omitempty\"`","","\t// Spec is a specification of a custom task","\t// +optional","\tSpec *EmbeddedRunSpec `json:\"spec,omitempty\"`","","\t// +optional","\tParams v1beta1.Params `json:\"params,omitempty\"`","","\t// Used for cancelling a run (and maybe more later on)","\t// +optional","\tStatus RunSpecStatus `json:\"status,omitempty\"`","","\t// Status message for cancellation.","\t// +optional","\tStatusMessage RunSpecStatusMessage `json:\"statusMessage,omitempty\"`","","\t// Used for propagating retries count to custom tasks","\t// +optional","\tRetries int `json:\"retries,omitempty\"`","","\t// +optional","\tServiceAccountName string `json:\"serviceAccountName\"`","","\t// PodTemplate holds pod specific configuration","\t// +optional","\tPodTemplate *pod.PodTemplate `json:\"podTemplate,omitempty\"`","","\t// Time after which the custom-task times out.","\t// Refer Go's ParseDuration documentation for expected format: https://golang.org/pkg/time/#ParseDuration","\t// +optional","\tTimeout *metav1.Duration `json:\"timeout,omitempty\"`","","\t// Workspaces is a list of WorkspaceBindings from volumes to workspaces.","\t// +optional","\tWorkspaces []v1beta1.WorkspaceBinding `json:\"workspaces,omitempty\"`","}","","// RunSpecStatus defines the taskrun spec status the user can provide","type RunSpecStatus string","","const (","\t// RunSpecStatusCancelled indicates that the user wants to cancel the run,","\t// if not already cancelled or terminated","\tRunSpecStatusCancelled RunSpecStatus = \"RunCancelled\"",")","","// RunSpecStatusMessage defines human readable status messages for the TaskRun.","type RunSpecStatusMessage string","","const (","\t// RunCancelledByPipelineMsg indicates that the PipelineRun of which part this Run was","\t// has been cancelled.","\tRunCancelledByPipelineMsg RunSpecStatusMessage = \"Run cancelled as the PipelineRun it belongs to has been cancelled.\"","\t// RunCancelledByPipelineTimeoutMsg indicates that the Run was cancelled because the PipelineRun running it timed out.","\tRunCancelledByPipelineTimeoutMsg RunSpecStatusMessage = \"Run cancelled as the PipelineRun it belongs to has timed out.\"",")","","// GetParam gets the Param from the RunSpec with the given name","// TODO(jasonhall): Move this to a Params type so other code can use it?","func (rs RunSpec) GetParam(name string) *v1beta1.Param {","\tfor _, p := range rs.Params {","\t\tif p.Name == name {","\t\t\treturn \u0026p","\t\t}","\t}","\treturn nil","}","","// RunReason is an enum used to store all Run reason for the Succeeded condition that are controlled by the Run itself.","type RunReason string","","const (","\t// RunReasonStarted is the reason set when the Run has just started.","\tRunReasonStarted RunReason = \"Started\"","\t// RunReasonRunning is the reason set when the Run is running.","\tRunReasonRunning RunReason = \"Running\"","\t// RunReasonSuccessful is the reason set when the Run completed successfully.","\tRunReasonSuccessful RunReason = \"Succeeded\"","\t// RunReasonFailed is the reason set when the Run completed with a failure.","\tRunReasonFailed RunReason = \"Failed\"","\t// RunReasonCancelled must be used in the Condition Reason to indicate that a Run was cancelled.","\tRunReasonCancelled RunReason = \"RunCancelled\"","\t// RunReasonTimedOut must be used in the Condition Reason to indicate that a Run was timed out.","\tRunReasonTimedOut RunReason = \"RunTimedOut\"","\t// RunReasonWorkspaceNotSupported can be used in the Condition Reason to indicate that the","\t// Run contains a workspace which is not supported by this custom task.","\tRunReasonWorkspaceNotSupported RunReason = \"RunWorkspaceNotSupported\"","\t// RunReasonPodTemplateNotSupported can be used in the Condition Reason to indicate that the","\t// Run contains a pod template which is not supported by this custom task.","\tRunReasonPodTemplateNotSupported RunReason = \"RunPodTemplateNotSupported\"",")","","func (t RunReason) String() string {","\treturn string(t)","}","","// RunStatus defines the observed state of Run.","type RunStatus = runv1alpha1.RunStatus","","var runCondSet = apis.NewBatchConditionSet()","","// GetConditionSet retrieves the condition set for this resource. Implements","// the KRShaped interface.","func (r *Run) GetConditionSet() apis.ConditionSet { return runCondSet }","","// GetStatus retrieves the status of the Parallel. Implements the KRShaped","// interface.","func (r *Run) GetStatus() *duckv1.Status { return \u0026r.Status.Status }","","// RunStatusFields holds the fields of Run's status.  This is defined","// separately and inlined so that other types can readily consume these fields","// via duck typing.","type RunStatusFields = runv1alpha1.RunStatusFields","","// RunResult used to describe the results of a task","type RunResult = runv1alpha1.RunResult","","// +genclient","// +genreconciler","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// Run represents a single execution of a Custom Task.","//","// +k8s:openapi-gen=true","type Run struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ObjectMeta `json:\"metadata,omitempty\"`","","\t// +optional","\tSpec RunSpec `json:\"spec,omitempty\"`","\t// +optional","\tStatus RunStatus `json:\"status,omitempty\"`","}","","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// RunList contains a list of Run","type RunList struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ListMeta `json:\"metadata,omitempty\"`","\tItems           []Run `json:\"items\"`","}","","// GetStatusCondition returns the task run status as a ConditionAccessor","func (r *Run) GetStatusCondition() apis.ConditionAccessor {","\treturn \u0026r.Status","}","","// GetGroupVersionKind implements kmeta.OwnerRefable.","func (*Run) GetGroupVersionKind() schema.GroupVersionKind {","\treturn SchemeGroupVersion.WithKind(pipeline.RunControllerName)","}","","// HasPipelineRunOwnerReference returns true of Run has","// owner reference of type PipelineRun","func (r *Run) HasPipelineRunOwnerReference() bool {","\tfor _, ref := range r.GetOwnerReferences() {","\t\tif ref.Kind == pipeline.PipelineRunControllerName {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// IsCancelled returns true if the Run's spec status is set to Cancelled state","func (r *Run) IsCancelled() bool {","\treturn r.Spec.Status == RunSpecStatusCancelled","}","","// IsDone returns true if the Run's status indicates that it is done.","func (r *Run) IsDone() bool {","\treturn !r.Status.GetCondition(apis.ConditionSucceeded).IsUnknown()","}","","// HasStarted function check whether taskrun has valid start time set in its status","func (r *Run) HasStarted() bool {","\treturn r.Status.StartTime != nil \u0026\u0026 !r.Status.StartTime.IsZero()","}","","// IsSuccessful returns true if the Run's status indicates that it has succeeded.","func (r *Run) IsSuccessful() bool {","\treturn r != nil \u0026\u0026 r.Status.GetCondition(apis.ConditionSucceeded).IsTrue()","}","","// GetRunKey return the run's key for timeout handler map","func (r *Run) GetRunKey() string {","\t// The address of the pointer is a threadsafe unique identifier for the run","\treturn fmt.Sprintf(\"%s/%p\", \"Run\", r)","}","","// HasTimedOut returns true if the Run's running time is beyond the allowed timeout","func (r *Run) HasTimedOut(c clock.PassiveClock) bool {","\tif r.Status.StartTime == nil || r.Status.StartTime.IsZero() {","\t\treturn false","\t}","\ttimeout := r.GetTimeout()","\t// If timeout is set to 0 or defaulted to 0, there is no timeout.","\tif timeout == apisconfig.NoTimeoutDuration {","\t\treturn false","\t}","\truntime := c.Since(r.Status.StartTime.Time)","\treturn runtime \u003e timeout","}","","// GetTimeout returns the timeout for this run, or the default if not configured","func (r *Run) GetTimeout() time.Duration {","\t// Use the platform default if no timeout is set","\tif r.Spec.Timeout == nil {","\t\treturn apisconfig.DefaultTimeoutMinutes * time.Minute","\t}","\treturn r.Spec.Timeout.Duration","}","","// GetRetryCount returns the number of times this Run has already been retried","func (r *Run) GetRetryCount() int {","\treturn len(r.Status.RetriesStatus)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,1,1,1,1,1,0,1,0,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,1,1,1,1,0,0,2,2,2,2,2,2,2,1,1,2,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2]},{"id":62,"path":"pkg/apis/pipeline/v1alpha1/run_validation.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1alpha1","","import (","\t\"context\"","\t\"fmt\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/validate\"","\tadmissionregistrationv1 \"k8s.io/api/admissionregistration/v1\"","\t\"k8s.io/apimachinery/pkg/api/equality\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/webhook/resourcesemantics\"",")","","var _ apis.Validatable = (*Run)(nil)","var _ resourcesemantics.VerbLimited = (*Run)(nil)","","// SupportedVerbs returns the operations that validation should be called for","func (r *Run) SupportedVerbs() []admissionregistrationv1.OperationType {","\treturn []admissionregistrationv1.OperationType{admissionregistrationv1.Create, admissionregistrationv1.Update}","}","","// Validate taskrun","func (r *Run) Validate(ctx context.Context) *apis.FieldError {","\tif err := validate.ObjectMetadata(r.GetObjectMeta()).ViaField(\"metadata\"); err != nil {","\t\treturn err","\t}","\treturn r.Spec.Validate(ctx)","}","","// Validate Run spec","func (rs *RunSpec) Validate(ctx context.Context) *apis.FieldError {","\t// this covers the case rs.Ref == nil \u0026\u0026 rs.Spec == nil","\tif equality.Semantic.DeepEqual(rs, \u0026RunSpec{}) {","\t\treturn apis.ErrMissingField(\"spec\")","\t}","","\tif rs.Ref != nil \u0026\u0026 rs.Spec != nil {","\t\treturn apis.ErrMultipleOneOf(\"spec.ref\", \"spec.spec\")","\t}","\tif rs.Ref == nil \u0026\u0026 rs.Spec == nil {","\t\treturn apis.ErrMissingOneOf(\"spec.ref\", \"spec.spec\")","\t}","\tif rs.Ref != nil {","\t\tif rs.Ref.APIVersion == \"\" {","\t\t\treturn apis.ErrMissingField(\"spec.ref.apiVersion\")","\t\t}","\t\tif rs.Ref.Kind == \"\" {","\t\t\treturn apis.ErrMissingField(\"spec.ref.kind\")","\t\t}","\t}","\tif rs.Spec != nil {","\t\tif rs.Spec.APIVersion == \"\" {","\t\t\treturn apis.ErrMissingField(\"spec.spec.apiVersion\")","\t\t}","\t\tif rs.Spec.Kind == \"\" {","\t\t\treturn apis.ErrMissingField(\"spec.spec.kind\")","\t\t}","\t}","\tif rs.Status == \"\" {","\t\tif rs.StatusMessage != \"\" {","\t\t\treturn apis.ErrInvalidValue(fmt.Sprintf(\"statusMessage should not be set if status is not set, but it is currently set to %s\", rs.StatusMessage), \"statusMessage\")","\t\t}","\t}","\tif err := v1beta1.ValidateParameters(ctx, rs.Params).ViaField(\"spec.params\"); err != nil {","\t\treturn err","\t}","","\treturn v1beta1.ValidateWorkspaceBindings(ctx, rs.Workspaces).ViaField(\"spec.workspaces\")","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,2,2,1,1,2,0,0,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,2,0,2,2,2,0,2,0]},{"id":63,"path":"pkg/apis/pipeline/v1alpha1/stepaction_conversion.go","lines":["/*","Copyright 2023 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1alpha1","","import (","\t\"context\"","\t\"fmt\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Convertible = (*StepAction)(nil)","","// ConvertTo implements apis.Convertible","func (s *StepAction) ConvertTo(ctx context.Context, to apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\tswitch sink := to.(type) {","\tcase *v1beta1.StepAction:","\t\tsink.ObjectMeta = s.ObjectMeta","\t\treturn s.Spec.ConvertTo(ctx, \u0026sink.Spec)","\tdefault:","\t\treturn fmt.Errorf(\"unknown version, got: %T\", sink)","\t}","}","","// ConvertTo implements apis.Convertible","func (ss *StepActionSpec) ConvertTo(ctx context.Context, sink *v1beta1.StepActionSpec) error {","\tsink.Description = ss.Description","\tsink.Image = ss.Image","\tsink.Command = ss.Command","\tsink.Args = ss.Args","\tsink.Env = ss.Env","\tsink.Script = ss.Script","\tsink.WorkingDir = ss.WorkingDir","\tsink.Params = ss.Params","\tsink.Results = ss.Results","\tsink.SecurityContext = ss.SecurityContext","\tsink.VolumeMounts = ss.VolumeMounts","","\treturn nil","}","","// ConvertFrom implements apis.Convertible","func (s *StepAction) ConvertFrom(ctx context.Context, from apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\tswitch source := from.(type) {","\tcase *v1beta1.StepAction:","\t\ts.ObjectMeta = source.ObjectMeta","\t\treturn s.Spec.ConvertFrom(ctx, \u0026source.Spec)","\tdefault:","\t\treturn fmt.Errorf(\"unknown version, got: %T\", source)","\t}","}","","// ConvertFrom implements apis.Convertible","func (ss *StepActionSpec) ConvertFrom(ctx context.Context, source *v1beta1.StepActionSpec) error {","\tss.Description = source.Description","\tss.Image = source.Image","\tss.Command = source.Command","\tss.Args = source.Args","\tss.Env = source.Env","\tss.Script = source.Script","\tss.WorkingDir = source.WorkingDir","","\tss.Params = source.Params","\tss.Results = source.Results","\tss.SecurityContext = source.SecurityContext","\tss.VolumeMounts = source.VolumeMounts","","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,1,1,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]},{"id":64,"path":"pkg/apis/pipeline/v1alpha1/stepaction_defaults.go","lines":["/*","Copyright 2023 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1alpha1","","import (","\t\"context\"","","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Defaultable = (*StepAction)(nil)","","// SetDefaults implements apis.Defaultable","func (s *StepAction) SetDefaults(ctx context.Context) {","\ts.Spec.SetDefaults(ctx)","}","","// SetDefaults set any defaults for the StepAction spec","func (ss *StepActionSpec) SetDefaults(ctx context.Context) {","\tfor i := range ss.Params {","\t\tss.Params[i].SetDefaults(ctx)","\t}","\tfor i := range ss.Results {","\t\tss.Results[i].SetDefaults(ctx)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,2,2,2,2,2,2,2,0]},{"id":65,"path":"pkg/apis/pipeline/v1alpha1/stepaction_types.go","lines":["/*","Copyright 2023 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1alpha1","","import (","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/kmeta\"",")","","// +genclient","// +genclient:noStatus","// +genreconciler:krshapedlogic=false","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// StepAction represents the actionable components of Step.","// The Step can only reference it from the cluster or using remote resolution.","//","// +k8s:openapi-gen=true","type StepAction struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ObjectMeta `json:\"metadata\"`","","\t// Spec holds the desired state of the Step from the client","\t// +optional","\tSpec StepActionSpec `json:\"spec\"`","}","","var _ kmeta.OwnerRefable = (*StepAction)(nil)","","// StepAction returns the step action's spec","func (s *StepAction) StepActionSpec() StepActionSpec {","\treturn s.Spec","}","","// StepActionMetadata returns the step action's ObjectMeta","func (s *StepAction) StepActionMetadata() metav1.ObjectMeta {","\treturn s.ObjectMeta","}","","// Copy returns a deep copy of the stepaction","func (s *StepAction) Copy() StepActionObject {","\treturn s.DeepCopy()","}","","// GetGroupVersionKind implements kmeta.OwnerRefable.","func (*StepAction) GetGroupVersionKind() schema.GroupVersionKind {","\treturn SchemeGroupVersion.WithKind(\"StepAction\")","}","","// StepActionList contains a list of StepActions","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","type StepActionList struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ListMeta `json:\"metadata,omitempty\"`","\tItems           []StepAction `json:\"items\"`","}","","// StepActionSpec contains the actionable components of a step.","type StepActionSpec struct {","\t// Description is a user-facing description of the stepaction that may be","\t// used to populate a UI.","\t// +optional","\tDescription string `json:\"description,omitempty\"`","\t// Image reference name to run for this StepAction.","\t// More info: https://kubernetes.io/docs/concepts/containers/images","\t// +optional","\tImage string `json:\"image,omitempty\" protobuf:\"bytes,2,opt,name=image\"`","\t// Entrypoint array. Not executed within a shell.","\t// The image's ENTRYPOINT is used if this is not provided.","\t// Variable references $(VAR_NAME) are expanded using the container's environment. If a variable","\t// cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced","\t// to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$$(VAR_NAME)\" will","\t// produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless","\t// of whether the variable exists or not. Cannot be updated.","\t// More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell","\t// +optional","\t// +listType=atomic","\tCommand []string `json:\"command,omitempty\" protobuf:\"bytes,3,rep,name=command\"`","\t// Arguments to the entrypoint.","\t// The image's CMD is used if this is not provided.","\t// Variable references $(VAR_NAME) are expanded using the container's environment. If a variable","\t// cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced","\t// to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$$(VAR_NAME)\" will","\t// produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless","\t// of whether the variable exists or not. Cannot be updated.","\t// More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell","\t// +optional","\t// +listType=atomic","\tArgs []string `json:\"args,omitempty\" protobuf:\"bytes,4,rep,name=args\"`","\t// List of environment variables to set in the container.","\t// Cannot be updated.","\t// +optional","\t// +patchMergeKey=name","\t// +patchStrategy=merge","\t// +listType=atomic","\tEnv []corev1.EnvVar `json:\"env,omitempty\" patchMergeKey:\"name\" patchStrategy:\"merge\" protobuf:\"bytes,7,rep,name=env\"`","\t// Script is the contents of an executable file to execute.","\t//","\t// If Script is not empty, the Step cannot have an Command and the Args will be passed to the Script.","\t// +optional","\tScript string `json:\"script,omitempty\"`","\t// Step's working directory.","\t// If not specified, the container runtime's default will be used, which","\t// might be configured in the container image.","\t// Cannot be updated.","\t// +optional","\tWorkingDir string `json:\"workingDir,omitempty\" protobuf:\"bytes,5,opt,name=workingDir\"`","\t// Params is a list of input parameters required to run the stepAction.","\t// Params must be supplied as inputs in Steps unless they declare a defaultvalue.","\t// +optional","\tParams v1.ParamSpecs `json:\"params,omitempty\"`","\t// Results are values that this StepAction can output","\t// +optional","\t// +listType=atomic","\tResults []v1.StepResult `json:\"results,omitempty\"`","\t// SecurityContext defines the security options the Step should be run with.","\t// If set, the fields of SecurityContext override the equivalent fields of PodSecurityContext.","\t// More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/","\t// The value set in StepAction will take precedence over the value from Task.","\t// +optional","\tSecurityContext *corev1.SecurityContext `json:\"securityContext,omitempty\" protobuf:\"bytes,15,opt,name=securityContext\"`","\t// Volumes to mount into the Step's filesystem.","\t// Cannot be updated.","\t// +optional","\t// +patchMergeKey=mountPath","\t// +patchStrategy=merge","\t// +listType=atomic","\tVolumeMounts []corev1.VolumeMount `json:\"volumeMounts,omitempty\" patchMergeKey:\"mountPath\" patchStrategy:\"merge\" protobuf:\"bytes,9,rep,name=volumeMounts\"`","}","","// ToStep converts the StepActionSpec to a Step struct","func (ss *StepActionSpec) ToStep() *v1.Step {","\treturn \u0026v1.Step{","\t\tImage:           ss.Image,","\t\tCommand:         ss.Command,","\t\tArgs:            ss.Args,","\t\tWorkingDir:      ss.WorkingDir,","\t\tScript:          ss.Script,","\t\tEnv:             ss.Env,","\t\tVolumeMounts:    ss.VolumeMounts,","\t\tSecurityContext: ss.SecurityContext,","\t\tResults:         ss.Results,","\t}","}","","// StepActionObject is implemented by StepAction","type StepActionObject interface {","\tapis.Defaultable","\tStepActionMetadata() metav1.ObjectMeta","\tStepActionSpec() StepActionSpec","\tCopy() StepActionObject","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0]},{"id":66,"path":"pkg/apis/pipeline/v1alpha1/stepaction_validation.go","lines":["/*","Copyright 2023 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1alpha1","","import (","\t\"context\"","\t\"fmt\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/validate\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\tadmissionregistrationv1 \"k8s.io/api/admissionregistration/v1\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/webhook/resourcesemantics\"",")","","var (","\t_ apis.Validatable              = (*StepAction)(nil)","\t_ resourcesemantics.VerbLimited = (*StepAction)(nil)",")","","// SupportedVerbs returns the operations that validation should be called for","func (s *StepAction) SupportedVerbs() []admissionregistrationv1.OperationType {","\treturn []admissionregistrationv1.OperationType{admissionregistrationv1.Create, admissionregistrationv1.Update}","}","","// Validate implements apis.Validatable","func (s *StepAction) Validate(ctx context.Context) (errs *apis.FieldError) {","\terrs = validate.ObjectMetadata(s.GetObjectMeta()).ViaField(\"metadata\")","\terrs = errs.Also(s.Spec.Validate(apis.WithinSpec(ctx)).ViaField(\"spec\"))","\treturn errs","}","","// Validate implements apis.Validatable","func (ss *StepActionSpec) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif ss.Image == \"\" {","\t\terrs = errs.Also(apis.ErrMissingField(\"Image\"))","\t}","","\tif ss.Script != \"\" {","\t\tif len(ss.Command) \u003e 0 {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"script cannot be used with command\",","\t\t\t\tPaths:   []string{\"script\"},","\t\t\t})","\t\t}","","\t\tcleaned := strings.TrimSpace(ss.Script)","\t\tif strings.HasPrefix(cleaned, \"#!win\") {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"windows script support\", config.AlphaAPIFields).ViaField(\"script\"))","\t\t}","\t\terrs = errs.Also(validateNoParamSubstitutionsInScript(ss.Script))","\t}","\terrs = errs.Also(validateUsageOfDeclaredParameters(ctx, *ss))","\terrs = errs.Also(v1.ValidateParameterTypes(ctx, ss.Params).ViaField(\"params\"))","\terrs = errs.Also(validateParameterVariables(ctx, *ss, ss.Params))","\terrs = errs.Also(v1.ValidateStepResultsVariables(ctx, ss.Results, ss.Script))","\terrs = errs.Also(v1.ValidateStepResults(ctx, ss.Results).ViaField(\"results\"))","\terrs = errs.Also(validateVolumeMounts(ss.VolumeMounts, ss.Params).ViaField(\"volumeMounts\"))","\treturn errs","}","","// validateNoParamSubstitutionsInScript validates that param substitutions are not invoked in the script","func validateNoParamSubstitutionsInScript(script string) *apis.FieldError {","\t_, present, errString := substitution.ExtractVariablesFromString(script, \"params\")","\tif errString != \"\" || present {","\t\treturn \u0026apis.FieldError{","\t\t\tMessage: \"param substitution in scripts is not allowed.\",","\t\t\tPaths:   []string{\"script\"},","\t\t}","\t}","\treturn nil","}","","// validateUsageOfDeclaredParameters validates that all parameters referenced in the Task are declared by the Task.","func validateUsageOfDeclaredParameters(ctx context.Context, sas StepActionSpec) *apis.FieldError {","\tparams := sas.Params","\tvar errs *apis.FieldError","\t_, _, objectParams := params.SortByType()","\tallParameterNames := sets.NewString(params.GetNames()...)","\terrs = errs.Also(validateStepActionVariables(ctx, sas, \"params\", allParameterNames))","\terrs = errs.Also(validateObjectUsage(ctx, sas, objectParams))","\terrs = errs.Also(v1.ValidateObjectParamsHaveProperties(ctx, params))","\treturn errs","}","","func validateVolumeMounts(volumeMounts []corev1.VolumeMount, params v1.ParamSpecs) (errs *apis.FieldError) {","\tif len(volumeMounts) == 0 {","\t\treturn","\t}","\tparamNames := sets.String{}","\tfor _, p := range params {","\t\tparamNames.Insert(p.Name)","\t}","\tfor idx, v := range volumeMounts {","\t\tmatches, _ := substitution.ExtractVariableExpressions(v.Name, \"params\")","\t\tif len(matches) != 1 {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(v.Name, \"name\", \"expect the Name to be a single param reference\").ViaIndex(idx))","\t\t\treturn errs","\t\t} else if matches[0] != v.Name {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(v.Name, \"name\", \"expect the Name to be a single param reference\").ViaIndex(idx))","\t\t\treturn errs","\t\t}","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(v.Name, \"params\", paramNames).ViaIndex(idx))","\t}","\treturn errs","}","","// validateParameterVariables validates all variables within a slice of ParamSpecs against a StepAction","func validateParameterVariables(ctx context.Context, sas StepActionSpec, params v1.ParamSpecs) *apis.FieldError {","\tvar errs *apis.FieldError","\terrs = errs.Also(params.ValidateNoDuplicateNames())","\tstringParams, arrayParams, objectParams := params.SortByType()","\tstringParameterNames := sets.NewString(stringParams.GetNames()...)","\tarrayParameterNames := sets.NewString(arrayParams.GetNames()...)","\terrs = errs.Also(v1.ValidateNameFormat(stringParameterNames.Insert(arrayParameterNames.List()...), objectParams))","\terrs = errs.Also(validateStepActionArrayUsage(sas, \"params\", arrayParameterNames))","\treturn errs.Also(validateDefaultParameterReferences(params))","}","","// validateDefaultParameterReferences ensures that parameters referenced in default values are defined","func validateDefaultParameterReferences(params v1.ParamSpecs) *apis.FieldError {","\tvar errs *apis.FieldError","\tallParams := sets.NewString(params.GetNames()...)","","\t// First pass: collect all parameters that have no references in their default values","\tresolvedParams := sets.NewString()","\tparamsNeedingResolution := make(map[string][]string)","","\tfor _, p := range params {","\t\tif p.Default != nil {","\t\t\tmatches, _ := substitution.ExtractVariableExpressions(p.Default.StringVal, \"params\")","\t\t\tif len(matches) == 0 {","\t\t\t\tresolvedParams.Insert(p.Name)","\t\t\t} else {","\t\t\t\t// Track which parameters this parameter depends on","\t\t\t\treferencedParams := make([]string, 0, len(matches))","\t\t\t\thasUndefinedParam := false","\t\t\t\tfor _, match := range matches {","\t\t\t\t\tparamName := strings.TrimSuffix(strings.TrimPrefix(match, \"$(params.\"), \")\")","\t\t\t\t\tif !allParams.Has(paramName) {","\t\t\t\t\t\thasUndefinedParam = true","\t\t\t\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\t\t\t\tMessage: fmt.Sprintf(\"param %q default value references param %q which is not defined\", p.Name, paramName),","\t\t\t\t\t\t\tPaths:   []string{\"params\"},","\t\t\t\t\t\t})","\t\t\t\t\t}","\t\t\t\t\treferencedParams = append(referencedParams, paramName)","\t\t\t\t}","\t\t\t\t// Only track dependencies if all referenced parameters exist","\t\t\t\tif !hasUndefinedParam {","\t\t\t\t\tparamsNeedingResolution[p.Name] = referencedParams","\t\t\t\t}","\t\t\t}","\t\t} else {","\t\t\tresolvedParams.Insert(p.Name)","\t\t}","\t}","","\t// Second pass: iteratively resolve parameters whose dependencies are satisfied","\tfor len(paramsNeedingResolution) \u003e 0 {","\t\tparamWasResolved := false","\t\tfor paramName, referencedParams := range paramsNeedingResolution {","\t\t\tcanResolveParam := true","\t\t\tfor _, referencedParam := range referencedParams {","\t\t\t\tif !resolvedParams.Has(referencedParam) {","\t\t\t\t\tcanResolveParam = false","\t\t\t\t\tbreak","\t\t\t\t}","\t\t\t}","\t\t\tif canResolveParam {","\t\t\t\tresolvedParams.Insert(paramName)","\t\t\t\tdelete(paramsNeedingResolution, paramName)","\t\t\t\tparamWasResolved = true","\t\t\t}","\t\t}","\t\tif !paramWasResolved {","\t\t\t// If we couldn't resolve any parameters in this iteration,","\t\t\t// we have a circular dependency","\t\t\tfor paramName := range paramsNeedingResolution {","\t\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\t\tMessage: fmt.Sprintf(\"param %q default value has a circular dependency\", paramName),","\t\t\t\t\tPaths:   []string{\"params\"},","\t\t\t\t})","\t\t\t}","\t\t\tbreak","\t\t}","\t}","","\treturn errs","}","","// validateObjectUsage validates the usage of individual attributes of an object param and the usage of the entire object","func validateObjectUsage(ctx context.Context, sas StepActionSpec, params v1.ParamSpecs) (errs *apis.FieldError) {","\tobjectParameterNames := sets.NewString()","\tfor _, p := range params {","\t\t// collect all names of object type params","\t\tobjectParameterNames.Insert(p.Name)","","\t\t// collect all keys for this object param","\t\tobjectKeys := sets.NewString()","\t\tfor key := range p.Properties {","\t\t\tobjectKeys.Insert(key)","\t\t}","","\t\t// check if the object's key names are referenced correctly i.e. param.objectParam.key1","\t\terrs = errs.Also(validateStepActionVariables(ctx, sas, \"params\\\\.\"+p.Name, objectKeys))","\t}","","\treturn errs.Also(validateStepActionObjectUsageAsWhole(sas, \"params\", objectParameterNames))","}","","// validateStepActionObjectUsageAsWhole returns an error if the StepAction contains references to the entire input object params in fields where these references are prohibited","func validateStepActionObjectUsageAsWhole(sas StepActionSpec, prefix string, vars sets.String) *apis.FieldError {","\terrs := substitution.ValidateNoReferencesToEntireProhibitedVariables(sas.Image, prefix, vars).ViaField(\"image\")","\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(sas.Script, prefix, vars).ViaField(\"script\"))","\tfor i, cmd := range sas.Command {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(cmd, prefix, vars).ViaFieldIndex(\"command\", i))","\t}","\tfor i, arg := range sas.Args {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(arg, prefix, vars).ViaFieldIndex(\"args\", i))","\t}","\tfor _, env := range sas.Env {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(env.Value, prefix, vars).ViaFieldKey(\"env\", env.Name))","\t}","\tfor i, vm := range sas.VolumeMounts {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(vm.Name, prefix, vars).ViaFieldIndex(\"volumeMounts\", i))","\t}","\treturn errs","}","","// validateStepActionArrayUsage returns an error if the Step contains references to the input array params in fields where these references are prohibited","func validateStepActionArrayUsage(sas StepActionSpec, prefix string, arrayParamNames sets.String) *apis.FieldError {","\terrs := substitution.ValidateNoReferencesToProhibitedVariables(sas.Image, prefix, arrayParamNames).ViaField(\"image\")","\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(sas.Script, prefix, arrayParamNames).ViaField(\"script\"))","\tfor i, cmd := range sas.Command {","\t\terrs = errs.Also(substitution.ValidateVariableReferenceIsIsolated(cmd, prefix, arrayParamNames).ViaFieldIndex(\"command\", i))","\t}","\tfor i, arg := range sas.Args {","\t\terrs = errs.Also(substitution.ValidateVariableReferenceIsIsolated(arg, prefix, arrayParamNames).ViaFieldIndex(\"args\", i))","\t}","\tfor _, env := range sas.Env {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(env.Value, prefix, arrayParamNames).ViaFieldKey(\"env\", env.Name))","\t}","\tfor i, vm := range sas.VolumeMounts {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(vm.Name, prefix, arrayParamNames).ViaFieldIndex(\"volumeMounts\", i))","\t}","\treturn errs","}","","// validateStepActionVariables returns an error if the StepAction contains references to any unknown variables","func validateStepActionVariables(ctx context.Context, sas StepActionSpec, prefix string, vars sets.String) *apis.FieldError {","\terrs := substitution.ValidateNoReferencesToUnknownVariables(sas.Image, prefix, vars).ViaField(\"image\")","\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(sas.Script, prefix, vars).ViaField(\"script\"))","\tfor i, cmd := range sas.Command {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(cmd, prefix, vars).ViaFieldIndex(\"command\", i))","\t}","\tfor i, arg := range sas.Args {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(arg, prefix, vars).ViaFieldIndex(\"args\", i))","\t}","\tfor _, env := range sas.Env {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(env.Value, prefix, vars).ViaFieldKey(\"env\", env.Name))","\t}","\tfor i, vm := range sas.VolumeMounts {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(vm.Name, prefix, vars).ViaFieldIndex(\"volumeMounts\", i))","\t}","\treturn errs","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,2,2,2,2,2,0,0,2,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0]},{"id":67,"path":"pkg/apis/pipeline/v1alpha1/verificationpolicy_defaults.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1alpha1","","import (","\t\"context\"","","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Defaultable = (*VerificationPolicy)(nil)","","// SetDefaults implements apis.Defaultable","func (v *VerificationPolicy) SetDefaults(ctx context.Context) {","","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]},{"id":68,"path":"pkg/apis/pipeline/v1alpha1/verificationpolicy_types.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1alpha1","","import (","\t\"crypto\"","","\tv1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"",")","","// +genclient","// +genclient:noStatus","// +genreconciler:krshapedlogic=false","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// VerificationPolicy defines the rules to verify Tekton resources.","// VerificationPolicy can config the mapping from resources to a list of public","// keys, so when verifying the resources we can use the corresponding public keys.","// +k8s:openapi-gen=true","type VerificationPolicy struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ObjectMeta `json:\"metadata\"`","","\t// Spec holds the desired state of the VerificationPolicy.","\tSpec VerificationPolicySpec `json:\"spec\"`","}","","// VerificationPolicyList contains a list of VerificationPolicy","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","type VerificationPolicyList struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ListMeta `json:\"metadata,omitempty\"`","\tItems           []VerificationPolicy `json:\"items\"`","}","","// GetGroupVersionKind implements kmeta.OwnerRefable.","func (*VerificationPolicy) GetGroupVersionKind() schema.GroupVersionKind {","\treturn SchemeGroupVersion.WithKind(\"VerificationPolicy\")","}","","// VerificationPolicySpec defines the patterns and authorities.","type VerificationPolicySpec struct {","\t// Resources defines the patterns of resources sources that should be subject to this policy.","\t// For example, we may want to apply this Policy from a certain GitHub repo.","\t// Then the ResourcesPattern should be valid regex. E.g. If using gitresolver, and we want to config keys from a certain git repo.","\t// `ResourcesPattern` can be `https://github.com/tektoncd/catalog.git`, we will use regex to filter out those resources.","\tResources []ResourcePattern `json:\"resources\"`","\t// Authorities defines the rules for validating signatures.","\tAuthorities []Authority `json:\"authorities\"`","\t// Mode controls whether a failing policy will fail the taskrun/pipelinerun, or only log the warnings","\t// enforce - fail the taskrun/pipelinerun if verification fails (default)","\t// warn - don't fail the taskrun/pipelinerun if verification fails but log warnings","\t// +optional","\tMode ModeType `json:\"mode,omitempty\"`","}","","// ResourcePattern defines the pattern of the resource source","type ResourcePattern struct {","\t// Pattern defines a resource pattern. Regex is created to filter resources based on `Pattern`","\t// Example patterns:","\t// GitHub resource: https://github.com/tektoncd/catalog.git, https://github.com/tektoncd/*","\t// Bundle resource: gcr.io/tekton-releases/catalog/upstream/git-clone, gcr.io/tekton-releases/catalog/upstream/*","\t// Hub resource: https://artifacthub.io/*,","\tPattern string `json:\"pattern\"`","}","","// The Authority block defines the keys for validating signatures.","type Authority struct {","\t// Name is the name for this authority.","\tName string `json:\"name\"`","\t// Key contains the public key to validate the resource.","\tKey *KeyRef `json:\"key,omitempty\"`","}","","// ModeType indicates the type of a mode for VerificationPolicy","type ModeType string","","// Valid ModeType:","const (","\tModeWarn    ModeType = \"warn\"","\tModeEnforce ModeType = \"enforce\"",")","","// KeyRef defines the reference to a public key","type KeyRef struct {","\t// SecretRef sets a reference to a secret with the key.","\t// +optional","\tSecretRef *v1.SecretReference `json:\"secretRef,omitempty\"`","\t// Data contains the inline public key.","\t// +optional","\tData string `json:\"data,omitempty\"`","\t// KMS contains the KMS url of the public key","\t// Supported formats differ based on the KMS system used.","\t// One example of a KMS url could be:","\t// gcpkms://projects/[PROJECT]/locations/[LOCATION]\u003e/keyRings/[KEYRING]/cryptoKeys/[KEY]/cryptoKeyVersions/[KEY_VERSION]","\t// For more examples please refer https://docs.sigstore.dev/cosign/kms_support.","\t// Note that the KMS is not supported yet.","\t// +optional","\tKMS string `json:\"kms,omitempty\"`","\t// HashAlgorithm always defaults to sha256 if the algorithm hasn't been explicitly set","\t// +optional","\tHashAlgorithm HashAlgorithm `json:\"hashAlgorithm,omitempty\"`","}","","// HashAlgorithm defines the hash algorithm used for the public key","type HashAlgorithm string","","const (","\tsha224 HashAlgorithm = \"sha224\"","\tsha256 HashAlgorithm = \"sha256\"","\tsha384 HashAlgorithm = \"sha384\"","\tsha512 HashAlgorithm = \"sha512\"","\tempty  HashAlgorithm = \"\"",")","","// SupportedSignatureAlgorithms sets a list of support signature algorithms that is similar to the list supported by cosign.","// empty HashAlgorithm is allowed and will be set to SHA256.","var SupportedSignatureAlgorithms = map[HashAlgorithm]crypto.Hash{","\tsha224: crypto.SHA224,","\tsha256: crypto.SHA256,","\tsha384: crypto.SHA384,","\tsha512: crypto.SHA512,","\tempty:  crypto.SHA256,","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]},{"id":69,"path":"pkg/apis/pipeline/v1alpha1/verificationpolicy_validation.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1alpha1","","import (","\t\"context\"","\t\"fmt\"","\t\"regexp\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/validate\"","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Validatable = (*VerificationPolicy)(nil)","","var (","\t// InvalidResourcePatternErr is returned when the pattern is not valid regex expression","\tInvalidResourcePatternErr = \"resourcePattern cannot be compiled by regex\"",")","","// Validate VerificationPolicy","func (v *VerificationPolicy) Validate(ctx context.Context) (errs *apis.FieldError) {","\terrs = errs.Also(validate.ObjectMetadata(v.GetObjectMeta()).ViaField(\"metadata\"))","\terrs = errs.Also(v.Spec.Validate(ctx))","\treturn errs","}","","// Validate VerificationPolicySpec, the validation requires Resources is not empty, for each","// resource it must be able to be regex expression and can be compiled with no error. The Authorities","// shouldn't be empty and each Authority should be valid.","func (vs *VerificationPolicySpec) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif len(vs.Resources) == 0 {","\t\terrs = errs.Also(apis.ErrMissingField(\"resources\"))","\t}","\tfor _, r := range vs.Resources {","\t\terrs = errs.Also(r.Validate(ctx))","\t}","\tif len(vs.Authorities) == 0 {","\t\terrs = errs.Also(apis.ErrMissingField(\"authorities\"))","\t}","\tfor i, a := range vs.Authorities {","\t\tif a.Key != nil {","\t\t\terrs = errs.Also(a.Key.Validate(ctx).ViaFieldIndex(\"key\", i))","\t\t}","\t}","\tif vs.Mode != \"\" \u0026\u0026 vs.Mode != ModeEnforce \u0026\u0026 vs.Mode != ModeWarn {","\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"available values are: %s, %s, but got: %s\", ModeEnforce, ModeWarn, vs.Mode), \"mode\"))","\t}","\treturn errs","}","","// Validate KeyRef will check if one of KeyRef's Data or SecretRef exists, and the","// Supported HashAlgorithm is in supportedSignatureAlgorithms.","func (key *KeyRef) Validate(ctx context.Context) (errs *apis.FieldError) {","\t// Validate that one and only one of Data, SecretRef, KMS is defined.","\tkeyCount := 0","\tif key.Data != \"\" {","\t\tkeyCount++","\t}","\tif key.SecretRef != nil {","\t\tkeyCount++","\t}","\tif key.KMS != \"\" {","\t\tkeyCount++","\t}","","\tswitch keyCount {","\tcase 0:","\t\terrs = errs.Also(apis.ErrMissingOneOf(\"data\", \"kms\", \"secretref\"))","\tcase 1:","\t\t// do nothing -- a single key definition is valid","\tdefault:","\t\terrs = errs.Also(apis.ErrMultipleOneOf(\"data\", \"kms\", \"secretref\"))","\t}","","\terrs = errs.Also(validateHashAlgorithm(key.HashAlgorithm))","","\treturn errs","}","","// Validate ResourcePattern and make sure the Pattern is valid regex expression","func (r *ResourcePattern) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif _, err := regexp.Compile(r.Pattern); err != nil {","\t\terrs = errs.Also(apis.ErrInvalidValue(r.Pattern, \"ResourcePattern\", fmt.Sprintf(\"%v: %v\", InvalidResourcePatternErr, err)))","\t\treturn errs","\t}","\treturn nil","}","","// validateHashAlgorithm checks if the algorithm is supported","func validateHashAlgorithm(algorithmName HashAlgorithm) (errs *apis.FieldError) {","\tnormalizedAlgo := strings.ToLower(string(algorithmName))","\t_, exists := SupportedSignatureAlgorithms[HashAlgorithm(normalizedAlgo)]","\tif !exists {","\t\treturn apis.ErrInvalidValue(algorithmName, \"HashAlgorithm\")","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,0,0,2,2,0,0,2,2,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0]},{"id":70,"path":"pkg/apis/pipeline/v1beta1/container_conversion.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"",")","","func (r Ref) convertTo(ctx context.Context, sink *v1.Ref) {","\tsink.Name = r.Name","\tnew := v1.ResolverRef{}","\tr.ResolverRef.convertTo(ctx, \u0026new)","\tsink.ResolverRef = new","}","","func (r *Ref) convertFrom(ctx context.Context, source v1.Ref) {","\tr.Name = source.Name","\tnew := ResolverRef{}","\tnew.convertFrom(ctx, source.ResolverRef)","\tr.ResolverRef = new","}","","func (s Step) convertTo(ctx context.Context, sink *v1.Step) {","\tsink.Name = s.Name","\tsink.DisplayName = s.DisplayName","\tsink.Image = s.Image","\tsink.Command = s.Command","\tsink.Args = s.Args","\tsink.WorkingDir = s.WorkingDir","\tsink.EnvFrom = s.EnvFrom","\tsink.Env = s.Env","\tsink.ComputeResources = s.Resources","\tsink.VolumeMounts = s.VolumeMounts","\tsink.VolumeDevices = s.VolumeDevices","\tsink.ImagePullPolicy = s.ImagePullPolicy","\tsink.SecurityContext = s.SecurityContext","\tsink.Script = s.Script","\tsink.Timeout = s.Timeout","","\tsink.Workspaces = nil","\tfor _, w := range s.Workspaces {","\t\tnew := v1.WorkspaceUsage{}","\t\tw.convertTo(ctx, \u0026new)","\t\tsink.Workspaces = append(sink.Workspaces, new)","\t}","\tsink.OnError = (v1.OnErrorType)(s.OnError)","\tsink.StdoutConfig = (*v1.StepOutputConfig)(s.StdoutConfig)","\tsink.StderrConfig = (*v1.StepOutputConfig)(s.StderrConfig)","\tif s.Ref != nil {","\t\tsink.Ref = \u0026v1.Ref{}","\t\ts.Ref.convertTo(ctx, sink.Ref)","\t}","\tsink.Params = nil","\tfor _, p := range s.Params {","\t\tnew := v1.Param{}","\t\tp.convertTo(ctx, \u0026new)","\t\tsink.Params = append(sink.Params, new)","\t}","\tsink.Results = s.Results","\tfor _, w := range s.When {","\t\tnew := v1.WhenExpression{}","\t\tw.convertTo(ctx, \u0026new)","\t\tsink.When = append(sink.When, new)","\t}","}","","func (s *Step) convertFrom(ctx context.Context, source v1.Step) {","\ts.Name = source.Name","\ts.DisplayName = source.DisplayName","\ts.Image = source.Image","\ts.Command = source.Command","\ts.Args = source.Args","\ts.WorkingDir = source.WorkingDir","\ts.EnvFrom = source.EnvFrom","\ts.Env = source.Env","\ts.Resources = source.ComputeResources","\ts.VolumeMounts = source.VolumeMounts","\ts.VolumeDevices = source.VolumeDevices","\ts.ImagePullPolicy = source.ImagePullPolicy","\ts.SecurityContext = source.SecurityContext","\ts.Script = source.Script","\ts.Timeout = source.Timeout","","\ts.Workspaces = nil","\tfor _, w := range source.Workspaces {","\t\tnew := WorkspaceUsage{}","\t\tnew.convertFrom(ctx, w)","\t\ts.Workspaces = append(s.Workspaces, new)","\t}","\ts.OnError = (OnErrorType)(source.OnError)","\ts.StdoutConfig = (*StepOutputConfig)(source.StdoutConfig)","\ts.StderrConfig = (*StepOutputConfig)(source.StderrConfig)","\tif source.Ref != nil {","\t\tnewRef := Ref{}","\t\tnewRef.convertFrom(ctx, *source.Ref)","\t\ts.Ref = \u0026newRef","\t}","\ts.Params = nil","\tfor _, p := range source.Params {","\t\tnew := Param{}","\t\tnew.ConvertFrom(ctx, p)","\t\ts.Params = append(s.Params, new)","\t}","\ts.Results = source.Results","\tfor _, w := range source.When {","\t\tnew := WhenExpression{}","\t\tnew.convertFrom(ctx, w)","\t\ts.When = append(s.When, new)","\t}","}","","func (s StepTemplate) convertTo(ctx context.Context, sink *v1.StepTemplate) {","\tsink.Image = s.Image","\tsink.Command = s.Command","\tsink.Args = s.Args","\tsink.WorkingDir = s.WorkingDir","\tsink.EnvFrom = s.EnvFrom","\tsink.Env = s.Env","\tsink.ComputeResources = s.Resources","\tsink.VolumeMounts = s.VolumeMounts","\tsink.VolumeDevices = s.VolumeDevices","\tsink.ImagePullPolicy = s.ImagePullPolicy","\tsink.SecurityContext = s.SecurityContext","\t// TODO(#4546): Handle deprecated fields","\t// Name, Ports, LivenessProbe, ReadinessProbe, StartupProbe, Lifecycle, TerminationMessagePath","\t// TerminationMessagePolicy, Stdin, StdinOnce, TTY","}","","func (s *StepTemplate) convertFrom(ctx context.Context, source *v1.StepTemplate) {","\ts.Image = source.Image","\ts.Command = source.Command","\ts.Args = source.Args","\ts.WorkingDir = source.WorkingDir","\ts.EnvFrom = source.EnvFrom","\ts.Env = source.Env","\ts.Resources = source.ComputeResources","\ts.VolumeMounts = source.VolumeMounts","\ts.VolumeDevices = source.VolumeDevices","\ts.ImagePullPolicy = source.ImagePullPolicy","\ts.SecurityContext = source.SecurityContext","}","","func (s Sidecar) convertTo(ctx context.Context, sink *v1.Sidecar) {","\tsink.Name = s.Name","\tsink.Image = s.Image","\tsink.Command = s.Command","\tsink.Args = s.Args","\tsink.WorkingDir = s.WorkingDir","\tsink.Ports = s.Ports","\tsink.EnvFrom = s.EnvFrom","\tsink.Env = s.Env","\tsink.ComputeResources = s.Resources","\tsink.VolumeMounts = s.VolumeMounts","\tsink.VolumeDevices = s.VolumeDevices","\tsink.LivenessProbe = s.LivenessProbe","\tsink.ReadinessProbe = s.ReadinessProbe","\tsink.StartupProbe = s.StartupProbe","\tsink.Lifecycle = s.Lifecycle","\tsink.TerminationMessagePath = s.TerminationMessagePath","\tsink.TerminationMessagePolicy = s.TerminationMessagePolicy","\tsink.ImagePullPolicy = s.ImagePullPolicy","\tsink.SecurityContext = s.SecurityContext","\tsink.Stdin = s.Stdin","\tsink.StdinOnce = s.StdinOnce","\tsink.TTY = s.TTY","\tsink.Script = s.Script","\tsink.Workspaces = nil","\tfor _, w := range s.Workspaces {","\t\tnew := v1.WorkspaceUsage{}","\t\tw.convertTo(ctx, \u0026new)","\t\tsink.Workspaces = append(sink.Workspaces, new)","\t}","}","","func (s *Sidecar) convertFrom(ctx context.Context, source v1.Sidecar) {","\ts.Name = source.Name","\ts.Image = source.Image","\ts.Command = source.Command","\ts.Args = source.Args","\ts.WorkingDir = source.WorkingDir","\ts.Ports = source.Ports","\ts.EnvFrom = source.EnvFrom","\ts.Env = source.Env","\ts.Resources = source.ComputeResources","\ts.VolumeMounts = source.VolumeMounts","\ts.VolumeDevices = source.VolumeDevices","\ts.LivenessProbe = source.LivenessProbe","\ts.ReadinessProbe = source.ReadinessProbe","\ts.StartupProbe = source.StartupProbe","\ts.Lifecycle = source.Lifecycle","\ts.TerminationMessagePath = source.TerminationMessagePath","\ts.TerminationMessagePolicy = source.TerminationMessagePolicy","\ts.ImagePullPolicy = source.ImagePullPolicy","\ts.SecurityContext = source.SecurityContext","\ts.Stdin = source.Stdin","\ts.StdinOnce = source.StdinOnce","\ts.TTY = source.TTY","\ts.Script = source.Script","\ts.Workspaces = nil","\tfor _, w := range source.Workspaces {","\t\tnew := WorkspaceUsage{}","\t\tnew.convertFrom(ctx, w)","\t\ts.Workspaces = append(s.Workspaces, new)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0]},{"id":71,"path":"pkg/apis/pipeline/v1beta1/container_types.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"",")","","// Step runs a subcomponent of a Task","type Step struct {","\t// Name of the Step specified as a DNS_LABEL.","\t// Each Step in a Task must have a unique name.","\tName string `json:\"name\" protobuf:\"bytes,1,opt,name=name\"`","\t// DisplayName is a user-facing name of the step that may be","\t// used to populate a UI.","\t// +optional","\tDisplayName string `json:\"displayName,omitempty\"`","\t// Image reference name to run for this Step.","\t// More info: https://kubernetes.io/docs/concepts/containers/images","\t// +optional","\tImage string `json:\"image,omitempty\" protobuf:\"bytes,2,opt,name=image\"`","\t// Entrypoint array. Not executed within a shell.","\t// The image's ENTRYPOINT is used if this is not provided.","\t// Variable references $(VAR_NAME) are expanded using the container's environment. If a variable","\t// cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced","\t// to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$$(VAR_NAME)\" will","\t// produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless","\t// of whether the variable exists or not. Cannot be updated.","\t// More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell","\t// +optional","\t// +listType=atomic","\tCommand []string `json:\"command,omitempty\" protobuf:\"bytes,3,rep,name=command\"`","\t// Arguments to the entrypoint.","\t// The image's CMD is used if this is not provided.","\t// Variable references $(VAR_NAME) are expanded using the container's environment. If a variable","\t// cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced","\t// to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$$(VAR_NAME)\" will","\t// produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless","\t// of whether the variable exists or not. Cannot be updated.","\t// More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell","\t// +optional","\t// +listType=atomic","\tArgs []string `json:\"args,omitempty\" protobuf:\"bytes,4,rep,name=args\"`","\t// Step's working directory.","\t// If not specified, the container runtime's default will be used, which","\t// might be configured in the container image.","\t// Cannot be updated.","\t// +optional","\tWorkingDir string `json:\"workingDir,omitempty\" protobuf:\"bytes,5,opt,name=workingDir\"`","\t// List of ports to expose from the Step's container. Exposing a port here gives","\t// the system additional information about the network connections a","\t// container uses, but is primarily informational. Not specifying a port here","\t// DOES NOT prevent that port from being exposed. Any port which is","\t// listening on the default \"0.0.0.0\" address inside a container will be","\t// accessible from the network.","\t// Cannot be updated.","\t//","\t// Deprecated: This field will be removed in a future release.","\t//","\t// +optional","\t// +patchMergeKey=containerPort","\t// +patchStrategy=merge","\t// +listType=map","\t// +listMapKey=containerPort","\t// +listMapKey=protocol","\tDeprecatedPorts []corev1.ContainerPort `json:\"ports,omitempty\" patchMergeKey:\"containerPort\" patchStrategy:\"merge\" protobuf:\"bytes,6,rep,name=ports\"`","\t// List of sources to populate environment variables in the container.","\t// The keys defined within a source must be a C_IDENTIFIER. All invalid keys","\t// will be reported as an event when the container is starting. When a key exists in multiple","\t// sources, the value associated with the last source will take precedence.","\t// Values defined by an Env with a duplicate key will take precedence.","\t// Cannot be updated.","\t// +optional","\t// +listType=atomic","\tEnvFrom []corev1.EnvFromSource `json:\"envFrom,omitempty\" protobuf:\"bytes,19,rep,name=envFrom\"`","\t// List of environment variables to set in the container.","\t// Cannot be updated.","\t// +optional","\t// +patchMergeKey=name","\t// +patchStrategy=merge","\t// +listType=atomic","\tEnv []corev1.EnvVar `json:\"env,omitempty\" patchMergeKey:\"name\" patchStrategy:\"merge\" protobuf:\"bytes,7,rep,name=env\"`","\t// Compute Resources required by this Step.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/","\t// +optional","\tResources corev1.ResourceRequirements `json:\"resources,omitempty\" protobuf:\"bytes,8,opt,name=resources\"`","\t// Volumes to mount into the Step's filesystem.","\t// Cannot be updated.","\t// +optional","\t// +patchMergeKey=mountPath","\t// +patchStrategy=merge","\t// +listType=atomic","\tVolumeMounts []corev1.VolumeMount `json:\"volumeMounts,omitempty\" patchMergeKey:\"mountPath\" patchStrategy:\"merge\" protobuf:\"bytes,9,rep,name=volumeMounts\"`","\t// volumeDevices is the list of block devices to be used by the Step.","\t// +patchMergeKey=devicePath","\t// +patchStrategy=merge","\t// +optional","\t// +listType=atomic","\tVolumeDevices []corev1.VolumeDevice `json:\"volumeDevices,omitempty\" patchMergeKey:\"devicePath\" patchStrategy:\"merge\" protobuf:\"bytes,21,rep,name=volumeDevices\"`","\t// Periodic probe of container liveness.","\t// Step will be restarted if the probe fails.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes","\t//","\t// Deprecated: This field will be removed in a future release.","\t//","\t// +optional","\tDeprecatedLivenessProbe *corev1.Probe `json:\"livenessProbe,omitempty\" protobuf:\"bytes,10,opt,name=livenessProbe\"`","\t// Periodic probe of container service readiness.","\t// Step will be removed from service endpoints if the probe fails.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes","\t//","\t// Deprecated: This field will be removed in a future release.","\t//","\t// +optional","\tDeprecatedReadinessProbe *corev1.Probe `json:\"readinessProbe,omitempty\" protobuf:\"bytes,11,opt,name=readinessProbe\"`","","\t// DeprecatedStartupProbe indicates that the Pod this Step runs in has successfully initialized.","\t// If specified, no other probes are executed until this completes successfully.","\t// If this probe fails, the Pod will be restarted, just as if the livenessProbe failed.","\t// This can be used to provide different probe parameters at the beginning of a Pod's lifecycle,","\t// when it might take a long time to load data or warm a cache, than during steady-state operation.","\t// This cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes","\t//","\t// Deprecated: This field will be removed in a future release.","\t//","\t// +optional","\tDeprecatedStartupProbe *corev1.Probe `json:\"startupProbe,omitempty\" protobuf:\"bytes,22,opt,name=startupProbe\"`","\t// Actions that the management system should take in response to container lifecycle events.","\t// Cannot be updated.","\t//","\t// Deprecated: This field will be removed in a future release.","\t//","\t// +optional","\tDeprecatedLifecycle *corev1.Lifecycle `json:\"lifecycle,omitempty\" protobuf:\"bytes,12,opt,name=lifecycle\"`","\t// Deprecated: This field will be removed in a future release and can't be meaningfully used.","\t// +optional","\tDeprecatedTerminationMessagePath string `json:\"terminationMessagePath,omitempty\" protobuf:\"bytes,13,opt,name=terminationMessagePath\"`","\t// Deprecated: This field will be removed in a future release and can't be meaningfully used.","\t// +optional","\tDeprecatedTerminationMessagePolicy corev1.TerminationMessagePolicy `json:\"terminationMessagePolicy,omitempty\" protobuf:\"bytes,20,opt,name=terminationMessagePolicy,casttype=TerminationMessagePolicy\"`","\t// Image pull policy.","\t// One of Always, Never, IfNotPresent.","\t// Defaults to Always if :latest tag is specified, or IfNotPresent otherwise.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/containers/images#updating-images","\t// +optional","\tImagePullPolicy corev1.PullPolicy `json:\"imagePullPolicy,omitempty\" protobuf:\"bytes,14,opt,name=imagePullPolicy,casttype=PullPolicy\"`","\t// SecurityContext defines the security options the Step should be run with.","\t// If set, the fields of SecurityContext override the equivalent fields of PodSecurityContext.","\t// More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/","\t// +optional","\tSecurityContext *corev1.SecurityContext `json:\"securityContext,omitempty\" protobuf:\"bytes,15,opt,name=securityContext\"`","","\t// Variables for interactive containers, these are deprecated and should not be used.","","\t// Whether this container should allocate a buffer for stdin in the container runtime. If this","\t// is not set, reads from stdin in the container will always result in EOF.","\t// Default is false.","\t//","\t// Deprecated: This field will be removed in a future release.","\t//","\t// +optional","\tDeprecatedStdin bool `json:\"stdin,omitempty\" protobuf:\"varint,16,opt,name=stdin\"`","\t// Whether the container runtime should close the stdin channel after it has been opened by","\t// a single attach. When stdin is true the stdin stream will remain open across multiple attach","\t// sessions. If stdinOnce is set to true, stdin is opened on container start, is empty until the","\t// first client attaches to stdin, and then remains open and accepts data until the client disconnects,","\t// at which time stdin is closed and remains closed until the container is restarted. If this","\t// flag is false, a container processes that reads from stdin will never receive an EOF.","\t// Default is false","\t//","\t// Deprecated: This field will be removed in a future release.","\t//","\t// +optional","\tDeprecatedStdinOnce bool `json:\"stdinOnce,omitempty\" protobuf:\"varint,17,opt,name=stdinOnce\"`","\t// Whether this container should allocate a DeprecatedTTY for itself, also requires 'stdin' to be true.","\t// Default is false.","\t//","\t// Deprecated: This field will be removed in a future release.","\t//","\t// +optional","\tDeprecatedTTY bool `json:\"tty,omitempty\" protobuf:\"varint,18,opt,name=tty\"`","","\t// Script is the contents of an executable file to execute.","\t//","\t// If Script is not empty, the Step cannot have an Command and the Args will be passed to the Script.","\t// +optional","\tScript string `json:\"script,omitempty\"`","","\t// Timeout is the time after which the step times out. Defaults to never.","\t// Refer to Go's ParseDuration documentation for expected format: https://golang.org/pkg/time/#ParseDuration","\t// +optional","\tTimeout *metav1.Duration `json:\"timeout,omitempty\"`","","\t// This is an alpha field. You must set the \"enable-api-fields\" feature flag to \"alpha\"","\t// for this field to be supported.","\t//","\t// Workspaces is a list of workspaces from the Task that this Step wants","\t// exclusive access to. Adding a workspace to this list means that any","\t// other Step or Sidecar that does not also request this Workspace will","\t// not have access to it.","\t// +optional","\t// +listType=atomic","\tWorkspaces []WorkspaceUsage `json:\"workspaces,omitempty\"`","","\t// OnError defines the exiting behavior of a container on error","\t// can be set to [ continue | stopAndFail ]","\tOnError OnErrorType `json:\"onError,omitempty\"`","","\t// Stores configuration for the stdout stream of the step.","\t// +optional","\tStdoutConfig *StepOutputConfig `json:\"stdoutConfig,omitempty\"`","\t// Stores configuration for the stderr stream of the step.","\t// +optional","\tStderrConfig *StepOutputConfig `json:\"stderrConfig,omitempty\"`","","\t// Contains the reference to an existing StepAction.","\t//+optional","\tRef *Ref `json:\"ref,omitempty\"`","\t// Params declares parameters passed to this step action.","\t// +optional","\tParams Params `json:\"params,omitempty\"`","\t// Results declares StepResults produced by the Step.","\t//","\t// It can be used in an inlined Step when used to store Results to $(step.results.resultName.path).","\t// It cannot be used when referencing StepActions using [v1beta1.Step.Ref].","\t// The Results declared by the StepActions will be stored here instead.","\t// +optional","\t// +listType=atomic","\tResults []v1.StepResult `json:\"results,omitempty\"`","","\tWhen StepWhenExpressions `json:\"when,omitempty\"`","}","","// Ref can be used to refer to a specific instance of a StepAction.","type Ref struct {","\t// Name of the referenced step","\tName string `json:\"name,omitempty\"`","\t// ResolverRef allows referencing a StepAction in a remote location","\t// like a git repo.","\t// +optional","\tResolverRef `json:\",omitempty\"`","}","","// OnErrorType defines a list of supported exiting behavior of a container on error","type OnErrorType string","","const (","\t// StopAndFail indicates exit the taskRun if the container exits with non-zero exit code","\tStopAndFail OnErrorType = \"stopAndFail\"","\t// Continue indicates continue executing the rest of the steps irrespective of the container exit code","\tContinue OnErrorType = \"continue\"",")","","// StepOutputConfig stores configuration for a step output stream.","type StepOutputConfig struct {","\t// Path to duplicate stdout stream to on container's local filesystem.","\t// +optional","\tPath string `json:\"path,omitempty\"`","}","","// ToK8sContainer converts the Step to a Kubernetes Container struct","func (s *Step) ToK8sContainer() *corev1.Container {","\treturn \u0026corev1.Container{","\t\tName:                     s.Name,","\t\tImage:                    s.Image,","\t\tCommand:                  s.Command,","\t\tArgs:                     s.Args,","\t\tWorkingDir:               s.WorkingDir,","\t\tPorts:                    s.DeprecatedPorts,","\t\tEnvFrom:                  s.EnvFrom,","\t\tEnv:                      s.Env,","\t\tResources:                s.Resources,","\t\tVolumeMounts:             s.VolumeMounts,","\t\tVolumeDevices:            s.VolumeDevices,","\t\tLivenessProbe:            s.DeprecatedLivenessProbe,","\t\tReadinessProbe:           s.DeprecatedReadinessProbe,","\t\tStartupProbe:             s.DeprecatedStartupProbe,","\t\tLifecycle:                s.DeprecatedLifecycle,","\t\tTerminationMessagePath:   s.DeprecatedTerminationMessagePath,","\t\tTerminationMessagePolicy: s.DeprecatedTerminationMessagePolicy,","\t\tImagePullPolicy:          s.ImagePullPolicy,","\t\tSecurityContext:          s.SecurityContext,","\t\tStdin:                    s.DeprecatedStdin,","\t\tStdinOnce:                s.DeprecatedStdinOnce,","\t\tTTY:                      s.DeprecatedTTY,","\t}","}","","// SetContainerFields sets the fields of the Step to the values of the corresponding fields in the Container","func (s *Step) SetContainerFields(c corev1.Container) {","\ts.Name = c.Name","\ts.Image = c.Image","\ts.Command = c.Command","\ts.Args = c.Args","\ts.WorkingDir = c.WorkingDir","\ts.DeprecatedPorts = c.Ports","\ts.EnvFrom = c.EnvFrom","\ts.Env = c.Env","\ts.Resources = c.Resources","\ts.VolumeMounts = c.VolumeMounts","\ts.VolumeDevices = c.VolumeDevices","\ts.DeprecatedLivenessProbe = c.LivenessProbe","\ts.DeprecatedReadinessProbe = c.ReadinessProbe","\ts.DeprecatedStartupProbe = c.StartupProbe","\ts.DeprecatedLifecycle = c.Lifecycle","\ts.DeprecatedTerminationMessagePath = c.TerminationMessagePath","\ts.DeprecatedTerminationMessagePolicy = c.TerminationMessagePolicy","\ts.ImagePullPolicy = c.ImagePullPolicy","\ts.SecurityContext = c.SecurityContext","\ts.DeprecatedStdin = c.Stdin","\ts.DeprecatedStdinOnce = c.StdinOnce","\ts.DeprecatedTTY = c.TTY","}","","// StepTemplate is a template for a Step","type StepTemplate struct {","\t// Default name for each Step specified as a DNS_LABEL.","\t// Each Step in a Task must have a unique name.","\t// Cannot be updated.","\t//","\t// Deprecated: This field will be removed in a future release.","\t//","\tDeprecatedName string `json:\"name\" protobuf:\"bytes,1,opt,name=name\"`","\t// Default image name to use for each Step.","\t// More info: https://kubernetes.io/docs/concepts/containers/images","\t// This field is optional to allow higher level config management to default or override","\t// container images in workload controllers like Deployments and StatefulSets.","\t// +optional","\tImage string `json:\"image,omitempty\" protobuf:\"bytes,2,opt,name=image\"`","\t// Entrypoint array. Not executed within a shell.","\t// The docker image's ENTRYPOINT is used if this is not provided.","\t// Variable references $(VAR_NAME) are expanded using the Step's environment. If a variable","\t// cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced","\t// to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$$(VAR_NAME)\" will","\t// produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless","\t// of whether the variable exists or not. Cannot be updated.","\t// More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell","\t// +optional","\t// +listType=atomic","\tCommand []string `json:\"command,omitempty\" protobuf:\"bytes,3,rep,name=command\"`","\t// Arguments to the entrypoint.","\t// The image's CMD is used if this is not provided.","\t// Variable references $(VAR_NAME) are expanded using the Step's environment. If a variable","\t// cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced","\t// to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$$(VAR_NAME)\" will","\t// produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless","\t// of whether the variable exists or not. Cannot be updated.","\t// More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell","\t// +optional","\t// +listType=atomic","\tArgs []string `json:\"args,omitempty\" protobuf:\"bytes,4,rep,name=args\"`","\t// Step's working directory.","\t// If not specified, the container runtime's default will be used, which","\t// might be configured in the container image.","\t// Cannot be updated.","\t// +optional","\tWorkingDir string `json:\"workingDir,omitempty\" protobuf:\"bytes,5,opt,name=workingDir\"`","\t// List of ports to expose from the Step's container. Exposing a port here gives","\t// the system additional information about the network connections a","\t// container uses, but is primarily informational. Not specifying a port here","\t// DOES NOT prevent that port from being exposed. Any port which is","\t// listening on the default \"0.0.0.0\" address inside a container will be","\t// accessible from the network.","\t// Cannot be updated.","\t//","\t// Deprecated: This field will be removed in a future release.","\t//","\t// +optional","\t// +patchMergeKey=containerPort","\t// +patchStrategy=merge","\t// +listType=map","\t// +listMapKey=containerPort","\t// +listMapKey=protocol","\tDeprecatedPorts []corev1.ContainerPort `json:\"ports,omitempty\" patchMergeKey:\"containerPort\" patchStrategy:\"merge\" protobuf:\"bytes,6,rep,name=ports\"`","\t// List of sources to populate environment variables in the Step.","\t// The keys defined within a source must be a C_IDENTIFIER. All invalid keys","\t// will be reported as an event when the container is starting. When a key exists in multiple","\t// sources, the value associated with the last source will take precedence.","\t// Values defined by an Env with a duplicate key will take precedence.","\t// Cannot be updated.","\t// +optional","\t// +listType=atomic","\tEnvFrom []corev1.EnvFromSource `json:\"envFrom,omitempty\" protobuf:\"bytes,19,rep,name=envFrom\"`","\t// List of environment variables to set in the container.","\t// Cannot be updated.","\t// +optional","\t// +patchMergeKey=name","\t// +patchStrategy=merge","\t// +listType=atomic","\tEnv []corev1.EnvVar `json:\"env,omitempty\" patchMergeKey:\"name\" patchStrategy:\"merge\" protobuf:\"bytes,7,rep,name=env\"`","\t// Compute Resources required by this Step.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/","\t// +optional","\tResources corev1.ResourceRequirements `json:\"resources,omitempty\" protobuf:\"bytes,8,opt,name=resources\"`","\t// Volumes to mount into the Step's filesystem.","\t// Cannot be updated.","\t// +optional","\t// +patchMergeKey=mountPath","\t// +patchStrategy=merge","\t// +listType=atomic","\tVolumeMounts []corev1.VolumeMount `json:\"volumeMounts,omitempty\" patchMergeKey:\"mountPath\" patchStrategy:\"merge\" protobuf:\"bytes,9,rep,name=volumeMounts\"`","\t// volumeDevices is the list of block devices to be used by the Step.","\t// +patchMergeKey=devicePath","\t// +patchStrategy=merge","\t// +optional","\t// +listType=atomic","\tVolumeDevices []corev1.VolumeDevice `json:\"volumeDevices,omitempty\" patchMergeKey:\"devicePath\" patchStrategy:\"merge\" protobuf:\"bytes,21,rep,name=volumeDevices\"`","\t// Periodic probe of container liveness.","\t// Container will be restarted if the probe fails.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes","\t//","\t// Deprecated: This field will be removed in a future release.","\t//","\t// +optional","\tDeprecatedLivenessProbe *corev1.Probe `json:\"livenessProbe,omitempty\" protobuf:\"bytes,10,opt,name=livenessProbe\"`","\t// Periodic probe of container service readiness.","\t// Container will be removed from service endpoints if the probe fails.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes","\t//","\t// Deprecated: This field will be removed in a future release.","\t//","\t// +optional","\tDeprecatedReadinessProbe *corev1.Probe `json:\"readinessProbe,omitempty\" protobuf:\"bytes,11,opt,name=readinessProbe\"`","\t// DeprecatedStartupProbe indicates that the Pod has successfully initialized.","\t// If specified, no other probes are executed until this completes successfully.","\t// If this probe fails, the Pod will be restarted, just as if the livenessProbe failed.","\t// This can be used to provide different probe parameters at the beginning of a Pod's lifecycle,","\t// when it might take a long time to load data or warm a cache, than during steady-state operation.","\t// This cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes","\t//","\t// Deprecated: This field will be removed in a future release.","\t//","\t// +optional","\tDeprecatedStartupProbe *corev1.Probe `json:\"startupProbe,omitempty\" protobuf:\"bytes,22,opt,name=startupProbe\"`","\t// Actions that the management system should take in response to container lifecycle events.","\t// Cannot be updated.","\t//","\t// Deprecated: This field will be removed in a future release.","\t//","\t// +optional","\tDeprecatedLifecycle *corev1.Lifecycle `json:\"lifecycle,omitempty\" protobuf:\"bytes,12,opt,name=lifecycle\"`","\t// Deprecated: This field will be removed in a future release and cannot be meaningfully used.","\t// +optional","\tDeprecatedTerminationMessagePath string `json:\"terminationMessagePath,omitempty\" protobuf:\"bytes,13,opt,name=terminationMessagePath\"`","\t// Deprecated: This field will be removed in a future release and cannot be meaningfully used.","\t// +optional","\tDeprecatedTerminationMessagePolicy corev1.TerminationMessagePolicy `json:\"terminationMessagePolicy,omitempty\" protobuf:\"bytes,20,opt,name=terminationMessagePolicy,casttype=TerminationMessagePolicy\"`","\t// Image pull policy.","\t// One of Always, Never, IfNotPresent.","\t// Defaults to Always if :latest tag is specified, or IfNotPresent otherwise.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/containers/images#updating-images","\t// +optional","\tImagePullPolicy corev1.PullPolicy `json:\"imagePullPolicy,omitempty\" protobuf:\"bytes,14,opt,name=imagePullPolicy,casttype=PullPolicy\"`","\t// SecurityContext defines the security options the Step should be run with.","\t// If set, the fields of SecurityContext override the equivalent fields of PodSecurityContext.","\t// More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/","\t// +optional","\tSecurityContext *corev1.SecurityContext `json:\"securityContext,omitempty\" protobuf:\"bytes,15,opt,name=securityContext\"`","","\t// Variables for interactive containers, these are deprecated and should not be used.","","\t// Whether this Step should allocate a buffer for stdin in the container runtime. If this","\t// is not set, reads from stdin in the Step will always result in EOF.","\t// Default is false.","\t//","\t// Deprecated: This field will be removed in a future release.","\t//","\t// +optional","\tDeprecatedStdin bool `json:\"stdin,omitempty\" protobuf:\"varint,16,opt,name=stdin\"`","\t// Whether the container runtime should close the stdin channel after it has been opened by","\t// a single attach. When stdin is true the stdin stream will remain open across multiple attach","\t// sessions. If stdinOnce is set to true, stdin is opened on container start, is empty until the","\t// first client attaches to stdin, and then remains open and accepts data until the client disconnects,","\t// at which time stdin is closed and remains closed until the container is restarted. If this","\t// flag is false, a container processes that reads from stdin will never receive an EOF.","\t// Default is false","\t//","\t// Deprecated: This field will be removed in a future release.","\t//","\t// +optional","\tDeprecatedStdinOnce bool `json:\"stdinOnce,omitempty\" protobuf:\"varint,17,opt,name=stdinOnce\"`","\t// Whether this Step should allocate a DeprecatedTTY for itself, also requires 'stdin' to be true.","\t// Default is false.","\t//","\t// Deprecated: This field will be removed in a future release.","\t//","\t// +optional","\tDeprecatedTTY bool `json:\"tty,omitempty\" protobuf:\"varint,18,opt,name=tty\"`","}","","// SetContainerFields sets the fields of the Step to the values of the corresponding fields in the Container","func (s *StepTemplate) SetContainerFields(c corev1.Container) {","\ts.DeprecatedName = c.Name","\ts.Image = c.Image","\ts.Command = c.Command","\ts.Args = c.Args","\ts.WorkingDir = c.WorkingDir","\ts.DeprecatedPorts = c.Ports","\ts.EnvFrom = c.EnvFrom","\ts.Env = c.Env","\ts.Resources = c.Resources","\ts.VolumeMounts = c.VolumeMounts","\ts.VolumeDevices = c.VolumeDevices","\ts.DeprecatedLivenessProbe = c.LivenessProbe","\ts.DeprecatedReadinessProbe = c.ReadinessProbe","\ts.DeprecatedStartupProbe = c.StartupProbe","\ts.DeprecatedLifecycle = c.Lifecycle","\ts.DeprecatedTerminationMessagePath = c.TerminationMessagePath","\ts.DeprecatedTerminationMessagePolicy = c.TerminationMessagePolicy","\ts.ImagePullPolicy = c.ImagePullPolicy","\ts.SecurityContext = c.SecurityContext","\ts.DeprecatedStdin = c.Stdin","\ts.DeprecatedStdinOnce = c.StdinOnce","\ts.DeprecatedTTY = c.TTY","}","","// ToK8sContainer converts the StepTemplate to a Kubernetes Container struct","func (s *StepTemplate) ToK8sContainer() *corev1.Container {","\treturn \u0026corev1.Container{","\t\tName:                     s.DeprecatedName,","\t\tImage:                    s.Image,","\t\tCommand:                  s.Command,","\t\tArgs:                     s.Args,","\t\tWorkingDir:               s.WorkingDir,","\t\tPorts:                    s.DeprecatedPorts,","\t\tEnvFrom:                  s.EnvFrom,","\t\tEnv:                      s.Env,","\t\tResources:                s.Resources,","\t\tVolumeMounts:             s.VolumeMounts,","\t\tVolumeDevices:            s.VolumeDevices,","\t\tLivenessProbe:            s.DeprecatedLivenessProbe,","\t\tReadinessProbe:           s.DeprecatedReadinessProbe,","\t\tStartupProbe:             s.DeprecatedStartupProbe,","\t\tLifecycle:                s.DeprecatedLifecycle,","\t\tTerminationMessagePath:   s.DeprecatedTerminationMessagePath,","\t\tTerminationMessagePolicy: s.DeprecatedTerminationMessagePolicy,","\t\tImagePullPolicy:          s.ImagePullPolicy,","\t\tSecurityContext:          s.SecurityContext,","\t\tStdin:                    s.DeprecatedStdin,","\t\tStdinOnce:                s.DeprecatedStdinOnce,","\t\tTTY:                      s.DeprecatedTTY,","\t}","}","","// Sidecar has nearly the same data structure as Step but does not have the ability to timeout.","type Sidecar struct {","\t// Name of the Sidecar specified as a DNS_LABEL.","\t// Each Sidecar in a Task must have a unique name (DNS_LABEL).","\t// Cannot be updated.","\tName string `json:\"name\" protobuf:\"bytes,1,opt,name=name\"`","\t// Image name to be used by the Sidecar.","\t// More info: https://kubernetes.io/docs/concepts/containers/images","\t// +optional","\tImage string `json:\"image,omitempty\" protobuf:\"bytes,2,opt,name=image\"`","\t// Entrypoint array. Not executed within a shell.","\t// The image's ENTRYPOINT is used if this is not provided.","\t// Variable references $(VAR_NAME) are expanded using the Sidecar's environment. If a variable","\t// cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced","\t// to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$$(VAR_NAME)\" will","\t// produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless","\t// of whether the variable exists or not. Cannot be updated.","\t// More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell","\t// +optional","\t// +listType=atomic","\tCommand []string `json:\"command,omitempty\" protobuf:\"bytes,3,rep,name=command\"`","\t// Arguments to the entrypoint.","\t// The image's CMD is used if this is not provided.","\t// Variable references $(VAR_NAME) are expanded using the container's environment. If a variable","\t// cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced","\t// to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$$(VAR_NAME)\" will","\t// produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless","\t// of whether the variable exists or not. Cannot be updated.","\t// More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell","\t// +optional","\t// +listType=atomic","\tArgs []string `json:\"args,omitempty\" protobuf:\"bytes,4,rep,name=args\"`","\t// Sidecar's working directory.","\t// If not specified, the container runtime's default will be used, which","\t// might be configured in the container image.","\t// Cannot be updated.","\t// +optional","\tWorkingDir string `json:\"workingDir,omitempty\" protobuf:\"bytes,5,opt,name=workingDir\"`","\t// List of ports to expose from the Sidecar. Exposing a port here gives","\t// the system additional information about the network connections a","\t// container uses, but is primarily informational. Not specifying a port here","\t// DOES NOT prevent that port from being exposed. Any port which is","\t// listening on the default \"0.0.0.0\" address inside a container will be","\t// accessible from the network.","\t// Cannot be updated.","\t// +optional","\t// +patchMergeKey=containerPort","\t// +patchStrategy=merge","\t// +listType=map","\t// +listMapKey=containerPort","\t// +listMapKey=protocol","\tPorts []corev1.ContainerPort `json:\"ports,omitempty\" patchMergeKey:\"containerPort\" patchStrategy:\"merge\" protobuf:\"bytes,6,rep,name=ports\"`","\t// List of sources to populate environment variables in the Sidecar.","\t// The keys defined within a source must be a C_IDENTIFIER. All invalid keys","\t// will be reported as an event when the Sidecar is starting. When a key exists in multiple","\t// sources, the value associated with the last source will take precedence.","\t// Values defined by an Env with a duplicate key will take precedence.","\t// Cannot be updated.","\t// +optional","\t// +listType=atomic","\tEnvFrom []corev1.EnvFromSource `json:\"envFrom,omitempty\" protobuf:\"bytes,19,rep,name=envFrom\"`","\t// List of environment variables to set in the Sidecar.","\t// Cannot be updated.","\t// +optional","\t// +patchMergeKey=name","\t// +patchStrategy=merge","\t// +listType=atomic","\tEnv []corev1.EnvVar `json:\"env,omitempty\" patchMergeKey:\"name\" patchStrategy:\"merge\" protobuf:\"bytes,7,rep,name=env\"`","\t// Compute Resources required by this Sidecar.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/","\t// +optional","\tResources corev1.ResourceRequirements `json:\"resources,omitempty\" protobuf:\"bytes,8,opt,name=resources\"`","\t// Volumes to mount into the Sidecar's filesystem.","\t// Cannot be updated.","\t// +optional","\t// +patchMergeKey=mountPath","\t// +patchStrategy=merge","\t// +listType=atomic","\tVolumeMounts []corev1.VolumeMount `json:\"volumeMounts,omitempty\" patchMergeKey:\"mountPath\" patchStrategy:\"merge\" protobuf:\"bytes,9,rep,name=volumeMounts\"`","\t// volumeDevices is the list of block devices to be used by the Sidecar.","\t// +patchMergeKey=devicePath","\t// +patchStrategy=merge","\t// +optional","\t// +listType=atomic","\tVolumeDevices []corev1.VolumeDevice `json:\"volumeDevices,omitempty\" patchMergeKey:\"devicePath\" patchStrategy:\"merge\" protobuf:\"bytes,21,rep,name=volumeDevices\"`","\t// Periodic probe of Sidecar liveness.","\t// Container will be restarted if the probe fails.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes","\t// +optional","\tLivenessProbe *corev1.Probe `json:\"livenessProbe,omitempty\" protobuf:\"bytes,10,opt,name=livenessProbe\"`","\t// Periodic probe of Sidecar service readiness.","\t// Container will be removed from service endpoints if the probe fails.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes","\t// +optional","\tReadinessProbe *corev1.Probe `json:\"readinessProbe,omitempty\" protobuf:\"bytes,11,opt,name=readinessProbe\"`","\t// StartupProbe indicates that the Pod the Sidecar is running in has successfully initialized.","\t// If specified, no other probes are executed until this completes successfully.","\t// If this probe fails, the Pod will be restarted, just as if the livenessProbe failed.","\t// This can be used to provide different probe parameters at the beginning of a Pod's lifecycle,","\t// when it might take a long time to load data or warm a cache, than during steady-state operation.","\t// This cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes","\t// +optional","\tStartupProbe *corev1.Probe `json:\"startupProbe,omitempty\" protobuf:\"bytes,22,opt,name=startupProbe\"`","\t// Actions that the management system should take in response to Sidecar lifecycle events.","\t// Cannot be updated.","\t// +optional","\tLifecycle *corev1.Lifecycle `json:\"lifecycle,omitempty\" protobuf:\"bytes,12,opt,name=lifecycle\"`","\t// Optional: Path at which the file to which the Sidecar's termination message","\t// will be written is mounted into the Sidecar's filesystem.","\t// Message written is intended to be brief final status, such as an assertion failure message.","\t// Will be truncated by the node if greater than 4096 bytes. The total message length across","\t// all containers will be limited to 12kb.","\t// Defaults to /dev/termination-log.","\t// Cannot be updated.","\t// +optional","\tTerminationMessagePath string `json:\"terminationMessagePath,omitempty\" protobuf:\"bytes,13,opt,name=terminationMessagePath\"`","\t// Indicate how the termination message should be populated. File will use the contents of","\t// terminationMessagePath to populate the Sidecar status message on both success and failure.","\t// FallbackToLogsOnError will use the last chunk of Sidecar log output if the termination","\t// message file is empty and the Sidecar exited with an error.","\t// The log output is limited to 2048 bytes or 80 lines, whichever is smaller.","\t// Defaults to File.","\t// Cannot be updated.","\t// +optional","\tTerminationMessagePolicy corev1.TerminationMessagePolicy `json:\"terminationMessagePolicy,omitempty\" protobuf:\"bytes,20,opt,name=terminationMessagePolicy,casttype=TerminationMessagePolicy\"`","\t// Image pull policy.","\t// One of Always, Never, IfNotPresent.","\t// Defaults to Always if :latest tag is specified, or IfNotPresent otherwise.","\t// Cannot be updated.","\t// More info: https://kubernetes.io/docs/concepts/containers/images#updating-images","\t// +optional","\tImagePullPolicy corev1.PullPolicy `json:\"imagePullPolicy,omitempty\" protobuf:\"bytes,14,opt,name=imagePullPolicy,casttype=PullPolicy\"`","\t// SecurityContext defines the security options the Sidecar should be run with.","\t// If set, the fields of SecurityContext override the equivalent fields of PodSecurityContext.","\t// More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/","\t// +optional","\tSecurityContext *corev1.SecurityContext `json:\"securityContext,omitempty\" protobuf:\"bytes,15,opt,name=securityContext\"`","","\t// Variables for interactive containers, these have very specialized use-cases (e.g. debugging)","\t// and shouldn't be used for general purpose containers.","","\t// Whether this Sidecar should allocate a buffer for stdin in the container runtime. If this","\t// is not set, reads from stdin in the Sidecar will always result in EOF.","\t// Default is false.","\t// +optional","\tStdin bool `json:\"stdin,omitempty\" protobuf:\"varint,16,opt,name=stdin\"`","\t// Whether the container runtime should close the stdin channel after it has been opened by","\t// a single attach. When stdin is true the stdin stream will remain open across multiple attach","\t// sessions. If stdinOnce is set to true, stdin is opened on Sidecar start, is empty until the","\t// first client attaches to stdin, and then remains open and accepts data until the client disconnects,","\t// at which time stdin is closed and remains closed until the Sidecar is restarted. If this","\t// flag is false, a container processes that reads from stdin will never receive an EOF.","\t// Default is false","\t// +optional","\tStdinOnce bool `json:\"stdinOnce,omitempty\" protobuf:\"varint,17,opt,name=stdinOnce\"`","\t// Whether this Sidecar should allocate a TTY for itself, also requires 'stdin' to be true.","\t// Default is false.","\t// +optional","\tTTY bool `json:\"tty,omitempty\" protobuf:\"varint,18,opt,name=tty\"`","","\t// Script is the contents of an executable file to execute.","\t//","\t// If Script is not empty, the Step cannot have an Command or Args.","\t// +optional","\tScript string `json:\"script,omitempty\"`","","\t// This is an alpha field. You must set the \"enable-api-fields\" feature flag to \"alpha\"","\t// for this field to be supported.","\t//","\t// Workspaces is a list of workspaces from the Task that this Sidecar wants","\t// exclusive access to. Adding a workspace to this list means that any","\t// other Step or Sidecar that does not also request this Workspace will","\t// not have access to it.","\t// +optional","\t// +listType=atomic","\tWorkspaces []WorkspaceUsage `json:\"workspaces,omitempty\"`","","\t// RestartPolicy refers to kubernetes RestartPolicy. It can only be set for an","\t// initContainer and must have it's policy set to \"Always\". It is currently","\t// left optional to help support Kubernetes versions prior to 1.29 when this feature","\t// was introduced.","\t// +optional","\tRestartPolicy *corev1.ContainerRestartPolicy `json:\"restartPolicy,omitempty\"`","}","","// ToK8sContainer converts the Sidecar to a Kubernetes Container struct","func (s *Sidecar) ToK8sContainer() *corev1.Container {","\tif s.RestartPolicy == nil {","\t\treturn \u0026corev1.Container{","\t\t\tName:                     s.Name,","\t\t\tImage:                    s.Image,","\t\t\tCommand:                  s.Command,","\t\t\tArgs:                     s.Args,","\t\t\tWorkingDir:               s.WorkingDir,","\t\t\tPorts:                    s.Ports,","\t\t\tEnvFrom:                  s.EnvFrom,","\t\t\tEnv:                      s.Env,","\t\t\tResources:                s.Resources,","\t\t\tVolumeMounts:             s.VolumeMounts,","\t\t\tVolumeDevices:            s.VolumeDevices,","\t\t\tLivenessProbe:            s.LivenessProbe,","\t\t\tReadinessProbe:           s.ReadinessProbe,","\t\t\tStartupProbe:             s.StartupProbe,","\t\t\tLifecycle:                s.Lifecycle,","\t\t\tTerminationMessagePath:   s.TerminationMessagePath,","\t\t\tTerminationMessagePolicy: s.TerminationMessagePolicy,","\t\t\tImagePullPolicy:          s.ImagePullPolicy,","\t\t\tSecurityContext:          s.SecurityContext,","\t\t\tStdin:                    s.Stdin,","\t\t\tStdinOnce:                s.StdinOnce,","\t\t\tTTY:                      s.TTY,","\t\t}","\t}","\treturn \u0026corev1.Container{","\t\tName:                     s.Name,","\t\tImage:                    s.Image,","\t\tCommand:                  s.Command,","\t\tArgs:                     s.Args,","\t\tWorkingDir:               s.WorkingDir,","\t\tPorts:                    s.Ports,","\t\tEnvFrom:                  s.EnvFrom,","\t\tEnv:                      s.Env,","\t\tResources:                s.Resources,","\t\tVolumeMounts:             s.VolumeMounts,","\t\tVolumeDevices:            s.VolumeDevices,","\t\tLivenessProbe:            s.LivenessProbe,","\t\tReadinessProbe:           s.ReadinessProbe,","\t\tRestartPolicy:            s.RestartPolicy,","\t\tStartupProbe:             s.StartupProbe,","\t\tLifecycle:                s.Lifecycle,","\t\tTerminationMessagePath:   s.TerminationMessagePath,","\t\tTerminationMessagePolicy: s.TerminationMessagePolicy,","\t\tImagePullPolicy:          s.ImagePullPolicy,","\t\tSecurityContext:          s.SecurityContext,","\t\tStdin:                    s.Stdin,","\t\tStdinOnce:                s.StdinOnce,","\t\tTTY:                      s.TTY,","\t}","}","","// SetContainerFields sets the fields of the Sidecar to the values of the corresponding fields in the Container","func (s *Sidecar) SetContainerFields(c corev1.Container) {","\ts.Name = c.Name","\ts.Image = c.Image","\ts.Command = c.Command","\ts.Args = c.Args","\ts.WorkingDir = c.WorkingDir","\ts.Ports = c.Ports","\ts.EnvFrom = c.EnvFrom","\ts.Env = c.Env","\ts.Resources = c.Resources","\ts.VolumeMounts = c.VolumeMounts","\ts.VolumeDevices = c.VolumeDevices","\ts.LivenessProbe = c.LivenessProbe","\ts.ReadinessProbe = c.ReadinessProbe","\ts.StartupProbe = c.StartupProbe","\ts.Lifecycle = c.Lifecycle","\ts.TerminationMessagePath = c.TerminationMessagePath","\ts.TerminationMessagePolicy = c.TerminationMessagePolicy","\ts.ImagePullPolicy = c.ImagePullPolicy","\ts.SecurityContext = c.SecurityContext","\ts.Stdin = c.Stdin","\ts.StdinOnce = c.StdinOnce","\ts.TTY = c.TTY","\ts.RestartPolicy = c.RestartPolicy","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]},{"id":72,"path":"pkg/apis/pipeline/v1beta1/container_validation.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","\t\"regexp\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"k8s.io/apimachinery/pkg/util/validation\"","\t\"knative.dev/pkg/apis\"",")","","func validateRef(ctx context.Context, refName string, refResolver ResolverName, refParams Params) (errs *apis.FieldError) {","\tswitch {","\tcase refResolver != \"\" || refParams != nil:","\t\tif refParams != nil {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"resolver params\", config.BetaAPIFields).ViaField(\"params\"))","\t\t\tif refName != \"\" {","\t\t\t\terrs = errs.Also(apis.ErrMultipleOneOf(\"name\", \"params\"))","\t\t\t}","\t\t\tif refResolver == \"\" {","\t\t\t\terrs = errs.Also(apis.ErrMissingField(\"resolver\"))","\t\t\t}","\t\t\terrs = errs.Also(ValidateParameters(ctx, refParams))","\t\t}","\t\tif refResolver != \"\" {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"resolver\", config.BetaAPIFields).ViaField(\"resolver\"))","\t\t\tif refName != \"\" {","\t\t\t\t// make sure that the name is url-like.","\t\t\t\terr := RefNameLikeUrl(refName)","\t\t\t\tif err == nil \u0026\u0026 !config.FromContextOrDefaults(ctx).FeatureFlags.EnableConciseResolverSyntax {","\t\t\t\t\t// If name is url-like then concise resolver syntax must be enabled","\t\t\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"feature flag %s should be set to true to use concise resolver syntax\", config.EnableConciseResolverSyntax), \"\"))","\t\t\t\t}","\t\t\t\tif err != nil {","\t\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(err, \"name\"))","\t\t\t\t}","\t\t\t}","\t\t}","\tcase refName != \"\":","\t\t// ref name can be a Url-like format.","\t\tif err := RefNameLikeUrl(refName); err == nil {","\t\t\t// If name is url-like then concise resolver syntax must be enabled","\t\t\tif !config.FromContextOrDefaults(ctx).FeatureFlags.EnableConciseResolverSyntax {","\t\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"feature flag %s should be set to true to use concise resolver syntax\", config.EnableConciseResolverSyntax), \"\"))","\t\t\t}","\t\t\t// In stage1 of concise remote resolvers syntax, this is a required field.","\t\t\t// TODO: remove this check when implementing stage 2 where this is optional.","\t\t\tif refResolver == \"\" {","\t\t\t\terrs = errs.Also(apis.ErrMissingField(\"resolver\"))","\t\t\t}","\t\t\t// Or, it must be a valid k8s name","\t\t} else {","\t\t\t// ref name must be a valid k8s name","\t\t\tif errSlice := validation.IsQualifiedName(refName); len(errSlice) != 0 {","\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(strings.Join(errSlice, \",\"), \"name\"))","\t\t\t}","\t\t}","\tdefault:","\t\terrs = errs.Also(apis.ErrMissingField(\"name\"))","\t}","\treturn errs","}","","// Validate ensures that a supplied Ref field is populated","// correctly. No errors are returned for a nil Ref.","func (ref *Ref) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif ref == nil {","\t\treturn errs","\t}","\treturn validateRef(ctx, ref.Name, ref.Resolver, ref.Params)","}","","// RefNameLikeUrl checks if the name is url parsable and returns an error if it isn't.","func RefNameLikeUrl(name string) error {","\tschemeRegex := regexp.MustCompile(`[\\w-]+:\\/\\/*`)","\tif !schemeRegex.MatchString(name) {","\t\treturn errors.New(\"invalid URI for request\")","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,0,2,2,2,2,2,0,2,2,0,2,0,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0]},{"id":73,"path":"pkg/apis/pipeline/v1beta1/customrun_defaults.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Defaultable = (*CustomRun)(nil)","","// SetDefaults implements apis.Defaultable","func (r *CustomRun) SetDefaults(ctx context.Context) {","\tctx = apis.WithinParent(ctx, r.ObjectMeta)","\tr.Spec.SetDefaults(apis.WithinSpec(ctx))","}","","// SetDefaults implements apis.Defaultable","func (rs *CustomRunSpec) SetDefaults(ctx context.Context) {","\tcfg := config.FromContextOrDefaults(ctx)","\tdefaultSA := cfg.Defaults.DefaultServiceAccount","\tif rs.ServiceAccountName == \"\" \u0026\u0026 defaultSA != \"\" {","\t\trs.ServiceAccountName = defaultSA","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,1,1,1,1,1,1,0]},{"id":74,"path":"pkg/apis/pipeline/v1beta1/customrun_types.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"fmt\"","\t\"time\"","","\tapisconfig \"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\trunv1beta1 \"github.com/tektoncd/pipeline/pkg/apis/run/v1beta1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"","\t\"k8s.io/utils/clock\"","\t\"knative.dev/pkg/apis\"","\tduckv1 \"knative.dev/pkg/apis/duck/v1\"",")","","// EmbeddedCustomRunSpec allows custom task definitions to be embedded","type EmbeddedCustomRunSpec struct {","\truntime.TypeMeta `json:\",inline\"`","","\t// +optional","\tMetadata PipelineTaskMetadata `json:\"metadata,omitempty\"`","","\t// Spec is a specification of a custom task","\t// +optional","\tSpec runtime.RawExtension `json:\"spec,omitempty\"`","}","","// CustomRunSpec defines the desired state of CustomRun","type CustomRunSpec struct {","\t// +optional","\tCustomRef *TaskRef `json:\"customRef,omitempty\"`","","\t// Spec is a specification of a custom task","\t// +optional","\tCustomSpec *EmbeddedCustomRunSpec `json:\"customSpec,omitempty\"`","","\t// +optional","\tParams Params `json:\"params,omitempty\"`","","\t// Used for cancelling a customrun (and maybe more later on)","\t// +optional","\tStatus CustomRunSpecStatus `json:\"status,omitempty\"`","","\t// Status message for cancellation.","\t// +optional","\tStatusMessage CustomRunSpecStatusMessage `json:\"statusMessage,omitempty\"`","","\t// Used for propagating retries count to custom tasks","\t// +optional","\tRetries int `json:\"retries,omitempty\"`","","\t// +optional","\tServiceAccountName string `json:\"serviceAccountName\"`","","\t// Time after which the custom-task times out.","\t// Refer Go's ParseDuration documentation for expected format: https://golang.org/pkg/time/#ParseDuration","\t// +optional","\tTimeout *metav1.Duration `json:\"timeout,omitempty\"`","","\t// Workspaces is a list of WorkspaceBindings from volumes to workspaces.","\t// +optional","\t// +listType=atomic","\tWorkspaces []WorkspaceBinding `json:\"workspaces,omitempty\"`","}","","// CustomRunSpecStatus defines the taskrun spec status the user can provide","type CustomRunSpecStatus string","","const (","\t// CustomRunSpecStatusCancelled indicates that the user wants to cancel the run,","\t// if not already cancelled or terminated","\tCustomRunSpecStatusCancelled CustomRunSpecStatus = \"RunCancelled\"",")","","// CustomRunSpecStatusMessage defines human readable status messages for the TaskRun.","type CustomRunSpecStatusMessage string","","const (","\t// CustomRunCancelledByPipelineMsg indicates that the PipelineRun of which part this CustomRun was","\t// has been cancelled.","\tCustomRunCancelledByPipelineMsg CustomRunSpecStatusMessage = \"CustomRun cancelled as the PipelineRun it belongs to has been cancelled.\"","\t// CustomRunCancelledByPipelineTimeoutMsg indicates that the Run was cancelled because the PipelineRun running it timed out.","\tCustomRunCancelledByPipelineTimeoutMsg CustomRunSpecStatusMessage = \"CustomRun cancelled as the PipelineRun it belongs to has timed out.\"",")","","// GetParam gets the Param from the CustomRunSpec with the given name","// TODO(jasonhall): Move this to a Params type so other code can use it?","func (rs CustomRunSpec) GetParam(name string) *Param {","\tfor _, p := range rs.Params {","\t\tif p.Name == name {","\t\t\treturn \u0026p","\t\t}","\t}","\treturn nil","}","","// CustomRunReason is an enum used to store all Run reason for the Succeeded condition that are controlled by the CustomRun itself.","type CustomRunReason string","","const (","\t// CustomRunReasonStarted is the reason set when the CustomRun has just started.","\tCustomRunReasonStarted CustomRunReason = \"Started\"","\t// CustomRunReasonRunning is the reason set when the CustomRun is running.","\tCustomRunReasonRunning CustomRunReason = \"Running\"","\t// CustomRunReasonSuccessful is the reason set when the CustomRun completed successfully.","\tCustomRunReasonSuccessful CustomRunReason = \"Succeeded\"","\t// CustomRunReasonFailed is the reason set when the CustomRun completed with a failure.","\tCustomRunReasonFailed CustomRunReason = \"Failed\"","\t// CustomRunReasonCancelled must be used in the Condition Reason to indicate that a CustomRun was cancelled.","\tCustomRunReasonCancelled CustomRunReason = \"CustomRunCancelled\"","\t// CustomRunReasonTimedOut must be used in the Condition Reason to indicate that a CustomRun was timed out.","\tCustomRunReasonTimedOut CustomRunReason = \"CustomRunTimedOut\"","\t// CustomRunReasonWorkspaceNotSupported can be used in the Condition Reason to indicate that the","\t// CustomRun contains a workspace which is not supported by this custom task.","\tCustomRunReasonWorkspaceNotSupported CustomRunReason = \"CustomRunWorkspaceNotSupported\"",")","","func (t CustomRunReason) String() string {","\treturn string(t)","}","","// CustomRunStatus defines the observed state of CustomRun.","type CustomRunStatus = runv1beta1.CustomRunStatus","","var customrunCondSet = apis.NewBatchConditionSet()","","// GetConditionSet retrieves the condition set for this resource. Implements","// the KRShaped interface.","func (r *CustomRun) GetConditionSet() apis.ConditionSet { return customrunCondSet }","","// GetStatus retrieves the status of the Parallel. Implements the KRShaped","// interface.","func (r *CustomRun) GetStatus() *duckv1.Status { return \u0026r.Status.Status }","","// CustomRunStatusFields holds the fields of CustomRun's status.  This is defined","// separately and inlined so that other types can readily consume these fields","// via duck typing.","type CustomRunStatusFields = runv1beta1.CustomRunStatusFields","","// CustomRunResult used to describe the results of a task","type CustomRunResult = runv1beta1.CustomRunResult","","// +genclient","// +genreconciler","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// CustomRun represents a single execution of a Custom Task.","//","// +k8s:openapi-gen=true","type CustomRun struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ObjectMeta `json:\"metadata,omitempty\"`","","\t// +optional","\tSpec CustomRunSpec `json:\"spec,omitempty\"`","\t// +optional","\tStatus CustomRunStatus `json:\"status,omitempty\"`","}","","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// CustomRunList contains a list of CustomRun","type CustomRunList struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ListMeta `json:\"metadata,omitempty\"`","\tItems           []CustomRun `json:\"items\"`","}","","// GetStatusCondition returns the task run status as a ConditionAccessor","func (r *CustomRun) GetStatusCondition() apis.ConditionAccessor {","\treturn \u0026r.Status","}","","// GetGroupVersionKind implements kmeta.OwnerRefable.","func (*CustomRun) GetGroupVersionKind() schema.GroupVersionKind {","\treturn SchemeGroupVersion.WithKind(pipeline.CustomRunControllerName)","}","","// HasPipelineRunOwnerReference returns true of CustomRun has","// owner reference of type PipelineRun","func (r *CustomRun) HasPipelineRunOwnerReference() bool {","\tfor _, ref := range r.GetOwnerReferences() {","\t\tif ref.Kind == pipeline.PipelineRunControllerName {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// IsCancelled returns true if the CustomRun's spec status is set to Cancelled state","func (r *CustomRun) IsCancelled() bool {","\treturn r.Spec.Status == CustomRunSpecStatusCancelled","}","","// IsDone returns true if the CustomRun's status indicates that it is done.","func (r *CustomRun) IsDone() bool {","\treturn !r.Status.GetCondition(apis.ConditionSucceeded).IsUnknown()","}","","// HasStarted function check whether taskrun has valid start time set in its status","func (r *CustomRun) HasStarted() bool {","\treturn r.Status.StartTime != nil \u0026\u0026 !r.Status.StartTime.IsZero()","}","","// IsSuccessful returns true if the CustomRun's status indicates that it has succeeded.","func (r *CustomRun) IsSuccessful() bool {","\treturn r != nil \u0026\u0026 r.Status.GetCondition(apis.ConditionSucceeded).IsTrue()","}","","// IsFailure returns true if the CustomRun's status indicates that it has failed.","func (r *CustomRun) IsFailure() bool {","\treturn r != nil \u0026\u0026 r.Status.GetCondition(apis.ConditionSucceeded).IsFalse()","}","","// GetCustomRunKey return the customrun's key for timeout handler map","func (r *CustomRun) GetCustomRunKey() string {","\t// The address of the pointer is a threadsafe unique identifier for the customrun","\treturn fmt.Sprintf(\"%s/%p\", \"CustomRun\", r)","}","","// HasTimedOut returns true if the CustomRun's running time is beyond the allowed timeout","func (r *CustomRun) HasTimedOut(c clock.PassiveClock) bool {","\tif r.Status.StartTime == nil || r.Status.StartTime.IsZero() {","\t\treturn false","\t}","\ttimeout := r.GetTimeout()","\t// If timeout is set to 0 or defaulted to 0, there is no timeout.","\tif timeout == apisconfig.NoTimeoutDuration {","\t\treturn false","\t}","\truntime := c.Since(r.Status.StartTime.Time)","\treturn runtime \u003e timeout","}","","// GetTimeout returns the timeout for this customrun, or the default if not configured","func (r *CustomRun) GetTimeout() time.Duration {","\t// Use the platform default if no timeout is set","\tif r.Spec.Timeout == nil {","\t\treturn apisconfig.DefaultTimeoutMinutes * time.Minute","\t}","\treturn r.Spec.Timeout.Duration","}","","// GetRetryCount returns the number of times this CustomRun has already been retried","func (r *CustomRun) GetRetryCount() int {","\treturn len(r.Status.RetriesStatus)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,1,1,1,1,1,0,1,0,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,1,1,1,0,0,1,1,1,1,0,0,2,2,2,2,2,2,2,1,1,2,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2]},{"id":75,"path":"pkg/apis/pipeline/v1beta1/customrun_validation.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"fmt\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/validate\"","\tadmissionregistrationv1 \"k8s.io/api/admissionregistration/v1\"","\t\"k8s.io/apimachinery/pkg/api/equality\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/webhook/resourcesemantics\"",")","","var _ apis.Validatable = (*CustomRun)(nil)","var _ resourcesemantics.VerbLimited = (*CustomRun)(nil)","","// SupportedVerbs returns the operations that validation should be called for","func (r *CustomRun) SupportedVerbs() []admissionregistrationv1.OperationType {","\treturn []admissionregistrationv1.OperationType{admissionregistrationv1.Create, admissionregistrationv1.Update}","}","","// Validate customRun","func (r *CustomRun) Validate(ctx context.Context) *apis.FieldError {","\tif err := validate.ObjectMetadata(r.GetObjectMeta()).ViaField(\"metadata\"); err != nil {","\t\treturn err","\t}","\treturn r.Spec.Validate(ctx)","}","","// Validate CustomRun spec","func (rs *CustomRunSpec) Validate(ctx context.Context) *apis.FieldError {","\t// this covers the case rs.customRef == nil \u0026\u0026 rs.customSpec == nil","\tif equality.Semantic.DeepEqual(rs, \u0026CustomRunSpec{}) {","\t\treturn apis.ErrMissingField(\"spec\")","\t}","","\tif rs.CustomRef != nil \u0026\u0026 rs.CustomSpec != nil {","\t\treturn apis.ErrMultipleOneOf(\"spec.customRef\", \"spec.customSpec\")","\t}","\tif rs.CustomRef == nil \u0026\u0026 rs.CustomSpec == nil {","\t\treturn apis.ErrMissingOneOf(\"spec.customRef\", \"spec.customSpec\")","\t}","\tif rs.CustomRef != nil {","\t\tif rs.CustomRef.APIVersion == \"\" {","\t\t\treturn apis.ErrMissingField(\"spec.customRef.apiVersion\")","\t\t}","\t\tif rs.CustomRef.Kind == \"\" {","\t\t\treturn apis.ErrMissingField(\"spec.customRef.kind\")","\t\t}","\t}","\tif rs.CustomSpec != nil {","\t\tif rs.CustomSpec.APIVersion == \"\" {","\t\t\treturn apis.ErrMissingField(\"spec.customSpec.apiVersion\")","\t\t}","\t\tif rs.CustomSpec.Kind == \"\" {","\t\t\treturn apis.ErrMissingField(\"spec.customSpec.kind\")","\t\t}","\t}","\tif rs.Status == \"\" {","\t\tif rs.StatusMessage != \"\" {","\t\t\treturn apis.ErrInvalidValue(fmt.Sprintf(\"statusMessage should not be set if status is not set, but it is currently set to %s\", rs.StatusMessage), \"statusMessage\")","\t\t}","\t}","\tif err := ValidateParameters(ctx, rs.Params).ViaField(\"spec.params\"); err != nil {","\t\treturn err","\t}","","\treturn ValidateWorkspaceBindings(ctx, rs.Workspaces).ViaField(\"spec.workspaces\")","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,2,2,1,1,2,0,0,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,2,0,2,2,2,0,2,0]},{"id":76,"path":"pkg/apis/pipeline/v1beta1/matrix_types.go","lines":["/*","Copyright 2023 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"fmt\"","\t\"maps\"","\t\"sort\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"k8s.io/utils/strings/slices\"","\t\"knative.dev/pkg/apis\"",")","","// Matrix is used to fan out Tasks in a Pipeline","type Matrix struct {","\t// Params is a list of parameters used to fan out the pipelineTask","\t// Params takes only `Parameters` of type `\"array\"`","\t// Each array element is supplied to the `PipelineTask` by substituting `params` of type `\"string\"` in the underlying `Task`.","\t// The names of the `params` in the `Matrix` must match the names of the `params` in the underlying `Task` that they will be substituting.","\tParams Params `json:\"params,omitempty\"`","","\t// Include is a list of IncludeParams which allows passing in specific combinations of Parameters into the Matrix.","\t// +optional","\tInclude IncludeParamsList `json:\"include,omitempty\"`","}","","// IncludeParamsList is a list of IncludeParams which allows passing in specific combinations of Parameters into the Matrix.","// +listType=atomic","type IncludeParamsList []IncludeParams","","// IncludeParams allows passing in a specific combinations of Parameters into the Matrix.","type IncludeParams struct {","\t// Name the specified combination","\tName string `json:\"name,omitempty\"`","","\t// Params takes only `Parameters` of type `\"string\"`","\t// The names of the `params` must match the names of the `params` in the underlying `Task`","\tParams Params `json:\"params,omitempty\"`","}","","// Combination is a map, mainly defined to hold a single combination from a Matrix with key as param.Name and value as param.Value","type Combination map[string]string","","// Combinations is a Combination list","type Combinations []Combination","","// FanOut returns an list of params that represent combinations","func (m *Matrix) FanOut() []Params {","\tvar combinations, includeCombinations Combinations","\tincludeCombinations = m.getIncludeCombinations()","\tif m.HasInclude() \u0026\u0026 !m.HasParams() {","\t\t// If there are only Matrix Include Parameters return explicit combinations","\t\treturn includeCombinations.toParams()","\t}","\t// Generate combinations from Matrix Parameters","\tfor _, parameter := range m.Params {","\t\tcombinations = combinations.fanOutMatrixParams(parameter)","\t}","\tcombinations.overwriteCombinations(includeCombinations)","\tcombinations = combinations.addNewCombinations(includeCombinations)","\treturn combinations.toParams()","}","","// overwriteCombinations replaces any missing include params in the initial","// matrix params combinations by overwriting the initial combinations with the","// include combinations","func (cs Combinations) overwriteCombinations(ics Combinations) {","\tfor _, paramCombination := range cs {","\t\tfor _, includeCombination := range ics {","\t\t\tif paramCombination.contains(includeCombination) {","\t\t\t\t// overwrite the parameter name and value in existing combination","\t\t\t\t// with the include combination","\t\t\t\tfor name, val := range includeCombination {","\t\t\t\t\tparamCombination[name] = val","\t\t\t\t}","\t\t\t}","\t\t}","\t}","}","","// addNewCombinations creates a new combination for any include parameter","// values that are missing entirely from the initial combinations and","// returns all combinations","func (cs Combinations) addNewCombinations(ics Combinations) Combinations {","\tfor _, includeCombination := range ics {","\t\tif cs.shouldAddNewCombination(includeCombination) {","\t\t\tcs = append(cs, includeCombination)","\t\t}","\t}","\treturn cs","}","","// contains returns true if the include parameter name and value exists in combinations","func (c Combination) contains(includeCombination Combination) bool {","\tfor name, val := range includeCombination {","\t\tif _, exist := c[name]; exist {","\t\t\tif c[name] != val {","\t\t\t\treturn false","\t\t\t}","\t\t}","\t}","\treturn true","}","","// shouldAddNewCombination returns true if the include parameter name exists but the value is","// missing from combinations","func (cs Combinations) shouldAddNewCombination(includeCombination map[string]string) bool {","\tif len(includeCombination) == 0 {","\t\treturn false","\t}","\tfor _, paramCombination := range cs {","\t\tfor name, val := range includeCombination {","\t\t\tif _, exist := paramCombination[name]; exist {","\t\t\t\tif paramCombination[name] == val {","\t\t\t\t\treturn false","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn true","}","","// toParams transforms Combinations from a slice of map[string]string to a slice of Params","// such that, these combinations can be directly consumed in creating taskRun/run object","func (cs Combinations) toParams() []Params {","\tlistOfParams := make([]Params, len(cs))","\tfor i := range cs {","\t\tvar params Params","\t\tcombination := cs[i]","\t\torder, _ := combination.sortCombination()","\t\tfor _, key := range order {","\t\t\tparams = append(params, Param{","\t\t\t\tName:  key,","\t\t\t\tValue: ParamValue{Type: ParamTypeString, StringVal: combination[key]},","\t\t\t})","\t\t}","\t\tlistOfParams[i] = params","\t}","\treturn listOfParams","}","","// fanOutMatrixParams generates new combinations based on Matrix Parameters.","func (cs Combinations) fanOutMatrixParams(param Param) Combinations {","\tif len(cs) == 0 {","\t\treturn initializeCombinations(param)","\t}","\treturn cs.distribute(param)","}","","// getIncludeCombinations generates combinations based on Matrix Include Parameters","func (m *Matrix) getIncludeCombinations() Combinations {","\tvar combinations Combinations","\tfor i := range m.Include {","\t\tincludeParams := m.Include[i].Params","\t\tnewCombination := make(Combination)","\t\tfor _, param := range includeParams {","\t\t\tnewCombination[param.Name] = param.Value.StringVal","\t\t}","\t\tcombinations = append(combinations, newCombination)","\t}","\treturn combinations","}","","// distribute generates a new Combination of Parameters by adding a new Parameter to an existing list of Combinations.","func (cs Combinations) distribute(param Param) Combinations {","\tvar expandedCombinations Combinations","\tfor _, value := range param.Value.ArrayVal {","\t\tfor _, combination := range cs {","\t\t\tnewCombination := make(Combination)","\t\t\tmaps.Copy(newCombination, combination)","\t\t\tnewCombination[param.Name] = value","\t\t\t_, orderedCombination := newCombination.sortCombination()","\t\t\texpandedCombinations = append(expandedCombinations, orderedCombination)","\t\t}","\t}","\treturn expandedCombinations","}","","// initializeCombinations generates a new Combination based on the first Parameter in the Matrix.","func initializeCombinations(param Param) Combinations {","\tvar combinations Combinations","\tfor _, value := range param.Value.ArrayVal {","\t\tcombinations = append(combinations, Combination{param.Name: value})","\t}","\treturn combinations","}","","// sortCombination sorts the given Combination based on the Parameter names to produce a deterministic ordering","func (c Combination) sortCombination() ([]string, Combination) {","\tsortedCombination := make(Combination, len(c))","\torder := make([]string, 0, len(c))","\tfor key := range c {","\t\torder = append(order, key)","\t}","\tsort.Slice(order, func(i, j int) bool {","\t\treturn order[i] \u003c= order[j]","\t})","\tfor _, key := range order {","\t\tsortedCombination[key] = c[key]","\t}","\treturn order, sortedCombination","}","","// CountCombinations returns the count of Combinations of Parameters generated from the Matrix in PipelineTask.","func (m *Matrix) CountCombinations() int {","\t// Iterate over Matrix Parameters and compute count of all generated Combinations","\tcount := m.countGeneratedCombinationsFromParams()","","\t// Add any additional Combinations generated from Matrix Include Parameters","\tcount += m.countNewCombinationsFromInclude()","","\treturn count","}","","// countGeneratedCombinationsFromParams returns the count of Combinations of Parameters generated from the Matrix","// Parameters","func (m *Matrix) countGeneratedCombinationsFromParams() int {","\tif !m.HasParams() {","\t\treturn 0","\t}","\tcount := 1","\tfor _, param := range m.Params {","\t\tcount *= len(param.Value.ArrayVal)","\t}","\treturn count","}","","// countNewCombinationsFromInclude returns the count of Combinations of Parameters generated from the Matrix","// Include Parameters","func (m *Matrix) countNewCombinationsFromInclude() int {","\tif !m.HasInclude() {","\t\treturn 0","\t}","\tif !m.HasParams() {","\t\treturn len(m.Include)","\t}","\tcount := 0","\tmatrixParamMap := m.Params.extractParamMapArrVals()","\tfor _, include := range m.Include {","\t\tfor _, param := range include.Params {","\t\t\tif val, exist := matrixParamMap[param.Name]; exist {","\t\t\t\t// If the Matrix Include param values does not exist, a new Combination will be generated","\t\t\t\tif !slices.Contains(val, param.Value.StringVal) {","\t\t\t\t\tcount++","\t\t\t\t} else {","\t\t\t\t\tbreak","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn count","}","","// HasInclude returns true if the Matrix has Include Parameters","func (m *Matrix) HasInclude() bool {","\treturn m != nil \u0026\u0026 m.Include != nil \u0026\u0026 len(m.Include) \u003e 0","}","","// HasParams returns true if the Matrix has Parameters","func (m *Matrix) HasParams() bool {","\treturn m != nil \u0026\u0026 m.Params != nil \u0026\u0026 len(m.Params) \u003e 0","}","","// GetAllParams returns a list of all Matrix Parameters","func (m *Matrix) GetAllParams() Params {","\tvar params Params","\tif m.HasParams() {","\t\tparams = append(params, m.Params...)","\t}","\tif m.HasInclude() {","\t\tfor _, include := range m.Include {","\t\t\tparams = append(params, include.Params...)","\t\t}","\t}","\treturn params","}","","func (m *Matrix) validateCombinationsCount(ctx context.Context) (errs *apis.FieldError) {","\tmatrixCombinationsCount := m.CountCombinations()","\tmaxMatrixCombinationsCount := config.FromContextOrDefaults(ctx).Defaults.DefaultMaxMatrixCombinationsCount","\tif matrixCombinationsCount \u003e maxMatrixCombinationsCount {","\t\terrs = errs.Also(apis.ErrOutOfBoundsValue(matrixCombinationsCount, 0, maxMatrixCombinationsCount, \"matrix\"))","\t}","\treturn errs","}","","// validateUniqueParams validates Matrix.Params for a unique list of params","// and a unique list of params in each Matrix.Include.Params specification","func (m *Matrix) validateUniqueParams() (errs *apis.FieldError) {","\tif m != nil {","\t\tif m.HasInclude() {","\t\t\tfor i, include := range m.Include {","\t\t\t\terrs = errs.Also(include.Params.validateDuplicateParameters().ViaField(fmt.Sprintf(\"matrix.include[%d].params\", i)))","\t\t\t}","\t\t}","\t\tif m.HasParams() {","\t\t\terrs = errs.Also(m.Params.validateDuplicateParameters().ViaField(\"matrix.params\"))","\t\t}","\t}","\treturn errs","}","","// validatePipelineParametersVariablesInMatrixParameters validates all pipeline parameter variables including Matrix.Params and Matrix.Include.Params","// that may contain the reference(s) to other params to make sure those references are used appropriately.","func (m *Matrix) validatePipelineParametersVariablesInMatrixParameters(prefix string, paramNames sets.String, arrayParamNames sets.String, objectParamNameKeys map[string][]string) (errs *apis.FieldError) {","\tif m.HasInclude() {","\t\tfor _, include := range m.Include {","\t\t\tfor idx, param := range include.Params {","\t\t\t\tstringElement := param.Value.StringVal","\t\t\t\t// Matrix Include Params must be of type string","\t\t\t\terrs = errs.Also(validateStringVariable(stringElement, prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaFieldIndex(\"\", idx).ViaField(\"matrix.include.params\", \"\"))","\t\t\t}","\t\t}","\t}","\tif m.HasParams() {","\t\tfor _, param := range m.Params {","\t\t\tfor idx, arrayElement := range param.Value.ArrayVal {","\t\t\t\t// Matrix Params must be of type array","\t\t\t\terrs = errs.Also(validateArrayVariable(arrayElement, prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaFieldIndex(\"value\", idx).ViaFieldKey(\"matrix.params\", param.Name))","\t\t\t}","\t\t}","\t}","\treturn errs","}","","func (m *Matrix) validateParameterInOneOfMatrixOrParams(params Params) (errs *apis.FieldError) {","\tmatrixParamNames := m.GetAllParams().ExtractNames()","\tfor _, param := range params {","\t\tif matrixParamNames.Has(param.Name) {","\t\t\terrs = errs.Also(apis.ErrMultipleOneOf(\"matrix[\"+param.Name+\"]\", \"params[\"+param.Name+\"]\"))","\t\t}","\t}","\treturn errs","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,0,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,0,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,0,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,0,2,0]},{"id":77,"path":"pkg/apis/pipeline/v1beta1/merge.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"encoding/json\"","","\tcorev1 \"k8s.io/api/core/v1\"","\tv1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/util/strategicpatch\"",")","","// mergeData is used to store the intermediate data needed to merge an object","// with a template. It's provided to avoid repeatedly re-serializing the template.","// +k8s:openapi-gen=false","type mergeData struct {","\temptyJSON    []byte","\ttemplateJSON []byte","\tpatchSchema  strategicpatch.PatchMetaFromStruct","}","","// MergeStepsWithStepTemplate takes a possibly nil container template and a","// list of steps, merging each of the steps with the container template, if","// it's not nil, and returning the resulting list.","func MergeStepsWithStepTemplate(template *StepTemplate, steps []Step) ([]Step, error) {","\tif template == nil {","\t\treturn steps, nil","\t}","","\tmd, err := getMergeData(template.ToK8sContainer(), \u0026corev1.Container{})","\tif err != nil {","\t\treturn nil, err","\t}","","\tfor i, s := range steps {","\t\t// If the stepaction has not been fetched yet then do not merge.","\t\t// Skip over to the next one","\t\tif s.Ref != nil {","\t\t\tcontinue","\t\t}","\t\tmerged := corev1.Container{}","\t\terr := mergeObjWithTemplateBytes(md, s.ToK8sContainer(), \u0026merged)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","","\t\t// If the container's args is nil, reset it to empty instead","\t\tif merged.Args == nil \u0026\u0026 s.Args != nil {","\t\t\tmerged.Args = []string{}","\t\t}","","\t\tamendConflictingContainerFields(\u0026merged, s)","","\t\t// Pass through original step Script, for later conversion.","\t\tnewStep := Step{Script: s.Script, OnError: s.OnError, Timeout: s.Timeout, StdoutConfig: s.StdoutConfig, StderrConfig: s.StderrConfig, When: s.When}","\t\tnewStep.SetContainerFields(merged)","\t\tsteps[i] = newStep","\t}","\treturn steps, nil","}","","// MergeStepsWithOverrides takes a possibly nil list of overrides and a","// list of steps, merging each of the steps with the overrides' resource requirements, if","// it's not nil, and returning the resulting list.","func MergeStepsWithOverrides(steps []Step, overrides []TaskRunStepOverride) ([]Step, error) {","\tstepNameToOverride := make(map[string]TaskRunStepOverride, len(overrides))","\tfor _, o := range overrides {","\t\tstepNameToOverride[o.Name] = o","\t}","\tfor i, s := range steps {","\t\to, found := stepNameToOverride[s.Name]","\t\tif !found {","\t\t\tcontinue","\t\t}","\t\tmerged := v1.ResourceRequirements{}","\t\terr := mergeObjWithTemplate(\u0026s.Resources, \u0026o.Resources, \u0026merged)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tsteps[i].Resources = merged","\t}","\treturn steps, nil","}","","// MergeSidecarsWithOverrides takes a possibly nil list of overrides and a","// list of sidecars, merging each of the sidecars with the overrides' resource requirements, if","// it's not nil, and returning the resulting list.","func MergeSidecarsWithOverrides(sidecars []Sidecar, overrides []TaskRunSidecarOverride) ([]Sidecar, error) {","\tif len(overrides) == 0 {","\t\treturn sidecars, nil","\t}","\tsidecarNameToOverride := make(map[string]TaskRunSidecarOverride, len(overrides))","\tfor _, o := range overrides {","\t\tsidecarNameToOverride[o.Name] = o","\t}","\tfor i, s := range sidecars {","\t\to, found := sidecarNameToOverride[s.Name]","\t\tif !found {","\t\t\tcontinue","\t\t}","\t\tmerged := v1.ResourceRequirements{}","\t\terr := mergeObjWithTemplate(\u0026s.Resources, \u0026o.Resources, \u0026merged)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tsidecars[i].Resources = merged","\t}","\treturn sidecars, nil","}","","// mergeObjWithTemplate merges obj with template and updates out to reflect the merged result.","// template, obj, and out should point to the same type. out points to the zero value of that type.","func mergeObjWithTemplate(template, obj, out interface{}) error {","\tmd, err := getMergeData(template, out)","\tif err != nil {","\t\treturn err","\t}","\treturn mergeObjWithTemplateBytes(md, obj, out)","}","","// getMergeData serializes the template and empty object to get the intermediate results necessary for","// merging an object of the same type with this template.","// This function is provided to avoid repeatedly serializing an identical template.","func getMergeData(template, empty interface{}) (*mergeData, error) {","\t// We need JSON bytes to generate a patch to merge the object","\t// onto the template, so marshal the template.","\ttemplateJSON, err := json.Marshal(template)","\tif err != nil {","\t\treturn nil, err","\t}","\t// We need to do a three-way merge to actually merge the template and","\t// object, so we need an empty object as the \"original\"","\temptyJSON, err := json.Marshal(empty)","\tif err != nil {","\t\treturn nil, err","\t}","\t// Get the patch meta, which is needed for generating and applying the merge patch.","\tpatchSchema, err := strategicpatch.NewPatchMetaFromStruct(template)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn \u0026mergeData{templateJSON: templateJSON, emptyJSON: emptyJSON, patchSchema: patchSchema}, nil","}","","// mergeObjWithTemplateBytes merges obj with md's template JSON and updates out to reflect the merged result.","// out is a pointer to the zero value of obj's type.","// This function is provided to avoid repeatedly serializing an identical template.","func mergeObjWithTemplateBytes(md *mergeData, obj, out interface{}) error {","\t// Marshal the object to JSON","\tobjAsJSON, err := json.Marshal(obj)","\tif err != nil {","\t\treturn err","\t}","\t// Create a merge patch, with the empty JSON as the original, the object JSON as the modified, and the template","\t// JSON as the current - this lets us do a deep merge of the template and object, with awareness of","\t// the \"patchMerge\" tags.","\tpatch, err := strategicpatch.CreateThreeWayMergePatch(md.emptyJSON, objAsJSON, md.templateJSON, md.patchSchema, true)","\tif err != nil {","\t\treturn err","\t}","","\t// Actually apply the merge patch to the template JSON.","\tmergedAsJSON, err := strategicpatch.StrategicMergePatchUsingLookupPatchMeta(md.templateJSON, patch, md.patchSchema)","\tif err != nil {","\t\treturn err","\t}","\t// Unmarshal the merged JSON to a pointer, and return it.","\treturn json.Unmarshal(mergedAsJSON, out)","}","","// amendConflictingContainerFields amends conflicting container fields after merge, and overrides conflicting fields","// by fields in step.","func amendConflictingContainerFields(container *corev1.Container, step Step) {","\tif container == nil || len(step.Env) == 0 {","\t\treturn","\t}","","\tenvNameToStepEnv := make(map[string]corev1.EnvVar, len(step.Env))","\tfor _, e := range step.Env {","\t\tenvNameToStepEnv[e.Name] = e","\t}","","\tfor index, env := range container.Env {","\t\tif env.ValueFrom != nil \u0026\u0026 len(env.Value) \u003e 0 {","\t\t\tif e, ok := envNameToStepEnv[env.Name]; ok {","\t\t\t\tcontainer.Env[index] = e","\t\t\t}","\t\t}","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,2,2,1,1,0,2,2,2,2,2,0,2,2,2,1,1,0,0,2,1,1,0,2,2,2,2,2,2,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,1,1,2,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,1,1,2,0,2,0,0,0,0,2,2,2,1,1,2,0,0,0,0,0,2,2,2,2,2,1,1,0,0,2,2,1,1,0,2,2,1,1,2,0,0,0,0,0,2,2,2,2,1,1,0,0,0,2,2,1,1,0,0,2,2,1,1,0,2,0,0,0,0,2,2,2,2,0,2,2,2,2,0,2,2,2,2,2,0,0,0]},{"id":78,"path":"pkg/apis/pipeline/v1beta1/param_conversion.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"",")","","func (p ParamSpec) convertTo(ctx context.Context, sink *v1.ParamSpec) {","\tsink.Name = p.Name","\tif p.Type != \"\" {","\t\tsink.Type = v1.ParamType(p.Type)","\t} else {","\t\tsink.Type = v1.ParamType(ParamTypeString)","\t}","\tsink.Description = p.Description","\tsink.Enum = p.Enum","\tvar properties map[string]v1.PropertySpec","\tif p.Properties != nil {","\t\tproperties = make(map[string]v1.PropertySpec)","\t}","\tfor k, v := range p.Properties {","\t\tproperties[k] = v1.PropertySpec{Type: v1.ParamType(v.Type)}","\t}","\tsink.Properties = properties","\tif p.Default != nil {","\t\tsink.Default = \u0026v1.ParamValue{","\t\t\tType: v1.ParamType(p.Default.Type), StringVal: p.Default.StringVal,","\t\t\tArrayVal: p.Default.ArrayVal, ObjectVal: p.Default.ObjectVal,","\t\t}","\t}","}","","func (p *ParamSpec) convertFrom(ctx context.Context, source v1.ParamSpec) {","\tp.Name = source.Name","\tif source.Type != \"\" {","\t\tp.Type = ParamType(source.Type)","\t} else {","\t\tp.Type = ParamTypeString","\t}","\tp.Description = source.Description","\tp.Enum = source.Enum","\tvar properties map[string]PropertySpec","\tif source.Properties != nil {","\t\tproperties = make(map[string]PropertySpec)","\t}","\tfor k, v := range source.Properties {","\t\tproperties[k] = PropertySpec{Type: ParamType(v.Type)}","\t}","\tp.Properties = properties","\tif source.Default != nil {","\t\tp.Default = \u0026ParamValue{","\t\t\tType: ParamType(source.Default.Type), StringVal: source.Default.StringVal,","\t\t\tArrayVal: source.Default.ArrayVal, ObjectVal: source.Default.ObjectVal,","\t\t}","\t}","}","","func (p Param) convertTo(ctx context.Context, sink *v1.Param) {","\tsink.Name = p.Name","\tnewValue := v1.ParamValue{}","\tp.Value.convertTo(ctx, \u0026newValue)","\tsink.Value = newValue","}","","// ConvertFrom converts v1beta1 Param from v1 Param","func (p *Param) ConvertFrom(ctx context.Context, source v1.Param) {","\tp.Name = source.Name","\tnewValue := ParamValue{}","\tnewValue.convertFrom(ctx, source.Value)","\tp.Value = newValue","}","","func (v ParamValue) convertTo(ctx context.Context, sink *v1.ParamValue) {","\tif v.Type != \"\" {","\t\tsink.Type = v1.ParamType(v.Type)","\t} else {","\t\tsink.Type = v1.ParamType(ParamTypeString)","\t}","\tsink.StringVal = v.StringVal","\tsink.ArrayVal = v.ArrayVal","\tsink.ObjectVal = v.ObjectVal","}","","func (v *ParamValue) convertFrom(ctx context.Context, source v1.ParamValue) {","\tif source.Type != \"\" {","\t\tv.Type = ParamType(source.Type)","\t} else {","\t\tv.Type = ParamTypeString","\t}","\tv.StringVal = source.StringVal","\tv.ArrayVal = source.ArrayVal","\tv.ObjectVal = source.ObjectVal","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0]},{"id":79,"path":"pkg/apis/pipeline/v1beta1/param_types.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"encoding/json\"","\t\"fmt\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"k8s.io/utils/strings/slices\"","\t\"knative.dev/pkg/apis\"",")","","// ParamsPrefix is the prefix used in $(...) expressions referring to parameters","const ParamsPrefix = \"params\"","","// ParamSpec defines arbitrary parameters needed beyond typed inputs (such as","// resources). Parameter values are provided by users as inputs on a TaskRun","// or PipelineRun.","type ParamSpec struct {","\t// Name declares the name by which a parameter is referenced.","\tName string `json:\"name\"`","\t// Type is the user-specified type of the parameter. The possible types","\t// are currently \"string\", \"array\" and \"object\", and \"string\" is the default.","\t// +optional","\tType ParamType `json:\"type,omitempty\"`","\t// Description is a user-facing description of the parameter that may be","\t// used to populate a UI.","\t// +optional","\tDescription string `json:\"description,omitempty\"`","\t// Properties is the JSON Schema properties to support key-value pairs parameter.","\t// +optional","\tProperties map[string]PropertySpec `json:\"properties,omitempty\"`","\t// Default is the value a parameter takes if no input value is supplied. If","\t// default is set, a Task may be executed without a supplied value for the","\t// parameter.","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tDefault *ParamValue `json:\"default,omitempty\"`","\t// Enum declares a set of allowed param input values for tasks/pipelines that can be validated.","\t// If Enum is not set, no input validation is performed for the param.","\t// +optional","\tEnum []string `json:\"enum,omitempty\"`","}","","// ParamSpecs is a list of ParamSpec","// +listType=atomic","type ParamSpecs []ParamSpec","","// PropertySpec defines the struct for object keys","type PropertySpec struct {","\tType ParamType `json:\"type,omitempty\"`","}","","// SetDefaults set the default type","func (pp *ParamSpec) SetDefaults(context.Context) {","\tif pp == nil {","\t\treturn","\t}","","\t// Propagate inferred type to the parent ParamSpec's type, and default type to the PropertySpec's type","\t// The sequence to look at is type in ParamSpec -\u003e properties -\u003e type in default -\u003e array/string/object value in default","\t// If neither `properties` or `default` section is provided, ParamTypeString will be the default type.","\tswitch {","\tcase pp.Type != \"\":","\t\t// If param type is provided by the author, do nothing but just set default type for PropertySpec in case `properties` section is provided.","\t\tpp.setDefaultsForProperties()","\tcase pp.Properties != nil:","\t\tpp.Type = ParamTypeObject","\t\t// Also set default type for PropertySpec","\t\tpp.setDefaultsForProperties()","\tcase pp.Default == nil:","\t\t// ParamTypeString is the default value (when no type can be inferred from the default value)","\t\tpp.Type = ParamTypeString","\tcase pp.Default.Type != \"\":","\t\tpp.Type = pp.Default.Type","\tcase pp.Default.ArrayVal != nil:","\t\tpp.Type = ParamTypeArray","\tcase pp.Default.ObjectVal != nil:","\t\tpp.Type = ParamTypeObject","\tdefault:","\t\tpp.Type = ParamTypeString","\t}","}","","// getNames returns all the names of the declared parameters","func (ps ParamSpecs) getNames() []string {","\tvar names []string","\tfor _, p := range ps {","\t\tnames = append(names, p.Name)","\t}","\treturn names","}","","// sortByType splits the input params into string params, array params, and object params, in that order","func (ps ParamSpecs) sortByType() (ParamSpecs, ParamSpecs, ParamSpecs) {","\tvar stringParams, arrayParams, objectParams ParamSpecs","\tfor _, p := range ps {","\t\tswitch p.Type {","\t\tcase ParamTypeArray:","\t\t\tarrayParams = append(arrayParams, p)","\t\tcase ParamTypeObject:","\t\t\tobjectParams = append(objectParams, p)","\t\tcase ParamTypeString:","\t\t\tfallthrough","\t\tdefault:","\t\t\tstringParams = append(stringParams, p)","\t\t}","\t}","\treturn stringParams, arrayParams, objectParams","}","","// validateNoDuplicateNames returns an error if any of the params have the same name","func (ps ParamSpecs) validateNoDuplicateNames() *apis.FieldError {","\tvar errs *apis.FieldError","\tnames := ps.getNames()","\tfor dup := range findDups(names) {","\t\terrs = errs.Also(apis.ErrGeneric(\"parameter appears more than once\", \"\").ViaFieldKey(\"params\", dup))","\t}","\treturn errs","}","","// validateParamEnums validates feature flag, duplication and allowed types for Param Enum","func (ps ParamSpecs) validateParamEnums(ctx context.Context) *apis.FieldError {","\tvar errs *apis.FieldError","\tfor _, p := range ps {","\t\tif len(p.Enum) == 0 {","\t\t\tcontinue","\t\t}","\t\tif !config.FromContextOrDefaults(ctx).FeatureFlags.EnableParamEnum {","\t\t\terrs = errs.Also(errs, apis.ErrGeneric(fmt.Sprintf(\"feature flag `%s` should be set to true to use Enum\", config.EnableParamEnum), \"\").ViaKey(p.Name))","\t\t}","\t\tif p.Type != ParamTypeString {","\t\t\terrs = errs.Also(apis.ErrGeneric(\"enum can only be set with string type param\", \"\").ViaKey(p.Name))","\t\t}","\t\tfor dup := range findDups(p.Enum) {","\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"parameter enum value %v appears more than once\", dup), \"\").ViaKey(p.Name))","\t\t}","\t\tif p.Default != nil \u0026\u0026 p.Default.StringVal != \"\" {","\t\t\tif !slices.Contains(p.Enum, p.Default.StringVal) {","\t\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"param default value %v not in the enum list\", p.Default.StringVal), \"\").ViaKey(p.Name))","\t\t\t}","\t\t}","\t}","\treturn errs","}","","// findDups returns the duplicate element in the given slice","func findDups(vals []string) sets.String {","\tseen := sets.String{}","\tdups := sets.String{}","\tfor _, val := range vals {","\t\tif seen.Has(val) {","\t\t\tdups.Insert(val)","\t\t}","\t\tseen.Insert(val)","\t}","\treturn dups","}","","// setDefaultsForProperties sets default type for PropertySpec (string) if it's not specified","func (pp *ParamSpec) setDefaultsForProperties() {","\tfor key, propertySpec := range pp.Properties {","\t\tif propertySpec.Type == \"\" {","\t\t\tpp.Properties[key] = PropertySpec{Type: ParamTypeString}","\t\t}","\t}","}","","// Param declares an ParamValues to use for the parameter called name.","type Param struct {","\tName string `json:\"name\"`","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tValue ParamValue `json:\"value\"`","}","","// Params is a list of Param","// +listType=atomic","type Params []Param","","// ExtractNames returns a set of unique names","func (ps Params) ExtractNames() sets.String {","\tnames := sets.String{}","\tfor _, p := range ps {","\t\tnames.Insert(p.Name)","\t}","\treturn names","}","","func (ps Params) extractValues() []string {","\tpvs := []string{}","\tfor i := range ps {","\t\tpvs = append(pvs, ps[i].Value.StringVal)","\t\tpvs = append(pvs, ps[i].Value.ArrayVal...)","\t\tfor _, v := range ps[i].Value.ObjectVal {","\t\t\tpvs = append(pvs, v)","\t\t}","\t}","\treturn pvs","}","","// extractParamMapArrVals creates a param map with the key: param.Name and","// val: param.Value.ArrayVal","func (ps Params) extractParamMapArrVals() map[string][]string {","\tparamsMap := make(map[string][]string)","\tfor _, p := range ps {","\t\tparamsMap[p.Name] = p.Value.ArrayVal","\t}","\treturn paramsMap","}","","// ExtractParamArrayLengths extract and return the lengths of all array params","// Example of returned value: {\"a-array-params\": 2,\"b-array-params\": 2 }","func (ps Params) ExtractParamArrayLengths() map[string]int {","\t// Collect all array params","\tarrayParamsLengths := make(map[string]int)","","\t// Collect array params lengths from params","\tfor _, p := range ps {","\t\tif p.Value.Type == ParamTypeArray {","\t\t\tarrayParamsLengths[p.Name] = len(p.Value.ArrayVal)","\t\t}","\t}","\treturn arrayParamsLengths","}","","// validateDuplicateParameters checks if a parameter with the same name is defined more than once","func (ps Params) validateDuplicateParameters() (errs *apis.FieldError) {","\ttaskParamNames := sets.NewString()","\tfor i, param := range ps {","\t\tif taskParamNames.Has(param.Name) {","\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"parameter names must be unique,\"+","\t\t\t\t\" the parameter \\\"%s\\\" is also defined at\", param.Name), fmt.Sprintf(\"[%d].name\", i)))","\t\t}","\t\ttaskParamNames.Insert(param.Name)","\t}","\treturn errs","}","","// ReplaceVariables applies string, array and object replacements to variables in Params","func (ps Params) ReplaceVariables(stringReplacements map[string]string, arrayReplacements map[string][]string, objectReplacements map[string]map[string]string) Params {","\tparams := ps.DeepCopy()","\tfor i := range params {","\t\tparams[i].Value.ApplyReplacements(stringReplacements, arrayReplacements, objectReplacements)","\t}","\treturn params","}","","// ExtractDefaultParamArrayLengths extract and return the lengths of all array param defaults","// Example of returned value: {\"a-array-params\": 2,\"b-array-params\": 2 }","func (ps ParamSpecs) ExtractDefaultParamArrayLengths() map[string]int {","\t// Collect all array params","\tarrayParamsLengths := make(map[string]int)","","\t// Collect array params lengths from defaults","\tfor _, p := range ps {","\t\tif p.Default != nil {","\t\t\tif p.Default.Type == ParamTypeArray {","\t\t\t\tarrayParamsLengths[p.Name] = len(p.Default.ArrayVal)","\t\t\t}","\t\t}","\t}","\treturn arrayParamsLengths","}","","// extractArrayIndexingParamRefs takes a string of the form `foo-$(params.array-param[1])-bar` and extracts the portions of the string that reference an element in an array param.","// For example, for the string â€œfoo-$(params.array-param[1])-bar-$(params.other-array-param[2])-$(params.string-param)`,","// it would return [\"$(params.array-param[1])\", \"$(params.other-array-param[2])\"].","func extractArrayIndexingParamRefs(paramReference string) []string {","\tl := []string{}","\tlist := substitution.ExtractArrayIndexingParamsExpressions(paramReference)","\tfor _, val := range list {","\t\tindexString := substitution.ExtractIndexString(val)","\t\tif indexString != \"\" {","\t\t\tl = append(l, val)","\t\t}","\t}","\treturn l","}","","// extractParamRefsFromSteps get all array indexing references from steps","func extractParamRefsFromSteps(steps []Step) []string {","\tparamsRefs := []string{}","\tfor _, step := range steps {","\t\tparamsRefs = append(paramsRefs, step.Script)","\t\tcontainer := step.ToK8sContainer()","\t\tparamsRefs = append(paramsRefs, extractParamRefsFromContainer(container)...)","\t}","\treturn paramsRefs","}","","// extractParamRefsFromStepTemplate get all array indexing references from StepsTemplate","func extractParamRefsFromStepTemplate(stepTemplate *StepTemplate) []string {","\tif stepTemplate == nil {","\t\treturn nil","\t}","\tcontainer := stepTemplate.ToK8sContainer()","\treturn extractParamRefsFromContainer(container)","}","","// extractParamRefsFromSidecars get all array indexing references from sidecars","func extractParamRefsFromSidecars(sidecars []Sidecar) []string {","\tparamsRefs := []string{}","\tfor _, s := range sidecars {","\t\tparamsRefs = append(paramsRefs, s.Script)","\t\tcontainer := s.ToK8sContainer()","\t\tparamsRefs = append(paramsRefs, extractParamRefsFromContainer(container)...)","\t}","\treturn paramsRefs","}","","// extractParamRefsFromVolumes get all array indexing references from volumes","func extractParamRefsFromVolumes(volumes []corev1.Volume) []string {","\tparamsRefs := []string{}","\tfor i, v := range volumes {","\t\tparamsRefs = append(paramsRefs, v.Name)","\t\tif v.VolumeSource.ConfigMap != nil {","\t\t\tparamsRefs = append(paramsRefs, v.ConfigMap.Name)","\t\t\tfor _, item := range v.ConfigMap.Items {","\t\t\t\tparamsRefs = append(paramsRefs, item.Key)","\t\t\t\tparamsRefs = append(paramsRefs, item.Path)","\t\t\t}","\t\t}","\t\tif v.VolumeSource.Secret != nil {","\t\t\tparamsRefs = append(paramsRefs, v.Secret.SecretName)","\t\t\tfor _, item := range v.Secret.Items {","\t\t\t\tparamsRefs = append(paramsRefs, item.Key)","\t\t\t\tparamsRefs = append(paramsRefs, item.Path)","\t\t\t}","\t\t}","\t\tif v.PersistentVolumeClaim != nil {","\t\t\tparamsRefs = append(paramsRefs, v.PersistentVolumeClaim.ClaimName)","\t\t}","\t\tif v.Projected != nil {","\t\t\tfor _, s := range volumes[i].Projected.Sources {","\t\t\t\tif s.ConfigMap != nil {","\t\t\t\t\tparamsRefs = append(paramsRefs, s.ConfigMap.Name)","\t\t\t\t}","\t\t\t\tif s.Secret != nil {","\t\t\t\t\tparamsRefs = append(paramsRefs, s.Secret.Name)","\t\t\t\t}","\t\t\t\tif s.ServiceAccountToken != nil {","\t\t\t\t\tparamsRefs = append(paramsRefs, s.ServiceAccountToken.Audience)","\t\t\t\t}","\t\t\t}","\t\t}","\t\tif v.CSI != nil {","\t\t\tif v.CSI.NodePublishSecretRef != nil {","\t\t\t\tparamsRefs = append(paramsRefs, v.CSI.NodePublishSecretRef.Name)","\t\t\t}","\t\t\tif v.CSI.VolumeAttributes != nil {","\t\t\t\tfor _, value := range v.CSI.VolumeAttributes {","\t\t\t\t\tparamsRefs = append(paramsRefs, value)","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn paramsRefs","}","","// extractParamRefsFromContainer get all array indexing references from container","func extractParamRefsFromContainer(c *corev1.Container) []string {","\tparamsRefs := []string{}","\tparamsRefs = append(paramsRefs, c.Name)","\tparamsRefs = append(paramsRefs, c.Image)","\tparamsRefs = append(paramsRefs, string(c.ImagePullPolicy))","\tparamsRefs = append(paramsRefs, c.Args...)","","\tfor ie, e := range c.Env {","\t\tparamsRefs = append(paramsRefs, e.Value)","\t\tif c.Env[ie].ValueFrom != nil {","\t\t\tif e.ValueFrom.SecretKeyRef != nil {","\t\t\t\tparamsRefs = append(paramsRefs, e.ValueFrom.SecretKeyRef.LocalObjectReference.Name)","\t\t\t\tparamsRefs = append(paramsRefs, e.ValueFrom.SecretKeyRef.Key)","\t\t\t}","\t\t\tif e.ValueFrom.ConfigMapKeyRef != nil {","\t\t\t\tparamsRefs = append(paramsRefs, e.ValueFrom.ConfigMapKeyRef.LocalObjectReference.Name)","\t\t\t\tparamsRefs = append(paramsRefs, e.ValueFrom.ConfigMapKeyRef.Key)","\t\t\t}","\t\t}","\t}","","\tfor _, e := range c.EnvFrom {","\t\tparamsRefs = append(paramsRefs, e.Prefix)","\t\tif e.ConfigMapRef != nil {","\t\t\tparamsRefs = append(paramsRefs, e.ConfigMapRef.LocalObjectReference.Name)","\t\t}","\t\tif e.SecretRef != nil {","\t\t\tparamsRefs = append(paramsRefs, e.SecretRef.LocalObjectReference.Name)","\t\t}","\t}","","\tparamsRefs = append(paramsRefs, c.WorkingDir)","\tparamsRefs = append(paramsRefs, c.Command...)","","\tfor _, v := range c.VolumeMounts {","\t\tparamsRefs = append(paramsRefs, v.Name)","\t\tparamsRefs = append(paramsRefs, v.MountPath)","\t\tparamsRefs = append(paramsRefs, v.SubPath)","\t}","\treturn paramsRefs","}","","// ParamType indicates the type of an input parameter;","// Used to distinguish between a single string and an array of strings.","type ParamType string","","// Valid ParamTypes:","const (","\tParamTypeString ParamType = \"string\"","\tParamTypeArray  ParamType = \"array\"","\tParamTypeObject ParamType = \"object\"",")","","// AllParamTypes can be used for ParamType validation.","var AllParamTypes = []ParamType{ParamTypeString, ParamTypeArray, ParamTypeObject}","","// ParamValues is modeled after IntOrString in kubernetes/apimachinery:","","// ParamValue is a type that can hold a single string or string array.","// Used in JSON unmarshalling so that a single JSON field can accept","// either an individual string or an array of strings.","type ParamValue struct {","\tType      ParamType // Represents the stored type of ParamValues.","\tStringVal string","\t// +listType=atomic","\tArrayVal  []string","\tObjectVal map[string]string","}","","// ArrayOrString is deprecated, this is to keep backward compatibility","//","// Deprecated: Use ParamValue instead.","type ArrayOrString = ParamValue","","// UnmarshalJSON implements the json.Unmarshaller interface.","func (paramValues *ParamValue) UnmarshalJSON(value []byte) error {","\t// ParamValues is used for Results Value as well, the results can be any kind of","\t// data so we need to check if it is empty.","\tif len(value) == 0 {","\t\tparamValues.Type = ParamTypeString","\t\treturn nil","\t}","\tif value[0] == '[' {","\t\t// We're trying to Unmarshal to []string, but for cases like []int or other types","\t\t// of nested array which we don't support yet, we should continue and Unmarshal","\t\t// it to String. If the Type being set doesn't match what it actually should be,","\t\t// it will be captured by validation in reconciler.","\t\t// if failed to unmarshal to array, we will convert the value to string and marshal it to string","\t\tvar a []string","\t\tif err := json.Unmarshal(value, \u0026a); err == nil {","\t\t\tparamValues.Type = ParamTypeArray","\t\t\tparamValues.ArrayVal = a","\t\t\treturn nil","\t\t}","\t}","\tif value[0] == '{' {","\t\t// if failed to unmarshal to map, we will convert the value to string and marshal it to string","\t\tvar m map[string]string","\t\tif err := json.Unmarshal(value, \u0026m); err == nil {","\t\t\tparamValues.Type = ParamTypeObject","\t\t\tparamValues.ObjectVal = m","\t\t\treturn nil","\t\t}","\t}","","\t// By default we unmarshal to string","\tparamValues.Type = ParamTypeString","\tif err := json.Unmarshal(value, \u0026paramValues.StringVal); err == nil {","\t\treturn nil","\t}","\tparamValues.StringVal = string(value)","","\treturn nil","}","","// MarshalJSON implements the json.Marshaller interface.","func (paramValues ParamValue) MarshalJSON() ([]byte, error) {","\tswitch paramValues.Type {","\tcase ParamTypeString:","\t\treturn json.Marshal(paramValues.StringVal)","\tcase ParamTypeArray:","\t\treturn json.Marshal(paramValues.ArrayVal)","\tcase ParamTypeObject:","\t\treturn json.Marshal(paramValues.ObjectVal)","\tdefault:","\t\treturn []byte{}, fmt.Errorf(\"impossible ParamValues.Type: %q\", paramValues.Type)","\t}","}","","// ApplyReplacements applyes replacements for ParamValues type","func (paramValues *ParamValue) ApplyReplacements(stringReplacements map[string]string, arrayReplacements map[string][]string, objectReplacements map[string]map[string]string) {","\tswitch paramValues.Type {","\tcase ParamTypeArray:","\t\tnewArrayVal := []string{}","\t\tfor _, v := range paramValues.ArrayVal {","\t\t\tnewArrayVal = append(newArrayVal, substitution.ApplyArrayReplacements(v, stringReplacements, arrayReplacements)...)","\t\t}","\t\tparamValues.ArrayVal = newArrayVal","\tcase ParamTypeObject:","\t\tnewObjectVal := map[string]string{}","\t\tfor k, v := range paramValues.ObjectVal {","\t\t\tnewObjectVal[k] = substitution.ApplyReplacements(v, stringReplacements)","\t\t}","\t\tparamValues.ObjectVal = newObjectVal","\tcase ParamTypeString:","\t\tfallthrough","\tdefault:","\t\tparamValues.applyOrCorrect(stringReplacements, arrayReplacements, objectReplacements)","\t}","}","","// applyOrCorrect deals with string param whose value can be string literal or a reference to a string/array/object param/result.","// If the value of paramValues is a reference to array or object, the type will be corrected from string to array/object.","func (paramValues *ParamValue) applyOrCorrect(stringReplacements map[string]string, arrayReplacements map[string][]string, objectReplacements map[string]map[string]string) {","\tstringVal := paramValues.StringVal","","\t// if the stringVal is a string literal or a string that mixed with var references","\t// just do the normal string replacement","\tif !exactVariableSubstitutionRegex.MatchString(stringVal) {","\t\tparamValues.StringVal = substitution.ApplyReplacements(paramValues.StringVal, stringReplacements)","\t\treturn","\t}","","\t// trim the head \"$(\" and the tail \")\" or \"[*])\"","\t// i.e. get \"params.name\" from \"$(params.name)\" or \"$(params.name[*])\"","\ttrimedStringVal := substitution.StripStarVarSubExpression(stringVal)","","\t// if the stringVal is a reference to a string param","\tif _, ok := stringReplacements[trimedStringVal]; ok {","\t\tparamValues.StringVal = substitution.ApplyReplacements(paramValues.StringVal, stringReplacements)","\t}","","\t// if the stringVal is a reference to an array param, we need to change the type other than apply replacement","\tif _, ok := arrayReplacements[trimedStringVal]; ok {","\t\tparamValues.StringVal = \"\"","\t\tparamValues.ArrayVal = substitution.ApplyArrayReplacements(stringVal, stringReplacements, arrayReplacements)","\t\tparamValues.Type = ParamTypeArray","\t}","","\t// if the stringVal is a reference an object param, we need to change the type other than apply replacement","\tif _, ok := objectReplacements[trimedStringVal]; ok {","\t\tparamValues.StringVal = \"\"","\t\tparamValues.ObjectVal = objectReplacements[trimedStringVal]","\t\tparamValues.Type = ParamTypeObject","\t}","}","","// NewStructuredValues creates an ParamValues of type ParamTypeString or ParamTypeArray, based on","// how many inputs are given (\u003e1 input will create an array, not string).","func NewStructuredValues(value string, values ...string) *ParamValue {","\tif len(values) \u003e 0 {","\t\treturn \u0026ParamValue{","\t\t\tType:     ParamTypeArray,","\t\t\tArrayVal: append([]string{value}, values...),","\t\t}","\t}","\treturn \u0026ParamValue{","\t\tType:      ParamTypeString,","\t\tStringVal: value,","\t}","}","","// NewArrayOrString is the deprecated, this is to keep backward compatibility","var NewArrayOrString = NewStructuredValues","","// NewObject creates an ParamValues of type ParamTypeObject using the provided key-value pairs","func NewObject(pairs map[string]string) *ParamValue {","\treturn \u0026ParamValue{","\t\tType:      ParamTypeObject,","\t\tObjectVal: pairs,","\t}","}","","// ArrayReference returns the name of the parameter from array parameter reference","// returns arrayParam from $(params.arrayParam[*])","func ArrayReference(a string) string {","\treturn strings.TrimSuffix(strings.TrimPrefix(a, \"$(\"+ParamsPrefix+\".\"), \"[*])\")","}","","// validatePipelineParametersVariablesInTaskParameters validates param value that","// may contain the reference(s) to other params to make sure those references are used appropriately.","func validatePipelineParametersVariablesInTaskParameters(params Params, prefix string, paramNames sets.String, arrayParamNames sets.String, objectParamNameKeys map[string][]string) (errs *apis.FieldError) {","\terrs = errs.Also(params.validateDuplicateParameters()).ViaField(\"params\")","\tfor _, param := range params {","\t\tswitch param.Value.Type {","\t\tcase ParamTypeArray:","\t\t\tfor idx, arrayElement := range param.Value.ArrayVal {","\t\t\t\terrs = errs.Also(validateArrayVariable(arrayElement, prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaFieldIndex(\"value\", idx).ViaFieldKey(\"params\", param.Name))","\t\t\t}","\t\tcase ParamTypeObject:","\t\t\tfor key, val := range param.Value.ObjectVal {","\t\t\t\terrs = errs.Also(validateStringVariable(val, prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaFieldKey(\"properties\", key).ViaFieldKey(\"params\", param.Name))","\t\t\t}","\t\tcase ParamTypeString:","\t\t\tfallthrough","\t\tdefault:","\t\t\terrs = errs.Also(validateParamStringValue(param, prefix, paramNames, arrayParamNames, objectParamNameKeys))","\t\t}","\t}","\treturn errs","}","","// validateParamStringValue validates the param value field of string type","// that may contain references to other isolated array/object params other than string param.","func validateParamStringValue(param Param, prefix string, paramNames sets.String, arrayVars sets.String, objectParamNameKeys map[string][]string) (errs *apis.FieldError) {","\tstringValue := param.Value.StringVal","","\t// if the provided param value is an isolated reference to the whole array/object, we just check if the param name exists.","\tisIsolated, errs := substitution.ValidateWholeArrayOrObjectRefInStringVariable(param.Name, stringValue, prefix, paramNames)","\tif isIsolated {","\t\treturn errs","\t}","","\t// if the provided param value is string literal and/or contains multiple variables","\t// valid example: \"$(params.myString) and another $(params.myObject.key1)\"","\t// invalid example: \"$(params.myString) and another $(params.myObject[*])\"","\treturn validateStringVariable(stringValue, prefix, paramNames, arrayVars, objectParamNameKeys).ViaFieldKey(\"params\", param.Name)","}","","// validateStringVariable validates the normal string fields that can only accept references to string param or individual keys of object param","func validateStringVariable(value, prefix string, stringVars sets.String, arrayVars sets.String, objectParamNameKeys map[string][]string) *apis.FieldError {","\terrs := substitution.ValidateNoReferencesToUnknownVariables(value, prefix, stringVars)","\terrs = errs.Also(validateObjectVariable(value, prefix, objectParamNameKeys))","\treturn errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(value, prefix, arrayVars))","}","","func validateArrayVariable(value, prefix string, stringVars sets.String, arrayVars sets.String, objectParamNameKeys map[string][]string) *apis.FieldError {","\terrs := substitution.ValidateNoReferencesToUnknownVariables(value, prefix, stringVars)","\terrs = errs.Also(validateObjectVariable(value, prefix, objectParamNameKeys))","\treturn errs.Also(substitution.ValidateVariableReferenceIsIsolated(value, prefix, arrayVars))","}","","func validateObjectVariable(value, prefix string, objectParamNameKeys map[string][]string) (errs *apis.FieldError) {","\tobjectNames := sets.NewString()","\tfor objectParamName, keys := range objectParamNameKeys {","\t\tobjectNames.Insert(objectParamName)","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(value, fmt.Sprintf(\"%s\\\\.%s\", prefix, objectParamName), sets.NewString(keys...)))","\t}","","\treturn errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(value, prefix, objectNames))","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,1,1,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,0,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,2,2,2,2,2,2,1,1,0,0,0,0,2,0,0,0,2,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,2,0,2,0]},{"id":80,"path":"pkg/apis/pipeline/v1beta1/pipeline_conversion.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"fmt\"","","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/version\"","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Convertible = (*Pipeline)(nil)","","// ConvertTo implements apis.Convertible","func (p *Pipeline) ConvertTo(ctx context.Context, to apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\tswitch sink := to.(type) {","\tcase *v1.Pipeline:","\t\tsink.ObjectMeta = p.ObjectMeta","\t\tif err := serializePipelineResources(\u0026sink.ObjectMeta, \u0026p.Spec); err != nil {","\t\t\treturn err","\t\t}","\t\treturn p.Spec.ConvertTo(ctx, \u0026sink.Spec, \u0026sink.ObjectMeta)","\tdefault:","\t\treturn fmt.Errorf(\"unknown version, got: %T\", sink)","\t}","}","","// ConvertTo implements apis.Convertible","func (ps *PipelineSpec) ConvertTo(ctx context.Context, sink *v1.PipelineSpec, meta *metav1.ObjectMeta) error {","\tsink.DisplayName = ps.DisplayName","\tsink.Description = ps.Description","\tsink.Tasks = nil","\tfor _, t := range ps.Tasks {","\t\tnew := v1.PipelineTask{}","\t\terr := t.convertTo(ctx, \u0026new, meta)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tsink.Tasks = append(sink.Tasks, new)","\t}","\tsink.Params = nil","\tfor _, p := range ps.Params {","\t\tnew := v1.ParamSpec{}","\t\tp.convertTo(ctx, \u0026new)","\t\tsink.Params = append(sink.Params, new)","\t}","\tsink.Workspaces = nil","\tfor _, w := range ps.Workspaces {","\t\tnew := v1.PipelineWorkspaceDeclaration{}","\t\tw.convertTo(ctx, \u0026new)","\t\tsink.Workspaces = append(sink.Workspaces, new)","\t}","\tsink.Results = nil","\tfor _, r := range ps.Results {","\t\tnew := v1.PipelineResult{}","\t\tr.convertTo(ctx, \u0026new)","\t\tsink.Results = append(sink.Results, new)","\t}","\tsink.Finally = nil","\tfor _, f := range ps.Finally {","\t\tnew := v1.PipelineTask{}","\t\terr := f.convertTo(ctx, \u0026new, meta)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tsink.Finally = append(sink.Finally, new)","\t}","\treturn nil","}","","// ConvertFrom implements apis.Convertible","func (p *Pipeline) ConvertFrom(ctx context.Context, from apis.Convertible) error {","\tswitch source := from.(type) {","\tcase *v1.Pipeline:","\t\tp.ObjectMeta = source.ObjectMeta","\t\tif err := deserializePipelineResources(\u0026p.ObjectMeta, \u0026p.Spec); err != nil {","\t\t\treturn err","\t\t}","\t\treturn p.Spec.ConvertFrom(ctx, \u0026source.Spec, \u0026p.ObjectMeta)","\tdefault:","\t\treturn fmt.Errorf(\"unknown version, got: %T\", p)","\t}","}","","// ConvertFrom implements apis.Convertible","func (ps *PipelineSpec) ConvertFrom(ctx context.Context, source *v1.PipelineSpec, meta *metav1.ObjectMeta) error {","\tps.DisplayName = source.DisplayName","\tps.Description = source.Description","\tps.Tasks = nil","\tfor _, t := range source.Tasks {","\t\tnew := PipelineTask{}","\t\terr := new.convertFrom(ctx, t, meta)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tps.Tasks = append(ps.Tasks, new)","\t}","\tps.Params = nil","\tfor _, p := range source.Params {","\t\tnew := ParamSpec{}","\t\tnew.convertFrom(ctx, p)","\t\tps.Params = append(ps.Params, new)","\t}","\tps.Workspaces = nil","\tfor _, w := range source.Workspaces {","\t\tnew := PipelineWorkspaceDeclaration{}","\t\tnew.convertFrom(ctx, w)","\t\tps.Workspaces = append(ps.Workspaces, new)","\t}","\tps.Results = nil","\tfor _, r := range source.Results {","\t\tnew := PipelineResult{}","\t\tnew.convertFrom(ctx, r)","\t\tps.Results = append(ps.Results, new)","\t}","\tps.Finally = nil","\tfor _, f := range source.Finally {","\t\tnew := PipelineTask{}","\t\terr := new.convertFrom(ctx, f, meta)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tps.Finally = append(ps.Finally, new)","\t}","\treturn nil","}","","func (pt PipelineTask) convertTo(ctx context.Context, sink *v1.PipelineTask, meta *metav1.ObjectMeta) error {","\tsink.Name = pt.Name","\tsink.DisplayName = pt.DisplayName","\tsink.Description = pt.Description","\tif pt.TaskRef != nil {","\t\tsink.TaskRef = \u0026v1.TaskRef{}","\t\tpt.TaskRef.convertTo(ctx, sink.TaskRef)","\t}","\tif pt.TaskSpec != nil {","\t\tsink.TaskSpec = \u0026v1.EmbeddedTask{}","\t\terr := pt.TaskSpec.convertTo(ctx, sink.TaskSpec, meta, pt.Name)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t}","\tsink.When = nil","\tfor _, we := range pt.WhenExpressions {","\t\tnew := v1.WhenExpression{}","\t\twe.convertTo(ctx, \u0026new)","\t\tsink.When = append(sink.When, new)","\t}","\tsink.OnError = (v1.PipelineTaskOnErrorType)(pt.OnError)","\tsink.Retries = pt.Retries","\tsink.RunAfter = pt.RunAfter","\tsink.Params = nil","\tfor _, p := range pt.Params {","\t\tnew := v1.Param{}","\t\tp.convertTo(ctx, \u0026new)","\t\tsink.Params = append(sink.Params, new)","\t}","\tsink.Matrix = nil","\tif pt.IsMatrixed() {","\t\tnew := v1.Matrix{}","\t\tpt.Matrix.convertTo(ctx, \u0026new)","\t\tsink.Matrix = \u0026new","\t}","\tsink.Workspaces = nil","\tfor _, w := range pt.Workspaces {","\t\tnew := v1.WorkspacePipelineTaskBinding{}","\t\tw.convertTo(ctx, \u0026new)","\t\tsink.Workspaces = append(sink.Workspaces, new)","\t}","","\tsink.Timeout = pt.Timeout","\treturn nil","}","","func (pt *PipelineTask) convertFrom(ctx context.Context, source v1.PipelineTask, meta *metav1.ObjectMeta) error {","\tpt.Name = source.Name","\tpt.DisplayName = source.DisplayName","\tpt.Description = source.Description","\tif source.TaskRef != nil {","\t\tnewTaskRef := TaskRef{}","\t\tnewTaskRef.ConvertFrom(ctx, *source.TaskRef)","\t\tpt.TaskRef = \u0026newTaskRef","\t}","\tif source.TaskSpec != nil {","\t\tnewTaskSpec := EmbeddedTask{}","\t\terr := newTaskSpec.convertFrom(ctx, *source.TaskSpec, meta, pt.Name)","\t\tpt.TaskSpec = \u0026newTaskSpec","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t}","\tpt.WhenExpressions = nil","\tfor _, we := range source.When {","\t\tnew := WhenExpression{}","\t\tnew.convertFrom(ctx, we)","\t\tpt.WhenExpressions = append(pt.WhenExpressions, new)","\t}","\tpt.OnError = (PipelineTaskOnErrorType)(source.OnError)","\tpt.Retries = source.Retries","\tpt.RunAfter = source.RunAfter","\tpt.Params = nil","\tfor _, p := range source.Params {","\t\tnew := Param{}","\t\tnew.ConvertFrom(ctx, p)","\t\tpt.Params = append(pt.Params, new)","\t}","\tpt.Matrix = nil","\tif source.IsMatrixed() {","\t\tnew := Matrix{}","\t\tnew.convertFrom(ctx, *source.Matrix)","\t\tpt.Matrix = \u0026new","\t}","\tpt.Workspaces = nil","\tfor _, w := range source.Workspaces {","\t\tnew := WorkspacePipelineTaskBinding{}","\t\tnew.convertFrom(ctx, w)","\t\tpt.Workspaces = append(pt.Workspaces, new)","\t}","","\tpt.Timeout = source.Timeout","\treturn nil","}","","func (et EmbeddedTask) convertTo(ctx context.Context, sink *v1.EmbeddedTask, meta *metav1.ObjectMeta, taskName string) error {","\tsink.TypeMeta = et.TypeMeta","\tsink.Spec = et.Spec","\tsink.Metadata = v1.PipelineTaskMetadata(et.Metadata)","\tsink.TaskSpec = v1.TaskSpec{}","\treturn et.TaskSpec.ConvertTo(ctx, \u0026sink.TaskSpec, meta, taskName)","}","","func (et *EmbeddedTask) convertFrom(ctx context.Context, source v1.EmbeddedTask, meta *metav1.ObjectMeta, taskName string) error {","\tet.TypeMeta = source.TypeMeta","\tet.Spec = source.Spec","\tet.Metadata = PipelineTaskMetadata(source.Metadata)","\tet.TaskSpec = TaskSpec{}","\treturn et.TaskSpec.ConvertFrom(ctx, \u0026source.TaskSpec, meta, taskName)","}","","func (we WhenExpression) convertTo(ctx context.Context, sink *v1.WhenExpression) {","\tsink.Input = we.Input","\tsink.Operator = we.Operator","\tsink.Values = we.Values","\tsink.CEL = we.CEL","}","","func (we *WhenExpression) convertFrom(ctx context.Context, source v1.WhenExpression) {","\twe.Input = source.Input","\twe.Operator = source.Operator","\twe.Values = source.Values","\twe.CEL = source.CEL","}","","func (m *Matrix) convertTo(ctx context.Context, sink *v1.Matrix) {","\tfor _, param := range m.Params {","\t\tnew := v1.Param{}","\t\tparam.convertTo(ctx, \u0026new)","\t\tsink.Params = append(sink.Params, new)","\t}","\tfor i, include := range m.Include {","\t\tsink.Include = append(sink.Include, v1.IncludeParams{Name: include.Name})","\t\tfor _, param := range include.Params {","\t\t\tnewIncludeParam := v1.Param{}","\t\t\tparam.convertTo(ctx, \u0026newIncludeParam)","\t\t\tsink.Include[i].Params = append(sink.Include[i].Params, newIncludeParam)","\t\t}","\t}","}","","func (m *Matrix) convertFrom(ctx context.Context, source v1.Matrix) {","\tfor _, param := range source.Params {","\t\tnew := Param{}","\t\tnew.ConvertFrom(ctx, param)","\t\tm.Params = append(m.Params, new)","\t}","","\tfor i, include := range source.Include {","\t\tm.Include = append(m.Include, IncludeParams{Name: include.Name})","\t\tfor _, p := range include.Params {","\t\t\tnew := Param{}","\t\t\tnew.ConvertFrom(ctx, p)","\t\t\tm.Include[i].Params = append(m.Include[i].Params, new)","\t\t}","\t}","}","","func (pr PipelineResult) convertTo(ctx context.Context, sink *v1.PipelineResult) {","\tsink.Name = pr.Name","\tsink.Type = v1.ResultsType(pr.Type)","\tsink.Description = pr.Description","\tnewValue := v1.ParamValue{}","\tpr.Value.convertTo(ctx, \u0026newValue)","\tsink.Value = newValue","}","","func (pr *PipelineResult) convertFrom(ctx context.Context, source v1.PipelineResult) {","\tpr.Name = source.Name","\tpr.Type = ResultsType(source.Type)","\tpr.Description = source.Description","\tnewValue := ParamValue{}","\tnewValue.convertFrom(ctx, source.Value)","\tpr.Value = newValue","}","","func (ptm PipelineTaskMetadata) convertTo(ctx context.Context, sink *v1.PipelineTaskMetadata) {","\tsink.Labels = ptm.Labels","\tsink.Annotations = ptm.Annotations","}","","func (ptm *PipelineTaskMetadata) convertFrom(ctx context.Context, source v1.PipelineTaskMetadata) {","\tptm.Labels = source.Labels","\tptm.Annotations = source.Labels","}","","func serializePipelineResources(meta *metav1.ObjectMeta, spec *PipelineSpec) error {","\tif spec.Resources == nil {","\t\treturn nil","\t}","\treturn version.SerializeToMetadata(meta, spec.Resources, resourcesAnnotationKey)","}","","func deserializePipelineResources(meta *metav1.ObjectMeta, spec *PipelineSpec) error {","\tresources := \u0026[]PipelineDeclaredResource{}","\terr := version.DeserializeFromMetadata(meta, resources, resourcesAnnotationKey)","\tif err != nil {","\t\treturn err","\t}","\tif len(*resources) != 0 {","\t\tspec.Resources = *resources","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,2,2,2,2,1,1,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,1,1,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,0,2,0,0,0,2,2,2,2,2,1,1,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,1,1,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,0,2,2,2,2,0,2,2,2,2,0,2,2,2,2,2,0,0,2,2,2,2,1,1,2,2,2,2,0]},{"id":81,"path":"pkg/apis/pipeline/v1beta1/pipeline_defaults.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Defaultable = (*Pipeline)(nil)","","// SetDefaults sets default values on the Pipeline's Spec","func (p *Pipeline) SetDefaults(ctx context.Context) {","\tp.Spec.SetDefaults(ctx)","}","","// SetDefaults sets default values for the PipelineSpec's Params, Tasks, and Finally","func (ps *PipelineSpec) SetDefaults(ctx context.Context) {","\tfor i := range ps.Params {","\t\tps.Params[i].SetDefaults(ctx)","\t}","","\tfor _, pt := range ps.Tasks {","\t\tpt.SetDefaults(ctx)","\t}","","\tfor _, ft := range ps.Finally {","\t\tctx := ctx // Ensure local scoping per Task","\t\tft.SetDefaults(ctx)","\t}","}","","// SetDefaults sets default values for a PipelineTask","func (pt *PipelineTask) SetDefaults(ctx context.Context) {","\tcfg := config.FromContextOrDefaults(ctx)","\tif pt.TaskRef != nil {","\t\tif pt.TaskRef.Name == \"\" \u0026\u0026 pt.TaskRef.Resolver == \"\" {","\t\t\tpt.TaskRef.Resolver = ResolverName(cfg.Defaults.DefaultResolverType)","\t\t}","\t\tif pt.TaskRef.Kind == \"\" \u0026\u0026 pt.TaskRef.Resolver == \"\" {","\t\t\tpt.TaskRef.Kind = NamespacedTaskKind","\t\t}","\t}","\tif pt.TaskSpec != nil {","\t\tpt.TaskSpec.SetDefaults(ctx)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,2,2,2,2,0,2,2,2,0,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,0]},{"id":82,"path":"pkg/apis/pipeline/v1beta1/pipeline_types.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/internal/checksum\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/pipeline/dag\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"knative.dev/pkg/kmeta\"",")","","// PipelineTaskOnErrorType defines a list of supported failure handling behaviors of a PipelineTask on error","type PipelineTaskOnErrorType string","","const (","\t// PipelineTasksAggregateStatus is a param representing aggregate status of all dag pipelineTasks","\tPipelineTasksAggregateStatus = \"tasks.status\"","\t// PipelineTasks is a value representing a task is a member of \"tasks\" section of the pipeline","\tPipelineTasks = \"tasks\"","\t// PipelineFinallyTasks is a value representing a task is a member of \"finally\" section of the pipeline","\tPipelineFinallyTasks = \"finally\"","\t// PipelineTaskStopAndFail indicates to stop and fail the PipelineRun if the PipelineTask fails","\tPipelineTaskStopAndFail PipelineTaskOnErrorType = \"stopAndFail\"","\t// PipelineTaskContinue indicates to continue executing the rest of the DAG when the PipelineTask fails","\tPipelineTaskContinue PipelineTaskOnErrorType = \"continue\"",")","","// +genclient","// +genclient:noStatus","// +genreconciler:krshapedlogic=false","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","// +k8s:openapi-gen=true","","// Pipeline describes a list of Tasks to execute. It expresses how outputs","// of tasks feed into inputs of subsequent tasks.","//","// Deprecated: Please use v1.Pipeline instead.","type Pipeline struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ObjectMeta `json:\"metadata,omitempty\"`","","\t// Spec holds the desired state of the Pipeline from the client","\t// +optional","\tSpec PipelineSpec `json:\"spec\"`","}","","var _ kmeta.OwnerRefable = (*Pipeline)(nil)","","// PipelineMetadata returns the Pipeline's ObjectMeta, implementing PipelineObject","func (p *Pipeline) PipelineMetadata() metav1.ObjectMeta {","\treturn p.ObjectMeta","}","","// PipelineSpec returns the Pipeline's Spec, implementing PipelineObject","func (p *Pipeline) PipelineSpec() PipelineSpec {","\treturn p.Spec","}","","// Copy returns a deep copy of the Pipeline, implementing PipelineObject","func (p *Pipeline) Copy() PipelineObject {","\treturn p.DeepCopy()","}","","// GetGroupVersionKind implements kmeta.OwnerRefable.","func (*Pipeline) GetGroupVersionKind() schema.GroupVersionKind {","\treturn SchemeGroupVersion.WithKind(pipeline.PipelineControllerName)","}","","// Checksum computes the sha256 checksum of the task object.","// Prior to computing the checksum, it performs some preprocessing on the","// metadata of the object where it removes system provided annotations.","// Only the name, namespace, generateName, user-provided labels and annotations","// and the pipelineSpec are included for the checksum computation.","func (p *Pipeline) Checksum() ([]byte, error) {","\tobjectMeta := checksum.PrepareObjectMeta(p)","\tpreprocessedPipeline := Pipeline{","\t\tTypeMeta: metav1.TypeMeta{","\t\t\tAPIVersion: \"tekton.dev/v1beta1\",","\t\t\tKind:       \"Pipeline\"},","\t\tObjectMeta: objectMeta,","\t\tSpec:       p.Spec,","\t}","\tsha256Checksum, err := checksum.ComputeSha256Checksum(preprocessedPipeline)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn sha256Checksum, nil","}","","// PipelineSpec defines the desired state of Pipeline.","type PipelineSpec struct {","\t// DisplayName is a user-facing name of the pipeline that may be","\t// used to populate a UI.","\t// +optional","\tDisplayName string `json:\"displayName,omitempty\"`","\t// Description is a user-facing description of the pipeline that may be","\t// used to populate a UI.","\t// +optional","\tDescription string `json:\"description,omitempty\"`","\t// Deprecated: Unused, preserved only for backwards compatibility","\t// +listType=atomic","\tResources []PipelineDeclaredResource `json:\"resources,omitempty\"`","\t// Tasks declares the graph of Tasks that execute when this Pipeline is run.","\t// +listType=atomic","\tTasks []PipelineTask `json:\"tasks,omitempty\"`","\t// Params declares a list of input parameters that must be supplied when","\t// this Pipeline is run.","\tParams ParamSpecs `json:\"params,omitempty\"`","\t// Workspaces declares a set of named workspaces that are expected to be","\t// provided by a PipelineRun.","\t// +optional","\t// +listType=atomic","\tWorkspaces []PipelineWorkspaceDeclaration `json:\"workspaces,omitempty\"`","\t// Results are values that this pipeline can output once run","\t// +optional","\t// +listType=atomic","\tResults []PipelineResult `json:\"results,omitempty\"`","\t// Finally declares the list of Tasks that execute just before leaving the Pipeline","\t// i.e. either after all Tasks are finished executing successfully","\t// or after a failure which would result in ending the Pipeline","\t// +listType=atomic","\tFinally []PipelineTask `json:\"finally,omitempty\"`","}","","// PipelineResult used to describe the results of a pipeline","type PipelineResult struct {","\t// Name the given name","\tName string `json:\"name\"`","","\t// Type is the user-specified type of the result.","\t// The possible types are 'string', 'array', and 'object', with 'string' as the default.","\t// 'array' and 'object' types are alpha features.","\tType ResultsType `json:\"type,omitempty\"`","","\t// Description is a human-readable description of the result","\t// +optional","\tDescription string `json:\"description\"`","","\t// Value the expression used to retrieve the value","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tValue ResultValue `json:\"value\"`","}","","// PipelineTaskMetadata contains the labels or annotations for an EmbeddedTask","type PipelineTaskMetadata struct {","\t// +optional","\tLabels map[string]string `json:\"labels,omitempty\"`","","\t// +optional","\tAnnotations map[string]string `json:\"annotations,omitempty\"`","}","","// EmbeddedTask is used to define a Task inline within a Pipeline's PipelineTasks.","type EmbeddedTask struct {","\t// +optional","\truntime.TypeMeta `json:\",inline,omitempty\"`","","\t// Spec is a specification of a custom task","\t// +optional","\tSpec runtime.RawExtension `json:\"spec,omitempty\"`","","\t// +optional","\tMetadata PipelineTaskMetadata `json:\"metadata,omitempty\"`","","\t// TaskSpec is a specification of a task","\t// +optional","\tTaskSpec `json:\",inline,omitempty\"`","}","","// PipelineTask defines a task in a Pipeline, passing inputs from both","// Params and from the output of previous tasks.","type PipelineTask struct {","\t// Name is the name of this task within the context of a Pipeline. Name is","\t// used as a coordinate with the `from` and `runAfter` fields to establish","\t// the execution order of tasks relative to one another.","\tName string `json:\"name,omitempty\"`","","\t// DisplayName is the display name of this task within the context of a Pipeline.","\t// This display name may be used to populate a UI.","\t// +optional","\tDisplayName string `json:\"displayName,omitempty\"`","","\t// Description is the description of this task within the context of a Pipeline.","\t// This description may be used to populate a UI.","\t// +optional","\tDescription string `json:\"description,omitempty\"`","","\t// TaskRef is a reference to a task definition.","\t// +optional","\tTaskRef *TaskRef `json:\"taskRef,omitempty\"`","","\t// TaskSpec is a specification of a task","\t// Specifying TaskSpec can be disabled by setting","\t// `disable-inline-spec` feature flag.","\t// See Task.spec (API version: tekton.dev/v1beta1)","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tTaskSpec *EmbeddedTask `json:\"taskSpec,omitempty\"`","","\t// WhenExpressions is a list of when expressions that need to be true for the task to run","\t// +optional","\tWhenExpressions WhenExpressions `json:\"when,omitempty\"`","","\t// Retries represents how many times this task should be retried in case of task failure: ConditionSucceeded set to False","\t// +optional","\tRetries int `json:\"retries,omitempty\"`","","\t// RunAfter is the list of PipelineTask names that should be executed before","\t// this Task executes. (Used to force a specific ordering in graph execution.)","\t// +optional","\t// +listType=atomic","\tRunAfter []string `json:\"runAfter,omitempty\"`","","\t// Deprecated: Unused, preserved only for backwards compatibility","\t// +optional","\tResources *PipelineTaskResources `json:\"resources,omitempty\"`","","\t// Parameters declares parameters passed to this task.","\t// +optional","\tParams Params `json:\"params,omitempty\"`","","\t// Matrix declares parameters used to fan out this task.","\t// +optional","\tMatrix *Matrix `json:\"matrix,omitempty\"`","","\t// Workspaces maps workspaces from the pipeline spec to the workspaces","\t// declared in the Task.","\t// +optional","\t// +listType=atomic","\tWorkspaces []WorkspacePipelineTaskBinding `json:\"workspaces,omitempty\"`","","\t// Duration after which the TaskRun times out. Defaults to 1 hour.","\t// Refer Go's ParseDuration documentation for expected format: https://golang.org/pkg/time/#ParseDuration","\t// +optional","\tTimeout *metav1.Duration `json:\"timeout,omitempty\"`","","\t// PipelineRef is a reference to a pipeline definition","\t// Note: PipelineRef is in preview mode and not yet supported","\t// +optional","\tPipelineRef *PipelineRef `json:\"pipelineRef,omitempty\"`","","\t// PipelineSpec is a specification of a pipeline","\t// Note: PipelineSpec is in preview mode and not yet supported","\t// Specifying PipelineSpec can be disabled by setting","\t// `disable-inline-spec` feature flag.","\t// See Pipeline.spec (API version: tekton.dev/v1beta1)","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tPipelineSpec *PipelineSpec `json:\"pipelineSpec,omitempty\"`","","\t// OnError defines the exiting behavior of a PipelineRun on error","\t// can be set to [ continue | stopAndFail ]","\t// +optional","\tOnError PipelineTaskOnErrorType `json:\"onError,omitempty\"`","}","","// IsCustomTask checks whether an embedded TaskSpec is a Custom Task","func (et *EmbeddedTask) IsCustomTask() bool {","\t// Note that if `apiVersion` is set to `\"tekton.dev/v1beta1\"` and `kind` is set to `\"Task\"`,","\t// the reference will be considered a Custom Task - https://github.com/tektoncd/pipeline/issues/6457","\treturn et != nil \u0026\u0026 et.APIVersion != \"\" \u0026\u0026 et.Kind != \"\"","}","","// IsMatrixed return whether pipeline task is matrixed","func (pt *PipelineTask) IsMatrixed() bool {","\treturn pt.Matrix.HasParams() || pt.Matrix.HasInclude()","}","","// TaskSpecMetadata returns the metadata of the PipelineTask's EmbeddedTask spec.","func (pt *PipelineTask) TaskSpecMetadata() PipelineTaskMetadata {","\treturn pt.TaskSpec.Metadata","}","","// HashKey is the name of the PipelineTask, and is used as the key for this PipelineTask in the DAG","func (pt PipelineTask) HashKey() string {","\treturn pt.Name","}","","// Deps returns all other PipelineTask dependencies of this PipelineTask, based on resource usage or ordering","func (pt PipelineTask) Deps() []string {","\t// hold the list of dependencies in a set to avoid duplicates","\tdeps := sets.NewString()","","\t// add any new dependents from result references - resource dependency","\tfor _, ref := range PipelineTaskResultRefs(\u0026pt) {","\t\tdeps.Insert(ref.PipelineTask)","\t}","","\t// add any new dependents from runAfter - order dependency","\tfor _, runAfter := range pt.RunAfter {","\t\tdeps.Insert(runAfter)","\t}","","\treturn deps.List()","}","","// PipelineTaskList is a list of PipelineTasks","type PipelineTaskList []PipelineTask","","// Deps returns a map with key as name of a pipelineTask and value as a list of its dependencies","func (l PipelineTaskList) Deps() map[string][]string {","\tdeps := map[string][]string{}","\tfor _, pt := range l {","\t\t// get the list of deps for this pipelineTask","\t\td := pt.Deps()","\t\t// add the pipelineTask into the map if it has any deps","\t\tif len(d) \u003e 0 {","\t\t\tdeps[pt.HashKey()] = d","\t\t}","\t}","\treturn deps","}","","// Items returns a slice of all tasks in the PipelineTaskList, converted to dag.Tasks","func (l PipelineTaskList) Items() []dag.Task {","\ttasks := []dag.Task{}","\tfor _, t := range l {","\t\ttasks = append(tasks, dag.Task(t))","\t}","\treturn tasks","}","","// Names returns a set of pipeline task names from the given list of pipeline tasks","func (l PipelineTaskList) Names() sets.String {","\tnames := sets.String{}","\tfor _, pt := range l {","\t\tnames.Insert(pt.Name)","\t}","\treturn names","}","","// PipelineTaskParam is used to provide arbitrary string parameters to a Task.","type PipelineTaskParam struct {","\tName  string `json:\"name\"`","\tValue string `json:\"value\"`","}","","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// PipelineList contains a list of Pipeline","type PipelineList struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ListMeta `json:\"metadata,omitempty\"`","\tItems           []Pipeline `json:\"items\"`","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,2,2,2,0,0,1,1,1,0,0,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,0,2,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]},{"id":83,"path":"pkg/apis/pipeline/v1beta1/pipeline_validation.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"fmt\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/internal/artifactref\"","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/validate\"","\t\"github.com/tektoncd/pipeline/pkg/internal/resultref\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/pipeline/dag\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\tadmissionregistrationv1 \"k8s.io/api/admissionregistration/v1\"","\t\"k8s.io/apimachinery/pkg/api/equality\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"k8s.io/apimachinery/pkg/util/validation\"","\t\"k8s.io/utils/strings/slices\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/webhook/resourcesemantics\"",")","","var (","\t_ apis.Validatable              = (*Pipeline)(nil)","\t_ resourcesemantics.VerbLimited = (*Pipeline)(nil)",")","","const (","\ttaskRef      = \"taskRef\"","\ttaskSpec     = \"taskSpec\"","\tpipelineRef  = \"pipelineRef\"","\tpipelineSpec = \"pipelineSpec\"",")","","// SupportedVerbs returns the operations that validation should be called for","func (p *Pipeline) SupportedVerbs() []admissionregistrationv1.OperationType {","\treturn []admissionregistrationv1.OperationType{admissionregistrationv1.Create, admissionregistrationv1.Update}","}","","// Validate checks that the Pipeline structure is valid but does not validate","// that any references resources exist, that is done at run time.","func (p *Pipeline) Validate(ctx context.Context) *apis.FieldError {","\terrs := validate.ObjectMetadata(p.GetObjectMeta()).ViaField(\"metadata\")","\terrs = errs.Also(p.Spec.Validate(apis.WithinSpec(ctx)).ViaField(\"spec\"))","\t// When a Pipeline is created directly, instead of declared inline in a PipelineRun,","\t// we do not support propagated parameters and workspaces.","\t// Validate that all params and workspaces it uses are declared.","\terrs = errs.Also(p.Spec.validatePipelineParameterUsage(ctx).ViaField(\"spec\"))","\treturn errs.Also(p.Spec.validatePipelineWorkspacesUsage().ViaField(\"spec\"))","}","","// Validate checks that taskNames in the Pipeline are valid and that the graph","// of Tasks expressed in the Pipeline makes sense.","func (ps *PipelineSpec) Validate(ctx context.Context) (errs *apis.FieldError) {","\terrs = errs.Also(ps.ValidateBetaFields(ctx))","\tif equality.Semantic.DeepEqual(ps, \u0026PipelineSpec{}) {","\t\terrs = errs.Also(apis.ErrGeneric(\"expected at least one, got none\", \"description\", \"params\", \"resources\", \"tasks\", \"workspaces\"))","\t}","\t// PipelineTask must have a valid unique label and at least one of taskRef or taskSpec should be specified","\terrs = errs.Also(ValidatePipelineTasks(ctx, ps.Tasks, ps.Finally))","\tif len(ps.Resources) \u003e 0 {","\t\terrs = errs.Also(apis.ErrDisallowedFields(\"resources\"))","\t}","\t// Validate the pipeline task graph","\terrs = errs.Also(validateGraph(ps.Tasks))","\t// The parameter variables should be valid","\terrs = errs.Also(ValidatePipelineParameterVariables(ctx, ps.Tasks, ps.Params).ViaField(\"tasks\"))","\terrs = errs.Also(ValidatePipelineParameterVariables(ctx, ps.Finally, ps.Params).ViaField(\"finally\"))","\terrs = errs.Also(validatePipelineContextVariables(ps.Tasks).ViaField(\"tasks\"))","\terrs = errs.Also(validatePipelineContextVariables(ps.Finally).ViaField(\"finally\"))","\terrs = errs.Also(validateExecutionStatusVariables(ps.Tasks, ps.Finally))","\t// Validate the pipeline's workspaces.","\terrs = errs.Also(validatePipelineWorkspacesDeclarations(ps.Workspaces))","\t// Validate the pipeline's results","\terrs = errs.Also(validatePipelineResults(ps.Results, ps.Tasks, ps.Finally))","\terrs = errs.Also(validateTasksAndFinallySection(ps))","\terrs = errs.Also(validateFinalTasks(ps.Tasks, ps.Finally))","\terrs = errs.Also(validateWhenExpressions(ctx, ps.Tasks, ps.Finally))","\terrs = errs.Also(validateArtifactReference(ctx, ps.Tasks, ps.Finally))","\terrs = errs.Also(validateMatrix(ctx, ps.Tasks).ViaField(\"tasks\"))","\terrs = errs.Also(validateMatrix(ctx, ps.Finally).ViaField(\"finally\"))","\treturn errs","}","","// ValidateBetaFields returns an error if the PipelineSpec uses beta specifications governed by","// `enable-api-fields` but does not have \"enable-api-fields\" set to \"alpha\" or \"beta\".","func (ps *PipelineSpec) ValidateBetaFields(ctx context.Context) *apis.FieldError {","\tvar errs *apis.FieldError","\tfor i, pt := range ps.Tasks {","\t\terrs = errs.Also(pt.validateBetaFields(ctx).ViaFieldIndex(\"tasks\", i))","\t}","\tfor i, pt := range ps.Finally {","\t\terrs = errs.Also(pt.validateBetaFields(ctx).ViaFieldIndex(\"finally\", i))","\t}","\treturn errs","}","","// validateBetaFields returns an error if the PipelineTask uses beta features but does not","// have \"enable-api-fields\" set to \"alpha\" or \"beta\".","func (pt *PipelineTask) validateBetaFields(ctx context.Context) *apis.FieldError {","\tvar errs *apis.FieldError","\tif pt.TaskRef != nil {","\t\t// Resolvers","\t\tif pt.TaskRef.Resolver != \"\" {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"taskref.resolver\", config.BetaAPIFields))","\t\t}","\t\tif len(pt.TaskRef.Params) \u003e 0 {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"taskref.params\", config.BetaAPIFields))","\t\t}","\t}","\treturn errs","}","","// ValidatePipelineTasks ensures that pipeline tasks has unique label, pipeline tasks has specified one of","// taskRef or taskSpec, and in case of a pipeline task with taskRef, it has a reference to a valid task (task name)","func ValidatePipelineTasks(ctx context.Context, tasks []PipelineTask, finalTasks []PipelineTask) *apis.FieldError {","\ttaskNames := sets.NewString()","\tvar errs *apis.FieldError","\terrs = errs.Also(PipelineTaskList(tasks).Validate(ctx, taskNames, \"tasks\"))","\terrs = errs.Also(PipelineTaskList(finalTasks).Validate(ctx, taskNames, \"finally\"))","\treturn errs","}","","// Validate a list of pipeline tasks including custom task and bundles","func (l PipelineTaskList) Validate(ctx context.Context, taskNames sets.String, path string) (errs *apis.FieldError) {","\tfor i, t := range l {","\t\t// validate pipeline task name","\t\terrs = errs.Also(t.ValidateName().ViaFieldIndex(path, i))","\t\t// names cannot be duplicated - checking that pipelineTask names are unique","\t\tif _, ok := taskNames[t.Name]; ok {","\t\t\terrs = errs.Also(apis.ErrMultipleOneOf(\"name\").ViaFieldIndex(path, i))","\t\t}","\t\ttaskNames.Insert(t.Name)","\t\t// validate custom task, bundle, dag, or final task","\t\terrs = errs.Also(t.Validate(ctx).ViaFieldIndex(path, i))","\t}","\treturn errs","}","","// validateUsageOfDeclaredPipelineTaskParameters validates that all parameters referenced in the pipeline Task are declared by the pipeline Task.","func (l PipelineTaskList) validateUsageOfDeclaredPipelineTaskParameters(ctx context.Context, additionalParams []ParamSpec, path string) (errs *apis.FieldError) {","\tfor i, t := range l {","\t\tif t.TaskSpec != nil {","\t\t\terrs = errs.Also(ValidateUsageOfDeclaredParameters(ctx, t.TaskSpec.Steps, append(t.TaskSpec.Params, additionalParams...)).ViaFieldIndex(path, i))","\t\t}","\t}","\treturn errs","}","","// ValidateName checks whether the PipelineTask's name is a valid DNS label","func (pt PipelineTask) ValidateName() *apis.FieldError {","\tif err := validation.IsDNS1123Label(pt.Name); len(err) \u003e 0 {","\t\treturn \u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(\"invalid value %q\", pt.Name),","\t\t\tPaths:   []string{\"name\"},","\t\t\tDetails: \"Pipeline Task name must be a valid DNS Label.\" +","\t\t\t\t\"For more info refer to https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names\",","\t\t}","\t}","\treturn nil","}","","// Validate classifies whether a task is a custom task, bundle, or a regular task(dag/final)","// calls the validation routine based on the type of the task","func (pt PipelineTask) Validate(ctx context.Context) (errs *apis.FieldError) {","\terrs = errs.Also(pt.validateRefOrSpec(ctx))","","\terrs = errs.Also(pt.validateEnabledInlineSpec(ctx))","","\terrs = errs.Also(pt.validateEmbeddedOrType())","","\tif pt.Resources != nil {","\t\terrs = errs.Also(apis.ErrDisallowedFields(\"resources\"))","\t}","\t// taskKinds contains the kinds when the apiVersion is not set, they are not custom tasks,","\t// if apiVersion is set they are custom tasks.","\ttaskKinds := map[TaskKind]bool{","\t\t\"\":                 true,","\t\tNamespacedTaskKind: true,","\t}","","\terrs = errs.Also(pt.ValidateOnError(ctx))","","\t// Pipeline task having taskRef/taskSpec with APIVersion is classified as custom task","\tswitch {","\tcase pt.TaskRef != nil \u0026\u0026 !taskKinds[pt.TaskRef.Kind]:","\t\terrs = errs.Also(pt.validateCustomTask())","\tcase pt.TaskRef != nil \u0026\u0026 pt.TaskRef.APIVersion != \"\":","\t\terrs = errs.Also(pt.validateCustomTask())","\tcase pt.TaskSpec != nil \u0026\u0026 !taskKinds[TaskKind(pt.TaskSpec.Kind)]:","\t\terrs = errs.Also(pt.validateCustomTask())","\tcase pt.TaskSpec != nil \u0026\u0026 pt.TaskSpec.APIVersion != \"\":","\t\terrs = errs.Also(pt.validateCustomTask())","\tdefault:","\t\terrs = errs.Also(pt.validateTask(ctx))","\t}","\treturn //nolint:nakedret","}","","// ValidateOnError validates the OnError field of a PipelineTask","func (pt PipelineTask) ValidateOnError(ctx context.Context) (errs *apis.FieldError) {","\tif pt.OnError != \"\" \u0026\u0026 !isParamRefs(string(pt.OnError)) {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"OnError\", config.BetaAPIFields))","\t\tif pt.OnError != PipelineTaskContinue \u0026\u0026 pt.OnError != PipelineTaskStopAndFail {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(pt.OnError, \"OnError\", \"PipelineTask OnError must be either \\\"continue\\\" or \\\"stopAndFail\\\"\"))","\t\t}","\t\tif pt.OnError == PipelineTaskContinue \u0026\u0026 pt.Retries \u003e 0 {","\t\t\terrs = errs.Also(apis.ErrGeneric(\"PipelineTask OnError cannot be set to \\\"continue\\\" when Retries is greater than 0\"))","\t\t}","\t}","\treturn errs","}","","// validateEnabledInlineSpec validates that pipelineSpec or taskSpec is allowed by checking","// disable-inline-spec field","func (pt PipelineTask) validateEnabledInlineSpec(ctx context.Context) (errs *apis.FieldError) {","\tif pt.TaskSpec != nil {","\t\tif slices.Contains(strings.Split(","\t\t\tconfig.FromContextOrDefaults(ctx).FeatureFlags.DisableInlineSpec, \",\"), \"pipeline\") {","\t\t\terrs = errs.Also(apis.ErrDisallowedFields(\"taskSpec\"))","\t\t}","\t}","\tif pt.PipelineSpec != nil {","\t\tif slices.Contains(strings.Split(","\t\t\tconfig.FromContextOrDefaults(ctx).FeatureFlags.DisableInlineSpec, \",\"), \"pipeline\") {","\t\t\terrs = errs.Also(apis.ErrDisallowedFields(\"pipelineSpec\"))","\t\t}","\t}","\treturn errs","}","","func (pt *PipelineTask) validateMatrix(ctx context.Context) (errs *apis.FieldError) {","\tif pt.IsMatrixed() {","\t\t// This is a beta feature and will fail validation if it's used in a pipeline spec","\t\t// when the enable-api-fields feature gate is set to \"stable\".","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"matrix\", config.BetaAPIFields))","\t\terrs = errs.Also(pt.Matrix.validateCombinationsCount(ctx))","\t\terrs = errs.Also(pt.Matrix.validateUniqueParams())","\t}","\terrs = errs.Also(pt.Matrix.validateParameterInOneOfMatrixOrParams(pt.Params))","\treturn errs","}","","func (pt PipelineTask) validateEmbeddedOrType() (errs *apis.FieldError) {","\t// Reject cases where APIVersion and/or Kind are specified alongside an embedded Task.","\t// We determine if this is an embedded Task by checking of TaskSpec.TaskSpec.Steps has items.","\tif pt.TaskSpec != nil \u0026\u0026 len(pt.TaskSpec.TaskSpec.Steps) \u003e 0 {","\t\tif pt.TaskSpec.APIVersion != \"\" {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"taskSpec.apiVersion cannot be specified when using taskSpec.steps\",","\t\t\t\tPaths:   []string{\"taskSpec.apiVersion\"},","\t\t\t})","\t\t}","\t\tif pt.TaskSpec.Kind != \"\" {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"taskSpec.kind cannot be specified when using taskSpec.steps\",","\t\t\t\tPaths:   []string{\"taskSpec.kind\"},","\t\t\t})","\t\t}","\t}","\treturn","}","","func (pt *PipelineTask) validateWorkspaces(workspaceNames sets.String) (errs *apis.FieldError) {","\tworkspaceBindingNames := sets.NewString()","\tfor i, ws := range pt.Workspaces {","\t\tif workspaceBindingNames.Has(ws.Name) {","\t\t\terrs = errs.Also(apis.ErrGeneric(","\t\t\t\tfmt.Sprintf(\"workspace name %q must be unique\", ws.Name), \"\").ViaFieldIndex(\"workspaces\", i))","\t\t}","","\t\tif ws.Workspace == \"\" {","\t\t\tif !workspaceNames.Has(ws.Name) {","\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(","\t\t\t\t\tfmt.Sprintf(\"pipeline task %q expects workspace with name %q but none exists in pipeline spec\", pt.Name, ws.Name),","\t\t\t\t\t\"\",","\t\t\t\t).ViaFieldIndex(\"workspaces\", i))","\t\t\t}","\t\t} else if !workspaceNames.Has(ws.Workspace) {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(","\t\t\t\tfmt.Sprintf(\"pipeline task %q expects workspace with name %q but none exists in pipeline spec\", pt.Name, ws.Workspace),","\t\t\t\t\"\",","\t\t\t).ViaFieldIndex(\"workspaces\", i))","\t\t}","","\t\tworkspaceBindingNames.Insert(ws.Name)","\t}","\treturn errs","}","","// validateRefOrSpec validates at least one of taskRef or taskSpec or pipelineRef or pipelineSpec is specified","func (pt PipelineTask) validateRefOrSpec(ctx context.Context) (errs *apis.FieldError) {","\t// collect all the specified specifications","\tnonNilFields := []string{}","\tif pt.TaskRef != nil {","\t\tnonNilFields = append(nonNilFields, taskRef)","\t}","\tif pt.TaskSpec != nil {","\t\tnonNilFields = append(nonNilFields, taskSpec)","\t}","\tif pt.PipelineRef != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, pipelineRef, config.AlphaAPIFields))","\t\tnonNilFields = append(nonNilFields, pipelineRef)","\t}","\tif pt.PipelineSpec != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, pipelineSpec, config.AlphaAPIFields))","\t\tnonNilFields = append(nonNilFields, pipelineSpec)","\t}","","\t// check the length of nonNilFields","\t// if one of taskRef or taskSpec or pipelineRef or pipelineSpec is specified,","\t// the length of nonNilFields should exactly be 1","\tif len(nonNilFields) \u003e 1 {","\t\terrs = errs.Also(apis.ErrGeneric(\"expected exactly one, got multiple\", nonNilFields...))","\t} else if len(nonNilFields) == 0 {","\t\tcfg := config.FromContextOrDefaults(ctx)","\t\t// check for TaskRef or TaskSpec or PipelineRef or PipelineSpec with alpha feature flag","\t\tif cfg.FeatureFlags.EnableAPIFields == config.AlphaAPIFields {","\t\t\terrs = errs.Also(apis.ErrMissingOneOf(taskRef, taskSpec, pipelineRef, pipelineSpec))","\t\t} else {","\t\t\t// check for taskRef and taskSpec with beta/stable feature flag","\t\t\terrs = errs.Also(apis.ErrMissingOneOf(taskRef, taskSpec))","\t\t}","\t}","\treturn errs","}","","// isValidAPIVersion validates the format of an apiVersion string.","// Valid formats are \"group/version\" where both group and version are non-empty.","// For custom tasks, apiVersion must always be in the \"group/version\" format.","func isValidAPIVersion(apiVersion string) bool {","\tparts := strings.Split(apiVersion, \"/\")","\tif len(parts) != 2 {","\t\treturn false","\t}","\tgroup := parts[0]","\tversion := parts[1]","\treturn group != \"\" \u0026\u0026 version != \"\"","}","","// validateCustomTask validates custom task specifications - checking kind and fail if not yet supported features specified","func (pt PipelineTask) validateCustomTask() (errs *apis.FieldError) {","\tif pt.TaskRef != nil \u0026\u0026 pt.TaskRef.Kind == \"\" {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"custom task ref must specify kind\", \"taskRef.kind\"))","\t}","\tif pt.TaskSpec != nil \u0026\u0026 pt.TaskSpec.Kind == \"\" {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"custom task spec must specify kind\", \"taskSpec.kind\"))","\t}","\t// Validate apiVersion format for custom tasks","\tif pt.TaskRef != nil \u0026\u0026 pt.TaskRef.APIVersion != \"\" {","\t\tif !isValidAPIVersion(pt.TaskRef.APIVersion) {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"invalid apiVersion format %q, must be in the format \\\"group/version\\\"\", pt.TaskRef.APIVersion), \"taskRef.apiVersion\"))","\t\t}","\t} else if pt.TaskRef != nil {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"custom task ref must specify apiVersion\", \"taskRef.apiVersion\"))","\t}","\tif pt.TaskSpec != nil \u0026\u0026 pt.TaskSpec.APIVersion != \"\" {","\t\tif !isValidAPIVersion(pt.TaskSpec.APIVersion) {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"invalid apiVersion format %q, must be in the format \\\"group/version\\\"\", pt.TaskSpec.APIVersion), \"taskSpec.apiVersion\"))","\t\t}","\t} else if pt.TaskSpec != nil {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"custom task spec must specify apiVersion\", \"taskSpec.apiVersion\"))","\t}","\treturn errs","}","","// validateTask validates a pipeline task or a final task for taskRef and taskSpec","func (pt PipelineTask) validateTask(ctx context.Context) (errs *apis.FieldError) {","\tif pt.TaskSpec != nil {","\t\terrs = errs.Also(pt.TaskSpec.Validate(ctx).ViaField(\"taskSpec\"))","\t}","\tif pt.TaskRef != nil {","\t\terrs = errs.Also(pt.TaskRef.Validate(ctx).ViaField(\"taskRef\"))","\t}","\treturn errs","}","","// validatePipelineWorkspacesDeclarations validates the specified workspaces, ensuring having unique name without any","// empty string,","func validatePipelineWorkspacesDeclarations(wss []PipelineWorkspaceDeclaration) (errs *apis.FieldError) {","\t// Workspace names must be non-empty and unique.","\twsTable := sets.NewString()","\tfor i, ws := range wss {","\t\tif ws.Name == \"\" {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"workspace %d has empty name\", i),","\t\t\t\t\"\").ViaFieldIndex(\"workspaces\", i))","\t\t}","\t\tif wsTable.Has(ws.Name) {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"workspace with name %q appears more than once\", ws.Name),","\t\t\t\t\"\").ViaFieldIndex(\"workspaces\", i))","\t\t}","\t\twsTable.Insert(ws.Name)","\t}","\treturn errs","}","","// validatePipelineParameterUsage validates that parameters referenced in the Pipeline are declared by the Pipeline","func (ps *PipelineSpec) validatePipelineParameterUsage(ctx context.Context) (errs *apis.FieldError) {","\terrs = errs.Also(PipelineTaskList(ps.Tasks).validateUsageOfDeclaredPipelineTaskParameters(ctx, ps.Params, \"tasks\"))","\terrs = errs.Also(PipelineTaskList(ps.Finally).validateUsageOfDeclaredPipelineTaskParameters(ctx, ps.Params, \"finally\"))","\terrs = errs.Also(validatePipelineTaskParameterUsage(ps.Tasks, ps.Params).ViaField(\"tasks\"))","\terrs = errs.Also(validatePipelineTaskParameterUsage(ps.Finally, ps.Params).ViaField(\"finally\"))","\treturn errs","}","","// validatePipelineTaskParameterUsage validates that parameters referenced in the Pipeline Tasks are declared by the Pipeline","func validatePipelineTaskParameterUsage(tasks []PipelineTask, params ParamSpecs) (errs *apis.FieldError) {","\tallParamNames := sets.NewString(params.getNames()...)","\t_, arrayParams, objectParams := params.sortByType()","\tarrayParamNames := sets.NewString(arrayParams.getNames()...)","\tobjectParameterNameKeys := map[string][]string{}","\tfor _, p := range objectParams {","\t\tfor k := range p.Properties {","\t\t\tobjectParameterNameKeys[p.Name] = append(objectParameterNameKeys[p.Name], k)","\t\t}","\t}","\terrs = errs.Also(validatePipelineParametersVariables(tasks, \"params\", allParamNames, arrayParamNames, objectParameterNameKeys))","\tfor i, task := range tasks {","\t\terrs = errs.Also(task.Params.validateDuplicateParameters().ViaField(\"params\").ViaIndex(i))","\t}","\treturn errs","}","","// validatePipelineWorkspacesUsage validates that Workspaces referenced in the Pipeline are declared by the Pipeline","func (ps *PipelineSpec) validatePipelineWorkspacesUsage() (errs *apis.FieldError) {","\terrs = errs.Also(validatePipelineTasksWorkspacesUsage(ps.Workspaces, ps.Tasks).ViaField(\"tasks\"))","\terrs = errs.Also(validatePipelineTasksWorkspacesUsage(ps.Workspaces, ps.Finally).ViaField(\"finally\"))","\treturn errs","}","","// validatePipelineTasksWorkspacesUsage validates that all the referenced workspaces (by pipeline tasks) are specified in","// the pipeline","func validatePipelineTasksWorkspacesUsage(wss []PipelineWorkspaceDeclaration, pts []PipelineTask) (errs *apis.FieldError) {","\tworkspaceNames := sets.NewString()","\tfor _, ws := range wss {","\t\tworkspaceNames.Insert(ws.Name)","\t}","\t// Any workspaces used in PipelineTasks should have their name declared in the Pipeline's Workspaces list.","\tfor i, pt := range pts {","\t\terrs = errs.Also(pt.validateWorkspaces(workspaceNames).ViaIndex(i))","\t}","\treturn errs","}","","// ValidatePipelineParameterVariables validates parameters with those specified by each pipeline task,","// (1) it validates the type of parameter is either string or array (2) parameter default value matches","// with the type of that param (3) no duplication, feature flag and allowed param type when using param enum","func ValidatePipelineParameterVariables(ctx context.Context, tasks []PipelineTask, params ParamSpecs) (errs *apis.FieldError) {","\t// validates all the types within a slice of ParamSpecs","\terrs = errs.Also(ValidateParameterTypes(ctx, params).ViaField(\"params\"))","\terrs = errs.Also(params.validateNoDuplicateNames())","\terrs = errs.Also(params.validateParamEnums(ctx).ViaField(\"params\"))","\tfor i, task := range tasks {","\t\terrs = errs.Also(task.Params.validateDuplicateParameters().ViaField(\"params\").ViaIndex(i))","\t}","\treturn errs","}","","func validatePipelineParametersVariables(tasks []PipelineTask, prefix string, paramNames sets.String, arrayParamNames sets.String, objectParamNameKeys map[string][]string) (errs *apis.FieldError) {","\tfor idx, task := range tasks {","\t\terrs = errs.Also(validatePipelineParametersVariablesInTaskParameters(task.Params, prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaIndex(idx))","\t\tif task.IsMatrixed() {","\t\t\terrs = errs.Also(task.Matrix.validatePipelineParametersVariablesInMatrixParameters(prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaIndex(idx))","\t\t}","\t\terrs = errs.Also(task.WhenExpressions.validatePipelineParametersVariables(prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaIndex(idx))","\t}","\treturn errs","}","","func validatePipelineContextVariables(tasks []PipelineTask) *apis.FieldError {","\tpipelineRunContextNames := sets.NewString().Insert(","\t\t\"name\",","\t\t\"namespace\",","\t\t\"uid\",","\t)","\tpipelineContextNames := sets.NewString().Insert(","\t\t\"name\",","\t)","\tpipelineTaskContextNames := sets.NewString().Insert(","\t\t\"retries\",","\t)","\tvar paramValues []string","\tfor _, task := range tasks {","\t\tparamValues = task.extractAllParams().extractValues()","\t}","\terrs := validatePipelineContextVariablesInParamValues(paramValues, \"context\\\\.pipelineRun\", pipelineRunContextNames).","\t\tAlso(validatePipelineContextVariablesInParamValues(paramValues, \"context\\\\.pipeline\", pipelineContextNames)).","\t\tAlso(validatePipelineContextVariablesInParamValues(paramValues, \"context\\\\.pipelineTask\", pipelineTaskContextNames))","\treturn errs","}","","// extractAllParams extracts all the parameters in a PipelineTask:","// - pt.Params","// - pt.Matrix.Params","// - pt.Matrix.Include.Params","func (pt *PipelineTask) extractAllParams() Params {","\tallParams := pt.Params","\tif pt.Matrix.HasParams() {","\t\tallParams = append(allParams, pt.Matrix.Params...)","\t}","\tif pt.Matrix.HasInclude() {","\t\tfor _, include := range pt.Matrix.Include {","\t\t\tallParams = append(allParams, include.Params...)","\t\t}","\t}","\treturn allParams","}","","// containsExecutionStatusRef checks if a specified param has a reference to execution status or reason","// $(tasks.\u003ctask-name\u003e.status), $(tasks.status), or $(tasks.\u003ctask-name\u003e.reason)","func containsExecutionStatusRef(p string) bool {","\tif strings.HasPrefix(p, \"tasks.\") {","\t\tif strings.HasSuffix(p, \".status\") || strings.HasSuffix(p, \".reason\") {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","func validateExecutionStatusVariables(tasks []PipelineTask, finallyTasks []PipelineTask) (errs *apis.FieldError) {","\terrs = errs.Also(validateExecutionStatusVariablesInTasks(tasks).ViaField(\"tasks\"))","\terrs = errs.Also(validateExecutionStatusVariablesInFinally(PipelineTaskList(tasks).Names(), finallyTasks).ViaField(\"finally\"))","\treturn errs","}","","// validate dag pipeline tasks, task params can not access execution status of any other task","// dag tasks cannot have param value as $(tasks.pipelineTask.status)","func validateExecutionStatusVariablesInTasks(tasks []PipelineTask) (errs *apis.FieldError) {","\tfor idx, t := range tasks {","\t\terrs = errs.Also(t.validateExecutionStatusVariablesDisallowed().ViaIndex(idx))","\t}","\treturn errs","}","","// validate finally tasks accessing execution status of a dag task specified in the pipeline","// $(tasks.pipelineTask.status) is invalid if pipelineTask is not defined as a dag task","func validateExecutionStatusVariablesInFinally(tasksNames sets.String, finally []PipelineTask) (errs *apis.FieldError) {","\tfor idx, t := range finally {","\t\terrs = errs.Also(t.validateExecutionStatusVariablesAllowed(tasksNames).ViaIndex(idx))","\t}","\treturn errs","}","","func (pt *PipelineTask) validateExecutionStatusVariablesDisallowed() (errs *apis.FieldError) {","\tfor _, param := range pt.Params {","\t\tif expressions, ok := GetVarSubstitutionExpressionsForParam(param); ok {","\t\t\terrs = errs.Also(validateContainsExecutionStatusVariablesDisallowed(expressions, \"value\").","\t\t\t\tViaFieldKey(\"params\", param.Name))","\t\t}","\t}","\tfor i, we := range pt.WhenExpressions {","\t\tif expressions, ok := we.GetVarSubstitutionExpressions(); ok {","\t\t\terrs = errs.Also(validateContainsExecutionStatusVariablesDisallowed(expressions, \"\").","\t\t\t\tViaFieldIndex(\"when\", i))","\t\t}","\t}","\treturn errs","}","","func validateContainsExecutionStatusVariablesDisallowed(expressions []string, path string) (errs *apis.FieldError) {","\tif containsExecutionStatusReferences(expressions) {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"pipeline tasks can not refer to execution status\"+","\t\t\t\" of any other pipeline task or aggregate status of tasks\", path))","\t}","\treturn errs","}","","func containsExecutionStatusReferences(expressions []string) bool {","\t// validate tasks.pipelineTask.status/tasks.status if this expression is not a result reference","\tif !LooksLikeContainsResultRefs(expressions) {","\t\tfor _, e := range expressions {","\t\t\t// check if it contains context variable accessing execution status - $(tasks.taskname.status)","\t\t\t// or an aggregate status - $(tasks.status)","\t\t\tif containsExecutionStatusRef(e) {","\t\t\t\treturn true","\t\t\t}","\t\t}","\t}","\treturn false","}","","func (pt *PipelineTask) validateExecutionStatusVariablesAllowed(ptNames sets.String) (errs *apis.FieldError) {","\tfor _, param := range pt.Params {","\t\tif expressions, ok := GetVarSubstitutionExpressionsForParam(param); ok {","\t\t\terrs = errs.Also(validateExecutionStatusVariablesExpressions(expressions, ptNames, \"value\").","\t\t\t\tViaFieldKey(\"params\", param.Name))","\t\t}","\t}","\tfor i, we := range pt.WhenExpressions {","\t\tif expressions, ok := we.GetVarSubstitutionExpressions(); ok {","\t\t\terrs = errs.Also(validateExecutionStatusVariablesExpressions(expressions, ptNames, \"\").","\t\t\t\tViaFieldIndex(\"when\", i))","\t\t}","\t}","\treturn errs","}","","func validateExecutionStatusVariablesExpressions(expressions []string, ptNames sets.String, fieldPath string) (errs *apis.FieldError) {","\t// validate tasks.pipelineTask.status if this expression is not a result reference","\tif !LooksLikeContainsResultRefs(expressions) {","\t\tfor _, expression := range expressions {","\t\t\t// its a reference to aggregate status of dag tasks - $(tasks.status)","\t\t\tif expression == PipelineTasksAggregateStatus {","\t\t\t\tcontinue","\t\t\t}","\t\t\t// check if it contains context variable accessing execution status - $(tasks.taskname.status) | $(tasks.taskname.reason)","\t\t\tif containsExecutionStatusRef(expression) {","\t\t\t\tvar pt string","\t\t\t\tif strings.HasSuffix(expression, \".status\") {","\t\t\t\t\t// strip tasks. and .status from tasks.taskname.status to further verify task name","\t\t\t\t\tpt = strings.TrimSuffix(strings.TrimPrefix(expression, \"tasks.\"), \".status\")","\t\t\t\t}","\t\t\t\tif strings.HasSuffix(expression, \".reason\") {","\t\t\t\t\t// strip tasks. and .reason from tasks.taskname.reason to further verify task name","\t\t\t\t\tpt = strings.TrimSuffix(strings.TrimPrefix(expression, \"tasks.\"), \".reason\")","\t\t\t\t}","\t\t\t\t// report an error if the task name does not exist in the list of dag tasks","\t\t\t\tif !ptNames.Has(pt) {","\t\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"pipeline task %s is not defined in the pipeline\", pt), fieldPath))","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn errs","}","","func validatePipelineContextVariablesInParamValues(paramValues []string, prefix string, contextNames sets.String) (errs *apis.FieldError) {","\tfor _, paramValue := range paramValues {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(paramValue, prefix, contextNames).ViaField(\"value\"))","\t}","\treturn errs","}","","func filter(arr []string, cond func(string) bool) []string {","\tresult := []string{}","\tfor i := range arr {","\t\tif cond(arr[i]) {","\t\t\tresult = append(result, arr[i])","\t\t}","\t}","\treturn result","}","","// validatePipelineResults ensure that pipeline result variables are properly configured","func validatePipelineResults(results []PipelineResult, tasks []PipelineTask, finally []PipelineTask) (errs *apis.FieldError) {","\tpipelineTaskNames := getPipelineTasksNames(tasks)","\tpipelineFinallyTaskNames := getPipelineTasksNames(finally)","\tfor idx, result := range results {","\t\texpressions, ok := GetVarSubstitutionExpressionsForPipelineResult(result)","\t\tif !ok {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(\"expected pipeline results to be task result expressions but no expressions were found\",","\t\t\t\t\"value\").ViaFieldIndex(\"results\", idx))","\t\t}","","\t\tif !LooksLikeContainsResultRefs(expressions) {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(\"expected pipeline results to be task result expressions but an invalid expressions was found\",","\t\t\t\t\"value\").ViaFieldIndex(\"results\", idx))","\t\t}","","\t\texpressions = filter(expressions, resultref.LooksLikeResultRef)","\t\tresultRefs := NewResultRefs(expressions)","\t\tif len(expressions) != len(resultRefs) {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"expected all of the expressions %v to be result expressions but only %v were\", expressions, resultRefs),","\t\t\t\t\"value\").ViaFieldIndex(\"results\", idx))","\t\t}","","\t\tif !taskContainsResult(result.Value.StringVal, pipelineTaskNames, pipelineFinallyTaskNames) {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(\"referencing a nonexistent task\",","\t\t\t\t\"value\").ViaFieldIndex(\"results\", idx))","\t\t}","\t}","","\treturn errs","}","","// put task names in a set","func getPipelineTasksNames(pipelineTasks []PipelineTask) sets.String {","\tpipelineTaskNames := make(sets.String)","\tfor _, pipelineTask := range pipelineTasks {","\t\tpipelineTaskNames.Insert(pipelineTask.Name)","\t}","","\treturn pipelineTaskNames","}","","// taskContainsResult ensures the result value is referenced within the","// task names","func taskContainsResult(resultExpression string, pipelineTaskNames sets.String, pipelineFinallyTaskNames sets.String) bool {","\t// split incase of multiple resultExpressions in the same result.Value string","\t// i.e \"$(task.\u003ctask-name).result.\u003cresult-name\u003e) - $(task2.\u003ctask2-name).result2.\u003cresult2-name\u003e)\"","\tsplit := strings.Split(resultExpression, \"$\")","\tfor _, expression := range split {","\t\tif expression != \"\" {","\t\t\tvalue := stripVarSubExpression(\"$\" + expression)","\t\t\tpr, err := resultref.ParseTaskExpression(value)","\t\t\tif err != nil {","\t\t\t\treturn false","\t\t\t}","","\t\t\tif strings.HasPrefix(value, \"tasks\") \u0026\u0026 !pipelineTaskNames.Has(pr.ResourceName) {","\t\t\t\treturn false","\t\t\t}","\t\t\tif strings.HasPrefix(value, \"finally\") \u0026\u0026 !pipelineFinallyTaskNames.Has(pr.ResourceName) {","\t\t\t\treturn false","\t\t\t}","\t\t}","\t}","\treturn true","}","","func validateTasksAndFinallySection(ps *PipelineSpec) *apis.FieldError {","\tif len(ps.Finally) != 0 \u0026\u0026 len(ps.Tasks) == 0 {","\t\treturn apis.ErrInvalidValue(fmt.Sprintf(\"spec.tasks is empty but spec.finally has %d tasks\", len(ps.Finally)), \"finally\")","\t}","\treturn nil","}","","func validateFinalTasks(tasks []PipelineTask, finalTasks []PipelineTask) (errs *apis.FieldError) {","\tfor idx, f := range finalTasks {","\t\tif len(f.RunAfter) != 0 {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"no runAfter allowed under spec.finally, final task %s has runAfter specified\", f.Name), \"\").ViaFieldIndex(\"finally\", idx))","\t\t}","\t}","","\tts := PipelineTaskList(tasks).Names()","\tfts := PipelineTaskList(finalTasks).Names()","","\terrs = errs.Also(validateTaskResultReferenceInFinallyTasks(finalTasks, ts, fts))","","\treturn errs","}","","func validateTaskResultReferenceInFinallyTasks(finalTasks []PipelineTask, ts sets.String, fts sets.String) (errs *apis.FieldError) {","\tfor idx, t := range finalTasks {","\t\tfor _, p := range t.Params {","\t\t\tif expressions, ok := GetVarSubstitutionExpressionsForParam(p); ok {","\t\t\t\terrs = errs.Also(validateResultsVariablesExpressionsInFinally(expressions, ts, fts, \"value\").ViaFieldKey(","\t\t\t\t\t\"params\", p.Name).ViaFieldIndex(\"finally\", idx))","\t\t\t}","\t\t}","\t\tfor i, we := range t.WhenExpressions {","\t\t\tif expressions, ok := we.GetVarSubstitutionExpressions(); ok {","\t\t\t\terrs = errs.Also(validateResultsVariablesExpressionsInFinally(expressions, ts, fts, \"\").ViaFieldIndex(","\t\t\t\t\t\"when\", i).ViaFieldIndex(\"finally\", idx))","\t\t\t}","\t\t}","\t}","\treturn errs","}","","func validateResultsVariablesExpressionsInFinally(expressions []string, pipelineTasksNames sets.String, finalTasksNames sets.String, fieldPath string) (errs *apis.FieldError) {","\tif LooksLikeContainsResultRefs(expressions) {","\t\tresultRefs := NewResultRefs(expressions)","\t\tfor _, resultRef := range resultRefs {","\t\t\tpt := resultRef.PipelineTask","\t\t\tif finalTasksNames.Has(pt) {","\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"invalid task result reference, \"+","\t\t\t\t\t\"final task has task result reference from a final task %s\", pt), fieldPath))","\t\t\t} else if !pipelineTasksNames.Has(resultRef.PipelineTask) {","\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"invalid task result reference, \"+","\t\t\t\t\t\"final task has task result reference from a task %s which is not defined in the pipeline\", pt), fieldPath))","\t\t\t}","\t\t}","\t}","\treturn errs","}","","func validateWhenExpressions(ctx context.Context, tasks []PipelineTask, finalTasks []PipelineTask) (errs *apis.FieldError) {","\tfor i, t := range tasks {","\t\terrs = errs.Also(t.WhenExpressions.validate(ctx).ViaFieldIndex(\"tasks\", i))","\t}","\tfor i, t := range finalTasks {","\t\terrs = errs.Also(t.WhenExpressions.validate(ctx).ViaFieldIndex(\"finally\", i))","\t}","\treturn errs","}","","// validateGraph ensures the Pipeline's dependency Graph (DAG) make sense: that there is no dependency","// cycle or that they rely on values from Tasks that ran previously, and that the PipelineResource","// is actually an output of the Task it should come from.","func validateGraph(tasks []PipelineTask) (errs *apis.FieldError) {","\tif _, err := dag.Build(PipelineTaskList(tasks), PipelineTaskList(tasks).Deps()); err != nil {","\t\terrs = errs.Also(apis.ErrInvalidValue(err.Error(), \"tasks\"))","\t}","\treturn errs","}","","func validateMatrix(ctx context.Context, tasks []PipelineTask) (errs *apis.FieldError) {","\tfor idx, task := range tasks {","\t\terrs = errs.Also(task.validateMatrix(ctx).ViaIndex(idx))","\t}","\terrs = errs.Also(validateTaskResultsFromMatrixedPipelineTasksConsumed(tasks))","\treturn errs","}","","// findAndValidateResultRefsForMatrix checks that any result references to Matrixed PipelineTasks if consumed","// by another PipelineTask that the entire array of results produced by a matrix is consumed in aggregate","// since consuming a singular result produced by a matrix is currently not supported","func findAndValidateResultRefsForMatrix(tasks []PipelineTask, taskMapping map[string]PipelineTask) (resultRefs []*ResultRef, errs *apis.FieldError) {","\tfor _, t := range tasks {","\t\tfor _, p := range t.Params {","\t\t\tif expressions, ok := GetVarSubstitutionExpressionsForParam(p); ok {","\t\t\t\tif LooksLikeContainsResultRefs(expressions) {","\t\t\t\t\tresultRefs, errs = validateMatrixedPipelineTaskConsumed(expressions, taskMapping)","\t\t\t\t\tif errs != nil {","\t\t\t\t\t\treturn nil, errs","\t\t\t\t\t}","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn resultRefs, errs","}","","// validateMatrixedPipelineTaskConsumed checks that any Matrixed Pipeline Task that the is being consumed is consumed in","// aggregate [*] since consuming a singular result produced by a matrix is currently not supported","func validateMatrixedPipelineTaskConsumed(expressions []string, taskMapping map[string]PipelineTask) (resultRefs []*ResultRef, errs *apis.FieldError) {","\tvar filteredExpressions []string","\tfor _, expression := range expressions {","\t\t// if it is not matrix result ref expression, skip","\t\tif !resultref.LooksLikeResultRef(expression) {","\t\t\tcontinue","\t\t}","\t\t// ie. \"tasks.\u003cpipelineTaskName\u003e.results.\u003cresultName\u003e[*]\"","\t\tsubExpressions := strings.Split(expression, \".\")","\t\tpipelineTask := subExpressions[1] // pipelineTaskName","\t\ttaskConsumed := taskMapping[pipelineTask]","\t\tif taskConsumed.IsMatrixed() {","\t\t\tif !strings.HasSuffix(expression, \"[*]\") {","\t\t\t\terrs = errs.Also(apis.ErrGeneric(\"A matrixed pipelineTask can only be consumed in aggregate using [*] notation, but is currently set to \" + expression))","\t\t\t}","\t\t\tfilteredExpressions = append(filteredExpressions, expression)","\t\t}","\t}","\treturn NewResultRefs(filteredExpressions), errs","}","","// validateTaskResultsFromMatrixedPipelineTasksConsumed checks that any Matrixed Pipeline Task that the is being consumed","// is consumed in aggregate [*] since consuming a singular result produced by a matrix is currently not supported.","// It also validates that a matrix emitting results can only emit results with the underlying type string","// if those results are being consumed by another PipelineTask.","func validateTaskResultsFromMatrixedPipelineTasksConsumed(tasks []PipelineTask) (errs *apis.FieldError) {","\ttaskMapping := createTaskMapping(tasks)","\tresultRefs, errs := findAndValidateResultRefsForMatrix(tasks, taskMapping)","\tif errs != nil {","\t\treturn errs","\t}","","\terrs = errs.Also(validateMatrixEmittingStringResults(resultRefs, taskMapping))","\treturn errs","}","","// createTaskMapping maps the PipelineTaskName to the PipelineTask to easily access","// the pipelineTask by Name","func createTaskMapping(tasks []PipelineTask) (taskMap map[string]PipelineTask) {","\ttaskMapping := make(map[string]PipelineTask)","\tfor _, task := range tasks {","\t\ttaskMapping[task.Name] = task","\t}","\treturn taskMapping","}","","// validateMatrixEmittingStringResults checks a matrix emitting results can only emit results with the underlying type string","// if those results are being consumed by another PipelineTask.","func validateMatrixEmittingStringResults(resultRefs []*ResultRef, taskMapping map[string]PipelineTask) (errs *apis.FieldError) {","\tfor _, resultRef := range resultRefs {","\t\ttask := taskMapping[resultRef.PipelineTask]","\t\tresultName := resultRef.Result","\t\tif task.TaskRef != nil {","\t\t\treferencedTaskName := task.TaskRef.Name","\t\t\treferencedTask := taskMapping[referencedTaskName]","\t\t\tif referencedTask.TaskSpec != nil {","\t\t\t\terrs = errs.Also(validateStringResults(referencedTask.TaskSpec.Results, resultName))","\t\t\t}","\t\t} else if task.TaskSpec != nil {","\t\t\terrs = errs.Also(validateStringResults(task.TaskSpec.Results, resultName))","\t\t}","\t}","\treturn errs","}","","// validateStringResults ensure that the result type is string","func validateStringResults(results []TaskResult, resultName string) (errs *apis.FieldError) {","\tfor _, result := range results {","\t\tif result.Name == resultName {","\t\t\tif result.Type != ResultsTypeString {","\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(","\t\t\t\t\tfmt.Sprintf(\"Matrixed PipelineTasks emitting results must have an underlying type string, but result %s has type %s in pipelineTask\", resultName, string(result.Type)),","\t\t\t\t\t\"\",","\t\t\t\t))","\t\t\t}","\t\t}","\t}","\treturn errs","}","","// validateArtifactReference ensure that the feature flag enableArtifacts is set to true when using artifacts","func validateArtifactReference(ctx context.Context, tasks []PipelineTask, finalTasks []PipelineTask) (errs *apis.FieldError) {","\tif config.FromContextOrDefaults(ctx).FeatureFlags.EnableArtifacts {","\t\treturn errs","\t}","\tfor i, t := range tasks {","\t\tfor _, v := range t.Params.extractValues() {","\t\t\tif len(artifactref.TaskArtifactRegex.FindAllStringSubmatch(v, -1)) \u003e 0 {","\t\t\t\treturn errs.Also(apis.ErrGeneric(fmt.Sprintf(\"feature flag %s should be set to true to use artifacts feature.\", config.EnableArtifacts), \"\").ViaField(\"params\").ViaFieldIndex(\"tasks\", i))","\t\t\t}","\t\t}","\t}","\tfor i, t := range finalTasks {","\t\tfor _, v := range t.Params.extractValues() {","\t\t\tif len(artifactref.TaskArtifactRegex.FindAllStringSubmatch(v, -1)) \u003e 0 {","\t\t\t\treturn errs.Also(apis.ErrGeneric(fmt.Sprintf(\"feature flag %s should be set to true to use artifacts feature.\", config.EnableArtifacts), \"\").ViaField(\"params\").ViaFieldIndex(\"finally\", i))","\t\t\t}","\t\t}","\t}","\treturn errs","}","","// GetIndexingReferencesToArrayParams returns all strings referencing indices of PipelineRun array parameters","// from parameters, workspaces, and when expressions defined in the Pipeline's Tasks and Finally Tasks.","// For example, if a Task in the Pipeline has a parameter with a value \"$(params.array-param-name[1])\",","// this would be one of the strings returned.","func (ps *PipelineSpec) GetIndexingReferencesToArrayParams() sets.String {","\tparamsRefs := []string{}","\tfor i := range ps.Tasks {","\t\tparamsRefs = append(paramsRefs, ps.Tasks[i].Params.extractValues()...)","\t\tif ps.Tasks[i].IsMatrixed() {","\t\t\tparamsRefs = append(paramsRefs, ps.Tasks[i].Matrix.Params.extractValues()...)","\t\t}","\t\tfor j := range ps.Tasks[i].Workspaces {","\t\t\tparamsRefs = append(paramsRefs, ps.Tasks[i].Workspaces[j].SubPath)","\t\t}","\t\tfor _, wes := range ps.Tasks[i].WhenExpressions {","\t\t\tparamsRefs = append(paramsRefs, wes.Input)","\t\t\tparamsRefs = append(paramsRefs, wes.Values...)","\t\t}","\t}","\tfor i := range ps.Finally {","\t\tparamsRefs = append(paramsRefs, ps.Finally[i].Params.extractValues()...)","\t\tif ps.Finally[i].IsMatrixed() {","\t\t\tparamsRefs = append(paramsRefs, ps.Finally[i].Matrix.Params.extractValues()...)","\t\t}","\t\tfor _, wes := range ps.Finally[i].WhenExpressions {","\t\t\tparamsRefs = append(paramsRefs, wes.Input)","\t\t\tparamsRefs = append(paramsRefs, wes.Values...)","\t\t}","\t}","\t// extract all array indexing references, for example []{\"$(params.array-params[1])\"}","\tarrayIndexParamRefs := []string{}","\tfor _, p := range paramsRefs {","\t\tarrayIndexParamRefs = append(arrayIndexParamRefs, extractArrayIndexingParamRefs(p)...)","\t}","\treturn sets.NewString(arrayIndexParamRefs...)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,0,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,1,1,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,0,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,0,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,0,2,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,0,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,0,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,0,0,0,2,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,0,0,2,0,0,0,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,0,2,0,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,0,0,2,2,2,2,2,2,0,2,2,0,0,0,0,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,0,2,0,0,0,0,0,0,2,2,2,2,2,1,1,2,2,2,2,2,2,2,0,2,2,2,1,1,2,2,2,2,0,0,2,2,2,2,2,0]},{"id":84,"path":"pkg/apis/pipeline/v1beta1/pipelineref_conversion.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"",")","","func (pr PipelineRef) convertTo(ctx context.Context, sink *v1.PipelineRef) {","\tsink.Name = pr.Name","\tsink.APIVersion = pr.APIVersion","\tnew := v1.ResolverRef{}","\tpr.ResolverRef.convertTo(ctx, \u0026new)","\tsink.ResolverRef = new","}","","func (pr *PipelineRef) convertFrom(ctx context.Context, source v1.PipelineRef) {","\tpr.Name = source.Name","\tpr.APIVersion = source.APIVersion","\tnew := ResolverRef{}","\tnew.convertFrom(ctx, source.ResolverRef)","\tpr.ResolverRef = new","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2]},{"id":85,"path":"pkg/apis/pipeline/v1beta1/pipelineref_validation.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"fmt\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"k8s.io/apimachinery/pkg/util/validation\"","\t\"knative.dev/pkg/apis\"",")","","// Validate ensures that a supplied PipelineRef field is populated","// correctly. No errors are returned for a nil PipelineRef.","func (ref *PipelineRef) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif ref == nil {","\t\treturn errs","\t}","\tif apis.IsInCreate(ctx) \u0026\u0026 ref.Bundle != \"\" {","\t\terrs = errs.Also(apis.ErrDisallowedFields(\"bundle\"))","\t}","\tswitch {","\tcase ref.Resolver != \"\" || ref.Params != nil:","\t\tif ref.Params != nil {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"resolver params\", config.BetaAPIFields).ViaField(\"params\"))","\t\t\tif ref.Name != \"\" {","\t\t\t\terrs = errs.Also(apis.ErrMultipleOneOf(\"name\", \"params\"))","\t\t\t}","\t\t\tif ref.Resolver == \"\" {","\t\t\t\terrs = errs.Also(apis.ErrMissingField(\"resolver\"))","\t\t\t}","\t\t\terrs = errs.Also(ValidateParameters(ctx, ref.Params))","\t\t}","\t\tif ref.Resolver != \"\" {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"resolver\", config.BetaAPIFields).ViaField(\"resolver\"))","\t\t\tif ref.Name != \"\" {","\t\t\t\t// make sure that the name is url-like.","\t\t\t\terr := RefNameLikeUrl(ref.Name)","\t\t\t\tif err == nil \u0026\u0026 !config.FromContextOrDefaults(ctx).FeatureFlags.EnableConciseResolverSyntax {","\t\t\t\t\t// If name is url-like then concise resolver syntax must be enabled","\t\t\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"feature flag %s should be set to true to use concise resolver syntax\", config.EnableConciseResolverSyntax), \"\"))","\t\t\t\t}","\t\t\t\tif err != nil {","\t\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(err, \"name\"))","\t\t\t\t}","\t\t\t}","\t\t}","\tcase ref.Name != \"\":","\t\t// ref name can be a Url-like format.","\t\tif err := RefNameLikeUrl(ref.Name); err == nil {","\t\t\t// If name is url-like then concise resolver syntax must be enabled","\t\t\tif !config.FromContextOrDefaults(ctx).FeatureFlags.EnableConciseResolverSyntax {","\t\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"feature flag %s should be set to true to use concise resolver syntax\", config.EnableConciseResolverSyntax), \"\"))","\t\t\t}","\t\t\t// In stage1 of concise remote resolvers syntax, this is a required field.","\t\t\t// TODO: remove this check when implementing stage 2 where this is optional.","\t\t\tif ref.Resolver == \"\" {","\t\t\t\terrs = errs.Also(apis.ErrMissingField(\"resolver\"))","\t\t\t}","\t\t\t// Or, it must be a valid k8s name","\t\t} else {","\t\t\t// ref name must be a valid k8s name","\t\t\tif errSlice := validation.IsQualifiedName(ref.Name); len(errSlice) != 0 {","\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(strings.Join(errSlice, \",\"), \"name\"))","\t\t\t}","\t\t}","\tdefault:","\t\terrs = errs.Also(apis.ErrMissingField(\"name\"))","\t}","\treturn //nolint:nakedret","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,0,2,2,2,2,2,0,2,2,0,2,0]},{"id":86,"path":"pkg/apis/pipeline/v1beta1/pipelinerun_conversion.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"fmt\"","","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/version\"","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Convertible = (*PipelineRun)(nil)","","// ConvertTo implements apis.Convertible","func (pr *PipelineRun) ConvertTo(ctx context.Context, to apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\tswitch sink := to.(type) {","\tcase *v1.PipelineRun:","\t\tsink.ObjectMeta = pr.ObjectMeta","\t\tif err := serializePipelineRunResources(\u0026sink.ObjectMeta, \u0026pr.Spec); err != nil {","\t\t\treturn err","\t\t}","\t\tif err := pr.Status.convertTo(ctx, \u0026sink.Status, \u0026sink.ObjectMeta); err != nil {","\t\t\treturn err","\t\t}","\t\treturn pr.Spec.ConvertTo(ctx, \u0026sink.Spec, \u0026sink.ObjectMeta)","\tdefault:","\t\treturn fmt.Errorf(\"unknown version, got: %T\", sink)","\t}","}","","// ConvertTo implements apis.Convertible","func (prs PipelineRunSpec) ConvertTo(ctx context.Context, sink *v1.PipelineRunSpec, meta *metav1.ObjectMeta) error {","\tif prs.PipelineRef != nil {","\t\tsink.PipelineRef = \u0026v1.PipelineRef{}","\t\tprs.PipelineRef.convertTo(ctx, sink.PipelineRef)","\t}","\tif prs.PipelineSpec != nil {","\t\tsink.PipelineSpec = \u0026v1.PipelineSpec{}","\t\terr := prs.PipelineSpec.ConvertTo(ctx, sink.PipelineSpec, meta)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t}","\tsink.Params = nil","\tfor _, p := range prs.Params {","\t\tnew := v1.Param{}","\t\tp.convertTo(ctx, \u0026new)","\t\tsink.Params = append(sink.Params, new)","\t}","\tsink.Status = v1.PipelineRunSpecStatus(prs.Status)","\tif prs.Timeouts != nil {","\t\tsink.Timeouts = \u0026v1.TimeoutFields{}","\t\tprs.Timeouts.convertTo(ctx, sink.Timeouts)","\t}","\tif prs.Timeout != nil {","\t\tsink.Timeouts = \u0026v1.TimeoutFields{}","\t\tsink.Timeouts.Pipeline = prs.Timeout","\t}","\tsink.TaskRunTemplate = v1.PipelineTaskRunTemplate{}","\tsink.TaskRunTemplate.PodTemplate = prs.PodTemplate","\tsink.TaskRunTemplate.ServiceAccountName = prs.ServiceAccountName","\tsink.Workspaces = nil","\tfor _, w := range prs.Workspaces {","\t\tnew := v1.WorkspaceBinding{}","\t\tw.convertTo(ctx, \u0026new)","\t\tsink.Workspaces = append(sink.Workspaces, new)","\t}","\tsink.TaskRunSpecs = nil","\tfor _, ptrs := range prs.TaskRunSpecs {","\t\tnew := v1.PipelineTaskRunSpec{}","\t\tptrs.convertTo(ctx, \u0026new)","\t\tsink.TaskRunSpecs = append(sink.TaskRunSpecs, new)","\t}","\treturn nil","}","","// ConvertFrom implements apis.Convertible","func (pr *PipelineRun) ConvertFrom(ctx context.Context, from apis.Convertible) error {","\tswitch source := from.(type) {","\tcase *v1.PipelineRun:","\t\tpr.ObjectMeta = source.ObjectMeta","\t\tif err := deserializePipelineRunResources(\u0026pr.ObjectMeta, \u0026pr.Spec); err != nil {","\t\t\treturn err","\t\t}","\t\tif err := pr.Status.convertFrom(ctx, \u0026source.Status, \u0026pr.ObjectMeta); err != nil {","\t\t\treturn err","\t\t}","\t\treturn pr.Spec.ConvertFrom(ctx, \u0026source.Spec, \u0026pr.ObjectMeta)","\tdefault:","\t\treturn fmt.Errorf(\"unknown version, got: %T\", pr)","\t}","}","","// ConvertFrom implements apis.Convertible","func (prs *PipelineRunSpec) ConvertFrom(ctx context.Context, source *v1.PipelineRunSpec, meta *metav1.ObjectMeta) error {","\tif source.PipelineRef != nil {","\t\tnewPipelineRef := PipelineRef{}","\t\tnewPipelineRef.convertFrom(ctx, *source.PipelineRef)","\t\tprs.PipelineRef = \u0026newPipelineRef","\t}","\tif source.PipelineSpec != nil {","\t\tnewPipelineSpec := PipelineSpec{}","\t\terr := newPipelineSpec.ConvertFrom(ctx, source.PipelineSpec, meta)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tprs.PipelineSpec = \u0026newPipelineSpec","\t}","\tprs.Params = nil","\tfor _, p := range source.Params {","\t\tnew := Param{}","\t\tnew.ConvertFrom(ctx, p)","\t\tprs.Params = append(prs.Params, new)","\t}","\tprs.ServiceAccountName = source.TaskRunTemplate.ServiceAccountName","\tprs.Status = PipelineRunSpecStatus(source.Status)","\tif source.Timeouts != nil {","\t\tnewTimeouts := \u0026TimeoutFields{}","\t\tnewTimeouts.convertFrom(ctx, *source.Timeouts)","\t\tprs.Timeouts = newTimeouts","\t}","\tprs.PodTemplate = source.TaskRunTemplate.PodTemplate","\tprs.Workspaces = nil","\tfor _, w := range source.Workspaces {","\t\tnew := WorkspaceBinding{}","\t\tnew.ConvertFrom(ctx, w)","\t\tprs.Workspaces = append(prs.Workspaces, new)","\t}","\tprs.TaskRunSpecs = nil","\tfor _, trs := range source.TaskRunSpecs {","\t\tnew := PipelineTaskRunSpec{}","\t\tnew.convertFrom(ctx, trs)","\t\tprs.TaskRunSpecs = append(prs.TaskRunSpecs, new)","\t}","\treturn nil","}","","func (tf TimeoutFields) convertTo(ctx context.Context, sink *v1.TimeoutFields) {","\tsink.Pipeline = tf.Pipeline","\tsink.Tasks = tf.Tasks","\tsink.Finally = tf.Finally","}","","func (tf *TimeoutFields) convertFrom(ctx context.Context, source v1.TimeoutFields) {","\ttf.Pipeline = source.Pipeline","\ttf.Tasks = source.Tasks","\ttf.Finally = source.Finally","}","","func (ptrs PipelineTaskRunSpec) convertTo(ctx context.Context, sink *v1.PipelineTaskRunSpec) {","\tsink.PipelineTaskName = ptrs.PipelineTaskName","\tsink.ServiceAccountName = ptrs.TaskServiceAccountName","\tsink.PodTemplate = ptrs.TaskPodTemplate","\tsink.StepSpecs = nil","\tfor _, so := range ptrs.StepOverrides {","\t\tnew := v1.TaskRunStepSpec{}","\t\tso.convertTo(ctx, \u0026new)","\t\tsink.StepSpecs = append(sink.StepSpecs, new)","\t}","\tsink.SidecarSpecs = nil","\tfor _, so := range ptrs.SidecarOverrides {","\t\tnew := v1.TaskRunSidecarSpec{}","\t\tso.convertTo(ctx, \u0026new)","\t\tsink.SidecarSpecs = append(sink.SidecarSpecs, new)","\t}","\tif ptrs.Metadata != nil {","\t\tsink.Metadata = \u0026v1.PipelineTaskMetadata{}","\t\tptrs.Metadata.convertTo(ctx, sink.Metadata)","\t}","\tsink.ComputeResources = ptrs.ComputeResources","\tsink.Timeout = ptrs.Timeout","}","","func (ptrs *PipelineTaskRunSpec) convertFrom(ctx context.Context, source v1.PipelineTaskRunSpec) {","\tptrs.PipelineTaskName = source.PipelineTaskName","\tptrs.TaskServiceAccountName = source.ServiceAccountName","\tptrs.TaskPodTemplate = source.PodTemplate","\tptrs.StepOverrides = nil","\tfor _, so := range source.StepSpecs {","\t\tnew := TaskRunStepOverride{}","\t\tnew.convertFrom(ctx, so)","\t\tptrs.StepOverrides = append(ptrs.StepOverrides, new)","\t}","\tptrs.SidecarOverrides = nil","\tfor _, so := range source.SidecarSpecs {","\t\tnew := TaskRunSidecarOverride{}","\t\tnew.convertFrom(ctx, so)","\t\tptrs.SidecarOverrides = append(ptrs.SidecarOverrides, new)","\t}","\tif source.Metadata != nil {","\t\tnewMetadata := PipelineTaskMetadata{}","\t\tnewMetadata.convertFrom(ctx, *source.Metadata)","\t\tptrs.Metadata = \u0026newMetadata","\t}","\tptrs.ComputeResources = source.ComputeResources","\tptrs.Timeout = source.Timeout","}","","func (prs *PipelineRunStatus) convertTo(ctx context.Context, sink *v1.PipelineRunStatus, meta *metav1.ObjectMeta) error {","\tsink.Status = prs.Status","\tsink.StartTime = prs.StartTime","\tsink.CompletionTime = prs.CompletionTime","\tsink.Results = nil","\tfor _, pr := range prs.PipelineResults {","\t\tnew := v1.PipelineRunResult{}","\t\tpr.convertTo(ctx, \u0026new)","\t\tsink.Results = append(sink.Results, new)","\t}","\tif prs.PipelineSpec != nil {","\t\tsink.PipelineSpec = \u0026v1.PipelineSpec{}","\t\terr := prs.PipelineSpec.ConvertTo(ctx, sink.PipelineSpec, meta)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t}","\tsink.SkippedTasks = nil","\tfor _, st := range prs.SkippedTasks {","\t\tnew := v1.SkippedTask{}","\t\tst.convertTo(ctx, \u0026new)","\t\tsink.SkippedTasks = append(sink.SkippedTasks, new)","\t}","\tsink.ChildReferences = nil","\tfor _, cr := range prs.ChildReferences {","\t\tnew := v1.ChildStatusReference{}","\t\tcr.convertTo(ctx, \u0026new)","\t\tsink.ChildReferences = append(sink.ChildReferences, new)","\t}","\tsink.FinallyStartTime = prs.FinallyStartTime","\tif prs.Provenance != nil {","\t\tnew := v1.Provenance{}","\t\tprs.Provenance.convertTo(ctx, \u0026new)","\t\tsink.Provenance = \u0026new","\t}","\treturn nil","}","","func (prs *PipelineRunStatus) convertFrom(ctx context.Context, source *v1.PipelineRunStatus, meta *metav1.ObjectMeta) error {","\tprs.Status = source.Status","\tprs.StartTime = source.StartTime","\tprs.CompletionTime = source.CompletionTime","\tprs.PipelineResults = nil","\tfor _, pr := range source.Results {","\t\tnew := PipelineRunResult{}","\t\tnew.convertFrom(ctx, pr)","\t\tprs.PipelineResults = append(prs.PipelineResults, new)","\t}","\tif source.PipelineSpec != nil {","\t\tnewPipelineSpec := PipelineSpec{}","\t\terr := newPipelineSpec.ConvertFrom(ctx, source.PipelineSpec, meta)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tprs.PipelineSpec = \u0026newPipelineSpec","\t}","\tprs.SkippedTasks = nil","\tfor _, st := range source.SkippedTasks {","\t\tnew := SkippedTask{}","\t\tnew.convertFrom(ctx, st)","\t\tprs.SkippedTasks = append(prs.SkippedTasks, new)","\t}","\tprs.ChildReferences = nil","\tfor _, cr := range source.ChildReferences {","\t\tnew := ChildStatusReference{}","\t\tnew.convertFrom(ctx, cr)","\t\tprs.ChildReferences = append(prs.ChildReferences, new)","\t}","","\tprs.FinallyStartTime = source.FinallyStartTime","\tif source.Provenance != nil {","\t\tnew := Provenance{}","\t\tnew.convertFrom(ctx, *source.Provenance)","\t\tprs.Provenance = \u0026new","\t}","\treturn nil","}","","func (prr PipelineRunResult) convertTo(ctx context.Context, sink *v1.PipelineRunResult) {","\tsink.Name = prr.Name","\tnewValue := v1.ParamValue{}","\tprr.Value.convertTo(ctx, \u0026newValue)","\tsink.Value = newValue","}","","func (prr *PipelineRunResult) convertFrom(ctx context.Context, source v1.PipelineRunResult) {","\tprr.Name = source.Name","\tnewValue := ParamValue{}","\tnewValue.convertFrom(ctx, source.Value)","\tprr.Value = newValue","}","","func (st SkippedTask) convertTo(ctx context.Context, sink *v1.SkippedTask) {","\tsink.Name = st.Name","\tsink.Reason = v1.SkippingReason(st.Reason)","\tsink.WhenExpressions = nil","\tfor _, we := range st.WhenExpressions {","\t\tnew := v1.WhenExpression{}","\t\twe.convertTo(ctx, \u0026new)","\t\tsink.WhenExpressions = append(sink.WhenExpressions, new)","\t}","}","","func (st *SkippedTask) convertFrom(ctx context.Context, source v1.SkippedTask) {","\tst.Name = source.Name","\tst.Reason = SkippingReason(source.Reason)","\tst.WhenExpressions = nil","\tfor _, we := range source.WhenExpressions {","\t\tnew := WhenExpression{}","\t\tnew.convertFrom(ctx, we)","\t\tst.WhenExpressions = append(st.WhenExpressions, new)","\t}","}","","func (csr ChildStatusReference) convertTo(ctx context.Context, sink *v1.ChildStatusReference) {","\tsink.TypeMeta = csr.TypeMeta","\tsink.Name = csr.Name","\tsink.DisplayName = csr.DisplayName","\tsink.PipelineTaskName = csr.PipelineTaskName","\tsink.WhenExpressions = nil","\tfor _, we := range csr.WhenExpressions {","\t\tnew := v1.WhenExpression{}","\t\twe.convertTo(ctx, \u0026new)","\t\tsink.WhenExpressions = append(sink.WhenExpressions, new)","\t}","}","","func (csr *ChildStatusReference) convertFrom(ctx context.Context, source v1.ChildStatusReference) {","\tcsr.TypeMeta = source.TypeMeta","\tcsr.Name = source.Name","\tcsr.DisplayName = source.DisplayName","\tcsr.PipelineTaskName = source.PipelineTaskName","\tcsr.WhenExpressions = nil","\tfor _, we := range source.WhenExpressions {","\t\tnew := WhenExpression{}","\t\tnew.convertFrom(ctx, we)","\t\tcsr.WhenExpressions = append(csr.WhenExpressions, new)","\t}","}","","func serializePipelineRunResources(meta *metav1.ObjectMeta, spec *PipelineRunSpec) error {","\tif spec.Resources == nil {","\t\treturn nil","\t}","\treturn version.SerializeToMetadata(meta, spec.Resources, resourcesAnnotationKey)","}","","func deserializePipelineRunResources(meta *metav1.ObjectMeta, spec *PipelineRunSpec) error {","\tresources := []PipelineResourceBinding{}","\terr := version.DeserializeFromMetadata(meta, \u0026resources, resourcesAnnotationKey)","\tif err != nil {","\t\treturn err","\t}","\tif len(resources) != 0 {","\t\tspec.Resources = resources","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,2,2,2,2,1,1,2,1,1,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,1,1,2,1,1,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,1,1,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,0,2,2,2,2,1,1,2,2,2,2,0]},{"id":87,"path":"pkg/apis/pipeline/v1beta1/pipelinerun_defaults.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"regexp\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tpod \"github.com/tektoncd/pipeline/pkg/apis/pipeline/pod\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/kmap\"",")","","var (","\t_                              apis.Defaultable = (*PipelineRun)(nil)","\tfilterReservedAnnotationRegexp                  = regexp.MustCompile(pipeline.TektonReservedAnnotationExpr)",")","","// SetDefaults implements apis.Defaultable","func (pr *PipelineRun) SetDefaults(ctx context.Context) {","\tpr.Spec.SetDefaults(ctx)","","\t// Silently filtering out Tekton Reserved annotations at creation","\tif apis.IsInCreate(ctx) {","\t\tpr.ObjectMeta.Annotations = kmap.Filter(pr.ObjectMeta.Annotations, func(s string) bool {","\t\t\treturn filterReservedAnnotationRegexp.MatchString(s)","\t\t})","\t}","}","","// SetDefaults implements apis.Defaultable","func (prs *PipelineRunSpec) SetDefaults(ctx context.Context) {","\tcfg := config.FromContextOrDefaults(ctx)","\tif prs.PipelineRef != nil \u0026\u0026 prs.PipelineRef.Name == \"\" \u0026\u0026 prs.PipelineRef.Resolver == \"\" {","\t\tprs.PipelineRef.Resolver = ResolverName(cfg.Defaults.DefaultResolverType)","\t}","","\tif prs.Timeout == nil \u0026\u0026 prs.Timeouts == nil {","\t\tprs.Timeout = \u0026metav1.Duration{Duration: time.Duration(cfg.Defaults.DefaultTimeoutMinutes) * time.Minute}","\t}","","\tif prs.Timeouts != nil \u0026\u0026 prs.Timeouts.Pipeline == nil {","\t\tprs.Timeouts.Pipeline = \u0026metav1.Duration{Duration: time.Duration(cfg.Defaults.DefaultTimeoutMinutes) * time.Minute}","\t}","","\tdefaultSA := cfg.Defaults.DefaultServiceAccount","\tif prs.ServiceAccountName == \"\" \u0026\u0026 defaultSA != \"\" {","\t\tprs.ServiceAccountName = defaultSA","\t}","","\tdefaultPodTemplate := cfg.Defaults.DefaultPodTemplate","\tprs.PodTemplate = pod.MergePodTemplateWithDefault(prs.PodTemplate, defaultPodTemplate)","","\tif prs.PipelineSpec != nil {","\t\tprs.PipelineSpec.SetDefaults(ctx)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,0,2,2,2,0,2,2,2,0,2,2,2,2,0,2,2,2,2,2,2,0]},{"id":88,"path":"pkg/apis/pipeline/v1beta1/pipelinerun_types.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"fmt\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\tapisconfig \"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tpod \"github.com/tektoncd/pipeline/pkg/apis/pipeline/pod\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"","\t\"k8s.io/apimachinery/pkg/types\"","\t\"k8s.io/utils/clock\"","\t\"knative.dev/pkg/apis\"","\tduckv1 \"knative.dev/pkg/apis/duck/v1\"",")","","// +genclient","// +genreconciler:krshapedlogic=false","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","// +k8s:openapi-gen=true","","// PipelineRun represents a single execution of a Pipeline. PipelineRuns are how","// the graph of Tasks declared in a Pipeline are executed; they specify inputs","// to Pipelines such as parameter values and capture operational aspects of the","// Tasks execution such as service account and tolerations. Creating a","// PipelineRun creates TaskRuns for Tasks in the referenced Pipeline.","//","// Deprecated: Please use v1.PipelineRun instead.","type PipelineRun struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ObjectMeta `json:\"metadata,omitempty\"`","","\t// +optional","\tSpec PipelineRunSpec `json:\"spec,omitempty\"`","\t// +optional","\tStatus PipelineRunStatus `json:\"status,omitempty\"`","}","","// GetName Returns the name of the PipelineRun","func (pr *PipelineRun) GetName() string {","\treturn pr.ObjectMeta.GetName()","}","","// GetStatusCondition returns the task run status as a ConditionAccessor","func (pr *PipelineRun) GetStatusCondition() apis.ConditionAccessor {","\treturn \u0026pr.Status","}","","// GetGroupVersionKind implements kmeta.OwnerRefable.","func (*PipelineRun) GetGroupVersionKind() schema.GroupVersionKind {","\treturn SchemeGroupVersion.WithKind(pipeline.PipelineRunControllerName)","}","","// IsDone returns true if the PipelineRun's status indicates that it is done.","func (pr *PipelineRun) IsDone() bool {","\treturn !pr.Status.GetCondition(apis.ConditionSucceeded).IsUnknown()","}","","// HasStarted function check whether pipelinerun has valid start time set in its status","func (pr *PipelineRun) HasStarted() bool {","\treturn pr.Status.StartTime != nil \u0026\u0026 !pr.Status.StartTime.IsZero()","}","","// IsCancelled returns true if the PipelineRun's spec status is set to Cancelled state","func (pr *PipelineRun) IsCancelled() bool {","\treturn pr.Spec.Status == PipelineRunSpecStatusCancelled","}","","// IsGracefullyCancelled returns true if the PipelineRun's spec status is set to CancelledRunFinally state","func (pr *PipelineRun) IsGracefullyCancelled() bool {","\treturn pr.Spec.Status == PipelineRunSpecStatusCancelledRunFinally","}","","// IsGracefullyStopped returns true if the PipelineRun's spec status is set to StoppedRunFinally state","func (pr *PipelineRun) IsGracefullyStopped() bool {","\treturn pr.Spec.Status == PipelineRunSpecStatusStoppedRunFinally","}","","// PipelineTimeout returns the applicable timeout for the PipelineRun","func (pr *PipelineRun) PipelineTimeout(ctx context.Context) time.Duration {","\tif pr.Spec.Timeout != nil {","\t\treturn pr.Spec.Timeout.Duration","\t}","\tif pr.Spec.Timeouts != nil \u0026\u0026 pr.Spec.Timeouts.Pipeline != nil {","\t\treturn pr.Spec.Timeouts.Pipeline.Duration","\t}","\treturn time.Duration(config.FromContextOrDefaults(ctx).Defaults.DefaultTimeoutMinutes) * time.Minute","}","","// TasksTimeout returns the tasks timeout for the PipelineRun, if set,","// or the tasks timeout computed from the Pipeline and Finally timeouts, if those are set.","func (pr *PipelineRun) TasksTimeout() *metav1.Duration {","\tt := pr.Spec.Timeouts","\tif t == nil {","\t\treturn nil","\t}","\tif t.Tasks != nil {","\t\treturn t.Tasks","\t}","\tif t.Pipeline != nil \u0026\u0026 t.Finally != nil {","\t\tif t.Pipeline.Duration == apisconfig.NoTimeoutDuration || t.Finally.Duration == apisconfig.NoTimeoutDuration {","\t\t\treturn nil","\t\t}","\t\treturn \u0026metav1.Duration{Duration: (t.Pipeline.Duration - t.Finally.Duration)}","\t}","\treturn nil","}","","// FinallyTimeout returns the finally timeout for the PipelineRun, if set,","// or the finally timeout computed from the Pipeline and Tasks timeouts, if those are set.","func (pr *PipelineRun) FinallyTimeout() *metav1.Duration {","\tt := pr.Spec.Timeouts","\tif t == nil {","\t\treturn nil","\t}","\tif t.Finally != nil {","\t\treturn t.Finally","\t}","\tif t.Pipeline != nil \u0026\u0026 t.Tasks != nil {","\t\tif t.Pipeline.Duration == apisconfig.NoTimeoutDuration || t.Tasks.Duration == apisconfig.NoTimeoutDuration {","\t\t\treturn nil","\t\t}","\t\treturn \u0026metav1.Duration{Duration: (t.Pipeline.Duration - t.Tasks.Duration)}","\t}","\treturn nil","}","","// IsPending returns true if the PipelineRun's spec status is set to Pending state","func (pr *PipelineRun) IsPending() bool {","\treturn pr.Spec.Status == PipelineRunSpecStatusPending","}","","// GetNamespacedName returns a k8s namespaced name that identifies this PipelineRun","func (pr *PipelineRun) GetNamespacedName() types.NamespacedName {","\treturn types.NamespacedName{Namespace: pr.Namespace, Name: pr.Name}","}","","// IsTimeoutConditionSet returns true when the pipelinerun has the pipelinerun timed out reason","func (pr *PipelineRun) IsTimeoutConditionSet() bool {","\tcondition := pr.Status.GetCondition(apis.ConditionSucceeded)","\treturn condition.IsFalse() \u0026\u0026 condition.Reason == PipelineRunReasonTimedOut.String()","}","","// SetTimeoutCondition sets the status of the PipelineRun to timed out.","func (pr *PipelineRun) SetTimeoutCondition(ctx context.Context) {","\tpr.Status.SetCondition(\u0026apis.Condition{","\t\tType:    apis.ConditionSucceeded,","\t\tStatus:  corev1.ConditionFalse,","\t\tReason:  PipelineRunReasonTimedOut.String(),","\t\tMessage: fmt.Sprintf(\"PipelineRun %q failed to finish within %q\", pr.Name, pr.PipelineTimeout(ctx).String()),","\t})","}","","// HasTimedOut returns true if a pipelinerun has exceeded its spec.Timeout based on its status.Timeout","func (pr *PipelineRun) HasTimedOut(ctx context.Context, c clock.PassiveClock) bool {","\ttimeout := pr.PipelineTimeout(ctx)","\tstartTime := pr.Status.StartTime","","\tif !startTime.IsZero() {","\t\tif timeout == config.NoTimeoutDuration {","\t\t\treturn false","\t\t}","\t\truntime := c.Since(startTime.Time)","\t\tif runtime \u003e timeout {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// HasTimedOutForALongTime returns true if a pipelinerun has exceeed its spec.Timeout based its status.StartTime","// by a large margin","func (pr *PipelineRun) HasTimedOutForALongTime(ctx context.Context, c clock.PassiveClock) bool {","\tif !pr.HasTimedOut(ctx, c) {","\t\treturn false","\t}","\ttimeout := pr.PipelineTimeout(ctx)","\tstartTime := pr.Status.StartTime","\truntime := c.Since(startTime.Time)","\t// We are arbitrarily defining large margin as doubling the spec.timeout","\treturn runtime \u003e= 2*timeout","}","","// HaveTasksTimedOut returns true if a pipelinerun has exceeded its spec.Timeouts.Tasks","func (pr *PipelineRun) HaveTasksTimedOut(ctx context.Context, c clock.PassiveClock) bool {","\ttimeout := pr.TasksTimeout()","\tstartTime := pr.Status.StartTime","","\tif !startTime.IsZero() \u0026\u0026 timeout != nil {","\t\tif timeout.Duration == config.NoTimeoutDuration {","\t\t\treturn false","\t\t}","\t\truntime := c.Since(startTime.Time)","\t\tif runtime \u003e timeout.Duration {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// HasFinallyTimedOut returns true if a pipelinerun has exceeded its spec.Timeouts.Finally, based on status.FinallyStartTime","func (pr *PipelineRun) HasFinallyTimedOut(ctx context.Context, c clock.PassiveClock) bool {","\ttimeout := pr.FinallyTimeout()","\tstartTime := pr.Status.FinallyStartTime","","\tif startTime != nil \u0026\u0026 !startTime.IsZero() \u0026\u0026 timeout != nil {","\t\tif timeout.Duration == config.NoTimeoutDuration {","\t\t\treturn false","\t\t}","\t\truntime := c.Since(startTime.Time)","\t\tif runtime \u003e timeout.Duration {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// HasVolumeClaimTemplate returns true if PipelineRun contains volumeClaimTemplates that is","// used for creating PersistentVolumeClaims with an OwnerReference for each run","func (pr *PipelineRun) HasVolumeClaimTemplate() bool {","\tfor _, ws := range pr.Spec.Workspaces {","\t\tif ws.VolumeClaimTemplate != nil {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// PipelineRunSpec defines the desired state of PipelineRun","type PipelineRunSpec struct {","\t// +optional","\tPipelineRef *PipelineRef `json:\"pipelineRef,omitempty\"`","\t// Specifying PipelineSpec can be disabled by setting","\t// `disable-inline-spec` feature flag.","\t// See Pipeline.spec (API version: tekton.dev/v1beta1)","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tPipelineSpec *PipelineSpec `json:\"pipelineSpec,omitempty\"`","\t// Resources is a list of bindings specifying which actual instances of","\t// PipelineResources to use for the resources the Pipeline has declared","\t// it needs.","\t//","\t// Deprecated: Unused, preserved only for backwards compatibility","\t// +listType=atomic","\tResources []PipelineResourceBinding `json:\"resources,omitempty\"`","\t// Params is a list of parameter names and values.","\tParams Params `json:\"params,omitempty\"`","\t// +optional","\tServiceAccountName string `json:\"serviceAccountName,omitempty\"`","","\t// Used for cancelling a pipelinerun (and maybe more later on)","\t// +optional","\tStatus PipelineRunSpecStatus `json:\"status,omitempty\"`","\t// Time after which the Pipeline times out.","\t// Currently three keys are accepted in the map","\t// pipeline, tasks and finally","\t// with Timeouts.pipeline \u003e= Timeouts.tasks + Timeouts.finally","\t// +optional","\tTimeouts *TimeoutFields `json:\"timeouts,omitempty\"`","","\t// Timeout is the Time after which the Pipeline times out.","\t// Defaults to never.","\t// Refer to Go's ParseDuration documentation for expected format: https://golang.org/pkg/time/#ParseDuration","\t//","\t// Deprecated: use pipelineRunSpec.Timeouts.Pipeline instead","\t//","\t// +optional","\tTimeout *metav1.Duration `json:\"timeout,omitempty\"`","\t// PodTemplate holds pod specific configuration","\tPodTemplate *pod.PodTemplate `json:\"podTemplate,omitempty\"`","\t// Workspaces holds a set of workspace bindings that must match names","\t// with those declared in the pipeline.","\t// +optional","\t// +listType=atomic","\tWorkspaces []WorkspaceBinding `json:\"workspaces,omitempty\"`","\t// TaskRunSpecs holds a set of runtime specs","\t// +optional","\t// +listType=atomic","\tTaskRunSpecs []PipelineTaskRunSpec `json:\"taskRunSpecs,omitempty\"`","\t// ManagedBy indicates which controller is responsible for reconciling","\t// this resource. If unset or set to \"tekton.dev/pipeline\", the default","\t// Tekton controller will manage this resource.","\t// This field is immutable.","\t// +optional","\tManagedBy *string `json:\"managedBy,omitempty\"`","}","","// TimeoutFields allows granular specification of pipeline, task, and finally timeouts","type TimeoutFields struct {","\t// Pipeline sets the maximum allowed duration for execution of the entire pipeline. The sum of individual timeouts for tasks and finally must not exceed this value.","\tPipeline *metav1.Duration `json:\"pipeline,omitempty\"`","\t// Tasks sets the maximum allowed duration of this pipeline's tasks","\tTasks *metav1.Duration `json:\"tasks,omitempty\"`","\t// Finally sets the maximum allowed duration of this pipeline's finally","\tFinally *metav1.Duration `json:\"finally,omitempty\"`","}","","// PipelineRunSpecStatus defines the pipelinerun spec status the user can provide","type PipelineRunSpecStatus string","","const (","\t// PipelineRunSpecStatusCancelled indicates that the user wants to cancel the task,","\t// if not already cancelled or terminated","\tPipelineRunSpecStatusCancelled = \"Cancelled\"","","\t// PipelineRunSpecStatusCancelledRunFinally indicates that the user wants to cancel the pipeline run,","\t// if not already cancelled or terminated, but ensure finally is run normally","\tPipelineRunSpecStatusCancelledRunFinally = \"CancelledRunFinally\"","","\t// PipelineRunSpecStatusStoppedRunFinally indicates that the user wants to stop the pipeline run,","\t// wait for already running tasks to be completed and run finally","\t// if not already cancelled or terminated","\tPipelineRunSpecStatusStoppedRunFinally = \"StoppedRunFinally\"","","\t// PipelineRunSpecStatusPending indicates that the user wants to postpone starting a PipelineRun","\t// until some condition is met","\tPipelineRunSpecStatusPending = \"PipelineRunPending\"",")","","// PipelineRunStatus defines the observed state of PipelineRun","type PipelineRunStatus struct {","\tduckv1.Status `json:\",inline\"`","","\t// PipelineRunStatusFields inlines the status fields.","\tPipelineRunStatusFields `json:\",inline\"`","}","","// PipelineRunReason represents a reason for the pipeline run \"Succeeded\" condition","type PipelineRunReason string","","const (","\t// PipelineRunReasonStarted is the reason set when the PipelineRun has just started","\tPipelineRunReasonStarted PipelineRunReason = \"Started\"","\t// PipelineRunReasonRunning is the reason set when the PipelineRun is running","\tPipelineRunReasonRunning PipelineRunReason = \"Running\"","\t// PipelineRunReasonSuccessful is the reason set when the PipelineRun completed successfully","\tPipelineRunReasonSuccessful PipelineRunReason = \"Succeeded\"","\t// PipelineRunReasonCompleted is the reason set when the PipelineRun completed successfully with one or more skipped Tasks","\tPipelineRunReasonCompleted PipelineRunReason = \"Completed\"","\t// PipelineRunReasonFailed is the reason set when the PipelineRun completed with a failure","\tPipelineRunReasonFailed PipelineRunReason = \"Failed\"","\t// PipelineRunReasonCancelled is the reason set when the PipelineRun cancelled by the user","\t// This reason may be found with a corev1.ConditionFalse status, if the cancellation was processed successfully","\t// This reason may be found with a corev1.ConditionUnknown status, if the cancellation is being processed or failed","\tPipelineRunReasonCancelled PipelineRunReason = \"Cancelled\"","\t// PipelineRunReasonPending is the reason set when the PipelineRun is in the pending state","\tPipelineRunReasonPending PipelineRunReason = \"PipelineRunPending\"","\t// PipelineRunReasonTimedOut is the reason set when the PipelineRun has timed out","\tPipelineRunReasonTimedOut PipelineRunReason = \"PipelineRunTimeout\"","\t// PipelineRunReasonStopping indicates that no new Tasks will be scheduled by the controller, and the","\t// pipeline will stop once all running tasks complete their work","\tPipelineRunReasonStopping PipelineRunReason = \"PipelineRunStopping\"","\t// PipelineRunReasonCancelledRunningFinally indicates that pipeline has been gracefully cancelled","\t// and no new Tasks will be scheduled by the controller, but final tasks are now running","\tPipelineRunReasonCancelledRunningFinally PipelineRunReason = \"CancelledRunningFinally\"","\t// PipelineRunReasonStoppedRunningFinally indicates that pipeline has been gracefully stopped","\t// and no new Tasks will be scheduled by the controller, but final tasks are now running","\tPipelineRunReasonStoppedRunningFinally PipelineRunReason = \"StoppedRunningFinally\"",")","","func (t PipelineRunReason) String() string {","\treturn string(t)","}","","var pipelineRunCondSet = apis.NewBatchConditionSet()","","// GetCondition returns the Condition matching the given type.","func (pr *PipelineRunStatus) GetCondition(t apis.ConditionType) *apis.Condition {","\treturn pipelineRunCondSet.Manage(pr).GetCondition(t)","}","","// InitializeConditions will set all conditions in pipelineRunCondSet to unknown for the PipelineRun","// and set the started time to the current time","func (pr *PipelineRunStatus) InitializeConditions(c clock.PassiveClock) {","\tstarted := false","\tif pr.StartTime.IsZero() {","\t\tpr.StartTime = \u0026metav1.Time{Time: c.Now()}","\t\tstarted = true","\t}","\tconditionManager := pipelineRunCondSet.Manage(pr)","\tconditionManager.InitializeConditions()","\t// Ensure the started reason is set for the \"Succeeded\" condition","\tif started {","\t\tinitialCondition := conditionManager.GetCondition(apis.ConditionSucceeded)","\t\tinitialCondition.Reason = PipelineRunReasonStarted.String()","\t\tconditionManager.SetCondition(*initialCondition)","\t}","}","","// SetCondition sets the condition, unsetting previous conditions with the same","// type as necessary.","func (pr *PipelineRunStatus) SetCondition(newCond *apis.Condition) {","\tif newCond != nil {","\t\tpipelineRunCondSet.Manage(pr).SetCondition(*newCond)","\t}","}","","// MarkSucceeded changes the Succeeded condition to True with the provided reason and message.","func (pr *PipelineRunStatus) MarkSucceeded(reason, messageFormat string, messageA ...interface{}) {","\tpipelineRunCondSet.Manage(pr).MarkTrueWithReason(apis.ConditionSucceeded, reason, messageFormat, messageA...)","\tsucceeded := pr.GetCondition(apis.ConditionSucceeded)","\tpr.CompletionTime = \u0026succeeded.LastTransitionTime.Inner","}","","// MarkFailed changes the Succeeded condition to False with the provided reason and message.","func (pr *PipelineRunStatus) MarkFailed(reason, messageFormat string, messageA ...interface{}) {","\tpipelineRunCondSet.Manage(pr).MarkFalse(apis.ConditionSucceeded, reason, messageFormat, messageA...)","\tsucceeded := pr.GetCondition(apis.ConditionSucceeded)","\tpr.CompletionTime = \u0026succeeded.LastTransitionTime.Inner","}","","// MarkRunning changes the Succeeded condition to Unknown with the provided reason and message.","func (pr *PipelineRunStatus) MarkRunning(reason, messageFormat string, messageA ...interface{}) {","\tpipelineRunCondSet.Manage(pr).MarkUnknown(apis.ConditionSucceeded, reason, messageFormat, messageA...)","}","","// ChildStatusReference is used to point to the statuses of individual TaskRuns and Runs within this PipelineRun.","type ChildStatusReference struct {","\truntime.TypeMeta `json:\",inline\"`","\t// Name is the name of the TaskRun or Run this is referencing.","\tName string `json:\"name,omitempty\"`","\t// DisplayName is a user-facing name of the pipelineTask that may be","\t// used to populate a UI.","\tDisplayName string `json:\"displayName,omitempty\"`","\t// PipelineTaskName is the name of the PipelineTask this is referencing.","\tPipelineTaskName string `json:\"pipelineTaskName,omitempty\"`","","\t// WhenExpressions is the list of checks guarding the execution of the PipelineTask","\t// +optional","\t// +listType=atomic","\tWhenExpressions []WhenExpression `json:\"whenExpressions,omitempty\"`","}","","// PipelineRunStatusFields holds the fields of PipelineRunStatus' status.","// This is defined separately and inlined so that other types can readily","// consume these fields via duck typing.","type PipelineRunStatusFields struct {","\t// StartTime is the time the PipelineRun is actually started.","\tStartTime *metav1.Time `json:\"startTime,omitempty\"`","","\t// CompletionTime is the time the PipelineRun completed.","\tCompletionTime *metav1.Time `json:\"completionTime,omitempty\"`","","\t// TaskRuns is a map of PipelineRunTaskRunStatus with the taskRun name as the key.","\t//","\t// Deprecated: use ChildReferences instead. As of v0.45.0, this field is no","\t// longer populated and is only included for backwards compatibility with","\t// older server versions.","\t// +optional","\tTaskRuns map[string]*PipelineRunTaskRunStatus `json:\"taskRuns,omitempty\"`","","\t// Runs is a map of PipelineRunRunStatus with the run name as the key","\t//","\t// Deprecated: use ChildReferences instead. As of v0.45.0, this field is no","\t// longer populated and is only included for backwards compatibility with","\t// older server versions.","\t// +optional","\tRuns map[string]*PipelineRunRunStatus `json:\"runs,omitempty\"`","","\t// PipelineResults are the list of results written out by the pipeline task's containers","\t// +optional","\t// +listType=atomic","\tPipelineResults []PipelineRunResult `json:\"pipelineResults,omitempty\"`","","\t// PipelineSpec contains the exact spec used to instantiate the run.","\t// See Pipeline.spec (API version: tekton.dev/v1beta1)","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tPipelineSpec *PipelineSpec `json:\"pipelineSpec,omitempty\"`","","\t// list of tasks that were skipped due to when expressions evaluating to false","\t// +optional","\t// +listType=atomic","\tSkippedTasks []SkippedTask `json:\"skippedTasks,omitempty\"`","","\t// list of TaskRun and Run names, PipelineTask names, and API versions/kinds for children of this PipelineRun.","\t// +optional","\t// +listType=atomic","\tChildReferences []ChildStatusReference `json:\"childReferences,omitempty\"`","","\t// FinallyStartTime is when all non-finally tasks have been completed and only finally tasks are being executed.","\t// +optional","\tFinallyStartTime *metav1.Time `json:\"finallyStartTime,omitempty\"`","","\t// Provenance contains some key authenticated metadata about how a software artifact was built (what sources, what inputs/outputs, etc.).","\t// +optional","\tProvenance *Provenance `json:\"provenance,omitempty\"`","","\t// SpanContext contains tracing span context fields","\tSpanContext map[string]string `json:\"spanContext,omitempty\"`","}","","// SkippedTask is used to describe the Tasks that were skipped due to their When Expressions","// evaluating to False. This is a struct because we are looking into including more details","// about the When Expressions that caused this Task to be skipped.","type SkippedTask struct {","\t// Name is the Pipeline Task name","\tName string `json:\"name\"`","\t// Reason is the cause of the PipelineTask being skipped.","\tReason SkippingReason `json:\"reason\"`","\t// WhenExpressions is the list of checks guarding the execution of the PipelineTask","\t// +optional","\t// +listType=atomic","\tWhenExpressions []WhenExpression `json:\"whenExpressions,omitempty\"`","}","","// SkippingReason explains why a PipelineTask was skipped.","type SkippingReason string","","const (","\t// WhenExpressionsSkip means the task was skipped due to at least one of its when expressions evaluating to false","\tWhenExpressionsSkip SkippingReason = \"When Expressions evaluated to false\"","\t// ParentTasksSkip means the task was skipped because its parent was skipped","\tParentTasksSkip SkippingReason = \"Parent Tasks were skipped\"","\t// StoppingSkip means the task was skipped because the pipeline run is stopping","\tStoppingSkip SkippingReason = \"PipelineRun was stopping\"","\t// GracefullyCancelledSkip means the task was skipped because the pipeline run has been gracefully cancelled","\tGracefullyCancelledSkip SkippingReason = \"PipelineRun was gracefully cancelled\"","\t// GracefullyStoppedSkip means the task was skipped because the pipeline run has been gracefully stopped","\tGracefullyStoppedSkip SkippingReason = \"PipelineRun was gracefully stopped\"","\t// MissingResultsSkip means the task was skipped because it's missing necessary results","\tMissingResultsSkip SkippingReason = \"Results were missing\"","\t// PipelineTimedOutSkip means the task was skipped because the PipelineRun has passed its overall timeout.","\tPipelineTimedOutSkip SkippingReason = \"PipelineRun timeout has been reached\"","\t// TasksTimedOutSkip means the task was skipped because the PipelineRun has passed its Timeouts.Tasks.","\tTasksTimedOutSkip SkippingReason = \"PipelineRun Tasks timeout has been reached\"","\t// FinallyTimedOutSkip means the task was skipped because the PipelineRun has passed its Timeouts.Finally.","\tFinallyTimedOutSkip SkippingReason = \"PipelineRun Finally timeout has been reached\"","\t// EmptyArrayInMatrixParams means the task was skipped because Matrix parameters contain empty array.","\tEmptyArrayInMatrixParams SkippingReason = \"Matrix Parameters have an empty array\"","\t// None means the task was not skipped","\tNone SkippingReason = \"None\"",")","","// PipelineRunResult used to describe the results of a pipeline","type PipelineRunResult struct {","\t// Name is the result's name as declared by the Pipeline","\tName string `json:\"name\"`","","\t// Value is the result returned from the execution of this PipelineRun","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tValue ResultValue `json:\"value\"`","}","","// PipelineRunTaskRunStatus contains the name of the PipelineTask for this TaskRun and the TaskRun's Status","type PipelineRunTaskRunStatus struct {","\t// PipelineTaskName is the name of the PipelineTask.","\tPipelineTaskName string `json:\"pipelineTaskName,omitempty\"`","\t// Status is the TaskRunStatus for the corresponding TaskRun","\t// +optional","\tStatus *TaskRunStatus `json:\"status,omitempty\"`","\t// WhenExpressions is the list of checks guarding the execution of the PipelineTask","\t// +optional","\t// +listType=atomic","\tWhenExpressions []WhenExpression `json:\"whenExpressions,omitempty\"`","}","","// PipelineRunRunStatus contains the name of the PipelineTask for this CustomRun or Run and the CustomRun or Run's Status","type PipelineRunRunStatus struct {","\t// PipelineTaskName is the name of the PipelineTask.","\tPipelineTaskName string `json:\"pipelineTaskName,omitempty\"`","\t// Status is the CustomRunStatus for the corresponding CustomRun or Run","\t// +optional","\tStatus *CustomRunStatus `json:\"status,omitempty\"`","\t// WhenExpressions is the list of checks guarding the execution of the PipelineTask","\t// +optional","\t// +listType=atomic","\tWhenExpressions []WhenExpression `json:\"whenExpressions,omitempty\"`","}","","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// PipelineRunList contains a list of PipelineRun","type PipelineRunList struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ListMeta `json:\"metadata,omitempty\"`","\tItems           []PipelineRun `json:\"items\"`","}","","// PipelineTaskRun reports the results of running a step in the Task. Each","// task has the potential to succeed or fail (based on the exit code)","// and produces logs.","type PipelineTaskRun struct {","\tName string `json:\"name,omitempty\"`","}","","// PipelineTaskRunSpec  can be used to configure specific","// specs for a concrete Task","type PipelineTaskRunSpec struct {","\tPipelineTaskName       string           `json:\"pipelineTaskName,omitempty\"`","\tTaskServiceAccountName string           `json:\"taskServiceAccountName,omitempty\"`","\tTaskPodTemplate        *pod.PodTemplate `json:\"taskPodTemplate,omitempty\"`","\t// +listType=atomic","\tStepOverrides []TaskRunStepOverride `json:\"stepOverrides,omitempty\"`","\t// +listType=atomic","\tSidecarOverrides []TaskRunSidecarOverride `json:\"sidecarOverrides,omitempty\"`","","\t// +optional","\tMetadata *PipelineTaskMetadata `json:\"metadata,omitempty\"`","","\t// Compute resources to use for this TaskRun","\tComputeResources *corev1.ResourceRequirements `json:\"computeResources,omitempty\"`","","\t// Duration after which the TaskRun times out.","\t// Refer Go's ParseDuration documentation for expected format: https://golang.org/pkg/time/#ParseDuration","\t// +optional","\tTimeout *metav1.Duration `json:\"timeout,omitempty\"`","}","","// GetTaskRunSpec returns the task specific spec for a given","// PipelineTask if configured, otherwise it returns the PipelineRun's default.","func (pr *PipelineRun) GetTaskRunSpec(pipelineTaskName string) PipelineTaskRunSpec {","\ts := PipelineTaskRunSpec{","\t\tPipelineTaskName:       pipelineTaskName,","\t\tTaskServiceAccountName: pr.Spec.ServiceAccountName,","\t\tTaskPodTemplate:        pr.Spec.PodTemplate,","\t}","\tfor _, task := range pr.Spec.TaskRunSpecs {","\t\tif task.PipelineTaskName == pipelineTaskName {","\t\t\t// merge podTemplates specified in pipelineRun.spec.taskRunSpecs[].podTemplate and pipelineRun.spec.podTemplate","\t\t\t// with taskRunSpecs taking higher precedence","\t\t\ts.TaskPodTemplate = pod.MergePodTemplateWithDefault(task.TaskPodTemplate, s.TaskPodTemplate)","\t\t\tif task.TaskServiceAccountName != \"\" {","\t\t\t\ts.TaskServiceAccountName = task.TaskServiceAccountName","\t\t\t}","\t\t\ts.StepOverrides = task.StepOverrides","\t\t\ts.SidecarOverrides = task.SidecarOverrides","\t\t\ts.Metadata = task.Metadata","\t\t\ts.ComputeResources = task.ComputeResources","\t\t\ts.Timeout = task.Timeout","\t\t}","\t}","\treturn s","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,0,0,0,1,1,1,1,1,0,0,1,1,1,1,1,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0]},{"id":89,"path":"pkg/apis/pipeline/v1beta1/pipelinerun_validation.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"fmt\"","\t\"strings\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/validate\"","\t\"github.com/tektoncd/pipeline/pkg/internal/resultref\"","\tadmissionregistrationv1 \"k8s.io/api/admissionregistration/v1\"","\t\"k8s.io/apimachinery/pkg/api/equality\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"k8s.io/utils/strings/slices\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/webhook/resourcesemantics\"",")","","var (","\t_ apis.Validatable = (*PipelineRun)(nil)","\t_ resourcesemantics.VerbLimited",")","","// SupportedVerbs returns the operations that validation should be called for","func (pr *PipelineRun) SupportedVerbs() []admissionregistrationv1.OperationType {","\treturn []admissionregistrationv1.OperationType{admissionregistrationv1.Create, admissionregistrationv1.Update}","}","","// Validate pipelinerun","func (pr *PipelineRun) Validate(ctx context.Context) *apis.FieldError {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","","\terrs := validate.ObjectMetadata(pr.GetObjectMeta()).ViaField(\"metadata\")","","\tif pr.IsPending() \u0026\u0026 pr.HasStarted() {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"PipelineRun cannot be Pending after it is started\", \"spec.status\"))","\t}","","\treturn errs.Also(pr.Spec.Validate(apis.WithinSpec(ctx)).ViaField(\"spec\"))","}","","// Validate pipelinerun spec","func (ps *PipelineRunSpec) Validate(ctx context.Context) (errs *apis.FieldError) {","\t// Validate the spec changes","\terrs = errs.Also(ps.ValidateUpdate(ctx))","","\t// Must have exactly one of pipelineRef and pipelineSpec.","\tif ps.PipelineRef == nil \u0026\u0026 ps.PipelineSpec == nil {","\t\terrs = errs.Also(apis.ErrMissingOneOf(\"pipelineRef\", \"pipelineSpec\"))","\t}","\tif ps.PipelineRef != nil \u0026\u0026 ps.PipelineSpec != nil {","\t\terrs = errs.Also(apis.ErrMultipleOneOf(\"pipelineRef\", \"pipelineSpec\"))","\t}","","\t// Validate PipelineRef if it's present","\tif ps.PipelineRef != nil {","\t\terrs = errs.Also(ps.PipelineRef.Validate(ctx).ViaField(\"pipelineRef\"))","\t}","","\t// Validate PipelineSpec if it's present","\tif ps.PipelineSpec != nil {","\t\tif slices.Contains(strings.Split(","\t\t\tconfig.FromContextOrDefaults(ctx).FeatureFlags.DisableInlineSpec, \",\"), \"pipelinerun\") {","\t\t\terrs = errs.Also(apis.ErrDisallowedFields(\"pipelineSpec\"))","\t\t}","\t\terrs = errs.Also(ps.PipelineSpec.Validate(ctx).ViaField(\"pipelineSpec\"))","\t}","","\t// Validate PipelineRun parameters","\terrs = errs.Also(ps.validatePipelineRunParameters(ctx))","","\t// Validate propagated parameters","\terrs = errs.Also(ps.validateInlineParameters(ctx))","\t// Validate propagated workspaces","\terrs = errs.Also(ps.validatePropagatedWorkspaces(ctx))","","\tif ps.Timeout != nil {","\t\t// timeout should be a valid duration of at least 0.","\t\tif ps.Timeout.Duration \u003c 0 {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(ps.Timeout.Duration.String()+\" should be \u003e= 0\", \"timeout\"))","\t\t}","\t}","","\tif ps.Timeouts != nil {","\t\tif ps.Timeout != nil {","\t\t\t// can't have both at the same time","\t\t\terrs = errs.Also(apis.ErrDisallowedFields(\"timeout\", \"timeouts\"))","\t\t}","","\t\t// tasks timeout should be a valid duration of at least 0.","\t\terrs = errs.Also(validateTimeoutDuration(\"tasks\", ps.Timeouts.Tasks))","","\t\t// finally timeout should be a valid duration of at least 0.","\t\terrs = errs.Also(validateTimeoutDuration(\"finally\", ps.Timeouts.Finally))","","\t\t// pipeline timeout should be a valid duration of at least 0.","\t\terrs = errs.Also(validateTimeoutDuration(\"pipeline\", ps.Timeouts.Pipeline))","","\t\tif ps.Timeouts.Pipeline != nil {","\t\t\terrs = errs.Also(ps.validatePipelineTimeout(ps.Timeouts.Pipeline.Duration, \"should be \u003c= pipeline duration\"))","\t\t} else {","\t\t\tdefaultTimeout := time.Duration(config.FromContextOrDefaults(ctx).Defaults.DefaultTimeoutMinutes)","\t\t\terrs = errs.Also(ps.validatePipelineTimeout(defaultTimeout, \"should be \u003c= default timeout duration\"))","\t\t}","\t}","","\terrs = errs.Also(validateSpecStatus(ps.Status))","","\tif ps.Workspaces != nil {","\t\twsNames := make(map[string]int)","\t\tfor idx, ws := range ps.Workspaces {","\t\t\terrs = errs.Also(ws.Validate(ctx).ViaFieldIndex(\"workspaces\", idx))","\t\t\tif prevIdx, alreadyExists := wsNames[ws.Name]; alreadyExists {","\t\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"workspace %q provided by pipelinerun more than once, at index %d and %d\", ws.Name, prevIdx, idx), \"name\").ViaFieldIndex(\"workspaces\", idx))","\t\t\t}","\t\t\twsNames[ws.Name] = idx","\t\t}","\t}","\tfor idx, trs := range ps.TaskRunSpecs {","\t\terrs = errs.Also(validateTaskRunSpec(ctx, trs, ps.Timeouts).ViaIndex(idx).ViaField(\"taskRunSpecs\"))","\t}","\tif ps.PodTemplate != nil {","\t\terrs = errs.Also(validatePodTemplateEnv(ctx, *ps.PodTemplate))","\t}","\tif ps.Resources != nil {","\t\terrs = errs.Also(apis.ErrDisallowedFields(\"resources\"))","\t}","","\treturn errs","}","","// ValidateUpdate validates the update of a PipelineRunSpec","func (ps *PipelineRunSpec) ValidateUpdate(ctx context.Context) (errs *apis.FieldError) {","\tif !apis.IsInUpdate(ctx) {","\t\treturn","\t}","\toldObj, ok := apis.GetBaseline(ctx).(*PipelineRun)","\tif !ok || oldObj == nil {","\t\treturn","\t}","","\tif (oldObj.Spec.ManagedBy == nil) != (ps.ManagedBy == nil) || (oldObj.Spec.ManagedBy != nil \u0026\u0026 *oldObj.Spec.ManagedBy != *ps.ManagedBy) {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"managedBy is immutable\", \"spec.managedBy\"))","\t}","","\tif oldObj.IsDone() {","\t\t// try comparing without any copying first","\t\t// this handles the common case where only finalizers changed","\t\tif equality.Semantic.DeepEqual(\u0026oldObj.Spec, ps) {","\t\t\treturn nil // Specs identical, allow update","\t\t}","","\t\t// Specs differ, this could be due to different defaults after upgrade","\t\t// Apply current defaults to old spec to normalize","\t\toldCopy := oldObj.Spec.DeepCopy()","\t\toldCopy.SetDefaults(ctx)","","\t\tif equality.Semantic.DeepEqual(oldCopy, ps) {","\t\t\treturn nil // Difference was only defaults, allow update","\t\t}","","\t\t// Real spec changes detected, reject update","\t\terrs = errs.Also(apis.ErrInvalidValue(\"Once the PipelineRun is complete, no updates are allowed\", \"\"))","\t\treturn errs","\t}","","\t// Handle started but not done case","\told := oldObj.Spec.DeepCopy()","\told.Status = ps.Status","\told.ManagedBy = ps.ManagedBy // Already tested before","\tif !equality.Semantic.DeepEqual(old, ps) {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"Once the PipelineRun has started, only status updates are allowed\", \"\"))","\t}","","\treturn","}","","func (ps *PipelineRunSpec) validatePipelineRunParameters(ctx context.Context) (errs *apis.FieldError) {","\tif len(ps.Params) == 0 {","\t\treturn errs","\t}","","\t// Validate parameter types and uniqueness","\terrs = errs.Also(ValidateParameters(ctx, ps.Params).ViaField(\"params\"))","","\t// Validate that task results aren't used in param values","\tfor _, param := range ps.Params {","\t\texpressions, ok := GetVarSubstitutionExpressionsForParam(param)","\t\tif ok {","\t\t\tif LooksLikeContainsResultRefs(expressions) {","\t\t\t\texpressions = filter(expressions, resultref.LooksLikeResultRef)","\t\t\t\tresultRefs := NewResultRefs(expressions)","\t\t\t\tif len(resultRefs) \u003e 0 {","\t\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"cannot use result expressions in %v as PipelineRun parameter values\", expressions),","\t\t\t\t\t\t\"value\").ViaFieldKey(\"params\", param.Name))","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn errs","}","","// validatePropagatedWorkspaces validates workspaces that are propagated.","func (ps *PipelineRunSpec) validatePropagatedWorkspaces(ctx context.Context) (errs *apis.FieldError) {","\tif ps.PipelineSpec == nil {","\t\treturn errs","\t}","\tworkspaceNames := sets.NewString()","\tfor _, w := range ps.Workspaces {","\t\tworkspaceNames.Insert(w.Name)","\t}","","\tfor _, w := range ps.PipelineSpec.Workspaces {","\t\tworkspaceNames.Insert(w.Name)","\t}","","\tfor i, pt := range ps.PipelineSpec.Tasks {","\t\tfor _, w := range pt.Workspaces {","\t\t\tworkspaceNames.Insert(w.Name)","\t\t}","\t\terrs = errs.Also(pt.validateWorkspaces(workspaceNames).ViaIndex(i))","\t}","\tfor i, pt := range ps.PipelineSpec.Finally {","\t\tfor _, w := range pt.Workspaces {","\t\t\tworkspaceNames.Insert(w.Name)","\t\t}","\t\terrs = errs.Also(pt.validateWorkspaces(workspaceNames).ViaIndex(i))","\t}","\treturn errs","}","","// validateInlineParameters validates parameters that are defined inline.","// This is crucial for propagated parameters since the parameters could","// be defined under pipelineRun and then called directly in the task steps.","// In this case, parameters cannot be validated by the underlying pipelineSpec","// or taskSpec since they may not have the parameters declared because of propagation.","func (ps *PipelineRunSpec) validateInlineParameters(ctx context.Context) (errs *apis.FieldError) {","\tif ps.PipelineSpec == nil {","\t\treturn errs","\t}","\tparamSpecForValidation := make(map[string]ParamSpec)","\tfor _, p := range ps.Params {","\t\tparamSpecForValidation = createParamSpecFromParam(p, paramSpecForValidation)","\t}","\tfor _, p := range ps.PipelineSpec.Params {","\t\tvar err *apis.FieldError","\t\tparamSpecForValidation, err = combineParamSpec(p, paramSpecForValidation)","\t\tif err != nil {","\t\t\terrs = errs.Also(err)","\t\t}","\t}","\tfor _, pt := range ps.PipelineSpec.Tasks {","\t\tparamSpecForValidation = appendPipelineTaskParams(paramSpecForValidation, pt.Params)","\t\tif pt.TaskSpec != nil \u0026\u0026 pt.TaskSpec.Params != nil {","\t\t\tfor _, p := range pt.TaskSpec.Params {","\t\t\t\tvar err *apis.FieldError","\t\t\t\tparamSpecForValidation, err = combineParamSpec(p, paramSpecForValidation)","\t\t\t\tif err != nil {","\t\t\t\t\terrs = errs.Also(err)","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\tvar paramSpec []ParamSpec","\tfor _, v := range paramSpecForValidation {","\t\tparamSpec = append(paramSpec, v)","\t}","\tif ps.PipelineSpec != nil \u0026\u0026 ps.PipelineSpec.Tasks != nil {","\t\tfor _, pt := range ps.PipelineSpec.Tasks {","\t\t\tif pt.TaskSpec != nil \u0026\u0026 pt.TaskSpec.Steps != nil {","\t\t\t\terrs = errs.Also(ValidateParameterTypes(ctx, paramSpec))","\t\t\t\terrs = errs.Also(ValidateParameterVariables(ctx, pt.TaskSpec.Steps, paramSpec))","\t\t\t\terrs = errs.Also(ValidateUsageOfDeclaredParameters(ctx, pt.TaskSpec.Steps, paramSpec))","\t\t\t}","\t\t}","\t\terrs = errs.Also(ValidatePipelineParameterVariables(ctx, ps.PipelineSpec.Tasks, paramSpec))","\t\terrs = errs.Also(validatePipelineTaskParameterUsage(ps.PipelineSpec.Tasks, paramSpec))","\t}","\treturn errs","}","","func appendPipelineTaskParams(paramSpecForValidation map[string]ParamSpec, params Params) map[string]ParamSpec {","\tfor _, p := range params {","\t\tif pSpec, ok := paramSpecForValidation[p.Name]; ok {","\t\t\tif p.Value.ObjectVal != nil {","\t\t\t\tfor k, v := range p.Value.ObjectVal {","\t\t\t\t\tpSpec.Default.ObjectVal[k] = v","\t\t\t\t\tpSpec.Properties[k] = PropertySpec{Type: ParamTypeString}","\t\t\t\t}","\t\t\t}","\t\t\tparamSpecForValidation[p.Name] = pSpec","\t\t} else {","\t\t\tparamSpecForValidation = createParamSpecFromParam(p, paramSpecForValidation)","\t\t}","\t}","\treturn paramSpecForValidation","}","","func validateSpecStatus(status PipelineRunSpecStatus) *apis.FieldError {","\tswitch status {","\tcase \"\":","\t\treturn nil","\tcase PipelineRunSpecStatusPending:","\t\treturn nil","\tcase PipelineRunSpecStatusCancelled,","\t\tPipelineRunSpecStatusCancelledRunFinally,","\t\tPipelineRunSpecStatusStoppedRunFinally:","\t\treturn nil","\t}","","\treturn apis.ErrInvalidValue(fmt.Sprintf(\"%s should be %s, %s, %s or %s\", status,","\t\tPipelineRunSpecStatusCancelled,","\t\tPipelineRunSpecStatusCancelledRunFinally,","\t\tPipelineRunSpecStatusStoppedRunFinally,","\t\tPipelineRunSpecStatusPending), \"status\")","}","","func validateTimeoutDuration(field string, d *metav1.Duration) (errs *apis.FieldError) {","\tif d != nil \u0026\u0026 d.Duration \u003c 0 {","\t\tfieldPath := \"timeouts.\" + field","\t\treturn errs.Also(apis.ErrInvalidValue(d.Duration.String()+\" should be \u003e= 0\", fieldPath))","\t}","\treturn nil","}","","func (ps *PipelineRunSpec) validatePipelineTimeout(timeout time.Duration, errorMsg string) (errs *apis.FieldError) {","\tif ps.Timeouts.Tasks != nil {","\t\ttasksTimeoutErr := false","\t\ttasksTimeoutStr := ps.Timeouts.Tasks.Duration.String()","\t\tif ps.Timeouts.Tasks.Duration \u003e timeout \u0026\u0026 timeout != config.NoTimeoutDuration {","\t\t\ttasksTimeoutErr = true","\t\t}","\t\tif ps.Timeouts.Tasks.Duration == config.NoTimeoutDuration \u0026\u0026 timeout != config.NoTimeoutDuration {","\t\t\ttasksTimeoutErr = true","\t\t\ttasksTimeoutStr += \" (no timeout)\"","\t\t}","\t\tif tasksTimeoutErr {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"%s %s\", tasksTimeoutStr, errorMsg), \"timeouts.tasks\"))","\t\t}","\t}","","\tif ps.Timeouts.Finally != nil {","\t\tfinallyTimeoutErr := false","\t\tfinallyTimeoutStr := ps.Timeouts.Finally.Duration.String()","\t\tif ps.Timeouts.Finally.Duration \u003e timeout \u0026\u0026 timeout != config.NoTimeoutDuration {","\t\t\tfinallyTimeoutErr = true","\t\t}","\t\tif ps.Timeouts.Finally.Duration == config.NoTimeoutDuration \u0026\u0026 timeout != config.NoTimeoutDuration {","\t\t\tfinallyTimeoutErr = true","\t\t\tfinallyTimeoutStr += \" (no timeout)\"","\t\t}","\t\tif finallyTimeoutErr {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"%s %s\", finallyTimeoutStr, errorMsg), \"timeouts.finally\"))","\t\t}","\t}","","\tif ps.Timeouts.Tasks != nil \u0026\u0026 ps.Timeouts.Finally != nil {","\t\tif ps.Timeouts.Tasks.Duration+ps.Timeouts.Finally.Duration \u003e timeout {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"%s + %s %s\", ps.Timeouts.Tasks.Duration.String(), ps.Timeouts.Finally.Duration.String(), errorMsg), \"timeouts.tasks\"))","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"%s + %s %s\", ps.Timeouts.Tasks.Duration.String(), ps.Timeouts.Finally.Duration.String(), errorMsg), \"timeouts.finally\"))","\t\t}","\t}","\treturn errs","}","","func validateTaskRunSpec(ctx context.Context, trs PipelineTaskRunSpec, pipelineTimeouts *TimeoutFields) (errs *apis.FieldError) {","\tif trs.StepOverrides != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"stepOverrides\", config.BetaAPIFields).ViaField(\"stepOverrides\"))","\t\terrs = errs.Also(validateStepOverrides(trs.StepOverrides).ViaField(\"stepOverrides\"))","\t}","\tif trs.SidecarOverrides != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"sidecarOverrides\", config.BetaAPIFields).ViaField(\"sidecarOverrides\"))","\t\terrs = errs.Also(validateSidecarOverrides(trs.SidecarOverrides).ViaField(\"sidecarOverrides\"))","\t}","\tif trs.ComputeResources != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"computeResources\", config.BetaAPIFields).ViaField(\"computeResources\"))","\t\terrs = errs.Also(validateTaskRunComputeResources(trs.ComputeResources, trs.StepOverrides))","\t}","\tif trs.TaskPodTemplate != nil {","\t\terrs = errs.Also(validatePodTemplateEnv(ctx, *trs.TaskPodTemplate))","\t}","","\t// Check taskRunSpec timeout against pipeline limits","\terrs = errs.Also(validateTaskRunSpecTimeout(ctx, trs.Timeout, pipelineTimeouts))","","\treturn errs","}","","// validateTaskRunSpecTimeout validates a TaskRunSpec's timeout against pipeline timeouts.","// This function works in isolation and doesn't rely on previous validation steps.","func validateTaskRunSpecTimeout(ctx context.Context, timeout *metav1.Duration, pipelineTimeouts *TimeoutFields) *apis.FieldError {","\tif timeout == nil {","\t\treturn nil","\t}","","\tcfg := config.FromContextOrDefaults(ctx)","\tvar errs *apis.FieldError","","\t// Validate basic timeout (negative values)","\t_, err := validateTimeout(timeout, cfg.Defaults.DefaultTimeoutMinutes)","\tif err != nil {","\t\terrs = errs.Also(err)","\t}","","\t// Validate timeout against effective pipeline timeout (explicit or default)","\tif err == nil {","\t\t// Find applicable timeout limit: Tasks -\u003e Pipeline -\u003e Default (60min)","\t\tvar maxTimeout *metav1.Duration","\t\tvar timeoutSource string","","\t\tswitch {","\t\tcase pipelineTimeouts != nil \u0026\u0026 pipelineTimeouts.Tasks != nil:","\t\t\tif validatedTimeout, err := validateTimeout(pipelineTimeouts.Tasks, cfg.Defaults.DefaultTimeoutMinutes); err != nil {","\t\t\t\t// Add error if Tasks timeout is invalid (prevents silent failures)","\t\t\t\terrs = errs.Also(err)","\t\t\t} else {","\t\t\t\tmaxTimeout = validatedTimeout","\t\t\t\ttimeoutSource = \"pipeline tasks duration\"","\t\t\t}","\t\tcase pipelineTimeouts != nil \u0026\u0026 pipelineTimeouts.Pipeline != nil:","\t\t\tif validatedTimeout, err := validateTimeout(pipelineTimeouts.Pipeline, cfg.Defaults.DefaultTimeoutMinutes); err != nil {","\t\t\t\t// Add error if Pipeline timeout is invalid (prevents silent failures)","\t\t\t\terrs = errs.Also(err)","\t\t\t} else {","\t\t\t\tmaxTimeout = validatedTimeout","\t\t\t\ttimeoutSource = \"pipeline duration\"","\t\t\t}","\t\tdefault:","\t\t\tmaxTimeout = \u0026metav1.Duration{Duration: time.Duration(cfg.Defaults.DefaultTimeoutMinutes) * time.Minute}","\t\t\ttimeoutSource = \"default pipeline duration\"","\t\t}","","\t\t// Always check against max timeout if it's not \"no timeout\"","\t\tif maxTimeout != nil \u0026\u0026 maxTimeout.Duration != config.NoTimeoutDuration {","\t\t\ttaskRunTimeout, _ := validateTimeout(timeout, cfg.Defaults.DefaultTimeoutMinutes) // We know this won't error from above","\t\t\tif taskRunTimeout.Duration \u003e maxTimeout.Duration {","\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(","\t\t\t\t\tfmt.Sprintf(\"%s should be \u003c= %s %s\", taskRunTimeout.Duration, timeoutSource, maxTimeout.Duration),","\t\t\t\t\t\"timeout\"))","\t\t\t}","\t\t}","\t}","","\treturn errs","}","","// validateTimeout validates a timeout field and returns the validated timeout with defaults applied.","// If timeout is nil, returns default timeout. If timeout is negative, returns an error.","func validateTimeout(timeout *metav1.Duration, defaultTimeoutMinutes int) (*metav1.Duration, *apis.FieldError) {","\tif timeout == nil {","\t\treturn \u0026metav1.Duration{Duration: time.Duration(defaultTimeoutMinutes) * time.Minute}, nil","\t}","\tif timeout.Duration \u003c 0 {","\t\treturn nil, apis.ErrInvalidValue(timeout.Duration.String()+\" should be \u003e= 0\", \"timeout\")","\t}","\treturn timeout, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,2,2,1,1,0,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,2,2,2,0,0,0,2,2,2,2,1,1,0,0,2,2,0,0,0,2,2,2,2,2,2,0,2,0,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,0,2,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,1,1,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,0,2,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,0,2,0,0,2,2,2,2,2,2,0,0,2,2,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,0,0,0,2,2,2,2,0,2,2,2,2,2,2,1,1,0,0,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,0,0,2,0,0,0,0,2,2,1,1,2,1,1,2,0]},{"id":90,"path":"pkg/apis/pipeline/v1beta1/provenance_conversion.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"",")","","func (p Provenance) convertTo(ctx context.Context, sink *v1.Provenance) {","\tif p.RefSource != nil {","\t\tnew := v1.RefSource{}","\t\tp.RefSource.convertTo(ctx, \u0026new)","\t\tsink.RefSource = \u0026new","\t}","\tif p.FeatureFlags != nil {","\t\tsink.FeatureFlags = p.FeatureFlags","\t}","}","","func (p *Provenance) convertFrom(ctx context.Context, source v1.Provenance) {","\tif source.RefSource != nil {","\t\tnew := RefSource{}","\t\tnew.convertFrom(ctx, *source.RefSource)","\t\tp.RefSource = \u0026new","\t}","\tif source.FeatureFlags != nil {","\t\tp.FeatureFlags = source.FeatureFlags","\t}","}","","func (cs RefSource) convertTo(ctx context.Context, sink *v1.RefSource) {","\tsink.URI = cs.URI","\tsink.Digest = cs.Digest","\tsink.EntryPoint = cs.EntryPoint","}","","func (cs *RefSource) convertFrom(ctx context.Context, source v1.RefSource) {","\tcs.URI = source.URI","\tcs.Digest = source.Digest","\tcs.EntryPoint = source.EntryPoint","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,2,2,2,2,2]},{"id":91,"path":"pkg/apis/pipeline/v1beta1/register.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"",")","","// SchemeGroupVersion is group version used to register these objects","var SchemeGroupVersion = schema.GroupVersion{Group: pipeline.GroupName, Version: \"v1beta1\"}","","// Kind takes an unqualified kind and returns back a Group qualified GroupKind","func Kind(kind string) schema.GroupKind {","\treturn SchemeGroupVersion.WithKind(kind).GroupKind()","}","","// Resource takes an unqualified resource and returns a Group qualified GroupResource","func Resource(resource string) schema.GroupResource {","\treturn SchemeGroupVersion.WithResource(resource).GroupResource()","}","","var (","\tschemeBuilder = runtime.NewSchemeBuilder(addKnownTypes)","","\t// AddToScheme adds Build types to the scheme.","\tAddToScheme = schemeBuilder.AddToScheme",")","","// Adds the list of known types to Scheme.","func addKnownTypes(scheme *runtime.Scheme) error {","\tscheme.AddKnownTypes(SchemeGroupVersion,","\t\t\u0026Task{},","\t\t\u0026TaskList{},","\t\t\u0026Pipeline{},","\t\t\u0026PipelineList{},","\t\t\u0026TaskRun{},","\t\t\u0026TaskRunList{},","\t\t\u0026PipelineRun{},","\t\t\u0026PipelineRunList{},","\t\t\u0026CustomRun{},","\t\t\u0026CustomRunList{},","\t\t\u0026StepAction{},","\t\t\u0026StepActionList{},","\t)","\t// \u0026Condition{},","\t// \u0026ConditionList{},","","\tmetav1.AddToGroupVersion(scheme, SchemeGroupVersion)","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]},{"id":92,"path":"pkg/apis/pipeline/v1beta1/resolver_conversion.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"",")","","func (rr ResolverRef) convertTo(ctx context.Context, sink *v1.ResolverRef) {","\tsink.Resolver = v1.ResolverName(rr.Resolver)","\tsink.Params = nil","\tfor _, r := range rr.Params {","\t\tnew := v1.Param{}","\t\tr.convertTo(ctx, \u0026new)","\t\tsink.Params = append(sink.Params, new)","\t}","}","","func (rr *ResolverRef) convertFrom(ctx context.Context, source v1.ResolverRef) {","\trr.Resolver = ResolverName(source.Resolver)","\trr.Params = nil","\tfor _, r := range source.Params {","\t\tnew := Param{}","\t\tnew.ConvertFrom(ctx, r)","\t\trr.Params = append(rr.Params, new)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0]},{"id":93,"path":"pkg/apis/pipeline/v1beta1/result_conversion.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"",")","","func (r TaskResult) convertTo(ctx context.Context, sink *v1.TaskResult) {","\tsink.Name = r.Name","\tsink.Type = v1.ResultsType(r.Type)","\tsink.Description = r.Description","\tif r.Properties != nil {","\t\tproperties := make(map[string]v1.PropertySpec)","\t\tfor k, v := range r.Properties {","\t\t\tproperties[k] = v1.PropertySpec{Type: v1.ParamType(v.Type)}","\t\t}","\t\tsink.Properties = properties","\t}","\tif r.Value != nil {","\t\tsink.Value = \u0026v1.ParamValue{}","\t\tr.Value.convertTo(ctx, sink.Value)","\t}","}","","func (r *TaskResult) convertFrom(ctx context.Context, source v1.TaskResult) {","\tr.Name = source.Name","\tr.Type = ResultsType(source.Type)","\tr.Description = source.Description","\tif source.Properties != nil {","\t\tproperties := make(map[string]PropertySpec)","\t\tfor k, v := range source.Properties {","\t\t\tproperties[k] = PropertySpec{Type: ParamType(v.Type)}","\t\t}","\t\tr.Properties = properties","\t}","\tif source.Value != nil {","\t\tr.Value = \u0026ParamValue{}","\t\tr.Value.convertFrom(ctx, *source.Value)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0]},{"id":94,"path":"pkg/apis/pipeline/v1beta1/result_defaults.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import \"context\"","","// SetDefaults set the default type for TaskResult","func (tr *TaskResult) SetDefaults(context.Context) {","\tif tr == nil {","\t\treturn","\t}","\tif tr.Type == \"\" {","\t\tif tr.Properties != nil {","\t\t\t// Set type to object if `properties` is given","\t\t\ttr.Type = ResultsTypeObject","\t\t} else {","\t\t\t// ResultsTypeString is the default value","\t\t\ttr.Type = ResultsTypeString","\t\t}","\t}","","\t// Set default type of object values to string","\tfor key, propertySpec := range tr.Properties {","\t\tif propertySpec.Type == \"\" {","\t\t\ttr.Properties[key] = PropertySpec{Type: ParamType(ResultsTypeString)}","\t\t}","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,0,0]},{"id":95,"path":"pkg/apis/pipeline/v1beta1/result_types.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import \"strings\"","","// TaskResult used to describe the results of a task","type TaskResult struct {","\t// Name the given name","\tName string `json:\"name\"`","","\t// Type is the user-specified type of the result. The possible type","\t// is currently \"string\" and will support \"array\" in following work.","\t// +optional","\tType ResultsType `json:\"type,omitempty\"`","","\t// Properties is the JSON Schema properties to support key-value pairs results.","\t// +optional","\tProperties map[string]PropertySpec `json:\"properties,omitempty\"`","","\t// Description is a human-readable description of the result","\t// +optional","\tDescription string `json:\"description,omitempty\"`","","\t// Value the expression used to retrieve the value of the result from an underlying Step.","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tValue *ResultValue `json:\"value,omitempty\"`","}","","// TaskRunResult used to describe the results of a task","type TaskRunResult struct {","\t// Name the given name","\tName string `json:\"name\"`","","\t// Type is the user-specified type of the result. The possible type","\t// is currently \"string\" and will support \"array\" in following work.","\t// +optional","\tType ResultsType `json:\"type,omitempty\"`","","\t// Value the given value of the result","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tValue ResultValue `json:\"value\"`","}","","// TaskRunStepResult is a type alias of TaskRunResult","type TaskRunStepResult = TaskRunResult","","// ResultValue is a type alias of ParamValue","type ResultValue = ParamValue","","// ResultsType indicates the type of a result;","// Used to distinguish between a single string and an array of strings.","// Note that there is ResultType used to find out whether a","// RunResult is from a task result or not, which is different from","// this ResultsType.","type ResultsType string","","// Valid ResultsType:","const (","\tResultsTypeString ResultsType = \"string\"","\tResultsTypeArray  ResultsType = \"array\"","\tResultsTypeObject ResultsType = \"object\"",")","","// AllResultsTypes can be used for ResultsTypes validation.","var AllResultsTypes = []ResultsType{ResultsTypeString, ResultsTypeArray, ResultsTypeObject}","","// ResultsArrayReference returns the reference of the result. e.g. results.resultname from $(results.resultname[*])","func ResultsArrayReference(a string) string {","\treturn strings.TrimSuffix(strings.TrimSuffix(strings.TrimPrefix(a, \"$(\"), \")\"), \"[*]\")","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2]},{"id":96,"path":"pkg/apis/pipeline/v1beta1/result_validation.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"fmt\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"k8s.io/apimachinery/pkg/util/validation\"","\t\"knative.dev/pkg/apis\"",")","","// Validate implements apis.Validatable","func (tr TaskResult) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif !resultNameFormatRegex.MatchString(tr.Name) {","\t\treturn apis.ErrInvalidKeyName(tr.Name, \"name\", fmt.Sprintf(\"Name must consist of alphanumeric characters, '-', '_', and must start and end with an alphanumeric character (e.g. 'MyName',  or 'my-name',  or 'my_name', regex used for validation is '%s')\", ResultNameFormat))","\t}","","\tswitch {","\tcase tr.Type == ResultsTypeObject:","\t\terrs = errs.Also(validateObjectResult(tr))","\tcase tr.Type == ResultsTypeArray:","\t// Resources created before the result. Type was introduced may not have Type set","\t// and should be considered valid","\tcase tr.Type == \"\":","\t// By default, the result type is string","\tcase tr.Type != ResultsTypeString:","\t\terrs = errs.Also(apis.ErrInvalidValue(tr.Type, \"type\", \"type must be string\"))","\t}","\treturn errs.Also(tr.validateValue(ctx))","}","","// validateObjectResult validates the object result and check if the Properties is missing","// for Properties values it will check if the type is string.","func validateObjectResult(tr TaskResult) (errs *apis.FieldError) {","\tif ParamType(tr.Type) == ParamTypeObject \u0026\u0026 tr.Properties == nil {","\t\treturn apis.ErrMissingField(tr.Name + \".properties\")","\t}","","\tinvalidKeys := []string{}","\tfor key, propertySpec := range tr.Properties {","\t\tif propertySpec.Type != ParamTypeString {","\t\t\tinvalidKeys = append(invalidKeys, key)","\t\t}","\t}","","\tif len(invalidKeys) != 0 {","\t\treturn \u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(\"The value type specified for these keys %v is invalid, the type must be string\", invalidKeys),","\t\t\tPaths:   []string{tr.Name + \".properties\"},","\t\t}","\t}","\treturn nil","}","","// validateValue validates the value of the TaskResult.","// It requires the value is of type string","// and format $(steps.\u003cstepName\u003e.results.\u003cresultName\u003e)","func (tr TaskResult) validateValue(ctx context.Context) (errs *apis.FieldError) {","\tif tr.Value == nil {","\t\treturn nil","\t}","\tif tr.Value.Type != ParamTypeString {","\t\treturn \u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(","\t\t\t\t\"Invalid Type. Wanted string but got: \\\"%v\\\"\", tr.Value.Type),","\t\t\tPaths: []string{","\t\t\t\ttr.Name + \".type\",","\t\t\t},","\t\t}","\t}","\tif tr.Value.StringVal != \"\" {","\t\tstepName, resultName, err := v1.ExtractStepResultName(tr.Value.StringVal)","\t\tif err != nil {","\t\t\treturn \u0026apis.FieldError{","\t\t\t\tMessage: err.Error(),","\t\t\t\tPaths:   []string{tr.Name + \".value\"},","\t\t\t}","\t\t}","\t\tif e := validation.IsDNS1123Label(stepName); len(e) \u003e 0 {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: fmt.Sprintf(\"invalid extracted step name %q\", stepName),","\t\t\t\tPaths:   []string{tr.Name + \".value\"},","\t\t\t\tDetails: \"stepName in $(steps.\u003cstepName\u003e.results.\u003cresultName\u003e) must be a valid DNS Label, For more info refer to https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names\",","\t\t\t})","\t\t}","\t\tif !resultNameFormatRegex.MatchString(resultName) {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: fmt.Sprintf(\"invalid extracted result name %q\", resultName),","\t\t\t\tPaths:   []string{tr.Name + \".value\"},","\t\t\t\tDetails: fmt.Sprintf(\"resultName in $(steps.\u003cstepName\u003e.results.\u003cresultName\u003e) must consist of alphanumeric characters, '-', '_', and must start and end with an alphanumeric character (e.g. 'MyName',  or 'my-name',  or 'my_name', regex used for validation is '%s')\", ResultNameFormat),","\t\t\t})","\t\t}","\t}","\treturn errs","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,2,2,2,0,0,0,0,0,2,2,0,2,0,0,0,0,2,2,2,2,0,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0]},{"id":97,"path":"pkg/apis/pipeline/v1beta1/resultref.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"regexp\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/internal/resultref\"",")","","// ResultRef is a type that represents a reference to a task run result","type ResultRef struct {","\tPipelineTask string `json:\"pipelineTask\"`","\tResult       string `json:\"result\"`","\tResultsIndex *int   `json:\"resultsIndex\"`","\tProperty     string `json:\"property\"`","}","","const (","\t// ResultTaskPart Constant used to define the \"tasks\" part of a pipeline result reference","\t// retained because of backwards compatibility","\tResultTaskPart = resultref.ResultTaskPart","\t// ResultFinallyPart Constant used to define the \"finally\" part of a pipeline result reference","\t// retained because of backwards compatibility","\tResultFinallyPart = resultref.ResultFinallyPart","\t// ResultResultPart Constant used to define the \"results\" part of a pipeline result reference","\t// retained because of backwards compatibility","\tResultResultPart = resultref.ResultResultPart","\t// TODO(#2462) use one regex across all substitutions","\t// variableSubstitutionFormat matches format like $result.resultname, $result.resultname[int] and $result.resultname[*]","\tvariableSubstitutionFormat = `\\$\\([_a-zA-Z0-9.-]+(\\.[_a-zA-Z0-9.-]+)*(\\[([0-9]+|\\*)\\])?\\)`","\t// exactVariableSubstitutionFormat matches strings that only contain a single reference to result or param variables, but nothing else","\t// i.e. `$(result.resultname)` is a match, but `foo $(result.resultname)` is not.","\texactVariableSubstitutionFormat = `^\\$\\([_a-zA-Z0-9.-]+(\\.[_a-zA-Z0-9.-]+)*(\\[([0-9]+|\\*)\\])?\\)$`","\t// ResultNameFormat Constant used to define the regex Result.Name should follow","\tResultNameFormat = `^([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9]$`",")","","// VariableSubstitutionRegex is a regex to find all result matching substitutions","var VariableSubstitutionRegex = regexp.MustCompile(variableSubstitutionFormat)","var exactVariableSubstitutionRegex = regexp.MustCompile(exactVariableSubstitutionFormat)","var resultNameFormatRegex = regexp.MustCompile(ResultNameFormat)","","// NewResultRefs extracts all ResultReferences from a param or a pipeline result.","// If the ResultReference can be extracted, they are returned. Expressions which are not","// results are ignored.","func NewResultRefs(expressions []string) []*ResultRef {","\tvar resultRefs []*ResultRef","\tfor _, expression := range expressions {","\t\tpr, err := resultref.ParseTaskExpression(expression)","\t\t// If the expression isn't a result but is some other expression,","\t\t// parseExpression will return an error, in which case we just skip that expression,","\t\t// since although it's not a result ref, it might be some other kind of reference","\t\tif err == nil {","\t\t\tresultRefs = append(resultRefs, \u0026ResultRef{","\t\t\t\tPipelineTask: pr.ResourceName,","\t\t\t\tResult:       pr.ResultName,","\t\t\t\tResultsIndex: pr.ArrayIdx,","\t\t\t\tProperty:     pr.ObjectKey,","\t\t\t})","\t\t}","\t}","\treturn resultRefs","}","","// LooksLikeContainsResultRefs attempts to check if param or a pipeline result looks like it contains any","// result references.","// This is useful if we want to make sure the param looks like a ResultReference before","// performing strict validation","func LooksLikeContainsResultRefs(expressions []string) bool {","\tfor _, expression := range expressions {","\t\tif resultref.LooksLikeResultRef(expression) {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// GetVarSubstitutionExpressionsForParam extracts all the value between \"$(\" and \")\"\" for a parameter","func GetVarSubstitutionExpressionsForParam(param Param) ([]string, bool) {","\tvar allExpressions []string","\tswitch param.Value.Type {","\tcase ParamTypeArray:","\t\t// array type","\t\tfor _, value := range param.Value.ArrayVal {","\t\t\tallExpressions = append(allExpressions, validateString(value)...)","\t\t}","\tcase ParamTypeString:","\t\t// string type","\t\tallExpressions = append(allExpressions, validateString(param.Value.StringVal)...)","\tcase ParamTypeObject:","\t\t// object type","\t\tfor _, value := range param.Value.ObjectVal {","\t\t\tallExpressions = append(allExpressions, validateString(value)...)","\t\t}","\tdefault:","\t\treturn nil, false","\t}","\treturn allExpressions, len(allExpressions) != 0","}","","// GetVarSubstitutionExpressionsForPipelineResult extracts all the value between \"$(\" and \")\"\" for a pipeline result","func GetVarSubstitutionExpressionsForPipelineResult(result PipelineResult) ([]string, bool) {","\tallExpressions := validateString(result.Value.StringVal)","\tfor _, v := range result.Value.ArrayVal {","\t\tallExpressions = append(allExpressions, validateString(v)...)","\t}","\tfor _, v := range result.Value.ObjectVal {","\t\tallExpressions = append(allExpressions, validateString(v)...)","\t}","\treturn allExpressions, len(allExpressions) != 0","}","","func validateString(value string) []string {","\texpressions := VariableSubstitutionRegex.FindAllString(value, -1)","\tif expressions == nil {","\t\treturn nil","\t}","\tvar result []string","\tfor _, expression := range expressions {","\t\tresult = append(result, stripVarSubExpression(expression))","\t}","\treturn result","}","","func stripVarSubExpression(expression string) string {","\treturn strings.TrimSuffix(strings.TrimPrefix(expression, \"$(\"), \")\")","}","","// ParseResultName parse the input string to extract resultName and result index.","// Array indexing:","// Input:  anArrayResult[1]","// Output: anArrayResult, \"1\"","// Array star reference:","// Input:  anArrayResult[*]","// Output: anArrayResult, \"*\"","func ParseResultName(resultName string) (string, string) {","\treturn resultref.ParseResultName(resultName)","}","","// PipelineTaskResultRefs walks all the places a result reference can be used","// in a PipelineTask and returns a list of any references that are found.","func PipelineTaskResultRefs(pt *PipelineTask) []*ResultRef {","\trefs := []*ResultRef{}","\tfor _, p := range pt.extractAllParams() {","\t\texpressions, _ := GetVarSubstitutionExpressionsForParam(p)","\t\trefs = append(refs, NewResultRefs(expressions)...)","\t}","\tfor _, whenExpression := range pt.WhenExpressions {","\t\texpressions, _ := whenExpression.GetVarSubstitutionExpressions()","\t\trefs = append(refs, NewResultRefs(expressions)...)","\t}","\treturn refs","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,0,0,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,0,0,0,0,0,0,0,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0]},{"id":98,"path":"pkg/apis/pipeline/v1beta1/stepaction_conversion.go","lines":["/*","Copyright 2023 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Convertible = (*StepAction)(nil)","","// ConvertTo implements apis.Convertible","func (s *StepAction) ConvertTo(ctx context.Context, to apis.Convertible) error {","\treturn nil","}","","// ConvertTo implements apis.Convertible","func (ss *StepActionSpec) ConvertTo(ctx context.Context, sink *StepActionSpec) error {","\treturn nil","}","","// ConvertFrom implements apis.Convertible","func (s *StepAction) ConvertFrom(ctx context.Context, from apis.Convertible) error {","\treturn nil","}","","// ConvertFrom implements apis.Convertible","func (ss *StepActionSpec) ConvertFrom(ctx context.Context, source *StepActionSpec) error {","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1]},{"id":99,"path":"pkg/apis/pipeline/v1beta1/stepaction_defaults.go","lines":["/*","Copyright 2023 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Defaultable = (*StepAction)(nil)","","// SetDefaults implements apis.Defaultable","func (s *StepAction) SetDefaults(ctx context.Context) {","\ts.Spec.SetDefaults(ctx)","}","","// SetDefaults set any defaults for the StepAction spec","func (ss *StepActionSpec) SetDefaults(ctx context.Context) {","\tfor i := range ss.Params {","\t\tss.Params[i].SetDefaults(ctx)","\t}","\tfor i := range ss.Results {","\t\tss.Results[i].SetDefaults(ctx)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,2,2,2,2,2,2,2,0]},{"id":100,"path":"pkg/apis/pipeline/v1beta1/stepaction_types.go","lines":["/*","Copyright 2023 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/internal/checksum\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/kmeta\"",")","","// +genclient","// +genclient:noStatus","// +genreconciler:krshapedlogic=false","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// StepAction represents the actionable components of Step.","// The Step can only reference it from the cluster or using remote resolution.","//","// +k8s:openapi-gen=true","// +kubebuilder:storageversion","type StepAction struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ObjectMeta `json:\"metadata\"`","","\t// Spec holds the desired state of the Step from the client","\t// +optional","\tSpec StepActionSpec `json:\"spec\"`","}","","var _ kmeta.OwnerRefable = (*StepAction)(nil)","","// StepAction returns the step action's spec","func (s *StepAction) StepActionSpec() StepActionSpec {","\treturn s.Spec","}","","// StepActionMetadata returns the step action's ObjectMeta","func (s *StepAction) StepActionMetadata() metav1.ObjectMeta {","\treturn s.ObjectMeta","}","","// Copy returns a deep copy of the stepaction","func (s *StepAction) Copy() StepActionObject {","\treturn s.DeepCopy()","}","","// GetGroupVersionKind implements kmeta.OwnerRefable.","func (*StepAction) GetGroupVersionKind() schema.GroupVersionKind {","\treturn SchemeGroupVersion.WithKind(\"StepAction\")","}","","// Checksum computes the sha256 checksum of the stepaction object.","// Prior to computing the checksum, it performs some preprocessing on the","// metadata of the object where it removes system provided annotations.","// Only the name, namespace, generateName, user-provided labels and annotations","// and the taskSpec are included for the checksum computation.","func (s *StepAction) Checksum() ([]byte, error) {","\tobjectMeta := checksum.PrepareObjectMeta(s)","\tpreprocessedStepaction := StepAction{","\t\tTypeMeta: metav1.TypeMeta{","\t\t\tAPIVersion: \"tekton.dev/v1beta1\",","\t\t\tKind:       \"StepAction\",","\t\t},","\t\tObjectMeta: objectMeta,","\t\tSpec:       s.Spec,","\t}","\tsha256Checksum, err := checksum.ComputeSha256Checksum(preprocessedStepaction)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn sha256Checksum, nil","}","","// StepActionList contains a list of StepActions","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","type StepActionList struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ListMeta `json:\"metadata,omitempty\"`","\tItems           []StepAction `json:\"items\"`","}","","// +listType=atomic","type Args []string","","// StepActionSpec contains the actionable components of a step.","type StepActionSpec struct {","\t// Description is a user-facing description of the stepaction that may be","\t// used to populate a UI.","\t// +optional","\tDescription string `json:\"description,omitempty\"`","\t// Image reference name to run for this StepAction.","\t// More info: https://kubernetes.io/docs/concepts/containers/images","\t// +optional","\tImage string `json:\"image,omitempty\" protobuf:\"bytes,2,opt,name=image\"`","\t// Entrypoint array. Not executed within a shell.","\t// The image's ENTRYPOINT is used if this is not provided.","\t// Variable references $(VAR_NAME) are expanded using the container's environment. If a variable","\t// cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced","\t// to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$$(VAR_NAME)\" will","\t// produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless","\t// of whether the variable exists or not. Cannot be updated.","\t// More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell","\t// +optional","\t// +listType=atomic","\tCommand []string `json:\"command,omitempty\" protobuf:\"bytes,3,rep,name=command\"`","\t// Arguments to the entrypoint.","\t// The image's CMD is used if this is not provided.","\t// Variable references $(VAR_NAME) are expanded using the container's environment. If a variable","\t// cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced","\t// to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$$(VAR_NAME)\" will","\t// produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless","\t// of whether the variable exists or not. Cannot be updated.","\t// More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell","\t// +optional","\tArgs Args `json:\"args,omitempty\" protobuf:\"bytes,4,rep,name=args\"`","\t// List of environment variables to set in the container.","\t// Cannot be updated.","\t// +optional","\t// +patchMergeKey=name","\t// +patchStrategy=merge","\t// +listType=atomic","\tEnv []corev1.EnvVar `json:\"env,omitempty\" patchMergeKey:\"name\" patchStrategy:\"merge\" protobuf:\"bytes,7,rep,name=env\"`","\t// Script is the contents of an executable file to execute.","\t//","\t// If Script is not empty, the Step cannot have an Command and the Args will be passed to the Script.","\t// +optional","\tScript string `json:\"script,omitempty\"`","\t// Step's working directory.","\t// If not specified, the container runtime's default will be used, which","\t// might be configured in the container image.","\t// Cannot be updated.","\t// +optional","\tWorkingDir string `json:\"workingDir,omitempty\" protobuf:\"bytes,5,opt,name=workingDir\"`","\t// Params is a list of input parameters required to run the stepAction.","\t// Params must be supplied as inputs in Steps unless they declare a defaultvalue.","\t// +optional","\tParams v1.ParamSpecs `json:\"params,omitempty\"`","\t// Results are values that this StepAction can output","\t// +optional","\t// +listType=atomic","\tResults []v1.StepResult `json:\"results,omitempty\"`","\t// SecurityContext defines the security options the Step should be run with.","\t// If set, the fields of SecurityContext override the equivalent fields of PodSecurityContext.","\t// More info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/","\t// The value set in StepAction will take precedence over the value from Task.","\t// +optional","\tSecurityContext *corev1.SecurityContext `json:\"securityContext,omitempty\" protobuf:\"bytes,15,opt,name=securityContext\"`","\t// Volumes to mount into the Step's filesystem.","\t// Cannot be updated.","\t// +optional","\t// +patchMergeKey=mountPath","\t// +patchStrategy=merge","\t// +listType=atomic","\tVolumeMounts []corev1.VolumeMount `json:\"volumeMounts,omitempty\" patchMergeKey:\"mountPath\" patchStrategy:\"merge\" protobuf:\"bytes,9,rep,name=volumeMounts\"`","}","","// ToStep converts the StepActionSpec to a Step struct","func (ss *StepActionSpec) ToStep() *v1.Step {","\treturn \u0026v1.Step{","\t\tImage:           ss.Image,","\t\tCommand:         ss.Command,","\t\tArgs:            ss.Args,","\t\tWorkingDir:      ss.WorkingDir,","\t\tScript:          ss.Script,","\t\tEnv:             ss.Env,","\t\tVolumeMounts:    ss.VolumeMounts,","\t\tSecurityContext: ss.SecurityContext,","\t\tResults:         ss.Results,","\t}","}","","// StepActionObject is implemented by StepAction","type StepActionObject interface {","\tapis.Defaultable","\tStepActionMetadata() metav1.ObjectMeta","\tStepActionSpec() StepActionSpec","\tCopy() StepActionObject","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0]},{"id":101,"path":"pkg/apis/pipeline/v1beta1/stepaction_validation.go","lines":["/*","Copyright 2023 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/validate\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\tadmissionregistrationv1 \"k8s.io/api/admissionregistration/v1\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/webhook/resourcesemantics\"",")","","var (","\t_ apis.Validatable              = (*StepAction)(nil)","\t_ resourcesemantics.VerbLimited = (*StepAction)(nil)",")","","// SupportedVerbs returns the operations that validation should be called for","func (s *StepAction) SupportedVerbs() []admissionregistrationv1.OperationType {","\treturn []admissionregistrationv1.OperationType{admissionregistrationv1.Create, admissionregistrationv1.Update}","}","","// Validate implements apis.Validatable","func (s *StepAction) Validate(ctx context.Context) (errs *apis.FieldError) {","\terrs = validate.ObjectMetadata(s.GetObjectMeta()).ViaField(\"metadata\")","\terrs = errs.Also(s.Spec.Validate(apis.WithinSpec(ctx)).ViaField(\"spec\"))","\treturn errs","}","","// Validate implements apis.Validatable","func (ss *StepActionSpec) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif ss.Image == \"\" {","\t\terrs = errs.Also(apis.ErrMissingField(\"Image\"))","\t}","","\tif ss.Script != \"\" {","\t\tif len(ss.Command) \u003e 0 {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"script cannot be used with command\",","\t\t\t\tPaths:   []string{\"script\"},","\t\t\t})","\t\t}","","\t\tcleaned := strings.TrimSpace(ss.Script)","\t\tif strings.HasPrefix(cleaned, \"#!win\") {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"windows script support\", config.AlphaAPIFields).ViaField(\"script\"))","\t\t}","\t\terrs = errs.Also(validateNoParamSubstitutionsInScript(ss.Script))","\t}","\terrs = errs.Also(validateUsageOfDeclaredParameters(ctx, *ss))","\terrs = errs.Also(v1.ValidateParameterTypes(ctx, ss.Params).ViaField(\"params\"))","\terrs = errs.Also(validateParameterVariables(ctx, *ss, ss.Params))","\terrs = errs.Also(v1.ValidateStepResultsVariables(ctx, ss.Results, ss.Script))","\terrs = errs.Also(v1.ValidateStepResults(ctx, ss.Results).ViaField(\"results\"))","\terrs = errs.Also(validateVolumeMounts(ss.VolumeMounts, ss.Params).ViaField(\"volumeMounts\"))","\treturn errs","}","","// validateNoParamSubstitutionsInScript validates that param substitutions are not invoked in the script","func validateNoParamSubstitutionsInScript(script string) *apis.FieldError {","\t_, present, errString := substitution.ExtractVariablesFromString(script, \"params\")","\tif errString != \"\" || present {","\t\treturn \u0026apis.FieldError{","\t\t\tMessage: \"param substitution in scripts is not allowed.\",","\t\t\tPaths:   []string{\"script\"},","\t\t}","\t}","\treturn nil","}","","// validateUsageOfDeclaredParameters validates that all parameters referenced in the Task are declared by the Task.","func validateUsageOfDeclaredParameters(ctx context.Context, sas StepActionSpec) *apis.FieldError {","\tparams := sas.Params","\tvar errs *apis.FieldError","\t_, _, objectParams := params.SortByType()","\tallParameterNames := sets.NewString(params.GetNames()...)","\terrs = errs.Also(validateStepActionVariables(ctx, sas, \"params\", allParameterNames))","\terrs = errs.Also(ValidateObjectUsage(ctx, sas, objectParams))","\terrs = errs.Also(v1.ValidateObjectParamsHaveProperties(ctx, params))","\treturn errs","}","","func validateVolumeMounts(volumeMounts []corev1.VolumeMount, params v1.ParamSpecs) (errs *apis.FieldError) {","\tif len(volumeMounts) == 0 {","\t\treturn","\t}","\tparamNames := sets.String{}","\tfor _, p := range params {","\t\tparamNames.Insert(p.Name)","\t}","\tfor idx, v := range volumeMounts {","\t\tmatches, _ := substitution.ExtractVariableExpressions(v.Name, \"params\")","\t\tif len(matches) != 1 {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(v.Name, \"name\", \"expect the Name to be a single param reference\").ViaIndex(idx))","\t\t\treturn errs","\t\t} else if matches[0] != v.Name {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(v.Name, \"name\", \"expect the Name to be a single param reference\").ViaIndex(idx))","\t\t\treturn errs","\t\t}","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(v.Name, \"params\", paramNames).ViaIndex(idx))","\t}","\treturn errs","}","","// validateParameterVariables validates all variables within a slice of ParamSpecs against a StepAction","func validateParameterVariables(ctx context.Context, sas StepActionSpec, params v1.ParamSpecs) *apis.FieldError {","\tvar errs *apis.FieldError","\terrs = errs.Also(params.ValidateNoDuplicateNames())","\tstringParams, arrayParams, objectParams := params.SortByType()","\tstringParameterNames := sets.NewString(stringParams.GetNames()...)","\tarrayParameterNames := sets.NewString(arrayParams.GetNames()...)","\terrs = errs.Also(v1.ValidateNameFormat(stringParameterNames.Insert(arrayParameterNames.List()...), objectParams))","\treturn errs.Also(validateStepActionArrayUsage(sas, \"params\", arrayParameterNames))","}","","// ValidateObjectUsage validates the usage of individual attributes of an object param and the usage of the entire object","func ValidateObjectUsage(ctx context.Context, sas StepActionSpec, params v1.ParamSpecs) (errs *apis.FieldError) {","\tobjectParameterNames := sets.NewString()","\tfor _, p := range params {","\t\t// collect all names of object type params","\t\tobjectParameterNames.Insert(p.Name)","","\t\t// collect all keys for this object param","\t\tobjectKeys := sets.NewString()","\t\tfor key := range p.Properties {","\t\t\tobjectKeys.Insert(key)","\t\t}","","\t\t// check if the object's key names are referenced correctly i.e. param.objectParam.key1","\t\terrs = errs.Also(validateStepActionVariables(ctx, sas, \"params\\\\.\"+p.Name, objectKeys))","\t}","","\treturn errs.Also(validateStepActionObjectUsageAsWhole(sas, \"params\", objectParameterNames))","}","","// validateStepActionObjectUsageAsWhole returns an error if the StepAction contains references to the entire input object params in fields where these references are prohibited","func validateStepActionObjectUsageAsWhole(sas StepActionSpec, prefix string, vars sets.String) *apis.FieldError {","\terrs := substitution.ValidateNoReferencesToEntireProhibitedVariables(sas.Image, prefix, vars).ViaField(\"image\")","\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(sas.Script, prefix, vars).ViaField(\"script\"))","\tfor i, cmd := range sas.Command {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(cmd, prefix, vars).ViaFieldIndex(\"command\", i))","\t}","\tfor i, arg := range sas.Args {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(arg, prefix, vars).ViaFieldIndex(\"args\", i))","\t}","\tfor _, env := range sas.Env {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(env.Value, prefix, vars).ViaFieldKey(\"env\", env.Name))","\t}","\tfor i, vm := range sas.VolumeMounts {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(vm.Name, prefix, vars).ViaFieldIndex(\"volumeMounts\", i))","\t}","\treturn errs","}","","// validateStepActionArrayUsage returns an error if the Step contains references to the input array params in fields where these references are prohibited","func validateStepActionArrayUsage(sas StepActionSpec, prefix string, arrayParamNames sets.String) *apis.FieldError {","\terrs := substitution.ValidateNoReferencesToProhibitedVariables(sas.Image, prefix, arrayParamNames).ViaField(\"image\")","\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(sas.Script, prefix, arrayParamNames).ViaField(\"script\"))","\tfor i, cmd := range sas.Command {","\t\terrs = errs.Also(substitution.ValidateVariableReferenceIsIsolated(cmd, prefix, arrayParamNames).ViaFieldIndex(\"command\", i))","\t}","\tfor i, arg := range sas.Args {","\t\terrs = errs.Also(substitution.ValidateVariableReferenceIsIsolated(arg, prefix, arrayParamNames).ViaFieldIndex(\"args\", i))","\t}","\tfor _, env := range sas.Env {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(env.Value, prefix, arrayParamNames).ViaFieldKey(\"env\", env.Name))","\t}","\tfor i, vm := range sas.VolumeMounts {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(vm.Name, prefix, arrayParamNames).ViaFieldIndex(\"volumeMounts\", i))","\t}","\treturn errs","}","","// validateStepActionVariables returns an error if the StepAction contains references to any unknown variables","func validateStepActionVariables(ctx context.Context, sas StepActionSpec, prefix string, vars sets.String) *apis.FieldError {","\terrs := substitution.ValidateNoReferencesToUnknownVariables(sas.Image, prefix, vars).ViaField(\"image\")","\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(sas.Script, prefix, vars).ViaField(\"script\"))","\tfor i, cmd := range sas.Command {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(cmd, prefix, vars).ViaFieldIndex(\"command\", i))","\t}","\tfor i, arg := range sas.Args {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(arg, prefix, vars).ViaFieldIndex(\"args\", i))","\t}","\tfor _, env := range sas.Env {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(env.Value, prefix, vars).ViaFieldKey(\"env\", env.Name))","\t}","\tfor i, vm := range sas.VolumeMounts {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(vm.Name, prefix, vars).ViaFieldIndex(\"volumeMounts\", i))","\t}","\treturn errs","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,2,2,2,2,2,0,0,2,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0]},{"id":102,"path":"pkg/apis/pipeline/v1beta1/task_conversion.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"encoding/json\"","\t\"errors\"","\t\"fmt\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/version\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"knative.dev/pkg/apis\"",")","","// TaskDeprecationsAnnotationKey is the annotation key for all deprecated fields of (a) Task(s) that belong(s) to an object.","// For example: a v1beta1.Pipeline contains two tasks","//","// spec:","//","//\t tasks:","//\t - name: task-1","//\t   stepTemplate:","//\t\t name: deprecated-name-field # deprecated field","//\t - name: task-2","//\t   steps:","//\t   - tty: true # deprecated field","//","// The annotation would be:","//","//\t\"tekton.dev/v1beta1.task-deprecations\": `{","//\t   \"task1\":{","//\t      \"deprecatedStepTemplates\":{","//\t         \"name\":\"deprecated-name-field\"","//\t       },","//\t    },","//\t   \"task-2\":{","//\t      \"deprecatedSteps\":[{\"tty\":true}],","//\t    },","//\t}`","const (","\tTaskDeprecationsAnnotationKey = \"tekton.dev/v1beta1.task-deprecations\"","\tresourcesAnnotationKey        = \"tekton.dev/v1beta1Resources\"",")","","var _ apis.Convertible = (*Task)(nil)","","// ConvertTo implements apis.Convertible","func (t *Task) ConvertTo(ctx context.Context, to apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\tswitch sink := to.(type) {","\tcase *v1.Task:","\t\tsink.ObjectMeta = t.ObjectMeta","\t\tif err := serializeResources(\u0026sink.ObjectMeta, \u0026t.Spec); err != nil {","\t\t\treturn err","\t\t}","\t\treturn t.Spec.ConvertTo(ctx, \u0026sink.Spec, \u0026sink.ObjectMeta, t.Name)","\tdefault:","\t\treturn fmt.Errorf(\"unknown version, got: %T\", sink)","\t}","}","","// ConvertTo implements apis.Convertible","func (ts *TaskSpec) ConvertTo(ctx context.Context, sink *v1.TaskSpec, meta *metav1.ObjectMeta, taskName string) error {","\tif err := serializeTaskDeprecations(meta, ts, taskName); err != nil {","\t\treturn err","\t}","\tsink.Steps = nil","\tfor _, s := range ts.Steps {","\t\tnew := v1.Step{}","\t\ts.convertTo(ctx, \u0026new)","\t\tsink.Steps = append(sink.Steps, new)","\t}","\tsink.Volumes = v1.Volumes(ts.Volumes)","\tif ts.StepTemplate != nil {","\t\tnew := v1.StepTemplate{}","\t\tts.StepTemplate.convertTo(ctx, \u0026new)","\t\tsink.StepTemplate = \u0026new","\t}","\tsink.Sidecars = nil","\tfor _, s := range ts.Sidecars {","\t\tnew := v1.Sidecar{}","\t\ts.convertTo(ctx, \u0026new)","\t\tsink.Sidecars = append(sink.Sidecars, new)","\t}","\tsink.Workspaces = nil","\tfor _, w := range ts.Workspaces {","\t\tnew := v1.WorkspaceDeclaration{}","\t\tw.convertTo(ctx, \u0026new)","\t\tsink.Workspaces = append(sink.Workspaces, new)","\t}","\tsink.Results = nil","\tfor _, r := range ts.Results {","\t\tnew := v1.TaskResult{}","\t\tr.convertTo(ctx, \u0026new)","\t\tsink.Results = append(sink.Results, new)","\t}","\tsink.Params = nil","\tfor _, p := range ts.Params {","\t\tnew := v1.ParamSpec{}","\t\tp.convertTo(ctx, \u0026new)","\t\tsink.Params = append(sink.Params, new)","\t}","\tsink.DisplayName = ts.DisplayName","\tsink.Description = ts.Description","\treturn nil","}","","// ConvertFrom implements apis.Convertible","func (t *Task) ConvertFrom(ctx context.Context, from apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\tswitch source := from.(type) {","\tcase *v1.Task:","\t\tt.ObjectMeta = source.ObjectMeta","\t\tif err := deserializeResources(\u0026t.ObjectMeta, \u0026t.Spec); err != nil {","\t\t\treturn err","\t\t}","\t\treturn t.Spec.ConvertFrom(ctx, \u0026source.Spec, \u0026t.ObjectMeta, t.Name)","\tdefault:","\t\treturn fmt.Errorf(\"unknown version, got: %T\", t)","\t}","}","","// ConvertFrom implements apis.Convertible","func (ts *TaskSpec) ConvertFrom(ctx context.Context, source *v1.TaskSpec, meta *metav1.ObjectMeta, taskName string) error {","\tts.Steps = nil","\tfor _, s := range source.Steps {","\t\tnew := Step{}","\t\tnew.convertFrom(ctx, s)","\t\tts.Steps = append(ts.Steps, new)","\t}","\tts.Volumes = Volumes(source.Volumes)","\tif source.StepTemplate != nil {","\t\tnew := StepTemplate{}","\t\tnew.convertFrom(ctx, source.StepTemplate)","\t\tts.StepTemplate = \u0026new","\t}","\tif err := deserializeTaskDeprecations(meta, ts, taskName); err != nil {","\t\treturn err","\t}","\tts.Sidecars = nil","\tfor _, s := range source.Sidecars {","\t\tnew := Sidecar{}","\t\tnew.convertFrom(ctx, s)","\t\tts.Sidecars = append(ts.Sidecars, new)","\t}","\tts.Workspaces = nil","\tfor _, w := range source.Workspaces {","\t\tnew := WorkspaceDeclaration{}","\t\tnew.convertFrom(ctx, w)","\t\tts.Workspaces = append(ts.Workspaces, new)","\t}","\tts.Results = nil","\tfor _, r := range source.Results {","\t\tnew := TaskResult{}","\t\tnew.convertFrom(ctx, r)","\t\tts.Results = append(ts.Results, new)","\t}","\tts.Params = nil","\tfor _, p := range source.Params {","\t\tnew := ParamSpec{}","\t\tnew.convertFrom(ctx, p)","\t\tts.Params = append(ts.Params, new)","\t}","\tts.DisplayName = source.DisplayName","\tts.Description = source.Description","\treturn nil","}","","// taskDeprecation contains deprecated fields of a Task","// +k8s:openapi-gen=false","type taskDeprecation struct {","\t// DeprecatedSteps contains Steps of a Task that with deprecated fields defined.","\t// +listType=atomic","\tDeprecatedSteps []Step `json:\"deprecatedSteps,omitempty\"`","\t// DeprecatedStepTemplate contains stepTemplate of a Task that with deprecated fields defined.","\tDeprecatedStepTemplate *StepTemplate `json:\"deprecatedStepTemplate,omitempty\"`","}","","// taskDeprecations contains deprecated fields of Tasks that belong to the same Pipeline or PipelineRun","// the key is Task name","// +k8s:openapi-gen=false","type taskDeprecations map[string]taskDeprecation","","// serializeTaskDeprecations appends the current Task's deprecation info to annotation of the object.","// The object could be Task, TaskRun, Pipeline or PipelineRun","func serializeTaskDeprecations(meta *metav1.ObjectMeta, spec *TaskSpec, taskName string) error {","\tvar taskDeprecation *taskDeprecation","\tif spec.HasDeprecatedFields() {","\t\ttaskDeprecation = retrieveTaskDeprecation(spec)","\t}","\texistingDeprecations := taskDeprecations{}","\tif str, ok := meta.Annotations[TaskDeprecationsAnnotationKey]; ok {","\t\tif err := json.Unmarshal([]byte(str), \u0026existingDeprecations); err != nil {","\t\t\treturn fmt.Errorf(\"error serializing key %s from metadata: %w\", TaskDeprecationsAnnotationKey, err)","\t\t}","\t}","\tif taskDeprecation != nil {","\t\texistingDeprecations[taskName] = *taskDeprecation","\t\treturn version.SerializeToMetadata(meta, existingDeprecations, TaskDeprecationsAnnotationKey)","\t}","\treturn nil","}","","// deserializeTaskDeprecations retrieves deprecation info of the Task from object annotation.","// The object could be Task, TaskRun, Pipeline or PipelineRun.","func deserializeTaskDeprecations(meta *metav1.ObjectMeta, spec *TaskSpec, taskName string) error {","\texistingDeprecations := taskDeprecations{}","\tif meta == nil || meta.Annotations == nil {","\t\treturn nil","\t}","\tif str, ok := meta.Annotations[TaskDeprecationsAnnotationKey]; ok {","\t\tif err := json.Unmarshal([]byte(str), \u0026existingDeprecations); err != nil {","\t\t\treturn fmt.Errorf(\"error deserializing key %s from metadata: %w\", TaskDeprecationsAnnotationKey, err)","\t\t}","\t}","\tif td, ok := existingDeprecations[taskName]; ok {","\t\tif len(spec.Steps) != len(td.DeprecatedSteps) {","\t\t\treturn errors.New(\"length of deserialized steps mismatch the length of target steps\")","\t\t}","\t\tfor i := range len(spec.Steps) {","\t\t\tspec.Steps[i].DeprecatedPorts = td.DeprecatedSteps[i].DeprecatedPorts","\t\t\tspec.Steps[i].DeprecatedLivenessProbe = td.DeprecatedSteps[i].DeprecatedLivenessProbe","\t\t\tspec.Steps[i].DeprecatedReadinessProbe = td.DeprecatedSteps[i].DeprecatedReadinessProbe","\t\t\tspec.Steps[i].DeprecatedStartupProbe = td.DeprecatedSteps[i].DeprecatedStartupProbe","\t\t\tspec.Steps[i].DeprecatedLifecycle = td.DeprecatedSteps[i].DeprecatedLifecycle","\t\t\tspec.Steps[i].DeprecatedTerminationMessagePath = td.DeprecatedSteps[i].DeprecatedTerminationMessagePath","\t\t\tspec.Steps[i].DeprecatedTerminationMessagePolicy = td.DeprecatedSteps[i].DeprecatedTerminationMessagePolicy","\t\t\tspec.Steps[i].DeprecatedStdin = td.DeprecatedSteps[i].DeprecatedStdin","\t\t\tspec.Steps[i].DeprecatedStdinOnce = td.DeprecatedSteps[i].DeprecatedStdinOnce","\t\t\tspec.Steps[i].DeprecatedTTY = td.DeprecatedSteps[i].DeprecatedTTY","\t\t}","\t\tif td.DeprecatedStepTemplate != nil {","\t\t\tif spec.StepTemplate == nil {","\t\t\t\tspec.StepTemplate = \u0026StepTemplate{}","\t\t\t}","\t\t\tspec.StepTemplate.DeprecatedName = td.DeprecatedStepTemplate.DeprecatedName","\t\t\tspec.StepTemplate.DeprecatedPorts = td.DeprecatedStepTemplate.DeprecatedPorts","\t\t\tspec.StepTemplate.DeprecatedLivenessProbe = td.DeprecatedStepTemplate.DeprecatedLivenessProbe","\t\t\tspec.StepTemplate.DeprecatedReadinessProbe = td.DeprecatedStepTemplate.DeprecatedReadinessProbe","\t\t\tspec.StepTemplate.DeprecatedStartupProbe = td.DeprecatedStepTemplate.DeprecatedStartupProbe","\t\t\tspec.StepTemplate.DeprecatedLifecycle = td.DeprecatedStepTemplate.DeprecatedLifecycle","\t\t\tspec.StepTemplate.DeprecatedTerminationMessagePath = td.DeprecatedStepTemplate.DeprecatedTerminationMessagePath","\t\t\tspec.StepTemplate.DeprecatedTerminationMessagePolicy = td.DeprecatedStepTemplate.DeprecatedTerminationMessagePolicy","\t\t\tspec.StepTemplate.DeprecatedStdin = td.DeprecatedStepTemplate.DeprecatedStdin","\t\t\tspec.StepTemplate.DeprecatedStdinOnce = td.DeprecatedStepTemplate.DeprecatedStdinOnce","\t\t\tspec.StepTemplate.DeprecatedTTY = td.DeprecatedStepTemplate.DeprecatedTTY","\t\t}","\t\tdelete(existingDeprecations, taskName)","\t\tif len(existingDeprecations) == 0 {","\t\t\tdelete(meta.Annotations, TaskDeprecationsAnnotationKey)","\t\t} else {","\t\t\tupdatedDeprecations, err := json.Marshal(existingDeprecations)","\t\t\tif err != nil {","\t\t\t\treturn err","\t\t\t}","\t\t\tmeta.Annotations[TaskDeprecationsAnnotationKey] = string(updatedDeprecations)","\t\t}","\t\tif len(meta.Annotations) == 0 {","\t\t\tmeta.Annotations = nil","\t\t}","\t}","\treturn nil","}","","func retrieveTaskDeprecation(spec *TaskSpec) *taskDeprecation {","\tif !spec.HasDeprecatedFields() {","\t\treturn nil","\t}","\tds := []Step{}","\tfor _, s := range spec.Steps {","\t\tds = append(ds, Step{","\t\t\tDeprecatedPorts:                    s.DeprecatedPorts,","\t\t\tDeprecatedLivenessProbe:            s.DeprecatedLivenessProbe,","\t\t\tDeprecatedReadinessProbe:           s.DeprecatedReadinessProbe,","\t\t\tDeprecatedStartupProbe:             s.DeprecatedStartupProbe,","\t\t\tDeprecatedLifecycle:                s.DeprecatedLifecycle,","\t\t\tDeprecatedTerminationMessagePath:   s.DeprecatedTerminationMessagePath,","\t\t\tDeprecatedTerminationMessagePolicy: s.DeprecatedTerminationMessagePolicy,","\t\t\tDeprecatedStdin:                    s.DeprecatedStdin,","\t\t\tDeprecatedStdinOnce:                s.DeprecatedStdinOnce,","\t\t\tDeprecatedTTY:                      s.DeprecatedTTY,","\t\t})","\t}","\tvar dst *StepTemplate","\tif spec.StepTemplate != nil {","\t\tdst = \u0026StepTemplate{","\t\t\tDeprecatedName:                     spec.StepTemplate.DeprecatedName,","\t\t\tDeprecatedPorts:                    spec.StepTemplate.DeprecatedPorts,","\t\t\tDeprecatedLivenessProbe:            spec.StepTemplate.DeprecatedLivenessProbe,","\t\t\tDeprecatedReadinessProbe:           spec.StepTemplate.DeprecatedReadinessProbe,","\t\t\tDeprecatedStartupProbe:             spec.StepTemplate.DeprecatedStartupProbe,","\t\t\tDeprecatedLifecycle:                spec.StepTemplate.DeprecatedLifecycle,","\t\t\tDeprecatedTerminationMessagePath:   spec.StepTemplate.DeprecatedTerminationMessagePath,","\t\t\tDeprecatedTerminationMessagePolicy: spec.StepTemplate.DeprecatedTerminationMessagePolicy,","\t\t\tDeprecatedStdin:                    spec.StepTemplate.DeprecatedStdin,","\t\t\tDeprecatedStdinOnce:                spec.StepTemplate.DeprecatedStdinOnce,","\t\t\tDeprecatedTTY:                      spec.StepTemplate.DeprecatedTTY,","\t\t}","\t}","\treturn \u0026taskDeprecation{","\t\tDeprecatedSteps:        ds,","\t\tDeprecatedStepTemplate: dst,","\t}","}","","func serializeResources(meta *metav1.ObjectMeta, spec *TaskSpec) error {","\tif spec.Resources == nil {","\t\treturn nil","\t}","\treturn version.SerializeToMetadata(meta, spec.Resources, resourcesAnnotationKey)","}","","func deserializeResources(meta *metav1.ObjectMeta, spec *TaskSpec) error {","\tresources := \u0026TaskResources{}","\terr := version.DeserializeFromMetadata(meta, resources, resourcesAnnotationKey)","\tif err != nil {","\t\treturn err","\t}","\tif resources.Inputs != nil || resources.Outputs != nil {","\t\tspec.Resources = resources","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,2,2,2,2,1,1,2,2,2,0,0,0,0,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,1,1,2,2,2,2,1,1,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,1,1,0,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,1,1,2,0,2,2,2,0,2,0,0,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,0,2,2,2,2,1,1,2,2,2,2,0]},{"id":103,"path":"pkg/apis/pipeline/v1beta1/task_defaults.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Defaultable = (*Task)(nil)","","// SetDefaults implements apis.Defaultable","func (t *Task) SetDefaults(ctx context.Context) {","\tt.Spec.SetDefaults(ctx)","}","","// SetDefaults set any defaults for the task spec","func (ts *TaskSpec) SetDefaults(ctx context.Context) {","\tfor i := range ts.Params {","\t\tts.Params[i].SetDefaults(ctx)","\t}","\tfor i := range ts.Results {","\t\tts.Results[i].SetDefaults(ctx)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,2,2,2,2,2,2,2,0]},{"id":104,"path":"pkg/apis/pipeline/v1beta1/task_types.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/internal/checksum\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"","\t\"knative.dev/pkg/kmeta\"",")","","// +genclient","// +genclient:noStatus","// +genreconciler:krshapedlogic=false","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","// +k8s:openapi-gen=true","","// Task represents a collection of sequential steps that are run as part of a","// Pipeline using a set of inputs and producing a set of outputs. Tasks execute","// when TaskRuns are created that provide the input parameters and resources and","// output resources the Task requires.","//","// Deprecated: Please use v1.Task instead.","type Task struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ObjectMeta `json:\"metadata\"`","","\t// Spec holds the desired state of the Task from the client","\t// +optional","\tSpec TaskSpec `json:\"spec\"`","}","","var _ kmeta.OwnerRefable = (*Task)(nil)","","// TaskSpec returns the task's spec","func (t *Task) TaskSpec() TaskSpec {","\treturn t.Spec","}","","// TaskMetadata returns the task's ObjectMeta","func (t *Task) TaskMetadata() metav1.ObjectMeta {","\treturn t.ObjectMeta","}","","// Copy returns a deep copy of the task","func (t *Task) Copy() TaskObject {","\treturn t.DeepCopy()","}","","// GetGroupVersionKind implements kmeta.OwnerRefable.","func (*Task) GetGroupVersionKind() schema.GroupVersionKind {","\treturn SchemeGroupVersion.WithKind(pipeline.TaskControllerName)","}","","// Checksum computes the sha256 checksum of the task object.","// Prior to computing the checksum, it performs some preprocessing on the","// metadata of the object where it removes system provided annotations.","// Only the name, namespace, generateName, user-provided labels and annotations","// and the taskSpec are included for the checksum computation.","func (t *Task) Checksum() ([]byte, error) {","\tobjectMeta := checksum.PrepareObjectMeta(t)","\tpreprocessedTask := Task{","\t\tTypeMeta: metav1.TypeMeta{","\t\t\tAPIVersion: \"tekton.dev/v1beta1\",","\t\t\tKind:       \"Task\"},","\t\tObjectMeta: objectMeta,","\t\tSpec:       t.Spec,","\t}","\tsha256Checksum, err := checksum.ComputeSha256Checksum(preprocessedTask)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn sha256Checksum, nil","}","","// +listType=atomic","type Volumes []corev1.Volume","","// TaskSpec defines the desired state of Task.","type TaskSpec struct {","\t// Resources is a list input and output resource to run the task","\t// Resources are represented in TaskRuns as bindings to instances of","\t// PipelineResources.","\t//","\t// Deprecated: Unused, preserved only for backwards compatibility","\t// +optional","\tResources *TaskResources `json:\"resources,omitempty\"`","","\t// Params is a list of input parameters required to run the task. Params","\t// must be supplied as inputs in TaskRuns unless they declare a default","\t// value.","\t// +optional","\tParams ParamSpecs `json:\"params,omitempty\"`","","\t// DisplayName is a user-facing name of the task that may be","\t// used to populate a UI.","\t// +optional","\tDisplayName string `json:\"displayName,omitempty\"`","","\t// Description is a user-facing description of the task that may be","\t// used to populate a UI.","\t// +optional","\tDescription string `json:\"description,omitempty\"`","","\t// Steps are the steps of the build; each step is run sequentially with the","\t// source mounted into /workspace.","\t// +listType=atomic","\tSteps []Step `json:\"steps,omitempty\"`","","\t// Volumes is a collection of volumes that are available to mount into the","\t// steps of the build.","\t// See Pod.spec.volumes (API version: v1)","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tVolumes Volumes `json:\"volumes,omitempty\"`","","\t// StepTemplate can be used as the basis for all step containers within the","\t// Task, so that the steps inherit settings on the base container.","\tStepTemplate *StepTemplate `json:\"stepTemplate,omitempty\"`","","\t// Sidecars are run alongside the Task's step containers. They begin before","\t// the steps start and end after the steps complete.","\t// +listType=atomic","\tSidecars []Sidecar `json:\"sidecars,omitempty\"`","","\t// Workspaces are the volumes that this Task requires.","\t// +listType=atomic","\tWorkspaces []WorkspaceDeclaration `json:\"workspaces,omitempty\"`","","\t// Results are values that this Task can output","\t// +listType=atomic","\tResults []TaskResult `json:\"results,omitempty\"`","}","","// TaskList contains a list of Task","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","type TaskList struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ListMeta `json:\"metadata,omitempty\"`","\tItems           []Task `json:\"items\"`","}","","// HasDeprecatedFields returns true if the TaskSpec has deprecated field specified.","func (ts *TaskSpec) HasDeprecatedFields() bool {","\tif ts == nil {","\t\treturn false","\t}","\tif len(ts.Steps) \u003e 0 {","\t\tfor _, s := range ts.Steps {","\t\t\tif len(s.DeprecatedPorts) \u003e 0 ||","\t\t\t\ts.DeprecatedLivenessProbe != nil ||","\t\t\t\ts.DeprecatedReadinessProbe != nil ||","\t\t\t\ts.DeprecatedStartupProbe != nil ||","\t\t\t\ts.DeprecatedLifecycle != nil ||","\t\t\t\ts.DeprecatedTerminationMessagePath != \"\" ||","\t\t\t\ts.DeprecatedTerminationMessagePolicy != \"\" ||","\t\t\t\ts.DeprecatedStdin ||","\t\t\t\ts.DeprecatedStdinOnce ||","\t\t\t\ts.DeprecatedTTY {","\t\t\t\treturn true","\t\t\t}","\t\t}","\t}","\tif ts.StepTemplate != nil {","\t\tif len(ts.StepTemplate.DeprecatedPorts) \u003e 0 ||","\t\t\tts.StepTemplate.DeprecatedName != \"\" ||","\t\t\tts.StepTemplate.DeprecatedReadinessProbe != nil ||","\t\t\tts.StepTemplate.DeprecatedStartupProbe != nil ||","\t\t\tts.StepTemplate.DeprecatedLifecycle != nil ||","\t\t\tts.StepTemplate.DeprecatedTerminationMessagePath != \"\" ||","\t\t\tts.StepTemplate.DeprecatedTerminationMessagePolicy != \"\" ||","\t\t\tts.StepTemplate.DeprecatedStdin ||","\t\t\tts.StepTemplate.DeprecatedStdinOnce ||","\t\t\tts.StepTemplate.DeprecatedTTY {","\t\t\treturn true","\t\t}","\t}","\treturn false","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,0]},{"id":105,"path":"pkg/apis/pipeline/v1beta1/task_validation.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"fmt\"","\t\"path/filepath\"","\t\"regexp\"","\t\"slices\"","\t\"strings\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/internal/artifactref\"","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/validate\"","\t\"github.com/tektoncd/pipeline/pkg/internal/resultref\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","","\tadmissionregistrationv1 \"k8s.io/api/admissionregistration/v1\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"k8s.io/apimachinery/pkg/util/validation\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/webhook/resourcesemantics\"",")","","const (","\t// stringAndArrayVariableNameFormat is the regex to validate if string/array variable name format follows the following rules.","\t// - Must only contain alphanumeric characters, hyphens (-), underscores (_), and dots (.)","\t// - Must begin with a letter or an underscore (_)","\tstringAndArrayVariableNameFormat = \"^[_a-zA-Z][_a-zA-Z0-9.-]*$\"","","\t// objectVariableNameFormat is the regext used to validate object name and key names format","\t// The difference with the array or string name format is that object variable names shouldn't contain dots.","\tobjectVariableNameFormat = \"^[_a-zA-Z][_a-zA-Z0-9-]*$\"",")","","var (","\t_ apis.Validatable              = (*Task)(nil)","\t_ resourcesemantics.VerbLimited = (*Task)(nil)",")","","// SupportedVerbs returns the operations that validation should be called for","func (t *Task) SupportedVerbs() []admissionregistrationv1.OperationType {","\treturn []admissionregistrationv1.OperationType{admissionregistrationv1.Create, admissionregistrationv1.Update}","}","","var (","\tstringAndArrayVariableNameFormatRegex = regexp.MustCompile(stringAndArrayVariableNameFormat)","\tobjectVariableNameFormatRegex         = regexp.MustCompile(objectVariableNameFormat)",")","","// Validate implements apis.Validatable","func (t *Task) Validate(ctx context.Context) *apis.FieldError {","\terrs := validate.ObjectMetadata(t.GetObjectMeta()).ViaField(\"metadata\")","\terrs = errs.Also(t.Spec.Validate(apis.WithinSpec(ctx)).ViaField(\"spec\"))","\t// When a Task is created directly, instead of declared inline in a TaskRun or PipelineRun,","\t// we do not support propagated parameters. Validate that all params it uses are declared.","\treturn errs.Also(ValidateUsageOfDeclaredParameters(ctx, t.Spec.Steps, t.Spec.Params).ViaField(\"spec\"))","}","","// Validate implements apis.Validatable","func (ts *TaskSpec) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif len(ts.Steps) == 0 {","\t\terrs = errs.Also(apis.ErrMissingField(\"steps\"))","\t}","","\terrs = errs.Also(ValidateVolumes(ts.Volumes).ViaField(\"volumes\"))","\terrs = errs.Also(validateDeclaredWorkspaces(ts.Workspaces, ts.Steps, ts.StepTemplate).ViaField(\"workspaces\"))","\terrs = errs.Also(validateWorkspaceUsages(ctx, ts))","\tmergedSteps, err := MergeStepsWithStepTemplate(ts.StepTemplate, ts.Steps)","\tif err != nil {","\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(\"error merging step template and steps: %s\", err),","\t\t\tPaths:   []string{\"stepTemplate\"},","\t\t\tDetails: err.Error(),","\t\t})","\t}","","\terrs = errs.Also(validateSteps(ctx, mergedSteps).ViaField(\"steps\"))","\terrs = errs.Also(validateSidecarNames(ts.Sidecars))","\terrs = errs.Also(ValidateParameterTypes(ctx, ts.Params).ViaField(\"params\"))","\terrs = errs.Also(ValidateParameterVariables(ctx, ts.Steps, ts.Params))","\terrs = errs.Also(validateTaskContextVariables(ctx, ts.Steps))","\terrs = errs.Also(validateTaskResultsVariables(ctx, ts.Steps, ts.Results))","\terrs = errs.Also(validateResults(ctx, ts.Results).ViaField(\"results\"))","\tif ts.Resources != nil {","\t\terrs = errs.Also(apis.ErrDisallowedFields(\"resources\"))","\t}","\treturn errs","}","","// ValidateUsageOfDeclaredParameters validates that all parameters referenced in the Task are declared by the Task.","func ValidateUsageOfDeclaredParameters(ctx context.Context, steps []Step, params ParamSpecs) *apis.FieldError {","\tvar errs *apis.FieldError","\t_, _, objectParams := params.sortByType()","\tallParameterNames := sets.NewString(params.getNames()...)","\terrs = errs.Also(validateVariables(ctx, steps, \"params\", allParameterNames))","\terrs = errs.Also(validateObjectUsage(ctx, steps, objectParams))","\terrs = errs.Also(validateObjectParamsHaveProperties(ctx, params))","\treturn errs","}","","// validateObjectParamsHaveProperties returns an error if any declared object params are missing properties","func validateObjectParamsHaveProperties(ctx context.Context, params ParamSpecs) *apis.FieldError {","\tvar errs *apis.FieldError","\tfor _, p := range params {","\t\tif p.Type == ParamTypeObject \u0026\u0026 p.Properties == nil {","\t\t\terrs = errs.Also(apis.ErrMissingField(p.Name + \".properties\"))","\t\t}","\t}","\treturn errs","}","","func validateSidecarNames(sidecars []Sidecar) (errs *apis.FieldError) {","\tfor _, sc := range sidecars {","\t\tif sc.Name == pipeline.ReservedResultsSidecarName {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: fmt.Sprintf(\"Invalid: cannot use reserved sidecar name %v \", sc.Name),","\t\t\t\tPaths:   []string{\"sidecars\"},","\t\t\t})","\t\t}","\t}","\treturn errs","}","","func validateResults(ctx context.Context, results []TaskResult) (errs *apis.FieldError) {","\tfor index, result := range results {","\t\terrs = errs.Also(result.Validate(ctx).ViaIndex(index))","\t}","\treturn errs","}","","// a mount path which conflicts with any other declared workspaces, with the explicitly","// declared volume mounts, or with the stepTemplate. The names must also be unique.","func validateDeclaredWorkspaces(workspaces []WorkspaceDeclaration, steps []Step, stepTemplate *StepTemplate) (errs *apis.FieldError) {","\tmountPaths := sets.NewString()","\tfor _, step := range steps {","\t\tfor _, vm := range step.VolumeMounts {","\t\t\tmountPaths.Insert(filepath.Clean(vm.MountPath))","\t\t}","\t}","\tif stepTemplate != nil {","\t\tfor _, vm := range stepTemplate.VolumeMounts {","\t\t\tmountPaths.Insert(filepath.Clean(vm.MountPath))","\t\t}","\t}","","\twsNames := sets.NewString()","\tfor idx, w := range workspaces {","\t\t// Workspace names must be unique","\t\tif wsNames.Has(w.Name) {","\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"workspace name %q must be unique\", w.Name), \"name\").ViaIndex(idx))","\t\t} else {","\t\t\twsNames.Insert(w.Name)","\t\t}","\t\t// Workspaces must not try to use mount paths that are already used","\t\tmountPath := filepath.Clean(w.GetMountPath())","\t\tif _, ok := mountPaths[mountPath]; ok {","\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"workspace mount path %q must be unique\", mountPath), \"mountpath\").ViaIndex(idx))","\t\t}","\t\tmountPaths[mountPath] = struct{}{}","\t}","\treturn errs","}","","// validateWorkspaceUsages checks that all WorkspaceUsage objects in Steps","// refer to workspaces that are defined in the Task.","//","// This is a beta feature and will fail validation if it's used by a step","// or sidecar when the enable-api-fields feature gate is anything but \"beta\".","//","// Note that this feature reached beta after the v1 API version has been released and","// consequently it is *not* implicitly enabled on the v1beta1 API to avoid suffering","// from the issues described in TEP-0138 https://github.com/tektoncd/community/pull/1034","func validateWorkspaceUsages(ctx context.Context, ts *TaskSpec) (errs *apis.FieldError) {","\tworkspaces := ts.Workspaces","\tsteps := ts.Steps","\tsidecars := ts.Sidecars","","\twsNames := sets.NewString()","\tfor _, w := range workspaces {","\t\twsNames.Insert(w.Name)","\t}","","\tfor stepIdx, step := range steps {","\t\tif len(step.Workspaces) != 0 {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"step workspaces\", config.BetaAPIFields).ViaIndex(stepIdx).ViaField(\"steps\"))","\t\t}","\t\tfor workspaceIdx, w := range step.Workspaces {","\t\t\tif !wsNames.Has(w.Name) {","\t\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"undefined workspace %q\", w.Name), \"name\").ViaIndex(workspaceIdx).ViaField(\"workspaces\").ViaIndex(stepIdx).ViaField(\"steps\"))","\t\t\t}","\t\t}","\t}","","\tfor sidecarIdx, sidecar := range sidecars {","\t\tif len(sidecar.Workspaces) != 0 {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"sidecar workspaces\", config.BetaAPIFields).ViaIndex(sidecarIdx).ViaField(\"sidecars\"))","\t\t}","\t\tfor workspaceIdx, w := range sidecar.Workspaces {","\t\t\tif !wsNames.Has(w.Name) {","\t\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"undefined workspace %q\", w.Name), \"name\").ViaIndex(workspaceIdx).ViaField(\"workspaces\").ViaIndex(sidecarIdx).ViaField(\"sidecars\"))","\t\t\t}","\t\t}","\t}","","\treturn errs","}","","// ValidateVolumes validates a slice of volumes to make sure there are no dupilcate names","func ValidateVolumes(volumes []corev1.Volume) (errs *apis.FieldError) {","\t// Task must not have duplicate volume names.","\tvols := sets.NewString()","\tfor idx, v := range volumes {","\t\tif vols.Has(v.Name) {","\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"multiple volumes with same name %q\", v.Name), \"name\").ViaIndex(idx))","\t\t} else {","\t\t\tvols.Insert(v.Name)","\t\t}","\t}","\treturn errs","}","","func validateSteps(ctx context.Context, steps []Step) (errs *apis.FieldError) {","\t// Task must not have duplicate step names.","\tnames := sets.NewString()","\tfor idx, s := range steps {","\t\terrs = errs.Also(validateStep(ctx, s, names).ViaIndex(idx))","\t\tif s.Results != nil {","\t\t\terrs = errs.Also(v1.ValidateStepResultsVariables(ctx, s.Results, s.Script).ViaIndex(idx))","\t\t\terrs = errs.Also(v1.ValidateStepResults(ctx, s.Results).ViaIndex(idx).ViaField(\"results\"))","\t\t}","\t\tif len(s.When) \u003e 0 {","\t\t\terrs = errs.Also(s.When.validate(ctx).ViaIndex(idx))","\t\t}","\t}","\treturn errs","}","","func errorIfStepResultReferenceinField(value, fieldName string) (errs *apis.FieldError) {","\tmatches := resultref.StepResultRegex.FindAllStringSubmatch(value, -1)","\tif len(matches) \u003e 0 {","\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\tMessage: \"stepResult substitutions are only allowed in env, command and args. Found usage in\",","\t\t\tPaths:   []string{fieldName},","\t\t})","\t}","\treturn errs","}","","func stepArtifactReferenceExists(src string) bool {","\treturn len(artifactref.StepArtifactRegex.FindAllStringSubmatch(src, -1)) \u003e 0 || strings.Contains(src, \"$(\"+artifactref.StepArtifactPathPattern+\")\")","}","","func taskArtifactReferenceExists(src string) bool {","\treturn len(artifactref.TaskArtifactRegex.FindAllStringSubmatch(src, -1)) \u003e 0 || strings.Contains(src, \"$(\"+artifactref.TaskArtifactPathPattern+\")\")","}","","func errorIfStepArtifactReferencedInField(value, fieldName string) (errs *apis.FieldError) {","\tif stepArtifactReferenceExists(value) {","\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\tMessage: \"stepArtifact substitutions are only allowed in env, command, args and script. Found usage in\",","\t\t\tPaths:   []string{fieldName},","\t\t})","\t}","\treturn errs","}","","func validateStepArtifactsReference(s Step) (errs *apis.FieldError) {","\terrs = errs.Also(errorIfStepArtifactReferencedInField(s.Name, \"name\"))","\terrs = errs.Also(errorIfStepArtifactReferencedInField(s.Image, \"image\"))","\terrs = errs.Also(errorIfStepArtifactReferencedInField(string(s.ImagePullPolicy), \"imagePullPolicy\"))","\terrs = errs.Also(errorIfStepArtifactReferencedInField(s.WorkingDir, \"workingDir\"))","\tfor _, e := range s.EnvFrom {","\t\terrs = errs.Also(errorIfStepArtifactReferencedInField(e.Prefix, \"envFrom.prefix\"))","\t\tif e.ConfigMapRef != nil {","\t\t\terrs = errs.Also(errorIfStepArtifactReferencedInField(e.ConfigMapRef.LocalObjectReference.Name, \"envFrom.configMapRef\"))","\t\t}","\t\tif e.SecretRef != nil {","\t\t\terrs = errs.Also(errorIfStepArtifactReferencedInField(e.SecretRef.LocalObjectReference.Name, \"envFrom.secretRef\"))","\t\t}","\t}","\tfor _, v := range s.VolumeMounts {","\t\terrs = errs.Also(errorIfStepArtifactReferencedInField(v.Name, \"volumeMounts.name\"))","\t\terrs = errs.Also(errorIfStepArtifactReferencedInField(v.MountPath, \"volumeMounts.mountPath\"))","\t\terrs = errs.Also(errorIfStepArtifactReferencedInField(v.SubPath, \"volumeMounts.subPath\"))","\t}","\tfor _, v := range s.VolumeDevices {","\t\terrs = errs.Also(errorIfStepArtifactReferencedInField(v.Name, \"volumeDevices.name\"))","\t\terrs = errs.Also(errorIfStepArtifactReferencedInField(v.DevicePath, \"volumeDevices.devicePath\"))","\t}","\treturn errs","}","","func validateStepResultReference(s Step) (errs *apis.FieldError) {","\terrs = errs.Also(errorIfStepResultReferenceinField(s.Name, \"name\"))","\terrs = errs.Also(errorIfStepResultReferenceinField(s.Image, \"image\"))","\terrs = errs.Also(errorIfStepResultReferenceinField(s.Script, \"script\"))","\terrs = errs.Also(errorIfStepResultReferenceinField(string(s.ImagePullPolicy), \"imagePullPolicy\"))","\terrs = errs.Also(errorIfStepResultReferenceinField(s.WorkingDir, \"workingDir\"))","\tfor _, e := range s.EnvFrom {","\t\terrs = errs.Also(errorIfStepResultReferenceinField(e.Prefix, \"envFrom.prefix\"))","\t\tif e.ConfigMapRef != nil {","\t\t\terrs = errs.Also(errorIfStepResultReferenceinField(e.ConfigMapRef.LocalObjectReference.Name, \"envFrom.configMapRef\"))","\t\t}","\t\tif e.SecretRef != nil {","\t\t\terrs = errs.Also(errorIfStepResultReferenceinField(e.SecretRef.LocalObjectReference.Name, \"envFrom.secretRef\"))","\t\t}","\t}","\tfor _, v := range s.VolumeMounts {","\t\terrs = errs.Also(errorIfStepResultReferenceinField(v.Name, \"volumeMounts.name\"))","\t\terrs = errs.Also(errorIfStepResultReferenceinField(v.MountPath, \"volumeMounts.mountPath\"))","\t\terrs = errs.Also(errorIfStepResultReferenceinField(v.SubPath, \"volumeMounts.subPath\"))","\t}","\tfor _, v := range s.VolumeDevices {","\t\terrs = errs.Also(errorIfStepResultReferenceinField(v.Name, \"volumeDevices.name\"))","\t\terrs = errs.Also(errorIfStepResultReferenceinField(v.DevicePath, \"volumeDevices.devicePath\"))","\t}","\treturn errs","}","","func validateStep(ctx context.Context, s Step, names sets.String) (errs *apis.FieldError) {","\tif err := validateArtifactsReferencesInStep(ctx, s); err != nil {","\t\treturn err","\t}","","\tif s.Ref != nil {","\t\terrs = errs.Also(s.Ref.Validate(ctx))","\t\tif s.Image != \"\" {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"image cannot be used with Ref\",","\t\t\t\tPaths:   []string{\"image\"},","\t\t\t})","\t\t}","\t\tif len(s.Command) \u003e 0 {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"command cannot be used with Ref\",","\t\t\t\tPaths:   []string{\"command\"},","\t\t\t})","\t\t}","\t\tif len(s.Args) \u003e 0 {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"args cannot be used with Ref\",","\t\t\t\tPaths:   []string{\"args\"},","\t\t\t})","\t\t}","\t\tif s.Script != \"\" {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"script cannot be used with Ref\",","\t\t\t\tPaths:   []string{\"script\"},","\t\t\t})","\t\t}","\t\tif s.WorkingDir != \"\" {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"working dir cannot be used with Ref\",","\t\t\t\tPaths:   []string{\"workingDir\"},","\t\t\t})","\t\t}","\t\tif s.Env != nil {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"env cannot be used with Ref\",","\t\t\t\tPaths:   []string{\"env\"},","\t\t\t})","\t\t}","\t\tif len(s.VolumeMounts) \u003e 0 {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"volumeMounts cannot be used with Ref\",","\t\t\t\tPaths:   []string{\"volumeMounts\"},","\t\t\t})","\t\t}","\t\tif len(s.Results) \u003e 0 {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"results cannot be used with Ref\",","\t\t\t\tPaths:   []string{\"results\"},","\t\t\t})","\t\t}","\t} else {","\t\tif len(s.Params) \u003e 0 {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: \"params cannot be used without Ref\",","\t\t\t\tPaths:   []string{\"params\"},","\t\t\t})","\t\t}","\t\tif s.Image == \"\" {","\t\t\terrs = errs.Also(apis.ErrMissingField(\"Image\"))","\t\t}","","\t\tif s.Script != \"\" {","\t\t\tif len(s.Command) \u003e 0 {","\t\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\t\tMessage: \"script cannot be used with command\",","\t\t\t\t\tPaths:   []string{\"script\"},","\t\t\t\t})","\t\t\t}","\t\t}","\t}","","\tif s.Name != \"\" {","\t\tif names.Has(s.Name) {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(s.Name, \"name\"))","\t\t}","\t\tif e := validation.IsDNS1123Label(s.Name); len(e) \u003e 0 {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: fmt.Sprintf(\"invalid value %q\", s.Name),","\t\t\t\tPaths:   []string{\"name\"},","\t\t\t\tDetails: \"Task step name must be a valid DNS Label, For more info refer to https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names\",","\t\t\t})","\t\t}","\t\tnames.Insert(s.Name)","\t}","","\tif s.Timeout != nil {","\t\tif s.Timeout.Duration \u003c time.Duration(0) {","\t\t\treturn apis.ErrInvalidValue(s.Timeout.Duration, \"negative timeout\")","\t\t}","\t}","","\tfor j, vm := range s.VolumeMounts {","\t\tif strings.HasPrefix(vm.MountPath, \"/tekton/\") \u0026\u0026","\t\t\t!strings.HasPrefix(vm.MountPath, \"/tekton/home\") {","\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"volumeMount cannot be mounted under /tekton/ (volumeMount %q mounted at %q)\", vm.Name, vm.MountPath), \"mountPath\").ViaFieldIndex(\"volumeMounts\", j))","\t\t}","\t\tif strings.HasPrefix(vm.Name, \"tekton-internal-\") {","\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(`volumeMount name %q cannot start with \"tekton-internal-\"`, vm.Name), \"name\").ViaFieldIndex(\"volumeMounts\", j))","\t\t}","\t}","","\tif s.OnError != \"\" {","\t\tif !isParamRefs(string(s.OnError)) \u0026\u0026 s.OnError != Continue \u0026\u0026 s.OnError != StopAndFail {","\t\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\t\tMessage: fmt.Sprintf(\"invalid value: \\\"%v\\\"\", s.OnError),","\t\t\t\tPaths:   []string{\"onError\"},","\t\t\t\tDetails: \"Task step onError must be either \\\"continue\\\" or \\\"stopAndFail\\\"\",","\t\t\t})","\t\t}","\t}","","\tif s.Script != \"\" {","\t\tcleaned := strings.TrimSpace(s.Script)","\t\tif strings.HasPrefix(cleaned, \"#!win\") {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"windows script support\", config.AlphaAPIFields).ViaField(\"script\"))","\t\t}","\t}","","\t// StdoutConfig is an alpha feature and will fail validation if it's used in a task spec","\t// when the enable-api-fields feature gate is not \"alpha\".","\tif s.StdoutConfig != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"step stdout stream support\", config.AlphaAPIFields).ViaField(\"stdoutconfig\"))","\t}","\t// StderrConfig is an alpha feature and will fail validation if it's used in a task spec","\t// when the enable-api-fields feature gate is not \"alpha\".","\tif s.StderrConfig != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"step stderr stream support\", config.AlphaAPIFields).ViaField(\"stderrconfig\"))","\t}","","\t// Validate usage of step result reference.","\t// Referencing previous step's results are only allowed in `env`, `command` and `args`.","\terrs = errs.Also(validateStepResultReference(s))","","\t// Validate usage of step artifacts output reference","\t// Referencing previous step's results are only allowed in `env`, `command` and `args`, `script`.","\terrs = errs.Also(validateStepArtifactsReference(s))","","\treturn errs","}","","func validateArtifactsReferencesInStep(ctx context.Context, s Step) *apis.FieldError {","\tif !config.FromContextOrDefaults(ctx).FeatureFlags.EnableArtifacts {","\t\tvar t []string","\t\tt = append(t, s.Script)","\t\tt = append(t, s.Command...)","\t\tt = append(t, s.Args...)","\t\tfor _, e := range s.Env {","\t\t\tt = append(t, e.Value)","\t\t}","\t\tif slices.ContainsFunc(t, stepArtifactReferenceExists) || slices.ContainsFunc(t, taskArtifactReferenceExists) {","\t\t\treturn apis.ErrGeneric(fmt.Sprintf(\"feature flag %s should be set to true to use artifacts feature.\", config.EnableArtifacts), \"\")","\t\t}","\t}","\treturn nil","}","","// ValidateParameterTypes validates all the types within a slice of ParamSpecs","func ValidateParameterTypes(ctx context.Context, params []ParamSpec) (errs *apis.FieldError) {","\tfor _, p := range params {","\t\terrs = errs.Also(p.ValidateType(ctx))","\t}","\treturn errs","}","","// ValidateType checks that the type of a ParamSpec is allowed and its default value matches that type","func (p ParamSpec) ValidateType(ctx context.Context) *apis.FieldError {","\t// Ensure param has a valid type.","\tvalidType := false","\tfor _, allowedType := range AllParamTypes {","\t\tif p.Type == allowedType {","\t\t\tvalidType = true","\t\t}","\t}","\tif !validType {","\t\treturn apis.ErrInvalidValue(p.Type, p.Name+\".type\")","\t}","","\t// If a default value is provided, ensure its type matches param's declared type.","\tif (p.Default != nil) \u0026\u0026 (p.Default.Type != p.Type) {","\t\treturn \u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(","\t\t\t\t\"\\\"%v\\\" type does not match default value's type: \\\"%v\\\"\", p.Type, p.Default.Type),","\t\t\tPaths: []string{","\t\t\t\tp.Name + \".type\",","\t\t\t\tp.Name + \".default.type\",","\t\t\t},","\t\t}","\t}","","\t// Check object type and its PropertySpec type","\treturn p.ValidateObjectType(ctx)","}","","// ValidateObjectType checks that object type parameter does not miss the","// definition of `properties` section and the type of a PropertySpec is allowed.","// (Currently, only string is allowed)","func (p ParamSpec) ValidateObjectType(ctx context.Context) *apis.FieldError {","\tinvalidKeys := []string{}","\tfor key, propertySpec := range p.Properties {","\t\tif propertySpec.Type != ParamTypeString {","\t\t\tinvalidKeys = append(invalidKeys, key)","\t\t}","\t}","","\tif len(invalidKeys) != 0 {","\t\treturn \u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(\"The value type specified for these keys %v is invalid\", invalidKeys),","\t\t\tPaths:   []string{p.Name + \".properties\"},","\t\t}","\t}","","\treturn nil","}","","// ValidateParameterVariables validates all variables within a slice of ParamSpecs against a slice of Steps","func ValidateParameterVariables(ctx context.Context, steps []Step, params ParamSpecs) *apis.FieldError {","\tvar errs *apis.FieldError","\terrs = errs.Also(params.validateNoDuplicateNames())","\terrs = errs.Also(params.validateParamEnums(ctx).ViaField(\"params\"))","\tstringParams, arrayParams, objectParams := params.sortByType()","\tstringParameterNames := sets.NewString(stringParams.getNames()...)","\tarrayParameterNames := sets.NewString(arrayParams.getNames()...)","\terrs = errs.Also(validateNameFormat(stringParameterNames.Insert(arrayParameterNames.List()...), objectParams))","\treturn errs.Also(validateArrayUsage(steps, \"params\", arrayParameterNames))","}","","// validateTaskContextVariables returns an error if any Steps reference context variables that don't exist.","func validateTaskContextVariables(ctx context.Context, steps []Step) *apis.FieldError {","\ttaskRunContextNames := sets.NewString().Insert(","\t\t\"name\",","\t\t\"namespace\",","\t\t\"uid\",","\t)","\ttaskContextNames := sets.NewString().Insert(","\t\t\"name\",","\t\t\"retry-count\",","\t)","\terrs := validateVariables(ctx, steps, \"context\\\\.taskRun\", taskRunContextNames)","\treturn errs.Also(validateVariables(ctx, steps, \"context\\\\.task\", taskContextNames))","}","","// validateTaskResultsVariables validates if the results referenced in step script are defined in task results","func validateTaskResultsVariables(ctx context.Context, steps []Step, results []TaskResult) (errs *apis.FieldError) {","\tresultsNames := sets.NewString()","\tfor _, r := range results {","\t\tresultsNames.Insert(r.Name)","\t}","\tfor idx, step := range steps {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariablesWithDetail(step.Script, \"results\", resultsNames).ViaField(\"script\").ViaFieldIndex(\"steps\", idx))","\t}","\treturn errs","}","","// validateObjectUsage validates the usage of individual attributes of an object param and the usage of the entire object","func validateObjectUsage(ctx context.Context, steps []Step, params []ParamSpec) (errs *apis.FieldError) {","\tobjectParameterNames := sets.NewString()","\tfor _, p := range params {","\t\t// collect all names of object type params","\t\tobjectParameterNames.Insert(p.Name)","","\t\t// collect all keys for this object param","\t\tobjectKeys := sets.NewString()","\t\tfor key := range p.Properties {","\t\t\tobjectKeys.Insert(key)","\t\t}","","\t\t// check if the object's key names are referenced correctly i.e. param.objectParam.key1","\t\terrs = errs.Also(validateVariables(ctx, steps, \"params\\\\.\"+p.Name, objectKeys))","\t}","","\treturn errs.Also(validateObjectUsageAsWhole(steps, \"params\", objectParameterNames))","}","","// validateObjectUsageAsWhole returns an error if the Steps contain references to the entire input object params in fields where these references are prohibited","func validateObjectUsageAsWhole(steps []Step, prefix string, vars sets.String) (errs *apis.FieldError) {","\tfor idx, step := range steps {","\t\terrs = errs.Also(validateStepObjectUsageAsWhole(step, prefix, vars)).ViaFieldIndex(\"steps\", idx)","\t}","\treturn errs","}","","// validateStepObjectUsageAsWhole returns an error if the Step contains references to the entire input object params in fields where these references are prohibited","func validateStepObjectUsageAsWhole(step Step, prefix string, vars sets.String) *apis.FieldError {","\terrs := substitution.ValidateNoReferencesToEntireProhibitedVariables(step.Name, prefix, vars).ViaField(\"name\")","\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(step.Image, prefix, vars).ViaField(\"image\"))","\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(step.WorkingDir, prefix, vars).ViaField(\"workingDir\"))","\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(step.Script, prefix, vars).ViaField(\"script\"))","\tfor i, cmd := range step.Command {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(cmd, prefix, vars).ViaFieldIndex(\"command\", i))","\t}","\tfor i, arg := range step.Args {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(arg, prefix, vars).ViaFieldIndex(\"args\", i))","\t}","\tfor _, env := range step.Env {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(env.Value, prefix, vars).ViaFieldKey(\"env\", env.Name))","\t}","\tfor i, v := range step.VolumeMounts {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(v.Name, prefix, vars).ViaField(\"name\").ViaFieldIndex(\"volumeMount\", i))","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(v.MountPath, prefix, vars).ViaField(\"mountPath\").ViaFieldIndex(\"volumeMount\", i))","\t\terrs = errs.Also(substitution.ValidateNoReferencesToEntireProhibitedVariables(v.SubPath, prefix, vars).ViaField(\"subPath\").ViaFieldIndex(\"volumeMount\", i))","\t}","\treturn errs","}","","// validateArrayUsage returns an error if the Steps contain references to the input array params in fields where these references are prohibited","func validateArrayUsage(steps []Step, prefix string, arrayParamNames sets.String) (errs *apis.FieldError) {","\tfor idx, step := range steps {","\t\terrs = errs.Also(validateStepArrayUsage(step, prefix, arrayParamNames)).ViaFieldIndex(\"steps\", idx)","\t}","\treturn errs","}","","// validateStepArrayUsage returns an error if the Step contains references to the input array params in fields where these references are prohibited","func validateStepArrayUsage(step Step, prefix string, arrayParamNames sets.String) *apis.FieldError {","\terrs := substitution.ValidateNoReferencesToProhibitedVariables(step.Name, prefix, arrayParamNames).ViaField(\"name\")","\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(step.Image, prefix, arrayParamNames).ViaField(\"image\"))","\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(step.WorkingDir, prefix, arrayParamNames).ViaField(\"workingDir\"))","\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(step.Script, prefix, arrayParamNames).ViaField(\"script\"))","\tfor i, cmd := range step.Command {","\t\terrs = errs.Also(substitution.ValidateVariableReferenceIsIsolated(cmd, prefix, arrayParamNames).ViaFieldIndex(\"command\", i))","\t}","\tfor i, arg := range step.Args {","\t\terrs = errs.Also(substitution.ValidateVariableReferenceIsIsolated(arg, prefix, arrayParamNames).ViaFieldIndex(\"args\", i))","\t}","\tfor _, env := range step.Env {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(env.Value, prefix, arrayParamNames).ViaFieldKey(\"env\", env.Name))","\t}","\tfor i, v := range step.VolumeMounts {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(v.Name, prefix, arrayParamNames).ViaField(\"name\").ViaFieldIndex(\"volumeMount\", i))","\t\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(v.MountPath, prefix, arrayParamNames).ViaField(\"mountPath\").ViaFieldIndex(\"volumeMount\", i))","\t\terrs = errs.Also(substitution.ValidateNoReferencesToProhibitedVariables(v.SubPath, prefix, arrayParamNames).ViaField(\"subPath\").ViaFieldIndex(\"volumeMount\", i))","\t}","\treturn errs","}","","// validateVariables returns an error if the Steps contain references to any unknown variables","func validateVariables(ctx context.Context, steps []Step, prefix string, vars sets.String) (errs *apis.FieldError) {","\t// We've checked param name format. Now, we want to check if param names are referenced correctly in each step","\tfor idx, step := range steps {","\t\terrs = errs.Also(validateStepVariables(ctx, step, prefix, vars).ViaFieldIndex(\"steps\", idx))","\t}","\treturn errs","}","","// validateNameFormat validates that the name format of all param types follows the rules","func validateNameFormat(stringAndArrayParams sets.String, objectParams []ParamSpec) (errs *apis.FieldError) {","\t// checking string or array name format","\t// ----","\tinvalidStringAndArrayNames := []string{}","\t// Converting to sorted list here rather than just looping map keys","\t// because we want the order of items in vars to be deterministic for purpose of unit testing","\tfor _, name := range stringAndArrayParams.List() {","\t\tif !stringAndArrayVariableNameFormatRegex.MatchString(name) {","\t\t\tinvalidStringAndArrayNames = append(invalidStringAndArrayNames, name)","\t\t}","\t}","","\tif len(invalidStringAndArrayNames) != 0 {","\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(\"The format of following array and string variable names is invalid: %s\", invalidStringAndArrayNames),","\t\t\tPaths:   []string{\"params\"},","\t\t\tDetails: \"String/Array Names: \\nMust only contain alphanumeric characters, hyphens (-), underscores (_), and dots (.)\\nMust begin with a letter or an underscore (_)\",","\t\t})","\t}","","\t// checking object name and key name format","\t// -----","\tinvalidObjectNames := map[string][]string{}","\tfor _, obj := range objectParams {","\t\t// check object param name","\t\tif !objectVariableNameFormatRegex.MatchString(obj.Name) {","\t\t\tinvalidObjectNames[obj.Name] = []string{}","\t\t}","","\t\t// check key names","\t\tfor k := range obj.Properties {","\t\t\tif !objectVariableNameFormatRegex.MatchString(k) {","\t\t\t\tinvalidObjectNames[obj.Name] = append(invalidObjectNames[obj.Name], k)","\t\t\t}","\t\t}","\t}","","\tif len(invalidObjectNames) != 0 {","\t\terrs = errs.Also(\u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(\"Object param name and key name format is invalid: %s\", invalidObjectNames),","\t\t\tPaths:   []string{\"params\"},","\t\t\tDetails: \"Object Names: \\nMust only contain alphanumeric characters, hyphens (-), underscores (_) \\nMust begin with a letter or an underscore (_)\",","\t\t})","\t}","","\treturn errs","}","","// validateStepVariables returns an error if the Step contains references to any unknown variables","func validateStepVariables(ctx context.Context, step Step, prefix string, vars sets.String) *apis.FieldError {","\terrs := substitution.ValidateNoReferencesToUnknownVariables(step.Name, prefix, vars).ViaField(\"name\")","\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(step.Image, prefix, vars).ViaField(\"image\"))","\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(step.WorkingDir, prefix, vars).ViaField(\"workingDir\"))","\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariablesWithDetail(step.Script, prefix, vars).ViaField(\"script\"))","\tfor i, cmd := range step.Command {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(cmd, prefix, vars).ViaFieldIndex(\"command\", i))","\t}","\tfor i, arg := range step.Args {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(arg, prefix, vars).ViaFieldIndex(\"args\", i))","\t}","\tfor _, env := range step.Env {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(env.Value, prefix, vars).ViaFieldKey(\"env\", env.Name))","\t}","\tfor i, v := range step.VolumeMounts {","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(v.Name, prefix, vars).ViaField(\"name\").ViaFieldIndex(\"volumeMount\", i))","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(v.MountPath, prefix, vars).ViaField(\"MountPath\").ViaFieldIndex(\"volumeMount\", i))","\t\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(v.SubPath, prefix, vars).ViaField(\"SubPath\").ViaFieldIndex(\"volumeMount\", i))","\t}","\terrs = errs.Also(substitution.ValidateNoReferencesToUnknownVariables(string(step.OnError), prefix, vars).ViaField(\"onError\"))","\treturn errs","}","","// isParamRefs attempts to check if a specified string looks like it contains any parameter reference","// This is useful to make sure the specified value looks like a Parameter Reference before performing any strict validation","func isParamRefs(s string) bool {","\treturn strings.HasPrefix(s, \"$(\"+ParamsPrefix)","}","","// GetIndexingReferencesToArrayParams returns all strings referencing indices of TaskRun array parameters","// from parameters, workspaces, and when expressions defined in the Task.","// For example, if a Task has a parameter with a value \"$(params.array-param-name[1])\",","// this would be one of the strings returned.","func (ts *TaskSpec) GetIndexingReferencesToArrayParams() sets.String {","\t// collect all the possible places to use param references","\tparamsRefs := []string{}","\tparamsRefs = append(paramsRefs, extractParamRefsFromSteps(ts.Steps)...)","\tparamsRefs = append(paramsRefs, extractParamRefsFromStepTemplate(ts.StepTemplate)...)","\tparamsRefs = append(paramsRefs, extractParamRefsFromVolumes(ts.Volumes)...)","\tfor _, v := range ts.Workspaces {","\t\tparamsRefs = append(paramsRefs, v.MountPath)","\t}","\tparamsRefs = append(paramsRefs, extractParamRefsFromSidecars(ts.Sidecars)...)","\t// extract all array indexing references, for example []{\"$(params.array-params[1])\"}","\tarrayIndexParamRefs := []string{}","\tfor _, p := range paramsRefs {","\t\tarrayIndexParamRefs = append(arrayIndexParamRefs, extractArrayIndexingParamRefs(p)...)","\t}","\treturn sets.NewString(arrayIndexParamRefs...)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,0,2,2,2,2,2,1,1,1,1,1,1,0,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,1,1,0,2,0,0,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,0,2,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,2,2,2,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,0,0,2,2,1,1,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,0,0,0,2,2,2,0,0,2,2,2,0,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0]},{"id":106,"path":"pkg/apis/pipeline/v1beta1/taskref_conversion.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"",")","","func (tr TaskRef) convertTo(ctx context.Context, sink *v1.TaskRef) {","\tsink.Name = tr.Name","\tsink.Kind = v1.TaskKind(tr.Kind)","\tsink.APIVersion = tr.APIVersion","\tnew := v1.ResolverRef{}","\ttr.ResolverRef.convertTo(ctx, \u0026new)","\tsink.ResolverRef = new","}","","// ConvertFrom converts v1beta1 TaskRef from v1 TaskRef","func (tr *TaskRef) ConvertFrom(ctx context.Context, source v1.TaskRef) {","\ttr.Name = source.Name","\ttr.Kind = TaskKind(source.Kind)","\ttr.APIVersion = source.APIVersion","\tnew := ResolverRef{}","\tnew.convertFrom(ctx, source.ResolverRef)","\ttr.ResolverRef = new","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2]},{"id":107,"path":"pkg/apis/pipeline/v1beta1/taskref_types.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","// TaskRef can be used to refer to a specific instance of a task.","type TaskRef struct {","\t// Name of the referent; More info: http://kubernetes.io/docs/user-guide/identifiers#names","\tName string `json:\"name,omitempty\"`","\t// TaskKind indicates the Kind of the Task:","\t// 1. Namespaced Task when Kind is set to \"Task\". If Kind is \"\", it defaults to \"Task\".","\t// 2. Custom Task when Kind is non-empty and APIVersion is non-empty","\tKind TaskKind `json:\"kind,omitempty\"`","\t// API version of the referent","\t// Note: A Task with non-empty APIVersion and Kind is considered a Custom Task","\t// +optional","\tAPIVersion string `json:\"apiVersion,omitempty\"`","\t// Bundle url reference to a Tekton Bundle.","\t//","\t// Deprecated: Please use ResolverRef with the bundles resolver instead.","\t// The field is staying there for go client backward compatibility, but is not used/allowed anymore.","\t// +optional","\tBundle string `json:\"bundle,omitempty\"`","","\t// ResolverRef allows referencing a Task in a remote location","\t// like a git repo. This field is only supported when the alpha","\t// feature gate is enabled.","\t// +optional","\tResolverRef `json:\",omitempty\"`","}","","// Check that Pipeline may be validated and defaulted.","","// TaskKind defines the type of Task used by the pipeline.","type TaskKind string","","const (","\t// NamespacedTaskKind indicates that the task type has a namespaced scope.","\tNamespacedTaskKind TaskKind = \"Task\"",")","","// IsCustomTask checks whether the reference is to a Custom Task","func (tr *TaskRef) IsCustomTask() bool {","\t// Note that if `apiVersion` is set to `\"tekton.dev/v1beta1\"` and `kind` is set to `\"Task\"`,","\t// the reference will be considered a Custom Task - https://github.com/tektoncd/pipeline/issues/6457","\treturn tr != nil \u0026\u0026 tr.APIVersion != \"\" \u0026\u0026 tr.Kind != \"\"","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2]},{"id":108,"path":"pkg/apis/pipeline/v1beta1/taskref_validation.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"fmt\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"k8s.io/apimachinery/pkg/util/validation\"","\t\"knative.dev/pkg/apis\"",")","","// Validate ensures that a supplied TaskRef field is populated","// correctly. No errors are returned for a nil TaskRef.","func (ref *TaskRef) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif ref == nil {","\t\treturn errs","\t}","\tif apis.IsInCreate(ctx) \u0026\u0026 ref.Bundle != \"\" {","\t\terrs = errs.Also(apis.ErrDisallowedFields(\"bundle\"))","\t}","\tswitch {","\tcase ref.Resolver != \"\" || ref.Params != nil:","\t\tif ref.Params != nil {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"resolver params\", config.BetaAPIFields).ViaField(\"params\"))","\t\t\tif ref.Name != \"\" {","\t\t\t\terrs = errs.Also(apis.ErrMultipleOneOf(\"name\", \"params\"))","\t\t\t}","\t\t\tif ref.Resolver == \"\" {","\t\t\t\terrs = errs.Also(apis.ErrMissingField(\"resolver\"))","\t\t\t}","\t\t\terrs = errs.Also(ValidateParameters(ctx, ref.Params))","\t\t}","\t\tif ref.Resolver != \"\" {","\t\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"resolver\", config.BetaAPIFields).ViaField(\"resolver\"))","\t\t\tif ref.Name != \"\" {","\t\t\t\t// make sure that the name is url-like.","\t\t\t\terr := RefNameLikeUrl(ref.Name)","\t\t\t\tif err == nil \u0026\u0026 !config.FromContextOrDefaults(ctx).FeatureFlags.EnableConciseResolverSyntax {","\t\t\t\t\t// If name is url-like then concise resolver syntax must be enabled","\t\t\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"feature flag %s should be set to true to use concise resolver syntax\", config.EnableConciseResolverSyntax), \"\"))","\t\t\t\t}","\t\t\t\tif err != nil {","\t\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(err, \"name\"))","\t\t\t\t}","\t\t\t}","\t\t}","\tcase ref.Name != \"\":","\t\t// ref name can be a Url-like format.","\t\tif err := RefNameLikeUrl(ref.Name); err == nil {","\t\t\t// If name is url-like then concise resolver syntax must be enabled","\t\t\tif !config.FromContextOrDefaults(ctx).FeatureFlags.EnableConciseResolverSyntax {","\t\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"feature flag %s should be set to true to use concise resolver syntax\", config.EnableConciseResolverSyntax), \"\"))","\t\t\t}","\t\t\t// In stage1 of concise remote resolvers syntax, this is a required field.","\t\t\t// TODO: remove this check when implementing stage 2 where this is optional.","\t\t\tif ref.Resolver == \"\" {","\t\t\t\terrs = errs.Also(apis.ErrMissingField(\"resolver\"))","\t\t\t}","\t\t\t// Or, it must be a valid k8s name","\t\t} else {","\t\t\t// ref name must be a valid k8s name","\t\t\tif errSlice := validation.IsQualifiedName(ref.Name); len(errSlice) != 0 {","\t\t\t\terrs = errs.Also(apis.ErrInvalidValue(strings.Join(errSlice, \",\"), \"name\"))","\t\t\t}","\t\t}","\tdefault:","\t\terrs = errs.Also(apis.ErrMissingField(\"name\"))","\t}","\treturn //nolint:nakedret","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,0,2,2,2,2,2,0,2,2,0,2,0]},{"id":109,"path":"pkg/apis/pipeline/v1beta1/taskrun_conversion.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"fmt\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/version\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"knative.dev/pkg/apis\"",")","","const (","\tcloudEventsAnnotationKey     = \"tekton.dev/v1beta1CloudEvents\"","\tresourcesResultAnnotationKey = \"tekton.dev/v1beta1ResourcesResult\"","\tresourcesStatusAnnotationKey = \"tekton.dev/v1beta1ResourcesStatus\"",")","","var _ apis.Convertible = (*TaskRun)(nil)","","// ConvertTo implements apis.Convertible","func (tr *TaskRun) ConvertTo(ctx context.Context, to apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\tswitch sink := to.(type) {","\tcase *v1.TaskRun:","\t\tsink.ObjectMeta = tr.ObjectMeta","\t\tif err := serializeTaskRunResources(\u0026sink.ObjectMeta, \u0026tr.Spec); err != nil {","\t\t\treturn err","\t\t}","\t\tif err := serializeTaskRunCloudEvents(\u0026sink.ObjectMeta, \u0026tr.Status); err != nil {","\t\t\treturn err","\t\t}","\t\tif err := serializeTaskRunResourcesResult(\u0026sink.ObjectMeta, \u0026tr.Status); err != nil {","\t\t\treturn err","\t\t}","\t\tif err := serializeTaskRunResourcesStatus(\u0026sink.ObjectMeta, \u0026tr.Status); err != nil {","\t\t\treturn err","\t\t}","\t\tif err := tr.Status.ConvertTo(ctx, \u0026sink.Status, \u0026sink.ObjectMeta); err != nil {","\t\t\treturn err","\t\t}","\t\treturn tr.Spec.ConvertTo(ctx, \u0026sink.Spec, \u0026sink.ObjectMeta)","\tdefault:","\t\treturn fmt.Errorf(\"unknown version, got: %T\", sink)","\t}","}","","// ConvertTo implements apis.Convertible","func (trs *TaskRunSpec) ConvertTo(ctx context.Context, sink *v1.TaskRunSpec, meta *metav1.ObjectMeta) error {","\tif trs.Debug != nil {","\t\tsink.Debug = \u0026v1.TaskRunDebug{}","\t\ttrs.Debug.convertTo(ctx, sink.Debug)","\t}","\tsink.Params = nil","\tfor _, p := range trs.Params {","\t\tnew := v1.Param{}","\t\tp.convertTo(ctx, \u0026new)","\t\tsink.Params = append(sink.Params, new)","\t}","\tsink.ServiceAccountName = trs.ServiceAccountName","\tif trs.TaskRef != nil {","\t\tsink.TaskRef = \u0026v1.TaskRef{}","\t\ttrs.TaskRef.convertTo(ctx, sink.TaskRef)","\t}","\tif trs.TaskSpec != nil {","\t\tsink.TaskSpec = \u0026v1.TaskSpec{}","\t\terr := trs.TaskSpec.ConvertTo(ctx, sink.TaskSpec, meta, meta.Name)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t}","\tsink.Status = v1.TaskRunSpecStatus(trs.Status)","\tsink.StatusMessage = v1.TaskRunSpecStatusMessage(trs.StatusMessage)","\tsink.Retries = trs.Retries","\tsink.Timeout = trs.Timeout","\tsink.PodTemplate = trs.PodTemplate","\tsink.Workspaces = nil","\tfor _, w := range trs.Workspaces {","\t\tnew := v1.WorkspaceBinding{}","\t\tw.convertTo(ctx, \u0026new)","\t\tsink.Workspaces = append(sink.Workspaces, new)","\t}","\tsink.StepSpecs = nil","\tfor _, so := range trs.StepOverrides {","\t\tnew := v1.TaskRunStepSpec{}","\t\tso.convertTo(ctx, \u0026new)","\t\tsink.StepSpecs = append(sink.StepSpecs, new)","\t}","\tsink.SidecarSpecs = nil","\tfor _, so := range trs.SidecarOverrides {","\t\tnew := v1.TaskRunSidecarSpec{}","\t\tso.convertTo(ctx, \u0026new)","\t\tsink.SidecarSpecs = append(sink.SidecarSpecs, new)","\t}","\tsink.ComputeResources = trs.ComputeResources","\treturn nil","}","","// ConvertFrom implements apis.Convertible","func (tr *TaskRun) ConvertFrom(ctx context.Context, from apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\tswitch source := from.(type) {","\tcase *v1.TaskRun:","\t\ttr.ObjectMeta = source.ObjectMeta","\t\tif err := deserializeTaskRunResources(\u0026tr.ObjectMeta, \u0026tr.Spec); err != nil {","\t\t\treturn err","\t\t}","\t\tif err := deserializeTaskRunCloudEvents(\u0026tr.ObjectMeta, \u0026tr.Status); err != nil {","\t\t\treturn err","\t\t}","\t\tif err := deserializeTaskRunResourcesResult(\u0026tr.ObjectMeta, \u0026tr.Status); err != nil {","\t\t\treturn err","\t\t}","\t\tif err := tr.Status.ConvertFrom(ctx, source.Status, \u0026tr.ObjectMeta); err != nil {","\t\t\treturn err","\t\t}","\t\tif err := deserializeTaskRunResourcesStatus(\u0026tr.ObjectMeta, \u0026tr.Status); err != nil {","\t\t\treturn err","\t\t}","\t\treturn tr.Spec.ConvertFrom(ctx, \u0026source.Spec, \u0026tr.ObjectMeta)","\tdefault:","\t\treturn fmt.Errorf(\"unknown version, got: %T\", tr)","\t}","}","","// ConvertFrom implements apis.Convertible","func (trs *TaskRunSpec) ConvertFrom(ctx context.Context, source *v1.TaskRunSpec, meta *metav1.ObjectMeta) error {","\tif source.Debug != nil {","\t\tnewDebug := TaskRunDebug{}","\t\tnewDebug.convertFrom(ctx, *source.Debug)","\t\ttrs.Debug = \u0026newDebug","\t}","\ttrs.Params = nil","\tfor _, p := range source.Params {","\t\tnew := Param{}","\t\tnew.ConvertFrom(ctx, p)","\t\ttrs.Params = append(trs.Params, new)","\t}","\ttrs.ServiceAccountName = source.ServiceAccountName","\tif source.TaskRef != nil {","\t\tnewTaskRef := TaskRef{}","\t\tnewTaskRef.ConvertFrom(ctx, *source.TaskRef)","\t\ttrs.TaskRef = \u0026newTaskRef","\t}","\tif source.TaskSpec != nil {","\t\tnewTaskSpec := TaskSpec{}","\t\terr := newTaskSpec.ConvertFrom(ctx, source.TaskSpec, meta, meta.Name)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\ttrs.TaskSpec = \u0026newTaskSpec","\t}","\ttrs.Status = TaskRunSpecStatus(source.Status)","\ttrs.StatusMessage = TaskRunSpecStatusMessage(source.StatusMessage)","\ttrs.Retries = source.Retries","\ttrs.Timeout = source.Timeout","\ttrs.PodTemplate = source.PodTemplate","\ttrs.Workspaces = nil","\tfor _, w := range source.Workspaces {","\t\tnew := WorkspaceBinding{}","\t\tnew.ConvertFrom(ctx, w)","\t\ttrs.Workspaces = append(trs.Workspaces, new)","\t}","\ttrs.StepOverrides = nil","\tfor _, so := range source.StepSpecs {","\t\tnew := TaskRunStepOverride{}","\t\tnew.convertFrom(ctx, so)","\t\ttrs.StepOverrides = append(trs.StepOverrides, new)","\t}","\ttrs.SidecarOverrides = nil","\tfor _, so := range source.SidecarSpecs {","\t\tnew := TaskRunSidecarOverride{}","\t\tnew.convertFrom(ctx, so)","\t\ttrs.SidecarOverrides = append(trs.SidecarOverrides, new)","\t}","\ttrs.ComputeResources = source.ComputeResources","\treturn nil","}","","func (trd TaskRunDebug) convertTo(ctx context.Context, sink *v1.TaskRunDebug) {","\tif trd.Breakpoints != nil {","\t\tsink.Breakpoints = \u0026v1.TaskBreakpoints{}","\t\ttrd.Breakpoints.convertTo(ctx, sink.Breakpoints)","\t}","}","","func (trd *TaskRunDebug) convertFrom(ctx context.Context, source v1.TaskRunDebug) {","\tif source.Breakpoints != nil {","\t\tnewBreakpoints := TaskBreakpoints{}","\t\tnewBreakpoints.convertFrom(ctx, *source.Breakpoints)","\t\ttrd.Breakpoints = \u0026newBreakpoints","\t}","}","","func (tbp TaskBreakpoints) convertTo(ctx context.Context, sink *v1.TaskBreakpoints) {","\tsink.OnFailure = tbp.OnFailure","\tif len(tbp.BeforeSteps) \u003e 0 {","\t\tsink.BeforeSteps = make([]string, 0)","\t\tsink.BeforeSteps = append(sink.BeforeSteps, tbp.BeforeSteps...)","\t}","}","","func (tbp *TaskBreakpoints) convertFrom(ctx context.Context, source v1.TaskBreakpoints) {","\ttbp.OnFailure = source.OnFailure","\tif len(source.BeforeSteps) \u003e 0 {","\t\ttbp.BeforeSteps = make([]string, 0)","\t\ttbp.BeforeSteps = append(tbp.BeforeSteps, source.BeforeSteps...)","\t}","}","","func (trso TaskRunStepOverride) convertTo(ctx context.Context, sink *v1.TaskRunStepSpec) {","\tsink.Name = trso.Name","\tsink.ComputeResources = trso.Resources","}","","func (trso *TaskRunStepOverride) convertFrom(ctx context.Context, source v1.TaskRunStepSpec) {","\ttrso.Name = source.Name","\ttrso.Resources = source.ComputeResources","}","","func (trso TaskRunSidecarOverride) convertTo(ctx context.Context, sink *v1.TaskRunSidecarSpec) {","\tsink.Name = trso.Name","\tsink.ComputeResources = trso.Resources","}","","func (trso *TaskRunSidecarOverride) convertFrom(ctx context.Context, source v1.TaskRunSidecarSpec) {","\ttrso.Name = source.Name","\ttrso.Resources = source.ComputeResources","}","","// ConvertTo implements apis.Convertible","func (trs *TaskRunStatus) ConvertTo(ctx context.Context, sink *v1.TaskRunStatus, meta *metav1.ObjectMeta) error {","\tsink.Status = trs.Status","\tsink.PodName = trs.PodName","\tsink.StartTime = trs.StartTime","\tsink.CompletionTime = trs.CompletionTime","\tsink.Steps = nil","\tfor _, ss := range trs.Steps {","\t\tnew := v1.StepState{}","\t\tss.convertTo(ctx, \u0026new)","\t\tsink.Steps = append(sink.Steps, new)","\t}","\tsink.RetriesStatus = nil","\tfor _, rr := range trs.RetriesStatus {","\t\tnew := v1.TaskRunStatus{}","\t\terr := rr.ConvertTo(ctx, \u0026new, meta)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tsink.RetriesStatus = append(sink.RetriesStatus, new)","\t}","\tsink.Results = nil","\tfor _, trr := range trs.TaskRunResults {","\t\tnew := v1.TaskRunResult{}","\t\ttrr.convertTo(ctx, \u0026new)","\t\tsink.Results = append(sink.Results, new)","\t}","\tsink.Sidecars = nil","\tfor _, sc := range trs.Sidecars {","\t\tnew := v1.SidecarState{}","\t\tsc.convertTo(ctx, \u0026new)","\t\tsink.Sidecars = append(sink.Sidecars, new)","\t}","","\tif trs.TaskSpec != nil {","\t\tsink.TaskSpec = \u0026v1.TaskSpec{}","\t\terr := trs.TaskSpec.ConvertTo(ctx, sink.TaskSpec, meta, meta.Name)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t}","\tif trs.Provenance != nil {","\t\tnew := v1.Provenance{}","\t\ttrs.Provenance.convertTo(ctx, \u0026new)","\t\tsink.Provenance = \u0026new","\t}","\treturn nil","}","","// ConvertFrom implements apis.Convertible","func (trs *TaskRunStatus) ConvertFrom(ctx context.Context, source v1.TaskRunStatus, meta *metav1.ObjectMeta) error {","\ttrs.Status = source.Status","\ttrs.PodName = source.PodName","\ttrs.StartTime = source.StartTime","\ttrs.CompletionTime = source.CompletionTime","\ttrs.Steps = nil","\tfor _, ss := range source.Steps {","\t\tnew := StepState{}","\t\tnew.convertFrom(ctx, ss)","\t\ttrs.Steps = append(trs.Steps, new)","\t}","\ttrs.RetriesStatus = nil","\tfor _, rr := range source.RetriesStatus {","\t\tnew := TaskRunStatus{}","\t\terr := new.ConvertFrom(ctx, rr, meta)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\ttrs.RetriesStatus = append(trs.RetriesStatus, new)","\t}","\ttrs.TaskRunResults = nil","\tfor _, trr := range source.Results {","\t\tnew := TaskRunResult{}","\t\tnew.convertFrom(ctx, trr)","\t\ttrs.TaskRunResults = append(trs.TaskRunResults, new)","\t}","\ttrs.Sidecars = nil","\tfor _, sc := range source.Sidecars {","\t\tnew := SidecarState{}","\t\tnew.convertFrom(ctx, sc)","\t\ttrs.Sidecars = append(trs.Sidecars, new)","\t}","","\tif source.TaskSpec != nil {","\t\ttrs.TaskSpec = \u0026TaskSpec{}","\t\terr := trs.TaskSpec.ConvertFrom(ctx, source.TaskSpec, meta, meta.Name)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t}","\tif source.Provenance != nil {","\t\tnew := Provenance{}","\t\tnew.convertFrom(ctx, *source.Provenance)","\t\ttrs.Provenance = \u0026new","\t}","\treturn nil","}","","func (ss StepState) convertTo(ctx context.Context, sink *v1.StepState) {","\tsink.ContainerState = ss.ContainerState","\tsink.Name = ss.Name","\tsink.Container = ss.ContainerName","\tsink.ImageID = ss.ImageID","\tsink.Results = nil","","\tif ss.Provenance != nil {","\t\tnew := v1.Provenance{}","\t\tss.Provenance.convertTo(ctx, \u0026new)","\t\tsink.Provenance = \u0026new","\t}","","\tif ss.ContainerState.Terminated != nil {","\t\tsink.TerminationReason = ss.ContainerState.Terminated.Reason","\t}","","\tfor _, o := range ss.Outputs {","\t\tnew := v1.TaskRunStepArtifact{}","\t\to.convertTo(ctx, \u0026new)","\t\tsink.Outputs = append(sink.Outputs, new)","\t}","","\tfor _, o := range ss.Inputs {","\t\tnew := v1.TaskRunStepArtifact{}","\t\to.convertTo(ctx, \u0026new)","\t\tsink.Inputs = append(sink.Inputs, new)","\t}","","\tfor _, r := range ss.Results {","\t\tnew := v1.TaskRunStepResult{}","\t\tr.convertTo(ctx, \u0026new)","\t\tsink.Results = append(sink.Results, new)","\t}","}","","func (ss *StepState) convertFrom(ctx context.Context, source v1.StepState) {","\tss.ContainerState = source.ContainerState","\tss.Name = source.Name","\tss.ContainerName = source.Container","\tss.ImageID = source.ImageID","\tss.Results = nil","\tfor _, r := range source.Results {","\t\tnew := TaskRunStepResult{}","\t\tnew.convertFrom(ctx, r)","\t\tss.Results = append(ss.Results, new)","\t}","\tif source.Provenance != nil {","\t\tnew := Provenance{}","\t\tnew.convertFrom(ctx, *source.Provenance)","\t\tss.Provenance = \u0026new","\t}","\tfor _, o := range source.Outputs {","\t\tnew := TaskRunStepArtifact{}","\t\tnew.convertFrom(ctx, o)","\t\tss.Outputs = append(ss.Outputs, new)","\t}","\tfor _, o := range source.Inputs {","\t\tnew := TaskRunStepArtifact{}","\t\tnew.convertFrom(ctx, o)","\t\tss.Inputs = append(ss.Inputs, new)","\t}","}","","func (trr TaskRunResult) convertTo(ctx context.Context, sink *v1.TaskRunResult) {","\tsink.Name = trr.Name","\tsink.Type = v1.ResultsType(trr.Type)","\tnewValue := v1.ParamValue{}","\ttrr.Value.convertTo(ctx, \u0026newValue)","\tsink.Value = newValue","}","","func (trr *TaskRunResult) convertFrom(ctx context.Context, source v1.TaskRunResult) {","\ttrr.Name = source.Name","\ttrr.Type = ResultsType(source.Type)","\tnewValue := ParamValue{}","\tnewValue.convertFrom(ctx, source.Value)","\ttrr.Value = newValue","}","","func (t *TaskRunStepArtifact) convertFrom(ctx context.Context, source v1.TaskRunStepArtifact) {","\tt.Name = source.Name","\tfor _, v := range source.Values {","\t\tnew := ArtifactValue{}","\t\tnew.convertFrom(ctx, v)","\t\tt.Values = append(t.Values, new)","\t}","}","","func (t TaskRunStepArtifact) convertTo(ctx context.Context, sink *v1.TaskRunStepArtifact) {","\tsink.Name = t.Name","\tfor _, v := range t.Values {","\t\tnew := v1.ArtifactValue{}","\t\tv.convertTo(ctx, \u0026new)","\t\tsink.Values = append(sink.Values, new)","\t}","}","","func (t *ArtifactValue) convertFrom(ctx context.Context, source v1.ArtifactValue) {","\tt.Uri = source.Uri","\tif source.Digest != nil {","\t\tt.Digest = map[Algorithm]string{}","\t\tfor i, a := range source.Digest {","\t\t\tt.Digest[Algorithm(i)] = a","\t\t}","\t}","}","func (t ArtifactValue) convertTo(ctx context.Context, sink *v1.ArtifactValue) {","\tsink.Uri = t.Uri","\tif t.Digest != nil {","\t\tsink.Digest = map[v1.Algorithm]string{}","\t\tfor i, a := range t.Digest {","\t\t\tsink.Digest[v1.Algorithm(i)] = a","\t\t}","\t}","}","","func (ss SidecarState) convertTo(ctx context.Context, sink *v1.SidecarState) {","\tsink.ContainerState = ss.ContainerState","\tsink.Name = ss.Name","\tsink.Container = ss.ContainerName","\tsink.ImageID = ss.ImageID","}","","func (ss *SidecarState) convertFrom(ctx context.Context, source v1.SidecarState) {","\tss.ContainerState = source.ContainerState","\tss.Name = source.Name","\tss.ContainerName = source.Container","\tss.ImageID = source.ImageID","}","","func serializeTaskRunResources(meta *metav1.ObjectMeta, spec *TaskRunSpec) error {","\tif spec.Resources == nil {","\t\treturn nil","\t}","\treturn version.SerializeToMetadata(meta, spec.Resources, resourcesAnnotationKey)","}","","func deserializeTaskRunResources(meta *metav1.ObjectMeta, spec *TaskRunSpec) error {","\tresources := \u0026TaskRunResources{}","\terr := version.DeserializeFromMetadata(meta, resources, resourcesAnnotationKey)","\tif err != nil {","\t\treturn err","\t}","\tif resources.Inputs != nil || resources.Outputs != nil {","\t\tspec.Resources = resources","\t}","\treturn nil","}","","func serializeTaskRunCloudEvents(meta *metav1.ObjectMeta, status *TaskRunStatus) error {","\tif status.CloudEvents == nil {","\t\treturn nil","\t}","\treturn version.SerializeToMetadata(meta, status.CloudEvents, cloudEventsAnnotationKey)","}","","func deserializeTaskRunCloudEvents(meta *metav1.ObjectMeta, status *TaskRunStatus) error {","\tcloudEvents := []CloudEventDelivery{}","\terr := version.DeserializeFromMetadata(meta, \u0026cloudEvents, cloudEventsAnnotationKey)","\tif err != nil {","\t\treturn err","\t}","\tif len(cloudEvents) != 0 {","\t\tstatus.CloudEvents = cloudEvents","\t}","\treturn nil","}","","func serializeTaskRunResourcesResult(meta *metav1.ObjectMeta, status *TaskRunStatus) error {","\tif status.ResourcesResult == nil {","\t\treturn nil","\t}","\treturn version.SerializeToMetadata(meta, status.ResourcesResult, resourcesResultAnnotationKey)","}","","func deserializeTaskRunResourcesResult(meta *metav1.ObjectMeta, status *TaskRunStatus) error {","\tresourcesResult := []RunResult{}","\terr := version.DeserializeFromMetadata(meta, \u0026resourcesResult, resourcesResultAnnotationKey)","\tif err != nil {","\t\treturn err","\t}","\tif len(resourcesResult) != 0 {","\t\tstatus.ResourcesResult = resourcesResult","\t}","\treturn nil","}","","func serializeTaskRunResourcesStatus(meta *metav1.ObjectMeta, status *TaskRunStatus) error {","\tif status.TaskSpec == nil {","\t\treturn nil","\t}","\tif status.TaskSpec.Resources == nil {","\t\treturn nil","\t}","\treturn version.SerializeToMetadata(meta, status.TaskSpec.Resources, resourcesStatusAnnotationKey)","}","","func deserializeTaskRunResourcesStatus(meta *metav1.ObjectMeta, status *TaskRunStatus) error {","\tresourcesStatus := \u0026TaskResources{}","\terr := version.DeserializeFromMetadata(meta, resourcesStatus, resourcesStatusAnnotationKey)","\tif err != nil {","\t\treturn err","\t}","\tif resourcesStatus.Inputs != nil || resourcesStatus.Outputs != nil {","\t\tif status.TaskRunStatusFields.TaskSpec == nil {","\t\t\tstatus.TaskSpec = \u0026TaskSpec{}","\t\t}","\t\tstatus.TaskSpec.Resources = resourcesStatus","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,2,2,2,2,1,1,2,1,1,2,1,1,2,1,1,2,1,1,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,1,1,2,2,2,2,1,1,2,1,1,2,1,1,2,1,1,2,1,1,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,2,2,2,2,0,2,2,2,2,0,2,2,2,2,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,1,1,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,1,1,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,0,0,2,2,2,2,1,1,2,2,2,2,0,0,2,2,2,2,2,0,0,2,2,2,2,1,1,2,2,2,2,0,0,2,2,2,2,2,0,0,2,2,2,2,1,1,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,1,1,2,2,1,1,2,0,2,0]},{"id":110,"path":"pkg/apis/pipeline/v1beta1/taskrun_defaults.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\tpod \"github.com/tektoncd/pipeline/pkg/apis/pipeline/pod\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/kmap\"",")","","var _ apis.Defaultable = (*TaskRun)(nil)","","// ManagedByLabelKey is the label key used to mark what is managing this resource","const ManagedByLabelKey = \"app.kubernetes.io/managed-by\"","","// SetDefaults implements apis.Defaultable","func (tr *TaskRun) SetDefaults(ctx context.Context) {","\tctx = apis.WithinParent(ctx, tr.ObjectMeta)","\ttr.Spec.SetDefaults(ctx)","","\t// Silently filtering out Tekton Reserved annotations at creation","\tif apis.IsInCreate(ctx) {","\t\ttr.ObjectMeta.Annotations = kmap.Filter(tr.ObjectMeta.Annotations, func(s string) bool {","\t\t\treturn filterReservedAnnotationRegexp.MatchString(s)","\t\t})","\t}","","\t// If the TaskRun doesn't have a managed-by label, apply the default","\t// specified in the config.","\tcfg := config.FromContextOrDefaults(ctx)","\tif tr.ObjectMeta.Labels == nil {","\t\ttr.ObjectMeta.Labels = map[string]string{}","\t}","\tif _, found := tr.ObjectMeta.Labels[ManagedByLabelKey]; !found {","\t\ttr.ObjectMeta.Labels[ManagedByLabelKey] = cfg.Defaults.DefaultManagedByLabelValue","\t}","}","","// SetDefaults implements apis.Defaultable","func (trs *TaskRunSpec) SetDefaults(ctx context.Context) {","\tcfg := config.FromContextOrDefaults(ctx)","\tif trs.TaskRef != nil {","\t\tif trs.TaskRef.Name == \"\" \u0026\u0026 trs.TaskRef.Resolver == \"\" {","\t\t\ttrs.TaskRef.Resolver = ResolverName(cfg.Defaults.DefaultResolverType)","\t\t}","\t\tif trs.TaskRef.Kind == \"\" \u0026\u0026 trs.TaskRef.Resolver == \"\" {","\t\t\ttrs.TaskRef.Kind = NamespacedTaskKind","\t\t}","\t}","","\tif trs.Timeout == nil {","\t\ttrs.Timeout = \u0026metav1.Duration{Duration: time.Duration(cfg.Defaults.DefaultTimeoutMinutes) * time.Minute}","\t}","","\tdefaultSA := cfg.Defaults.DefaultServiceAccount","\tif trs.ServiceAccountName == \"\" \u0026\u0026 defaultSA != \"\" {","\t\ttrs.ServiceAccountName = defaultSA","\t}","","\tdefaultPodTemplate := cfg.Defaults.DefaultPodTemplate","\ttrs.PodTemplate = pod.MergePodTemplateWithDefault(trs.PodTemplate, defaultPodTemplate)","","\t// If this taskrun has an embedded task, apply the usual task defaults","\tif trs.TaskSpec != nil {","\t\ttrs.TaskSpec.SetDefaults(ctx)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,2,2,2,2,0,2,2,2,2,2,2,2,0]},{"id":111,"path":"pkg/apis/pipeline/v1beta1/taskrun_types.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\tapisconfig \"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tpod \"github.com/tektoncd/pipeline/pkg/apis/pipeline/pod\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"","\t\"k8s.io/apimachinery/pkg/types\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"k8s.io/utils/clock\"","\t\"knative.dev/pkg/apis\"","\tduckv1 \"knative.dev/pkg/apis/duck/v1\"",")","","// TaskRunSpec defines the desired state of TaskRun","type TaskRunSpec struct {","\t// +optional","\tDebug *TaskRunDebug `json:\"debug,omitempty\"`","\t// +optional","\tParams Params `json:\"params,omitempty\"`","\t// Deprecated: Unused, preserved only for backwards compatibility","\t// +optional","\tResources *TaskRunResources `json:\"resources,omitempty\"`","\t// +optional","\tServiceAccountName string `json:\"serviceAccountName\"`","\t// no more than one of the TaskRef and TaskSpec may be specified.","\t// +optional","\tTaskRef *TaskRef `json:\"taskRef,omitempty\"`","\t// Specifying TaskSpec can be disabled by setting","\t// `disable-inline-spec` feature flag.","\t// See Task.spec (API version: tekton.dev/v1beta1)","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tTaskSpec *TaskSpec `json:\"taskSpec,omitempty\"`","\t// Used for cancelling a TaskRun (and maybe more later on)","\t// +optional","\tStatus TaskRunSpecStatus `json:\"status,omitempty\"`","\t// Status message for cancellation.","\t// +optional","\tStatusMessage TaskRunSpecStatusMessage `json:\"statusMessage,omitempty\"`","\t// Retries represents how many times this TaskRun should be retried in the event of Task failure.","\t// +optional","\tRetries int `json:\"retries,omitempty\"`","\t// Time after which one retry attempt times out. Defaults to 1 hour.","\t// Refer Go's ParseDuration documentation for expected format: https://golang.org/pkg/time/#ParseDuration","\t// +optional","\tTimeout *metav1.Duration `json:\"timeout,omitempty\"`","\t// PodTemplate holds pod specific configuration","\tPodTemplate *pod.PodTemplate `json:\"podTemplate,omitempty\"`","\t// Workspaces is a list of WorkspaceBindings from volumes to workspaces.","\t// +optional","\t// +listType=atomic","\tWorkspaces []WorkspaceBinding `json:\"workspaces,omitempty\"`","\t// Overrides to apply to Steps in this TaskRun.","\t// If a field is specified in both a Step and a StepOverride,","\t// the value from the StepOverride will be used.","\t// This field is only supported when the alpha feature gate is enabled.","\t// +optional","\t// +listType=atomic","\tStepOverrides []TaskRunStepOverride `json:\"stepOverrides,omitempty\"`","\t// Overrides to apply to Sidecars in this TaskRun.","\t// If a field is specified in both a Sidecar and a SidecarOverride,","\t// the value from the SidecarOverride will be used.","\t// This field is only supported when the alpha feature gate is enabled.","\t// +optional","\t// +listType=atomic","\tSidecarOverrides []TaskRunSidecarOverride `json:\"sidecarOverrides,omitempty\"`","\t// Compute resources to use for this TaskRun","\tComputeResources *corev1.ResourceRequirements `json:\"computeResources,omitempty\"`","\t// ManagedBy indicates which controller is responsible for reconciling","\t// this resource. If unset or set to \"tekton.dev/pipeline\", the default","\t// Tekton controller will manage this resource.","\t// This field is immutable.","\t// +optional","\tManagedBy *string `json:\"managedBy,omitempty\"`","}","","// TaskRunSpecStatus defines the TaskRun spec status the user can provide","type TaskRunSpecStatus string","","const (","\t// TaskRunSpecStatusCancelled indicates that the user wants to cancel the task,","\t// if not already cancelled or terminated","\tTaskRunSpecStatusCancelled = \"TaskRunCancelled\"",")","","// TaskRunSpecStatusMessage defines human readable status messages for the TaskRun.","type TaskRunSpecStatusMessage string","","const (","\t// TaskRunCancelledByPipelineMsg indicates that the PipelineRun of which this","\t// TaskRun was a part of has been cancelled.","\tTaskRunCancelledByPipelineMsg TaskRunSpecStatusMessage = \"TaskRun cancelled as the PipelineRun it belongs to has been cancelled.\"","\t// TaskRunCancelledByPipelineTimeoutMsg indicates that the TaskRun was cancelled because the PipelineRun running it timed out.","\tTaskRunCancelledByPipelineTimeoutMsg TaskRunSpecStatusMessage = \"TaskRun cancelled as the PipelineRun it belongs to has timed out.\"",")","","const (","\t// EnabledOnFailureBreakpoint is the value for TaskRunDebug.Breakpoints.OnFailure that means the breakpoint onFailure is enabled","\tEnabledOnFailureBreakpoint = \"enabled\"",")","","// TaskRunDebug defines the breakpoint config for a particular TaskRun","type TaskRunDebug struct {","\t// +optional","\tBreakpoints *TaskBreakpoints `json:\"breakpoints,omitempty\"`","}","","// TaskBreakpoints defines the breakpoint config for a particular Task","type TaskBreakpoints struct {","\t// if enabled, pause TaskRun on failure of a step","\t// failed step will not exit","\t// +optional","\tOnFailure string `json:\"onFailure,omitempty\"`","\t// +optional","\t// +listType=atomic","\tBeforeSteps []string `json:\"beforeSteps,omitempty\"`","}","","// NeedsDebugOnFailure return true if the TaskRun is configured to debug on failure","func (trd *TaskRunDebug) NeedsDebugOnFailure() bool {","\tif trd.Breakpoints == nil {","\t\treturn false","\t}","\treturn trd.Breakpoints.OnFailure == EnabledOnFailureBreakpoint","}","","// NeedsDebugBeforeStep return true if the step is configured to debug before execution","func (trd *TaskRunDebug) NeedsDebugBeforeStep(stepName string) bool {","\tif trd.Breakpoints == nil {","\t\treturn false","\t}","\tbeforeStepSets := sets.NewString(trd.Breakpoints.BeforeSteps...)","\treturn beforeStepSets.Has(stepName)","}","","// StepNeedsDebug return true if the step is configured to debug","func (trd *TaskRunDebug) StepNeedsDebug(stepName string) bool {","\treturn trd.NeedsDebugOnFailure() || trd.NeedsDebugBeforeStep(stepName)","}","","// HaveBeforeSteps return true if have any before steps","func (trd *TaskRunDebug) HaveBeforeSteps() bool {","\treturn trd.Breakpoints != nil \u0026\u0026 len(trd.Breakpoints.BeforeSteps) \u003e 0","}","","// NeedsDebug return true if defined onfailure or have any before, after steps","func (trd *TaskRunDebug) NeedsDebug() bool {","\treturn trd.NeedsDebugOnFailure() || trd.HaveBeforeSteps()","}","","var taskRunCondSet = apis.NewBatchConditionSet()","","// TaskRunStatus defines the observed state of TaskRun","type TaskRunStatus struct {","\tduckv1.Status `json:\",inline\"`","","\t// TaskRunStatusFields inlines the status fields.","\tTaskRunStatusFields `json:\",inline\"`","}","","// TaskRunConditionType is an enum used to store TaskRun custom","// conditions such as one used in spire results verification","type TaskRunConditionType string","","const (","\t// TaskRunConditionResultsVerified is a Condition Type that indicates that the results were verified by spire","\tTaskRunConditionResultsVerified TaskRunConditionType = \"SignedResultsVerified\"",")","","func (t TaskRunConditionType) String() string {","\treturn string(t)","}","","// TaskRunReason is an enum used to store all TaskRun reason for","// the Succeeded condition that are controlled by the TaskRun itself. Failure","// reasons that emerge from underlying resources are not included here","type TaskRunReason string","","const (","\t// TaskRunReasonStarted is the reason set when the TaskRun has just started","\tTaskRunReasonStarted TaskRunReason = \"Started\"","\t// TaskRunReasonRunning is the reason set when the TaskRun is running","\tTaskRunReasonRunning TaskRunReason = \"Running\"","\t// TaskRunReasonSuccessful is the reason set when the TaskRun completed successfully","\tTaskRunReasonSuccessful TaskRunReason = \"Succeeded\"","\t// TaskRunReasonFailed is the reason set when the TaskRun completed with a failure","\tTaskRunReasonFailed TaskRunReason = \"Failed\"","\t// TaskRunReasonToBeRetried is the reason set when the last TaskRun execution failed, and will be retried","\tTaskRunReasonToBeRetried TaskRunReason = \"ToBeRetried\"","\t// TaskRunReasonCancelled is the reason set when the TaskRun is cancelled by the user","\tTaskRunReasonCancelled TaskRunReason = \"TaskRunCancelled\"","\t// TaskRunReasonTimedOut is the reason set when one TaskRun execution has timed out","\tTaskRunReasonTimedOut TaskRunReason = \"TaskRunTimeout\"","\t// TaskRunReasonResolvingTaskRef indicates that the TaskRun is waiting for","\t// its taskRef to be asynchronously resolved.","\tTaskRunReasonResolvingTaskRef = \"ResolvingTaskRef\"","\t// TaskRunReasonImagePullFailed is the reason set when the step of a task fails due to image not being pulled","\tTaskRunReasonImagePullFailed TaskRunReason = \"TaskRunImagePullFailed\"","\t// TaskRunReasonResultsVerified is the reason set when the TaskRun results are verified by spire","\tTaskRunReasonResultsVerified TaskRunReason = \"TaskRunResultsVerified\"","\t// TaskRunReasonsResultsVerificationFailed is the reason set when the TaskRun results are failed to verify by spire","\tTaskRunReasonsResultsVerificationFailed TaskRunReason = \"TaskRunResultsVerificationFailed\"","\t// AwaitingTaskRunResults is the reason set when waiting upon `TaskRun` results and signatures to verify","\tAwaitingTaskRunResults TaskRunReason = \"AwaitingTaskRunResults\"","\t// TaskRunReasonResultLargerThanAllowedLimit is the reason set when one of the results exceeds its maximum allowed limit of 1 KB","\tTaskRunReasonResultLargerThanAllowedLimit TaskRunReason = \"TaskRunResultLargerThanAllowedLimit\"","\t// TaskRunReasonStopSidecarFailed indicates that the sidecar is not properly stopped.","\tTaskRunReasonStopSidecarFailed = \"TaskRunStopSidecarFailed\"",")","","func (t TaskRunReason) String() string {","\treturn string(t)","}","","// GetStartedReason returns the reason set to the \"Succeeded\" condition when","// InitializeConditions is invoked","func (trs *TaskRunStatus) GetStartedReason() string {","\treturn TaskRunReasonStarted.String()","}","","// GetRunningReason returns the reason set to the \"Succeeded\" condition when","// the TaskRun starts running. This is used indicate that the resource","// could be validated is starting to perform its job.","func (trs *TaskRunStatus) GetRunningReason() string {","\treturn TaskRunReasonRunning.String()","}","","// MarkResourceOngoing sets the ConditionSucceeded condition to ConditionUnknown","// with the reason and message.","func (trs *TaskRunStatus) MarkResourceOngoing(reason TaskRunReason, message string) {","\ttaskRunCondSet.Manage(trs).SetCondition(apis.Condition{","\t\tType:    apis.ConditionSucceeded,","\t\tStatus:  corev1.ConditionUnknown,","\t\tReason:  reason.String(),","\t\tMessage: message,","\t})","}","","// MarkResourceFailed sets the ConditionSucceeded condition to ConditionFalse","// based on an error that occurred and a reason","func (trs *TaskRunStatus) MarkResourceFailed(reason TaskRunReason, err error) {","\ttaskRunCondSet.Manage(trs).SetCondition(apis.Condition{","\t\tType:    apis.ConditionSucceeded,","\t\tStatus:  corev1.ConditionFalse,","\t\tReason:  reason.String(),","\t\tMessage: err.Error(),","\t})","\tsucceeded := trs.GetCondition(apis.ConditionSucceeded)","\ttrs.CompletionTime = \u0026succeeded.LastTransitionTime.Inner","}","","// +listType=atomic","type RetriesStatus []TaskRunStatus","","// TaskRunStatusFields holds the fields of TaskRun's status.  This is defined","// separately and inlined so that other types can readily consume these fields","// via duck typing.","type TaskRunStatusFields struct {","\t// PodName is the name of the pod responsible for executing this task's steps.","\tPodName string `json:\"podName\"`","","\t// StartTime is the time the build is actually started.","\tStartTime *metav1.Time `json:\"startTime,omitempty\"`","","\t// CompletionTime is the time the build completed.","\tCompletionTime *metav1.Time `json:\"completionTime,omitempty\"`","","\t// Steps describes the state of each build step container.","\t// +optional","\t// +listType=atomic","\tSteps []StepState `json:\"steps,omitempty\"`","","\t// CloudEvents describe the state of each cloud event requested via a","\t// CloudEventResource.","\t//","\t// Deprecated: Removed in v0.44.0.","\t//","\t// +optional","\t// +listType=atomic","\tCloudEvents []CloudEventDelivery `json:\"cloudEvents,omitempty\"`","","\t// RetriesStatus contains the history of TaskRunStatus in case of a retry in order to keep record of failures.","\t// All TaskRunStatus stored in RetriesStatus will have no date within the RetriesStatus as is redundant.","\t// See TaskRun.status (API version: tekton.dev/v1beta1)","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tRetriesStatus RetriesStatus `json:\"retriesStatus,omitempty\"`","","\t// Results from Resources built during the TaskRun.","\t// This is tomb-stoned along with the removal of pipelineResources","\t// Deprecated: this field is not populated and is preserved only for backwards compatibility","\t// +optional","\t// +listType=atomic","\tResourcesResult []PipelineResourceResult `json:\"resourcesResult,omitempty\"`","","\t// TaskRunResults are the list of results written out by the task's containers","\t// +optional","\t// +listType=atomic","\tTaskRunResults []TaskRunResult `json:\"taskResults,omitempty\"`","","\t// The list has one entry per sidecar in the manifest. Each entry is","\t// represents the imageid of the corresponding sidecar.","\t// +listType=atomic","\tSidecars []SidecarState `json:\"sidecars,omitempty\"`","","\t// TaskSpec contains the Spec from the dereferenced Task definition used to instantiate this TaskRun.","\t// See Task.spec (API version tekton.dev/v1beta1)","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tTaskSpec *TaskSpec `json:\"taskSpec,omitempty\"`","","\t// Provenance contains some key authenticated metadata about how a software artifact was built (what sources, what inputs/outputs, etc.).","\t// +optional","\tProvenance *Provenance `json:\"provenance,omitempty\"`","","\t// SpanContext contains tracing span context fields","\tSpanContext map[string]string `json:\"spanContext,omitempty\"`","}","","// TaskRunStepOverride is used to override the values of a Step in the corresponding Task.","type TaskRunStepOverride struct {","\t// The name of the Step to override.","\tName string `json:\"name\"`","\t// The resource requirements to apply to the Step.","\tResources corev1.ResourceRequirements `json:\"resources\"`","}","","// TaskRunSidecarOverride is used to override the values of a Sidecar in the corresponding Task.","type TaskRunSidecarOverride struct {","\t// The name of the Sidecar to override.","\tName string `json:\"name\"`","\t// The resource requirements to apply to the Sidecar.","\tResources corev1.ResourceRequirements `json:\"resources\"`","}","","// GetGroupVersionKind implements kmeta.OwnerRefable.","func (*TaskRun) GetGroupVersionKind() schema.GroupVersionKind {","\treturn SchemeGroupVersion.WithKind(pipeline.TaskRunControllerName)","}","","// GetStatusCondition returns the task run status as a ConditionAccessor","func (tr *TaskRun) GetStatusCondition() apis.ConditionAccessor {","\treturn \u0026tr.Status","}","","// GetCondition returns the Condition matching the given type.","func (trs *TaskRunStatus) GetCondition(t apis.ConditionType) *apis.Condition {","\treturn taskRunCondSet.Manage(trs).GetCondition(t)","}","","// InitializeConditions will set all conditions in taskRunCondSet to unknown for the TaskRun","// and set the started time to the current time","func (trs *TaskRunStatus) InitializeConditions() {","\tstarted := false","\tif trs.StartTime.IsZero() {","\t\ttrs.StartTime = \u0026metav1.Time{Time: time.Now()}","\t\tstarted = true","\t}","\tconditionManager := taskRunCondSet.Manage(trs)","\tconditionManager.InitializeConditions()","\t// Ensure the started reason is set for the \"Succeeded\" condition","\tif started {","\t\tinitialCondition := conditionManager.GetCondition(apis.ConditionSucceeded)","\t\tinitialCondition.Reason = TaskRunReasonStarted.String()","\t\tconditionManager.SetCondition(*initialCondition)","\t}","}","","// SetCondition sets the condition, unsetting previous conditions with the same","// type as necessary.","func (trs *TaskRunStatus) SetCondition(newCond *apis.Condition) {","\tif newCond != nil {","\t\ttaskRunCondSet.Manage(trs).SetCondition(*newCond)","\t}","}","","// StepState reports the results of running a step in a Task.","type StepState struct {","\tcorev1.ContainerState `json:\",inline\"`","\tName                  string                `json:\"name,omitempty\"`","\tContainerName         string                `json:\"container,omitempty\"`","\tImageID               string                `json:\"imageID,omitempty\"`","\tResults               []TaskRunStepResult   `json:\"results,omitempty\"`","\tProvenance            *Provenance           `json:\"provenance,omitempty\"`","\tInputs                []TaskRunStepArtifact `json:\"inputs,omitempty\"`","\tOutputs               []TaskRunStepArtifact `json:\"outputs,omitempty\"`","}","","// SidecarState reports the results of running a sidecar in a Task.","type SidecarState struct {","\tcorev1.ContainerState `json:\",inline\"`","\tName                  string `json:\"name,omitempty\"`","\tContainerName         string `json:\"container,omitempty\"`","\tImageID               string `json:\"imageID,omitempty\"`","}","","// CloudEventDelivery is the target of a cloud event along with the state of","// delivery.","type CloudEventDelivery struct {","\t// Target points to an addressable","\tTarget string                  `json:\"target,omitempty\"`","\tStatus CloudEventDeliveryState `json:\"status,omitempty\"`","}","","// CloudEventCondition is a string that represents the condition of the event.","type CloudEventCondition string","","const (","\t// CloudEventConditionUnknown means that the condition for the event to be","\t// triggered was not met yet, or we don't know the state yet.","\tCloudEventConditionUnknown CloudEventCondition = \"Unknown\"","\t// CloudEventConditionSent means that the event was sent successfully","\tCloudEventConditionSent CloudEventCondition = \"Sent\"","\t// CloudEventConditionFailed means that there was one or more attempts to","\t// send the event, and none was successful so far.","\tCloudEventConditionFailed CloudEventCondition = \"Failed\"",")","","// CloudEventDeliveryState reports the state of a cloud event to be sent.","type CloudEventDeliveryState struct {","\t// Current status","\tCondition CloudEventCondition `json:\"condition,omitempty\"`","\t// SentAt is the time at which the last attempt to send the event was made","\t// +optional","\tSentAt *metav1.Time `json:\"sentAt,omitempty\"`","\t// Error is the text of error (if any)","\tError string `json:\"message\"`","\t// RetryCount is the number of attempts of sending the cloud event","\tRetryCount int32 `json:\"retryCount\"`","}","","// +genclient","// +genreconciler:krshapedlogic=false","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","// +k8s:openapi-gen=true","","// TaskRun represents a single execution of a Task. TaskRuns are how the steps","// specified in a Task are executed; they specify the parameters and resources","// used to run the steps in a Task.","//","// Deprecated: Please use v1.TaskRun instead.","type TaskRun struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ObjectMeta `json:\"metadata,omitempty\"`","","\t// +optional","\tSpec TaskRunSpec `json:\"spec,omitempty\"`","\t// +optional","\tStatus TaskRunStatus `json:\"status,omitempty\"`","}","","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// TaskRunList contains a list of TaskRun","type TaskRunList struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ListMeta `json:\"metadata,omitempty\"`","\tItems           []TaskRun `json:\"items\"`","}","","// GetPipelineRunPVCName for TaskRun gets pipelinerun","func (tr *TaskRun) GetPipelineRunPVCName() string {","\tif tr == nil {","\t\treturn \"\"","\t}","\tfor _, ref := range tr.GetOwnerReferences() {","\t\tif ref.Kind == pipeline.PipelineRunControllerName {","\t\t\treturn ref.Name + \"-pvc\"","\t\t}","\t}","\treturn \"\"","}","","// HasPipelineRunOwnerReference returns true of TaskRun has","// owner reference of type PipelineRun","func (tr *TaskRun) HasPipelineRunOwnerReference() bool {","\tfor _, ref := range tr.GetOwnerReferences() {","\t\tif ref.Kind == pipeline.PipelineRunControllerName {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// IsDone returns true if the TaskRun's status indicates that it is done.","func (tr *TaskRun) IsDone() bool {","\treturn !tr.Status.GetCondition(apis.ConditionSucceeded).IsUnknown()","}","","// HasStarted function check whether TaskRun has valid start time set in its status","func (tr *TaskRun) HasStarted() bool {","\treturn tr.Status.StartTime != nil \u0026\u0026 !tr.Status.StartTime.IsZero()","}","","// IsSuccessful returns true if the TaskRun's status indicates that it has succeeded.","func (tr *TaskRun) IsSuccessful() bool {","\treturn tr != nil \u0026\u0026 tr.Status.GetCondition(apis.ConditionSucceeded).IsTrue()","}","","// IsFailure returns true if the TaskRun's status indicates that it has failed.","func (tr *TaskRun) IsFailure() bool {","\treturn tr != nil \u0026\u0026 tr.Status.GetCondition(apis.ConditionSucceeded).IsFalse()","}","","// IsCancelled returns true if the TaskRun's spec status is set to Cancelled state","func (tr *TaskRun) IsCancelled() bool {","\treturn tr.Spec.Status == TaskRunSpecStatusCancelled","}","","// IsTaskRunResultVerified returns true if the TaskRun's results have been validated by spire.","func (tr *TaskRun) IsTaskRunResultVerified() bool {","\treturn tr.Status.GetCondition(apis.ConditionType(TaskRunConditionResultsVerified.String())).IsTrue()","}","","// IsTaskRunResultDone returns true if the TaskRun's results are available for verification","func (tr *TaskRun) IsTaskRunResultDone() bool {","\treturn !tr.Status.GetCondition(apis.ConditionType(TaskRunConditionResultsVerified.String())).IsUnknown()","}","","// IsRetriable returns true if the TaskRun's Retries is not exhausted.","func (tr *TaskRun) IsRetriable() bool {","\treturn len(tr.Status.RetriesStatus) \u003c tr.Spec.Retries","}","","// HasTimedOut returns true if the TaskRun runtime is beyond the allowed timeout","func (tr *TaskRun) HasTimedOut(ctx context.Context, c clock.PassiveClock) bool {","\tif tr.Status.StartTime.IsZero() {","\t\treturn false","\t}","\ttimeout := tr.GetTimeout(ctx)","\t// If timeout is set to 0 or defaulted to 0, there is no timeout.","\tif timeout == apisconfig.NoTimeoutDuration {","\t\treturn false","\t}","\truntime := c.Since(tr.Status.StartTime.Time)","\treturn runtime \u003e timeout","}","","// GetTimeout returns the timeout for the TaskRun, or the default if not specified","func (tr *TaskRun) GetTimeout(ctx context.Context) time.Duration {","\t// Use the platform default is no timeout is set","\tif tr.Spec.Timeout == nil {","\t\tdefaultTimeout := time.Duration(config.FromContextOrDefaults(ctx).Defaults.DefaultTimeoutMinutes)","\t\treturn defaultTimeout * time.Minute //nolint:durationcheck","\t}","\treturn tr.Spec.Timeout.Duration","}","","// GetNamespacedName returns a k8s namespaced name that identifies this TaskRun","func (tr *TaskRun) GetNamespacedName() types.NamespacedName {","\treturn types.NamespacedName{Namespace: tr.Namespace, Name: tr.Name}","}","","// HasVolumeClaimTemplate returns true if TaskRun contains volumeClaimTemplates that is","// used for creating PersistentVolumeClaims with an OwnerReference for each run","func (tr *TaskRun) HasVolumeClaimTemplate() bool {","\tfor _, ws := range tr.Spec.Workspaces {","\t\tif ws.VolumeClaimTemplate != nil {","\t\t\treturn true","\t\t}","\t}","\treturn false","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,1,1,1,0,0,0,0,1,1,1,0,0,0,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,0,2,0,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,1,1,1,2,0,0,0,2,2,2,0,0,0,2,2,2,2,2,0,1,0]},{"id":112,"path":"pkg/apis/pipeline/v1beta1/taskrun_validation.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"fmt\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\tpod \"github.com/tektoncd/pipeline/pkg/apis/pipeline/pod\"","\t\"github.com/tektoncd/pipeline/pkg/apis/validate\"","\tadmissionregistrationv1 \"k8s.io/api/admissionregistration/v1\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/api/equality\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"k8s.io/utils/strings/slices\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/webhook/resourcesemantics\"",")","","var (","\t_ apis.Validatable              = (*TaskRun)(nil)","\t_ resourcesemantics.VerbLimited = (*TaskRun)(nil)",")","","// SupportedVerbs returns the operations that validation should be called for","func (tr *TaskRun) SupportedVerbs() []admissionregistrationv1.OperationType {","\treturn []admissionregistrationv1.OperationType{admissionregistrationv1.Create, admissionregistrationv1.Update}","}","","// Validate taskrun","func (tr *TaskRun) Validate(ctx context.Context) *apis.FieldError {","\terrs := validate.ObjectMetadata(tr.GetObjectMeta()).ViaField(\"metadata\")","\treturn errs.Also(tr.Spec.Validate(apis.WithinSpec(ctx)).ViaField(\"spec\"))","}","","// Validate taskrun spec","func (ts *TaskRunSpec) Validate(ctx context.Context) (errs *apis.FieldError) {","\t// Validate the spec changes","\terrs = errs.Also(ts.ValidateUpdate(ctx))","","\t// Must have exactly one of taskRef and taskSpec.","\tif ts.TaskRef == nil \u0026\u0026 ts.TaskSpec == nil {","\t\terrs = errs.Also(apis.ErrMissingOneOf(\"taskRef\", \"taskSpec\"))","\t}","\tif ts.TaskRef != nil \u0026\u0026 ts.TaskSpec != nil {","\t\terrs = errs.Also(apis.ErrMultipleOneOf(\"taskRef\", \"taskSpec\"))","\t}","\t// Validate TaskRef if it's present.","\tif ts.TaskRef != nil {","\t\terrs = errs.Also(ts.TaskRef.Validate(ctx).ViaField(\"taskRef\"))","\t}","\t// Validate TaskSpec if it's present.","\tif ts.TaskSpec != nil {","\t\tif slices.Contains(strings.Split(","\t\t\tconfig.FromContextOrDefaults(ctx).FeatureFlags.DisableInlineSpec, \",\"), \"taskrun\") {","\t\t\terrs = errs.Also(apis.ErrDisallowedFields(\"taskSpec\"))","\t\t}","\t\terrs = errs.Also(ts.TaskSpec.Validate(ctx).ViaField(\"taskSpec\"))","\t}","","\terrs = errs.Also(ValidateParameters(ctx, ts.Params).ViaField(\"params\"))","","\t// Validate propagated parameters","\terrs = errs.Also(ts.validateInlineParameters(ctx))","\terrs = errs.Also(ValidateWorkspaceBindings(ctx, ts.Workspaces).ViaField(\"workspaces\"))","\tif ts.Debug != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"debug\", config.AlphaAPIFields).ViaField(\"debug\"))","\t\terrs = errs.Also(validateDebug(ts.Debug).ViaField(\"debug\"))","\t}","\tif ts.StepOverrides != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"stepOverrides\", config.BetaAPIFields).ViaField(\"stepOverrides\"))","\t\terrs = errs.Also(validateStepOverrides(ts.StepOverrides).ViaField(\"stepOverrides\"))","\t}","\tif ts.SidecarOverrides != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"sidecarOverrides\", config.BetaAPIFields).ViaField(\"sidecarOverrides\"))","\t\terrs = errs.Also(validateSidecarOverrides(ts.SidecarOverrides).ViaField(\"sidecarOverrides\"))","\t}","\tif ts.ComputeResources != nil {","\t\terrs = errs.Also(config.ValidateEnabledAPIFields(ctx, \"computeResources\", config.BetaAPIFields).ViaField(\"computeResources\"))","\t\terrs = errs.Also(validateTaskRunComputeResources(ts.ComputeResources, ts.StepOverrides))","\t}","","\tif ts.Status != \"\" {","\t\tif ts.Status != TaskRunSpecStatusCancelled {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"%s should be %s\", ts.Status, TaskRunSpecStatusCancelled), \"status\"))","\t\t}","\t}","\tif ts.Status == \"\" {","\t\tif ts.StatusMessage != \"\" {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(fmt.Sprintf(\"statusMessage should not be set if status is not set, but it is currently set to %s\", ts.StatusMessage), \"statusMessage\"))","\t\t}","\t}","","\tif ts.PodTemplate != nil {","\t\terrs = errs.Also(validatePodTemplateEnv(ctx, *ts.PodTemplate))","\t}","","\tif ts.Timeout != nil \u0026\u0026 ts.Timeout.Duration \u003c 0 {","\t\terrs = errs.Also(apis.ErrInvalidValue(ts.Timeout.Duration.String()+\" should be \u003e= 0\", \"timeout\"))","\t}","","\tif ts.Resources != nil {","\t\terrs = errs.Also(apis.ErrDisallowedFields(\"resources\"))","\t}","\treturn errs","}","","// ValidateUpdate validates the update of a TaskRunSpec","func (ts *TaskRunSpec) ValidateUpdate(ctx context.Context) (errs *apis.FieldError) {","\tif !apis.IsInUpdate(ctx) {","\t\treturn","\t}","\toldObj, ok := apis.GetBaseline(ctx).(*TaskRun)","\tif !ok || oldObj == nil {","\t\treturn","\t}","","\tif (oldObj.Spec.ManagedBy == nil) != (ts.ManagedBy == nil) || (oldObj.Spec.ManagedBy != nil \u0026\u0026 *oldObj.Spec.ManagedBy != *ts.ManagedBy) {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"managedBy is immutable\", \"spec.managedBy\"))","\t}","","\tif oldObj.IsDone() {","\t\t// try comparing without any copying first","\t\t// this handles the common case where only finalizers changed","\t\tif equality.Semantic.DeepEqual(\u0026oldObj.Spec, ts) {","\t\t\treturn nil // Specs identical, allow update","\t\t}","","\t\t// Specs differ, this could be due to different defaults after upgrade","\t\t// Apply current defaults to old spec to normalize","\t\toldCopy := oldObj.Spec.DeepCopy()","\t\toldCopy.SetDefaults(ctx)","","\t\tif equality.Semantic.DeepEqual(oldCopy, ts) {","\t\t\treturn nil // Difference was only defaults, allow update","\t\t}","","\t\t// Real spec changes detected, reject update","\t\terrs = errs.Also(apis.ErrInvalidValue(\"Once the TaskRun is complete, no updates are allowed\", \"\"))","\t\treturn errs","\t}","","\t// Handle started but not done case","\told := oldObj.Spec.DeepCopy()","\told.Status = ts.Status","\told.StatusMessage = ts.StatusMessage","\told.ManagedBy = ts.ManagedBy // Already tested before","\tif !equality.Semantic.DeepEqual(old, ts) {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"Once the TaskRun has started, only status and statusMessage updates are allowed\", \"\"))","\t}","","\treturn","}","","// validateInlineParameters validates that any parameters called in the","// Task spec are declared in the TaskRun.","// This is crucial for propagated parameters because the parameters could","// be defined under taskRun and then called directly in the task steps.","// In this case, parameters cannot be validated by the underlying taskSpec","// since they may not have the parameters declared because of propagation.","func (ts *TaskRunSpec) validateInlineParameters(ctx context.Context) (errs *apis.FieldError) {","\tif ts.TaskSpec == nil {","\t\treturn errs","\t}","\tparamSpecForValidation := make(map[string]ParamSpec)","\tfor _, p := range ts.Params {","\t\tparamSpecForValidation = createParamSpecFromParam(p, paramSpecForValidation)","\t}","","\tfor _, p := range ts.TaskSpec.Params {","\t\tvar err *apis.FieldError","\t\tparamSpecForValidation, err = combineParamSpec(p, paramSpecForValidation)","\t\tif err != nil {","\t\t\terrs = errs.Also(err)","\t\t}","\t}","\tvar paramSpec []ParamSpec","\tfor _, v := range paramSpecForValidation {","\t\tparamSpec = append(paramSpec, v)","\t}","\tif ts.TaskSpec != nil \u0026\u0026 ts.TaskSpec.Steps != nil {","\t\terrs = errs.Also(ValidateParameterTypes(ctx, paramSpec))","\t\terrs = errs.Also(ValidateParameterVariables(ctx, ts.TaskSpec.Steps, paramSpec))","\t\terrs = errs.Also(ValidateUsageOfDeclaredParameters(ctx, ts.TaskSpec.Steps, paramSpec))","\t}","\treturn errs","}","","func validatePodTemplateEnv(ctx context.Context, podTemplate pod.Template) (errs *apis.FieldError) {","\tforbiddenEnvsConfigured := config.FromContextOrDefaults(ctx).Defaults.DefaultForbiddenEnv","\tif len(forbiddenEnvsConfigured) == 0 {","\t\treturn errs","\t}","\tfor _, pEnv := range podTemplate.Env {","\t\tif slices.Contains(forbiddenEnvsConfigured, pEnv.Name) {","\t\t\terrs = errs.Also(apis.ErrInvalidValue(\"PodTemplate cannot update a forbidden env: \"+pEnv.Name, \"PodTemplate.Env\"))","\t\t}","\t}","\treturn errs","}","","func createParamSpecFromParam(p Param, paramSpecForValidation map[string]ParamSpec) map[string]ParamSpec {","\tvalue := p.Value","\tpSpec := ParamSpec{","\t\tName:    p.Name,","\t\tDefault: \u0026value,","\t\tType:    p.Value.Type,","\t}","\tif p.Value.ObjectVal != nil {","\t\tpSpec.Properties = make(map[string]PropertySpec)","\t\tprop := make(map[string]PropertySpec)","\t\tfor k := range p.Value.ObjectVal {","\t\t\tprop[k] = PropertySpec{Type: ParamTypeString}","\t\t}","\t\tpSpec.Properties = prop","\t}","\tparamSpecForValidation[p.Name] = pSpec","\treturn paramSpecForValidation","}","","func combineParamSpec(p ParamSpec, paramSpecForValidation map[string]ParamSpec) (map[string]ParamSpec, *apis.FieldError) {","\tif pSpec, ok := paramSpecForValidation[p.Name]; ok {","\t\t// Merge defaults with provided values in the taskrun.","\t\tif p.Default != nil \u0026\u0026 p.Default.ObjectVal != nil {","\t\t\tfor k, v := range p.Default.ObjectVal {","\t\t\t\tif pSpec.Default.ObjectVal == nil {","\t\t\t\t\tpSpec.Default.ObjectVal = map[string]string{k: v}","\t\t\t\t} else {","\t\t\t\t\tpSpec.Default.ObjectVal[k] = v","\t\t\t\t}","\t\t\t}","\t\t\t// If Default values of object type are provided then Properties must also be fully declared.","\t\t\tif p.Properties == nil {","\t\t\t\treturn paramSpecForValidation, apis.ErrMissingField(p.Name + \".properties\")","\t\t\t}","\t\t}","","\t\t// Properties must be defined if paramSpec is of object Type","\t\tif pSpec.Type == ParamTypeObject {","\t\t\tif p.Properties == nil {","\t\t\t\treturn paramSpecForValidation, apis.ErrMissingField(p.Name + \".properties\")","\t\t\t}","\t\t\t// Expect Properties to be complete","\t\t\tpSpec.Properties = p.Properties","\t\t}","\t\tparamSpecForValidation[p.Name] = pSpec","\t} else {","\t\t// No values provided by task run but found a paramSpec declaration.","\t\t// Expect it to be fully speced out.","\t\tparamSpecForValidation[p.Name] = p","\t}","\treturn paramSpecForValidation, nil","}","","// validateDebug validates the debug section of the TaskRun.","// if set, onFailure breakpoint must be \"enabled\"","func validateDebug(db *TaskRunDebug) (errs *apis.FieldError) {","\tif db == nil || db.Breakpoints == nil {","\t\treturn errs","\t}","","\tif db.Breakpoints.OnFailure == \"\" {","\t\terrs = errs.Also(apis.ErrInvalidValue(\"onFailure breakpoint is empty, it is only allowed to be set as enabled\", \"breakpoints.onFailure\"))","\t}","","\tif db.Breakpoints.OnFailure != \"\" \u0026\u0026 db.Breakpoints.OnFailure != EnabledOnFailureBreakpoint {","\t\terrs = errs.Also(apis.ErrInvalidValue(db.Breakpoints.OnFailure+\" is not a valid onFailure breakpoint value, onFailure breakpoint is only allowed to be set as enabled\", \"breakpoints.onFailure\"))","\t}","\tbeforeSteps := sets.NewString()","\tfor i, step := range db.Breakpoints.BeforeSteps {","\t\tif beforeSteps.Has(step) {","\t\t\terrs = errs.Also(apis.ErrGeneric(fmt.Sprintf(\"before step must be unique, the same step: %s is defined multiple times at\", step), fmt.Sprintf(\"breakpoints.beforeSteps[%d]\", i)))","\t\t}","\t\tbeforeSteps.Insert(step)","\t}","\treturn errs","}","","// ValidateWorkspaceBindings makes sure the volumes provided for the Task's declared workspaces make sense.","func ValidateWorkspaceBindings(ctx context.Context, wb []WorkspaceBinding) (errs *apis.FieldError) {","\tvar names []string","\tfor idx, w := range wb {","\t\tnames = append(names, w.Name)","\t\terrs = errs.Also(w.Validate(ctx).ViaIndex(idx))","\t}","\terrs = errs.Also(validateNoDuplicateNames(names, true))","\treturn errs","}","","// ValidateParameters makes sure the params for the Task are valid.","func ValidateParameters(ctx context.Context, params Params) (errs *apis.FieldError) {","\tvar names []string","\tfor _, p := range params {","\t\tnames = append(names, p.Name)","\t}","\treturn errs.Also(validateNoDuplicateNames(names, false))","}","","func validateStepOverrides(overrides []TaskRunStepOverride) (errs *apis.FieldError) {","\tvar names []string","\tfor i, o := range overrides {","\t\tif o.Name == \"\" {","\t\t\terrs = errs.Also(apis.ErrMissingField(\"name\").ViaIndex(i))","\t\t} else {","\t\t\tnames = append(names, o.Name)","\t\t}","\t}","\terrs = errs.Also(validateNoDuplicateNames(names, true))","\treturn errs","}","","// validateTaskRunComputeResources ensures that compute resources are not configured at both the step level and the task level","func validateTaskRunComputeResources(computeResources *corev1.ResourceRequirements, overrides []TaskRunStepOverride) (errs *apis.FieldError) {","\tfor _, override := range overrides {","\t\tif override.Resources.Size() != 0 \u0026\u0026 computeResources != nil {","\t\t\treturn apis.ErrMultipleOneOf(","\t\t\t\t\"stepOverrides.resources\",","\t\t\t\t\"computeResources\",","\t\t\t)","\t\t}","\t}","\treturn nil","}","","func validateSidecarOverrides(overrides []TaskRunSidecarOverride) (errs *apis.FieldError) {","\tvar names []string","\tfor i, o := range overrides {","\t\tif o.Name == \"\" {","\t\t\terrs = errs.Also(apis.ErrMissingField(\"name\").ViaIndex(i))","\t\t} else {","\t\t\tnames = append(names, o.Name)","\t\t}","\t}","\terrs = errs.Also(validateNoDuplicateNames(names, true))","\treturn errs","}","","// validateNoDuplicateNames returns an error for each name that is repeated in names.","// Case insensitive.","// If byIndex is true, the error will be reported by index instead of by key.","func validateNoDuplicateNames(names []string, byIndex bool) (errs *apis.FieldError) {","\tseen := sets.NewString()","\tfor i, n := range names {","\t\tif seen.Has(strings.ToLower(n)) {","\t\t\tif byIndex {","\t\t\t\terrs = errs.Also(apis.ErrMultipleOneOf(\"name\").ViaIndex(i))","\t\t\t} else {","\t\t\t\terrs = errs.Also(apis.ErrMultipleOneOf(\"name\").ViaKey(n))","\t\t\t}","\t\t}","\t\tseen.Insert(strings.ToLower(n))","\t}","\treturn errs","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,2,2,2,2,0,0,2,2,2,0,2,2,2,0,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,2,2,2,0,0,0,2,2,2,2,1,1,0,0,2,2,0,0,0,2,2,2,2,2,2,2,0,2,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,0,0,2,2,1,1,0,2,0,2,2,2,2,2,2,2,0,0,0,0,2,2,1,1,0,2,2,2,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,2,2,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,0,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,0,2,0]},{"id":113,"path":"pkg/apis/pipeline/v1beta1/when_types.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"fmt\"","","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\t\"k8s.io/apimachinery/pkg/selection\"",")","","// WhenExpression allows a PipelineTask to declare expressions to be evaluated before the Task is run","// to determine whether the Task should be executed or skipped","type WhenExpression struct {","\t// Input is the string for guard checking which can be a static input or an output from a parent Task","\tInput string `json:\"input,omitempty\"`","","\t// Operator that represents an Input's relationship to the values","\tOperator selection.Operator `json:\"operator,omitempty\"`","","\t// Values is an array of strings, which is compared against the input, for guard checking","\t// It must be non-empty","\t// +listType=atomic","\tValues []string `json:\"values,omitempty\"`","","\t// CEL is a string of Common Language Expression, which can be used to conditionally execute","\t// the task based on the result of the expression evaluation","\t// More info about CEL syntax: https://github.com/google/cel-spec/blob/master/doc/langdef.md","\t// +optional","\tCEL string `json:\"cel,omitempty\"`","}","","func (we *WhenExpression) isInputInValues() bool {","\tfor i := range we.Values {","\t\tif we.Values[i] == we.Input {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","func (we *WhenExpression) isTrue() bool {","\tif we.Operator == selection.In {","\t\treturn we.isInputInValues()","\t}","\t// selection.NotIn","\treturn !we.isInputInValues()","}","","func (we *WhenExpression) applyReplacements(replacements map[string]string, arrayReplacements map[string][]string) WhenExpression {","\treplacedInput := substitution.ApplyReplacements(we.Input, replacements)","\treplacedCEL := substitution.ApplyReplacements(we.CEL, replacements)","","\tvar replacedValues []string","\tfor _, val := range we.Values {","\t\t// arrayReplacements holds a list of array parameters with a pattern - params.arrayParam1","\t\t// array params are referenced using $(params.arrayParam1[*])","\t\t// array results are referenced using $(results.resultname[*])","\t\t// check if the param exist in the arrayReplacements to replace it with a list of values","\t\tif _, ok := arrayReplacements[fmt.Sprintf(\"%s.%s\", ParamsPrefix, ArrayReference(val))]; ok {","\t\t\treplacedValues = append(replacedValues, substitution.ApplyArrayReplacements(val, replacements, arrayReplacements)...)","\t\t} else if _, ok := arrayReplacements[ResultsArrayReference(val)]; ok {","\t\t\treplacedValues = append(replacedValues, substitution.ApplyArrayReplacements(val, replacements, arrayReplacements)...)","\t\t} else {","\t\t\treplacedValues = append(replacedValues, substitution.ApplyReplacements(val, replacements))","\t\t}","\t}","","\treturn WhenExpression{Input: replacedInput, Operator: we.Operator, Values: replacedValues, CEL: replacedCEL}","}","","// GetVarSubstitutionExpressions extracts all the values between \"$(\" and \")\" in a When Expression","func (we *WhenExpression) GetVarSubstitutionExpressions() ([]string, bool) {","\tvar allExpressions []string","\tallExpressions = append(allExpressions, validateString(we.Input)...)","\tallExpressions = append(allExpressions, validateString(we.CEL)...)","\tfor _, value := range we.Values {","\t\tallExpressions = append(allExpressions, validateString(value)...)","\t}","\treturn allExpressions, len(allExpressions) != 0","}","","// WhenExpressions are used to specify whether a Task should be executed or skipped","// All of them need to evaluate to True for a guarded Task to be executed.","type WhenExpressions []WhenExpression","","type StepWhenExpressions = WhenExpressions","","// AllowsExecution evaluates an Input's relationship to an array of Values, based on the Operator,","// to determine whether all the When Expressions are True. If they are all True, the guarded Task is","// executed, otherwise it is skipped.","// If CEL expression exists, AllowsExecution will get the evaluated results from evaluatedCEL and determine","// if the Task should be skipped.","func (wes WhenExpressions) AllowsExecution(evaluatedCEL map[string]bool) bool {","\tfor _, we := range wes {","\t\tif !we.isTrue() || (we.CEL != \"\" \u0026\u0026 !evaluatedCEL[we.CEL]) {","\t\t\treturn false","\t\t}","\t}","\treturn true","}","","// ReplaceVariables interpolates variables, such as Parameters and Results, in","// the Input and Values.","func (wes WhenExpressions) ReplaceVariables(replacements map[string]string, arrayReplacements map[string][]string) WhenExpressions {","\treplaced := wes","\tfor i := range wes {","\t\treplaced[i] = wes[i].applyReplacements(replacements, arrayReplacements)","\t}","\treturn replaced","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,2,0,0,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,0]},{"id":114,"path":"pkg/apis/pipeline/v1beta1/when_validation.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","\t\"fmt\"","\t\"strings\"","","\t\"github.com/google/cel-go/cel\"","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"k8s.io/apimachinery/pkg/api/equality\"","\t\"k8s.io/apimachinery/pkg/selection\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"knative.dev/pkg/apis\"",")","","var validWhenOperators = []string{","\tstring(selection.In),","\tstring(selection.NotIn),","}","","func (wes WhenExpressions) validate(ctx context.Context) *apis.FieldError {","\treturn wes.validateWhenExpressionsFields(ctx).ViaField(\"when\")","}","","func (wes WhenExpressions) validateWhenExpressionsFields(ctx context.Context) (errs *apis.FieldError) {","\tfor idx, we := range wes {","\t\terrs = errs.Also(we.validateWhenExpressionFields(ctx).ViaIndex(idx))","\t}","\treturn errs","}","","func (we *WhenExpression) validateWhenExpressionFields(ctx context.Context) *apis.FieldError {","\tif we.CEL != \"\" {","\t\tif !config.FromContextOrDefaults(ctx).FeatureFlags.EnableCELInWhenExpression {","\t\t\treturn apis.ErrGeneric(fmt.Sprintf(\"feature flag %s should be set to true to use CEL: %s in WhenExpression\", config.EnableCELInWhenExpression, we.CEL), \"\")","\t\t}","\t\tif we.Input != \"\" || we.Operator != \"\" || len(we.Values) != 0 {","\t\t\treturn apis.ErrGeneric(fmt.Sprintf(\"cel and input+operator+values cannot be set in one WhenExpression: %v\", we))","\t\t}","\t\t// We need to compile the CEL expression and check if it is a valid expression","\t\t// note that at the validation webhook, Tekton's variables are not substituted,","\t\t// so they need to be wrapped with single quotes.","\t\t// e.g.  This is a valid CEL expression: '$(params.foo)' == 'foo';","\t\t//       But this is not a valid expression since CEL cannot recognize: $(params.foo) == 'foo';","\t\t//       This is not valid since we don't pass params to CEL's environment: params.foo == 'foo';","\t\tenv, _ := cel.NewEnv()","\t\t_, iss := env.Compile(we.CEL)","\t\tif iss.Err() != nil {","\t\t\treturn apis.ErrGeneric(\"invalid cel expression: %s with err: %s\", we.CEL, iss.Err().Error())","\t\t}","\t\treturn nil","\t}","","\tif equality.Semantic.DeepEqual(we, \u0026WhenExpression{}) || we == nil {","\t\treturn apis.ErrMissingField(apis.CurrentField)","\t}","\tif !sets.NewString(validWhenOperators...).Has(string(we.Operator)) {","\t\tmessage := fmt.Sprintf(\"operator %q is not recognized. valid operators: %s\", we.Operator, strings.Join(validWhenOperators, \",\"))","\t\treturn apis.ErrInvalidValue(message, apis.CurrentField)","\t}","\tif len(we.Values) == 0 {","\t\treturn apis.ErrInvalidValue(\"expecting non-empty values field\", apis.CurrentField)","\t}","\treturn nil","}","","func (wes WhenExpressions) validatePipelineParametersVariables(prefix string, paramNames sets.String, arrayParamNames sets.String, objectParamNameKeys map[string][]string) (errs *apis.FieldError) {","\tfor idx, we := range wes {","\t\terrs = errs.Also(validateStringVariable(we.Input, prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaField(\"input\").ViaFieldIndex(\"when\", idx))","\t\tfor _, val := range we.Values {","\t\t\t// one of the values could be a reference to an array param, such as, $(params.foo[*])","\t\t\t// extract the variable name from the pattern $(params.foo[*]), if the variable name matches with one of the array params","\t\t\t// validate the param as an array variable otherwise, validate it as a string variable","\t\t\tif arrayParamNames.Has(ArrayReference(val)) {","\t\t\t\terrs = errs.Also(validateArrayVariable(val, prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaField(\"values\").ViaFieldIndex(\"when\", idx))","\t\t\t} else {","\t\t\t\terrs = errs.Also(validateStringVariable(val, prefix, paramNames, arrayParamNames, objectParamNameKeys).ViaField(\"values\").ViaFieldIndex(\"when\", idx))","\t\t\t}","\t\t}","\t}","\treturn errs","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,0,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0]},{"id":115,"path":"pkg/apis/pipeline/v1beta1/workspace_conversion.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"",")","","func (w WorkspaceDeclaration) convertTo(ctx context.Context, sink *v1.WorkspaceDeclaration) {","\tsink.Name = w.Name","\tsink.Description = w.Description","\tsink.MountPath = w.MountPath","\tsink.ReadOnly = w.ReadOnly","\tsink.Optional = w.Optional","}","","func (w *WorkspaceDeclaration) convertFrom(ctx context.Context, source v1.WorkspaceDeclaration) {","\tw.Name = source.Name","\tw.Description = source.Description","\tw.MountPath = source.MountPath","\tw.ReadOnly = source.ReadOnly","\tw.Optional = source.Optional","}","","func (w WorkspaceUsage) convertTo(ctx context.Context, sink *v1.WorkspaceUsage) {","\tsink.Name = w.Name","\tsink.MountPath = w.MountPath","}","","func (w *WorkspaceUsage) convertFrom(ctx context.Context, source v1.WorkspaceUsage) {","\tw.Name = source.Name","\tw.MountPath = source.MountPath","}","","func (w PipelineWorkspaceDeclaration) convertTo(ctx context.Context, sink *v1.PipelineWorkspaceDeclaration) {","\tsink.Name = w.Name","\tsink.Description = w.Description","\tsink.Optional = w.Optional","}","","func (w *PipelineWorkspaceDeclaration) convertFrom(ctx context.Context, source v1.PipelineWorkspaceDeclaration) {","\tw.Name = source.Name","\tw.Description = source.Description","\tw.Optional = source.Optional","}","","func (w WorkspacePipelineTaskBinding) convertTo(ctx context.Context, sink *v1.WorkspacePipelineTaskBinding) {","\tsink.Name = w.Name","\tsink.Workspace = w.Workspace","\tsink.SubPath = w.SubPath","}","","func (w *WorkspacePipelineTaskBinding) convertFrom(ctx context.Context, source v1.WorkspacePipelineTaskBinding) {","\tw.Name = source.Name","\tw.Workspace = source.Workspace","\tw.SubPath = source.SubPath","}","","func (w WorkspaceBinding) convertTo(ctx context.Context, sink *v1.WorkspaceBinding) {","\tsink.Name = w.Name","\tsink.SubPath = w.SubPath","\tsink.VolumeClaimTemplate = w.VolumeClaimTemplate","\tsink.PersistentVolumeClaim = w.PersistentVolumeClaim","\tsink.EmptyDir = w.EmptyDir","\tsink.ConfigMap = w.ConfigMap","\tsink.Secret = w.Secret","\tsink.Projected = w.Projected","\tsink.CSI = w.CSI","}","","// ConvertFrom converts v1beta1 Param from v1 Param","func (w *WorkspaceBinding) ConvertFrom(ctx context.Context, source v1.WorkspaceBinding) {","\tw.Name = source.Name","\tw.SubPath = source.SubPath","\tw.VolumeClaimTemplate = source.VolumeClaimTemplate","\tw.PersistentVolumeClaim = source.PersistentVolumeClaim","\tw.EmptyDir = source.EmptyDir","\tw.ConfigMap = source.ConfigMap","\tw.Secret = source.Secret","\tw.Projected = source.Projected","\tw.CSI = source.CSI","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,2,0,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2]},{"id":116,"path":"pkg/apis/pipeline/v1beta1/workspace_types.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"path/filepath\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tcorev1 \"k8s.io/api/core/v1\"",")","","// WorkspaceDeclaration is a declaration of a volume that a Task requires.","type WorkspaceDeclaration struct {","\t// Name is the name by which you can bind the volume at runtime.","\tName string `json:\"name\"`","\t// Description is an optional human readable description of this volume.","\t// +optional","\tDescription string `json:\"description,omitempty\"`","\t// MountPath overrides the directory that the volume will be made available at.","\t// +optional","\tMountPath string `json:\"mountPath,omitempty\"`","\t// ReadOnly dictates whether a mounted volume is writable. By default this","\t// field is false and so mounted volumes are writable.","\tReadOnly bool `json:\"readOnly,omitempty\"`","\t// Optional marks a Workspace as not being required in TaskRuns. By default","\t// this field is false and so declared workspaces are required.","\tOptional bool `json:\"optional,omitempty\"`","}","","// GetMountPath returns the mountPath for w which is the MountPath if provided or the","// default if not.","func (w *WorkspaceDeclaration) GetMountPath() string {","\tif w.MountPath != \"\" {","\t\treturn w.MountPath","\t}","\treturn filepath.Join(pipeline.WorkspaceDir, w.Name)","}","","// WorkspaceBinding maps a Task's declared workspace to a Volume.","type WorkspaceBinding struct {","\t// Name is the name of the workspace populated by the volume.","\tName string `json:\"name\"`","\t// SubPath is optionally a directory on the volume which should be used","\t// for this binding (i.e. the volume will be mounted at this sub directory).","\t// +optional","\tSubPath string `json:\"subPath,omitempty\"`","\t// VolumeClaimTemplate is a template for a claim that will be created in the same namespace.","\t// The PipelineRun controller is responsible for creating a unique claim for each instance of PipelineRun.","\t// See PersistentVolumeClaim (API version: v1)","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tVolumeClaimTemplate *corev1.PersistentVolumeClaim `json:\"volumeClaimTemplate,omitempty\"`","\t// PersistentVolumeClaimVolumeSource represents a reference to a","\t// PersistentVolumeClaim in the same namespace. Either this OR EmptyDir can be used.","\t// +optional","\tPersistentVolumeClaim *corev1.PersistentVolumeClaimVolumeSource `json:\"persistentVolumeClaim,omitempty\"`","\t// EmptyDir represents a temporary directory that shares a Task's lifetime.","\t// More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir","\t// Either this OR PersistentVolumeClaim can be used.","\t// +optional","\tEmptyDir *corev1.EmptyDirVolumeSource `json:\"emptyDir,omitempty\"`","\t// ConfigMap represents a configMap that should populate this workspace.","\t// +optional","\tConfigMap *corev1.ConfigMapVolumeSource `json:\"configMap,omitempty\"`","\t// Secret represents a secret that should populate this workspace.","\t// +optional","\tSecret *corev1.SecretVolumeSource `json:\"secret,omitempty\"`","\t// Projected represents a projected volume that should populate this workspace.","\t// +optional","\tProjected *corev1.ProjectedVolumeSource `json:\"projected,omitempty\"`","\t// CSI (Container Storage Interface) represents ephemeral storage that is handled by certain external CSI drivers.","\t// +optional","\tCSI *corev1.CSIVolumeSource `json:\"csi,omitempty\"`","}","","// WorkspacePipelineDeclaration creates a named slot in a Pipeline that a PipelineRun","// is expected to populate with a workspace binding.","//","// Deprecated: use PipelineWorkspaceDeclaration type instead","type WorkspacePipelineDeclaration = PipelineWorkspaceDeclaration","","// PipelineWorkspaceDeclaration creates a named slot in a Pipeline that a PipelineRun","// is expected to populate with a workspace binding.","type PipelineWorkspaceDeclaration struct {","\t// Name is the name of a workspace to be provided by a PipelineRun.","\tName string `json:\"name\"`","\t// Description is a human readable string describing how the workspace will be","\t// used in the Pipeline. It can be useful to include a bit of detail about which","\t// tasks are intended to have access to the data on the workspace.","\t// +optional","\tDescription string `json:\"description,omitempty\"`","\t// Optional marks a Workspace as not being required in PipelineRuns. By default","\t// this field is false and so declared workspaces are required.","\tOptional bool `json:\"optional,omitempty\"`","}","","// WorkspacePipelineTaskBinding describes how a workspace passed into the pipeline should be","// mapped to a task's declared workspace.","type WorkspacePipelineTaskBinding struct {","\t// Name is the name of the workspace as declared by the task","\tName string `json:\"name\"`","\t// Workspace is the name of the workspace declared by the pipeline","\t// +optional","\tWorkspace string `json:\"workspace,omitempty\"`","\t// SubPath is optionally a directory on the volume which should be used","\t// for this binding (i.e. the volume will be mounted at this sub directory).","\t// +optional","\tSubPath string `json:\"subPath,omitempty\"`","}","","// WorkspaceUsage is used by a Step or Sidecar to declare that it wants isolated access","// to a Workspace defined in a Task.","type WorkspaceUsage struct {","\t// Name is the name of the workspace this Step or Sidecar wants access to.","\tName string `json:\"name\"`","\t// MountPath is the path that the workspace should be mounted to inside the Step or Sidecar,","\t// overriding any MountPath specified in the Task's WorkspaceDeclaration.","\tMountPath string `json:\"mountPath\"`","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]},{"id":117,"path":"pkg/apis/pipeline/v1beta1/workspace_validation.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","","\t\"k8s.io/apimachinery/pkg/api/equality\"","\t\"knative.dev/pkg/apis\"",")","","// allVolumeSourceFields is a list of all the volume source field paths that a","// WorkspaceBinding may include.","var allVolumeSourceFields = []string{","\t\"persistentvolumeclaim\",","\t\"volumeclaimtemplate\",","\t\"emptydir\",","\t\"configmap\",","\t\"secret\",","}","","// Validate looks at the Volume provided in wb and makes sure that it is valid.","// This means that only one VolumeSource can be specified, and also that the","// supported VolumeSource is itself valid.","func (b *WorkspaceBinding) Validate(ctx context.Context) (errs *apis.FieldError) {","\tif equality.Semantic.DeepEqual(b, \u0026WorkspaceBinding{}) || b == nil {","\t\treturn apis.ErrMissingField(apis.CurrentField)","\t}","","\tnumSources := b.numSources()","","\tif numSources \u003e 1 {","\t\treturn apis.ErrMultipleOneOf(allVolumeSourceFields...)","\t}","","\tif numSources == 0 {","\t\treturn apis.ErrMissingOneOf(allVolumeSourceFields...)","\t}","","\t// For a PersistentVolumeClaim to work, you must at least provide the name of the PVC to use.","\tif b.PersistentVolumeClaim != nil \u0026\u0026 b.PersistentVolumeClaim.ClaimName == \"\" {","\t\treturn apis.ErrMissingField(\"persistentvolumeclaim.claimname\")","\t}","","\t// For a ConfigMap to work, you must provide the name of the ConfigMap to use.","\tif b.ConfigMap != nil \u0026\u0026 b.ConfigMap.LocalObjectReference.Name == \"\" {","\t\treturn apis.ErrMissingField(\"configmap.name\")","\t}","","\t// For a Secret to work, you must provide the name of the Secret to use.","\tif b.Secret != nil \u0026\u0026 b.Secret.SecretName == \"\" {","\t\treturn apis.ErrMissingField(\"secret.secretName\")","\t}","","\t// For a Projected volume to work, you must provide at least one source.","\tif b.Projected != nil \u0026\u0026 len(b.Projected.Sources) == 0 {","\t\treturn apis.ErrMissingField(\"projected.sources\")","\t}","","\t// For a CSI to work, you must provide and have installed the driver to use.","\tif b.CSI != nil \u0026\u0026 b.CSI.Driver == \"\" {","\t\treturn apis.ErrMissingField(\"csi.driver\")","\t}","","\treturn nil","}","","// numSources returns the total number of volume sources that this WorkspaceBinding","// has been configured with.","func (b *WorkspaceBinding) numSources() int {","\tn := 0","\tif b.VolumeClaimTemplate != nil {","\t\tn++","\t}","\tif b.PersistentVolumeClaim != nil {","\t\tn++","\t}","\tif b.EmptyDir != nil {","\t\tn++","\t}","\tif b.ConfigMap != nil {","\t\tn++","\t}","\tif b.Secret != nil {","\t\tn++","\t}","\tif b.Projected != nil {","\t\tn++","\t}","\tif b.CSI != nil {","\t\tn++","\t}","\treturn n","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,2,2,2,2,2,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0]},{"id":118,"path":"pkg/apis/resolution/v1alpha1/register.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1alpha1","","import (","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"",")","","// SchemeGroupVersion is group version used to register these objects","var SchemeGroupVersion = schema.GroupVersion{Group: resolution.GroupName, Version: \"v1alpha1\"}","","// Kind takes an unqualified kind and returns back a Group qualified GroupKind","func Kind(kind string) schema.GroupKind {","\treturn SchemeGroupVersion.WithKind(kind).GroupKind()","}","","// Resource takes an unqualified resource and returns a Group qualified GroupResource","func Resource(resource string) schema.GroupResource {","\treturn SchemeGroupVersion.WithResource(resource).GroupResource()","}","","var (","\t// SchemeBuilder builds a scheme with the types known to the package.","\tSchemeBuilder = runtime.NewSchemeBuilder(addKnownTypes)","\t// AddToScheme adds the types known to this package to an existing schema.","\tAddToScheme = SchemeBuilder.AddToScheme",")","","// Adds the list of known types to Scheme.","func addKnownTypes(scheme *runtime.Scheme) error {","\tscheme.AddKnownTypes(SchemeGroupVersion,","\t\t\u0026ResolutionRequest{},","\t\t\u0026ResolutionRequestList{},","\t)","\tmetav1.AddToGroupVersion(scheme, SchemeGroupVersion)","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1]},{"id":119,"path":"pkg/apis/resolution/v1alpha1/resolution_request_conversion.go","lines":["/*"," Copyright 2022 The Tekton Authors",""," Licensed under the Apache License, Version 2.0 (the \"License\");"," you may not use this file except in compliance with the License."," You may obtain a copy of the License at","","     http://www.apache.org/licenses/LICENSE-2.0",""," Unless required by applicable law or agreed to in writing, software"," distributed under the License is distributed on an \"AS IS\" BASIS,"," WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied."," See the License for the specific language governing permissions and"," limitations under the License.","","*/","","package v1alpha1","","import (","\t\"context\"","\t\"fmt\"","\t\"strings\"","","\tpipelinev1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Convertible = (*ResolutionRequest)(nil)","","// ConvertTo implements apis.Convertible","func (rr *ResolutionRequest) ConvertTo(ctx context.Context, sink apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\tswitch sink := sink.(type) {","\tcase *v1beta1.ResolutionRequest:","\t\tsink.ObjectMeta = rr.ObjectMeta","\t\trr.Status.convertTo(ctx, \u0026sink.Status)","\t\treturn rr.Spec.ConvertTo(ctx, \u0026sink.Spec)","\tdefault:","\t\treturn fmt.Errorf(\"unknown version, got: %T\", sink)","\t}","}","","// ConvertTo converts a v1alpha1.ResolutionRequestSpec to a v1beta1.ResolutionRequestSpec","func (rrs *ResolutionRequestSpec) ConvertTo(ctx context.Context, sink *v1beta1.ResolutionRequestSpec) error {","\tfor k, v := range rrs.Parameters {","\t\tsink.Params = append(sink.Params, pipelinev1.Param{","\t\t\tName: k,","\t\t\tValue: pipelinev1.ParamValue{","\t\t\t\tType:      pipelinev1.ParamTypeString,","\t\t\t\tStringVal: v,","\t\t\t},","\t\t})","\t}","","\treturn nil","}","","// convertTo converts a v1alpha1.ResolutionRequestStatus to a v1beta1.ResolutionRequestStatus","func (rrs *ResolutionRequestStatus) convertTo(ctx context.Context, sink *v1beta1.ResolutionRequestStatus) {","\tsink.Data = rrs.Data","\tif rrs.RefSource != nil {","\t\trefSource := pipelinev1.RefSource{}","\t\trefSource.URI = rrs.RefSource.URI","\t\trefSource.EntryPoint = rrs.RefSource.EntryPoint","\t\tdigest := make(map[string]string)","\t\tfor k, v := range rrs.RefSource.Digest {","\t\t\tdigest[k] = v","\t\t}","\t\trefSource.Digest = digest","\t\tsink.RefSource = \u0026refSource","\t}","}","","// ConvertFrom implements apis.Convertible","func (rr *ResolutionRequest) ConvertFrom(ctx context.Context, from apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\tswitch from := from.(type) {","\tcase *v1beta1.ResolutionRequest:","\t\trr.ObjectMeta = from.ObjectMeta","\t\trr.Status.convertFrom(ctx, \u0026from.Status)","\t\treturn rr.Spec.ConvertFrom(ctx, \u0026from.Spec)","\tdefault:","\t\treturn fmt.Errorf(\"unknown version, got: %T\", from)","\t}","}","","// ConvertFrom converts a v1beta1.ResolutionRequestSpec to a v1alpha1.ResolutionRequestSpec","func (rrs *ResolutionRequestSpec) ConvertFrom(ctx context.Context, from *v1beta1.ResolutionRequestSpec) error {","\tvar nonStringParams []string","","\tfor _, p := range from.Params {","\t\tif p.Value.Type != pipelinev1.ParamTypeString {","\t\t\tnonStringParams = append(nonStringParams, p.Name)","\t\t} else {","\t\t\tif rrs.Parameters == nil {","\t\t\t\trrs.Parameters = make(map[string]string)","\t\t\t}","\t\t\trrs.Parameters[p.Name] = p.Value.StringVal","\t\t}","\t}","","\tif len(nonStringParams) \u003e 0 {","\t\treturn fmt.Errorf(\"cannot convert v1beta1 to v1alpha, non-string type parameter(s) found: %s\", strings.Join(nonStringParams, \", \"))","\t}","","\treturn nil","}","","// convertFrom converts a v1alpha1.ResolutionRequestStatus to a v1beta1.ResolutionRequestStatus","func (rrs *ResolutionRequestStatus) convertFrom(ctx context.Context, from *v1beta1.ResolutionRequestStatus) {","\trrs.Data = from.Data","","\tif from.RefSource != nil {","\t\trefSource := pipelinev1.RefSource{}","\t\trefSource.URI = from.RefSource.URI","\t\trefSource.EntryPoint = from.RefSource.EntryPoint","\t\tdigest := make(map[string]string)","\t\tfor k, v := range from.RefSource.Digest {","\t\t\tdigest[k] = v","\t\t}","\t\trefSource.Digest = digest","\t\trrs.RefSource = \u0026refSource","\t} else if from.Source != nil {","\t\trefSource := pipelinev1.RefSource{}","\t\trefSource.URI = from.Source.URI","\t\trefSource.EntryPoint = from.Source.EntryPoint","\t\tdigest := make(map[string]string)","\t\tfor k, v := range from.Source.Digest {","\t\t\tdigest[k] = v","\t\t}","\t\trefSource.Digest = digest","\t\trrs.RefSource = \u0026refSource","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,1,1,1,1,1,1,1,1,1,0,0,0,0,2,2,1,1,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,0,2,0,0,0,2,2,2,2,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,0,0]},{"id":120,"path":"pkg/apis/resolution/v1alpha1/resolution_request_defaults.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1alpha1","","import \"context\"","","// ManagedByLabelKey is the label key used to mark what is managing this resource","const ManagedByLabelKey = \"app.kubernetes.io/managed-by\"","","// SetDefaults walks a ResolutionRequest object and sets any default","// values that are required to be set before a reconciler sees it.","func (rr *ResolutionRequest) SetDefaults(ctx context.Context) {","\tif rr.TypeMeta.Kind == \"\" {","\t\trr.TypeMeta.Kind = \"ResolutionRequest\"","\t}","\tif rr.TypeMeta.APIVersion == \"\" {","\t\trr.TypeMeta.APIVersion = \"resolution.tekton.dev/v1alpha1\"","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0]},{"id":121,"path":"pkg/apis/resolution/v1alpha1/resolution_request_lifecycle.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1alpha1","","import (","\tresolutioncommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"","\t\"knative.dev/pkg/apis\"",")","","// ResolutionRequests only have apis.ConditionSucceeded for now.","var resolutionRequestCondSet = apis.NewBatchConditionSet()","","// GetGroupVersionKind implements kmeta.OwnerRefable.","func (*ResolutionRequest) GetGroupVersionKind() schema.GroupVersionKind {","\treturn SchemeGroupVersion.WithKind(\"ResolutionRequest\")","}","","// GetConditionSet implements KRShaped.","func (*ResolutionRequest) GetConditionSet() apis.ConditionSet {","\treturn resolutionRequestCondSet","}","","// HasStarted returns whether a ResolutionRequests Status is considered to","// be in-progress.","func (rr *ResolutionRequest) HasStarted() bool {","\treturn rr.Status.GetCondition(apis.ConditionSucceeded).IsUnknown()","}","","// IsDone returns whether a ResolutionRequests Status is considered to be","// in a completed state, independent of success/failure.","func (rr *ResolutionRequest) IsDone() bool {","\tfinalStateIsUnknown := rr.Status.GetCondition(apis.ConditionSucceeded).IsUnknown()","\treturn !finalStateIsUnknown","}","","// InitializeConditions set ths initial values of the conditions.","func (s *ResolutionRequestStatus) InitializeConditions() {","\tresolutionRequestCondSet.Manage(s).InitializeConditions()","}","","// MarkFailed sets the Succeeded condition to False with an accompanying","// error message.","func (s *ResolutionRequestStatus) MarkFailed(reason, message string) {","\tresolutionRequestCondSet.Manage(s).MarkFalse(apis.ConditionSucceeded, reason, message)","}","","// MarkSucceeded sets the Succeeded condition to True.","func (s *ResolutionRequestStatus) MarkSucceeded() {","\tresolutionRequestCondSet.Manage(s).MarkTrue(apis.ConditionSucceeded)","}","","// MarkInProgress updates the Succeeded condition to Unknown with an","// accompanying message.","func (s *ResolutionRequestStatus) MarkInProgress(message string) {","\tresolutionRequestCondSet.Manage(s).MarkUnknown(apis.ConditionSucceeded, resolutioncommon.ReasonResolutionInProgress, message)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,1,1,1,0,0,0,1,1,1,1,0,0,1,1,1,0,0,0,1,1,1,0,0,1,1,1,0,0,0,1,1,1]},{"id":122,"path":"pkg/apis/resolution/v1alpha1/resolution_request_types.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1alpha1","","import (","\tpipelinev1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\tduckv1 \"knative.dev/pkg/apis/duck/v1\"",")","","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// ResolutionRequest is an object for requesting the content of","// a Tekton resource like a pipeline.yaml.","//","// +genclient","// +genreconciler","type ResolutionRequest struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ObjectMeta `json:\"metadata,omitempty\"`","","\t// Spec holds the information for the request part of the resource request.","\t// +optional","\tSpec ResolutionRequestSpec `json:\"spec,omitempty\"`","","\t// Status communicates the state of the request and, ultimately,","\t// the content of the resolved resource.","\t// +optional","\tStatus ResolutionRequestStatus `json:\"status,omitempty\"`","}","","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// ResolutionRequestList is a list of ResolutionRequests.","type ResolutionRequestList struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ListMeta `json:\"metadata\"`","\tItems           []ResolutionRequest `json:\"items\"`","}","","// ResolutionRequestSpec are all the fields in the spec of the","// ResolutionRequest CRD.","type ResolutionRequestSpec struct {","\t// Parameters are the runtime attributes passed to","\t// the resolver to help it figure out how to resolve the","\t// resource being requested. For example: repo URL, commit SHA,","\t// path to file, the kind of authentication to leverage, etc.","\t// +optional","\tParameters map[string]string `json:\"params,omitempty\"`","}","","// ResolutionRequestStatus are all the fields in a ResolutionRequest's","// status subresource.","type ResolutionRequestStatus struct {","\tduckv1.Status                 `json:\",inline\"`","\tResolutionRequestStatusFields `json:\",inline\"`","}","","// ResolutionRequestStatusFields are the ResolutionRequest-specific fields","// for the status subresource.","type ResolutionRequestStatusFields struct {","\t// Data is a string representation of the resolved content","\t// of the requested resource in-lined into the ResolutionRequest","\t// object.","\tData string `json:\"data\"`","\t// RefSource is the source reference of the remote data that records where the remote","\t// file came from including the url, digest and the entrypoint.","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tRefSource *pipelinev1.RefSource `json:\"refSource\"`","}","","// GetStatus implements KRShaped.","func (rr *ResolutionRequest) GetStatus() *duckv1.Status {","\treturn \u0026rr.Status.Status","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1]},{"id":123,"path":"pkg/apis/resolution/v1alpha1/resolution_request_validation.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1alpha1","","import (","\t\"context\"","","\t\"github.com/tektoncd/pipeline/pkg/resolution/common\"","\tadmissionregistrationv1 \"k8s.io/api/admissionregistration/v1\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/webhook/resourcesemantics\"",")","","var (","\t_ apis.Validatable              = (*ResolutionRequest)(nil)","\t_ resourcesemantics.VerbLimited = (*ResolutionRequest)(nil)",")","","// SupportedVerbs returns the operations that validation should be called for","func (rr *ResolutionRequest) SupportedVerbs() []admissionregistrationv1.OperationType {","\treturn []admissionregistrationv1.OperationType{admissionregistrationv1.Create, admissionregistrationv1.Update}","}","","// Validate checks that a submitted ResolutionRequest is structurally","// sound before the controller receives it.","func (rr *ResolutionRequest) Validate(ctx context.Context) (errs *apis.FieldError) {","\terrs = errs.Also(validateTypeLabel(rr))","\treturn errs.Also(rr.Spec.Validate(ctx).ViaField(\"spec\"))","}","","// Validate checks the spec field of a ResolutionRequest is valid.","func (rs *ResolutionRequestSpec) Validate(ctx context.Context) (errs *apis.FieldError) {","\treturn nil","}","","func validateTypeLabel(rr *ResolutionRequest) *apis.FieldError {","\ttypeLabel := getTypeLabel(rr.ObjectMeta.Labels)","\tif typeLabel == \"\" {","\t\treturn apis.ErrMissingField(common.LabelKeyResolverType).ViaField(\"labels\").ViaField(\"meta\")","\t}","\treturn nil","}","","func getTypeLabel(labels map[string]string) string {","\tif labels == nil {","\t\treturn \"\"","\t}","\treturn labels[common.LabelKeyResolverType]","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,1,1,1,1,0,0,1,1,1,0,1,1,1,1,1,1,0,0,1,1,1,1,1,0]},{"id":124,"path":"pkg/apis/resolution/v1beta1/register.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"",")","","// SchemeGroupVersion is group version used to register these objects","var SchemeGroupVersion = schema.GroupVersion{Group: resolution.GroupName, Version: \"v1beta1\"}","","// Kind takes an unqualified kind and returns back a Group qualified GroupKind","func Kind(kind string) schema.GroupKind {","\treturn SchemeGroupVersion.WithKind(kind).GroupKind()","}","","// Resource takes an unqualified resource and returns a Group qualified GroupResource","func Resource(resource string) schema.GroupResource {","\treturn SchemeGroupVersion.WithResource(resource).GroupResource()","}","","var (","\t// SchemeBuilder builds a scheme with the types known to the package.","\tSchemeBuilder = runtime.NewSchemeBuilder(addKnownTypes)","\t// AddToScheme adds the types known to this package to an existing schema.","\tAddToScheme = SchemeBuilder.AddToScheme",")","","// Adds the list of known types to Scheme.","func addKnownTypes(scheme *runtime.Scheme) error {","\tscheme.AddKnownTypes(SchemeGroupVersion,","\t\t\u0026ResolutionRequest{},","\t\t\u0026ResolutionRequestList{},","\t)","\tmetav1.AddToGroupVersion(scheme, SchemeGroupVersion)","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1]},{"id":125,"path":"pkg/apis/resolution/v1beta1/resolution_request_conversion.go","lines":["/*"," Copyright 2022 The Tekton Authors",""," Licensed under the Apache License, Version 2.0 (the \"License\");"," you may not use this file except in compliance with the License."," You may obtain a copy of the License at","","     http://www.apache.org/licenses/LICENSE-2.0",""," Unless required by applicable law or agreed to in writing, software"," distributed under the License is distributed on an \"AS IS\" BASIS,"," WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied."," See the License for the specific language governing permissions and"," limitations under the License.","","*/","","package v1beta1","","import (","\t\"context\"","\t\"fmt\"","","\t\"knative.dev/pkg/apis\"",")","","var _ apis.Convertible = (*ResolutionRequest)(nil)","","// ConvertTo implements apis.Convertible","func (rr *ResolutionRequest) ConvertTo(ctx context.Context, sink apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\treturn fmt.Errorf(\"v1beta1 is the highest known version, got: %T\", sink)","}","","// ConvertFrom implements apis.Convertible","func (rr *ResolutionRequest) ConvertFrom(ctx context.Context, source apis.Convertible) error {","\tif apis.IsInDelete(ctx) {","\t\treturn nil","\t}","\treturn fmt.Errorf(\"v1beta1 is the highest known version, got: %T\", source)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,2,0,0,0,2,2,1,1,2,0]},{"id":126,"path":"pkg/apis/resolution/v1beta1/resolution_request_defaults.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import \"context\"","","// ManagedByLabelKey is the label key used to mark what is managing this resource","const ManagedByLabelKey = \"app.kubernetes.io/managed-by\"","","// SetDefaults walks a ResolutionRequest object and sets any default","// values that are required to be set before a reconciler sees it.","func (rr *ResolutionRequest) SetDefaults(ctx context.Context) {","\tif rr.TypeMeta.Kind == \"\" {","\t\trr.TypeMeta.Kind = \"ResolutionRequest\"","\t}","\tif rr.TypeMeta.APIVersion == \"\" {","\t\trr.TypeMeta.APIVersion = \"resolution.tekton.dev/v1beta1\"","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0]},{"id":127,"path":"pkg/apis/resolution/v1beta1/resolution_request_lifecycle.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\tresolutioncommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"","\t\"knative.dev/pkg/apis\"",")","","// ResolutionRequests only have apis.ConditionSucceeded for now.","var resolutionRequestCondSet = apis.NewBatchConditionSet()","","// GetGroupVersionKind implements kmeta.OwnerRefable.","func (*ResolutionRequest) GetGroupVersionKind() schema.GroupVersionKind {","\treturn SchemeGroupVersion.WithKind(\"ResolutionRequest\")","}","","// GetConditionSet implements KRShaped.","func (*ResolutionRequest) GetConditionSet() apis.ConditionSet {","\treturn resolutionRequestCondSet","}","","// HasStarted returns whether a ResolutionRequests Status is considered to","// be in-progress.","func (rr *ResolutionRequest) HasStarted() bool {","\treturn rr.Status.GetCondition(apis.ConditionSucceeded).IsUnknown()","}","","// IsDone returns whether a ResolutionRequests Status is considered to be","// in a completed state, independent of success/failure.","func (rr *ResolutionRequest) IsDone() bool {","\tfinalStateIsUnknown := rr.Status.GetCondition(apis.ConditionSucceeded).IsUnknown()","\treturn !finalStateIsUnknown","}","","// InitializeConditions set ths initial values of the conditions.","func (s *ResolutionRequestStatus) InitializeConditions() {","\tresolutionRequestCondSet.Manage(s).InitializeConditions()","}","","// MarkFailed sets the Succeeded condition to False with an accompanying","// error message.","func (s *ResolutionRequestStatus) MarkFailed(reason, message string) {","\tresolutionRequestCondSet.Manage(s).MarkFalse(apis.ConditionSucceeded, reason, message)","}","","// MarkSucceeded sets the Succeeded condition to True.","func (s *ResolutionRequestStatus) MarkSucceeded() {","\tresolutionRequestCondSet.Manage(s).MarkTrue(apis.ConditionSucceeded)","}","","// MarkInProgress updates the Succeeded condition to Unknown with an","// accompanying message.","func (s *ResolutionRequestStatus) MarkInProgress(message string) {","\tresolutionRequestCondSet.Manage(s).MarkUnknown(apis.ConditionSucceeded, resolutioncommon.ReasonResolutionInProgress, message)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,1,1,1,0,0,0,1,1,1,1,0,0,1,1,1,0,0,0,1,1,1,0,0,1,1,1,0,0,0,1,1,1]},{"id":128,"path":"pkg/apis/resolution/v1beta1/resolution_request_types.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\tpipelinev1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\tduckv1 \"knative.dev/pkg/apis/duck/v1\"",")","","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// ResolutionRequest is an object for requesting the content of","// a Tekton resource like a pipeline.yaml.","//","// +genclient","// +genreconciler","// +kubebuilder:storageversion","type ResolutionRequest struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ObjectMeta `json:\"metadata,omitempty\"`","","\t// Spec holds the information for the request part of the resource request.","\t// +optional","\tSpec ResolutionRequestSpec `json:\"spec,omitempty\"`","","\t// Status communicates the state of the request and, ultimately,","\t// the content of the resolved resource.","\t// +optional","\tStatus ResolutionRequestStatus `json:\"status,omitempty\"`","}","","// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object","","// ResolutionRequestList is a list of ResolutionRequests.","type ResolutionRequestList struct {","\tmetav1.TypeMeta `json:\",inline\"`","\t// +optional","\tmetav1.ListMeta `json:\"metadata,omitempty\"`","\tItems           []ResolutionRequest `json:\"items\"`","}","","// ResolutionRequestSpec are all the fields in the spec of the","// ResolutionRequest CRD.","type ResolutionRequestSpec struct {","\t// Parameters are the runtime attributes passed to","\t// the resolver to help it figure out how to resolve the","\t// resource being requested. For example: repo URL, commit SHA,","\t// path to file, the kind of authentication to leverage, etc.","\t// +optional","\t// +listType=atomic","\tParams []pipelinev1.Param `json:\"params,omitempty\"`","\t// URL is the runtime url passed to the resolver","\t// to help it figure out how to resolver the resource being","\t// requested.","\t// This is currently at an ALPHA stability level and subject to","\t// alpha API compatibility policies.","\t// +optional","\tURL string `json:\"url,omitempty\"`","}","","// ResolutionRequestStatus are all the fields in a ResolutionRequest's","// status subresource.","type ResolutionRequestStatus struct {","\tduckv1.Status                 `json:\",inline\"`","\tResolutionRequestStatusFields `json:\",inline\"`","}","","// ResolutionRequestStatusFields are the ResolutionRequest-specific fields","// for the status subresource.","type ResolutionRequestStatusFields struct {","\t// Data is a string representation of the resolved content","\t// of the requested resource in-lined into the ResolutionRequest","\t// object.","\tData string `json:\"data\"`","\t// Deprecated: Use RefSource instead","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tSource *pipelinev1.RefSource `json:\"source\"`","","\t// RefSource is the source reference of the remote data that records the url, digest","\t// and the entrypoint.","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tRefSource *pipelinev1.RefSource `json:\"refSource\"`","}","","// GetStatus implements KRShaped.","func (rr *ResolutionRequest) GetStatus() *duckv1.Status {","\treturn \u0026rr.Status.Status","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1]},{"id":129,"path":"pkg/apis/resolution/v1beta1/resolution_request_validation.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"context\"","","\t\"github.com/tektoncd/pipeline/pkg/resolution/common\"","\tadmissionregistrationv1 \"k8s.io/api/admissionregistration/v1\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/webhook/resourcesemantics\"",")","","var (","\t_ apis.Validatable              = (*ResolutionRequest)(nil)","\t_ resourcesemantics.VerbLimited = (*ResolutionRequest)(nil)",")","","// SupportedVerbs returns the operations that validation should be called for","func (rr *ResolutionRequest) SupportedVerbs() []admissionregistrationv1.OperationType {","\treturn []admissionregistrationv1.OperationType{admissionregistrationv1.Create, admissionregistrationv1.Update}","}","","// Validate checks that a submitted ResolutionRequest is structurally","// sound before the controller receives it.","func (rr *ResolutionRequest) Validate(ctx context.Context) (errs *apis.FieldError) {","\terrs = errs.Also(validateTypeLabel(rr))","\treturn errs.Also(rr.Spec.Validate(ctx).ViaField(\"spec\"))","}","","// Validate checks the spec field of a ResolutionRequest is valid.","func (rs *ResolutionRequestSpec) Validate(ctx context.Context) (errs *apis.FieldError) {","\treturn nil","}","","func validateTypeLabel(rr *ResolutionRequest) *apis.FieldError {","\ttypeLabel := getTypeLabel(rr.ObjectMeta.Labels)","\tif typeLabel == \"\" {","\t\treturn apis.ErrMissingField(common.LabelKeyResolverType).ViaField(\"labels\").ViaField(\"meta\")","\t}","\treturn nil","}","","func getTypeLabel(labels map[string]string) string {","\tif labels == nil {","\t\treturn \"\"","\t}","\treturn labels[common.LabelKeyResolverType]","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,1,1,1,1,0,0,1,1,1,0,1,1,1,1,1,1,0,0,1,1,1,1,1,0]},{"id":130,"path":"pkg/apis/resource/v1alpha1/register.go","lines":["/*","Copyright 2019 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1alpha1","","import (","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"",")","","// SchemeGroupVersion is group version used to register these objects","var SchemeGroupVersion = schema.GroupVersion{Group: pipeline.GroupName, Version: \"v1alpha1\"}","","// Kind takes an unqualified kind and returns back a Group qualified GroupKind","func Kind(kind string) schema.GroupKind {","\treturn SchemeGroupVersion.WithKind(kind).GroupKind()","}","","// Resource takes an unqualified resource and returns a Group qualified GroupResource","func Resource(resource string) schema.GroupResource {","\treturn SchemeGroupVersion.WithResource(resource).GroupResource()","}","","var (","\tschemeBuilder = runtime.NewSchemeBuilder(addKnownTypes)","","\t// AddToScheme adds Build types to the scheme.","\tAddToScheme = schemeBuilder.AddToScheme",")","","// Adds the list of known types to Scheme.","func addKnownTypes(scheme *runtime.Scheme) error {","\tscheme.AddKnownTypes(SchemeGroupVersion,","\t\t\u0026PipelineResource{},","\t\t\u0026PipelineResourceList{},","\t)","\tmetav1.AddToGroupVersion(scheme, SchemeGroupVersion)","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1]},{"id":131,"path":"pkg/apis/run/v1alpha1/runstatus_types.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1alpha1","","import (","\t\"encoding/json\"","\t\"time\"","","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"knative.dev/pkg/apis\"","\tduckv1 \"knative.dev/pkg/apis/duck/v1\"",")","","// This package exists to avoid an import cycle between v1alpha1 and v1beta1.","// It contains common definitions needed by v1alpha1.Run and v1beta1.PipelineRun.","","// +k8s:deepcopy-gen=true","","// RunStatus defines the observed state of Run","type RunStatus struct {","\tduckv1.Status `json:\",inline\"`","","\t// RunStatusFields inlines the status fields.","\tRunStatusFields `json:\",inline\"`","}","","// +k8s:deepcopy-gen=true","","// RunStatusFields holds the fields of Run's status.  This is defined","// separately and inlined so that other types can readily consume these fields","// via duck typing.","type RunStatusFields struct {","\t// StartTime is the time the build is actually started.","\t// +optional","\tStartTime *metav1.Time `json:\"startTime,omitempty\"`","","\t// CompletionTime is the time the build completed.","\t// +optional","\tCompletionTime *metav1.Time `json:\"completionTime,omitempty\"`","","\t// Results reports any output result values to be consumed by later","\t// tasks in a pipeline.","\t// +optional","\tResults []RunResult `json:\"results,omitempty\"`","","\t// RetriesStatus contains the history of RunStatus, in case of a retry.","\t// +optional","\tRetriesStatus []RunStatus `json:\"retriesStatus,omitempty\"`","","\t// ExtraFields holds arbitrary fields provided by the custom task","\t// controller.","\tExtraFields runtime.RawExtension `json:\"extraFields,omitempty\"`","}","","// RunResult used to describe the results of a task","type RunResult struct {","\t// Name the given name","\tName string `json:\"name\"`","\t// Value the given value of the result","\tValue string `json:\"value\"`","}","","var runCondSet = apis.NewBatchConditionSet()","","// GetCondition returns the Condition matching the given type.","func (r *RunStatus) GetCondition(t apis.ConditionType) *apis.Condition {","\treturn runCondSet.Manage(r).GetCondition(t)","}","","// InitializeConditions will set all conditions in runCondSet to unknown for the PipelineRun","// and set the started time to the current time","func (r *RunStatus) InitializeConditions() {","\tstarted := false","\tif r.StartTime.IsZero() {","\t\tr.StartTime = \u0026metav1.Time{Time: time.Now()}","\t\tstarted = true","\t}","\tconditionManager := runCondSet.Manage(r)","\tconditionManager.InitializeConditions()","\t// Ensure the started reason is set for the \"Succeeded\" condition","\tif started {","\t\tinitialCondition := conditionManager.GetCondition(apis.ConditionSucceeded)","\t\tinitialCondition.Reason = \"Started\"","\t\tconditionManager.SetCondition(*initialCondition)","\t}","}","","// SetCondition sets the condition, unsetting previous conditions with the same","// type as necessary.","func (r *RunStatus) SetCondition(newCond *apis.Condition) {","\tif newCond != nil {","\t\trunCondSet.Manage(r).SetCondition(*newCond)","\t}","}","","// MarkRunSucceeded changes the Succeeded condition to True with the provided reason and message.","func (r *RunStatus) MarkRunSucceeded(reason, messageFormat string, messageA ...interface{}) {","\trunCondSet.Manage(r).MarkTrueWithReason(apis.ConditionSucceeded, reason, messageFormat, messageA...)","\tsucceeded := r.GetCondition(apis.ConditionSucceeded)","\tr.CompletionTime = \u0026succeeded.LastTransitionTime.Inner","}","","// MarkRunFailed changes the Succeeded condition to False with the provided reason and message.","func (r *RunStatus) MarkRunFailed(reason, messageFormat string, messageA ...interface{}) {","\trunCondSet.Manage(r).MarkFalse(apis.ConditionSucceeded, reason, messageFormat, messageA...)","\tsucceeded := r.GetCondition(apis.ConditionSucceeded)","\tr.CompletionTime = \u0026succeeded.LastTransitionTime.Inner","}","","// MarkRunRunning changes the Succeeded condition to Unknown with the provided reason and message.","func (r *RunStatus) MarkRunRunning(reason, messageFormat string, messageA ...interface{}) {","\trunCondSet.Manage(r).MarkUnknown(apis.ConditionSucceeded, reason, messageFormat, messageA...)","}","","// DecodeExtraFields deserializes the extra fields in the Run status.","func (r *RunStatus) DecodeExtraFields(into interface{}) error {","\tif len(r.ExtraFields.Raw) == 0 {","\t\treturn nil","\t}","\treturn json.Unmarshal(r.ExtraFields.Raw, into)","}","","// EncodeExtraFields serializes the extra fields in the Run status.","func (r *RunStatus) EncodeExtraFields(from interface{}) error {","\tdata, err := json.Marshal(from)","\tif err != nil {","\t\treturn err","\t}","\tr.ExtraFields = runtime.RawExtension{","\t\tRaw: data,","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,0,0,1,1,1,1,1,0,0,1,1,1,0,0,1,1,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,0]},{"id":132,"path":"pkg/apis/run/v1beta1/customrunstatus_types.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package v1beta1","","import (","\t\"encoding/json\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/run/v1alpha1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"knative.dev/pkg/apis\"","\tduckv1 \"knative.dev/pkg/apis/duck/v1\"",")","","// This package contains common definitions needed by v1beta1.CustomRun and v1beta1.PipelineRun.","","// +k8s:deepcopy-gen=true","","// CustomRunStatus defines the observed state of CustomRun","type CustomRunStatus struct {","\tduckv1.Status `json:\",inline\"`","","\t// CustomRunStatusFields inlines the status fields.","\tCustomRunStatusFields `json:\",inline\"`","}","","// +k8s:deepcopy-gen=true","","// CustomRunStatusFields holds the fields of CustomRun's status.  This is defined","// separately and inlined so that other types can readily consume these fields","// via duck typing.","type CustomRunStatusFields struct {","\t// StartTime is the time the build is actually started.","\t// +optional","\tStartTime *metav1.Time `json:\"startTime,omitempty\"`","","\t// CompletionTime is the time the build completed.","\t// +optional","\tCompletionTime *metav1.Time `json:\"completionTime,omitempty\"`","","\t// Results reports any output result values to be consumed by later","\t// tasks in a pipeline.","\t// +optional","\tResults []CustomRunResult `json:\"results,omitempty\"`","","\t// RetriesStatus contains the history of CustomRunStatus, in case of a retry.","\t// See CustomRun.status (API version: tekton.dev/v1beta1)","\t// +optional","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tRetriesStatus []CustomRunStatus `json:\"retriesStatus,omitempty\"`","","\t// ExtraFields holds arbitrary fields provided by the custom task","\t// controller.","\t// +kubebuilder:pruning:PreserveUnknownFields","\t// +kubebuilder:validation:Schemaless","\tExtraFields runtime.RawExtension `json:\"extraFields,omitempty\"`","}","","// CustomRunResult used to describe the results of a task","type CustomRunResult struct {","\t// Name the given name","\tName string `json:\"name\"`","\t// Value the given value of the result","\tValue string `json:\"value\"`","}","","var customRunCondSet = apis.NewBatchConditionSet()","","// GetCondition returns the Condition matching the given type.","func (r *CustomRunStatus) GetCondition(t apis.ConditionType) *apis.Condition {","\treturn customRunCondSet.Manage(r).GetCondition(t)","}","","// InitializeConditions will set all conditions in customRunCondSet to unknown","// and set the started time to the current time","func (r *CustomRunStatus) InitializeConditions() {","\tstarted := false","\tif r.StartTime.IsZero() {","\t\tr.StartTime = \u0026metav1.Time{Time: time.Now()}","\t\tstarted = true","\t}","\tconditionManager := customRunCondSet.Manage(r)","\tconditionManager.InitializeConditions()","\t// Ensure the started reason is set for the \"Succeeded\" condition","\tif started {","\t\tinitialCondition := conditionManager.GetCondition(apis.ConditionSucceeded)","\t\tinitialCondition.Reason = \"Started\"","\t\tconditionManager.SetCondition(*initialCondition)","\t}","}","","// SetCondition sets the condition, unsetting previous conditions with the same","// type as necessary.","func (r *CustomRunStatus) SetCondition(newCond *apis.Condition) {","\tif newCond != nil {","\t\tcustomRunCondSet.Manage(r).SetCondition(*newCond)","\t}","}","","// MarkCustomRunSucceeded changes the Succeeded condition to True with the provided reason and message.","func (r *CustomRunStatus) MarkCustomRunSucceeded(reason, messageFormat string, messageA ...interface{}) {","\tcustomRunCondSet.Manage(r).MarkTrueWithReason(apis.ConditionSucceeded, reason, messageFormat, messageA...)","\tsucceeded := r.GetCondition(apis.ConditionSucceeded)","\tr.CompletionTime = \u0026succeeded.LastTransitionTime.Inner","}","","// MarkCustomRunFailed changes the Succeeded condition to False with the provided reason and message.","func (r *CustomRunStatus) MarkCustomRunFailed(reason, messageFormat string, messageA ...interface{}) {","\tcustomRunCondSet.Manage(r).MarkFalse(apis.ConditionSucceeded, reason, messageFormat, messageA...)","\tsucceeded := r.GetCondition(apis.ConditionSucceeded)","\tr.CompletionTime = \u0026succeeded.LastTransitionTime.Inner","}","","// MarkCustomRunRunning changes the Succeeded condition to Unknown with the provided reason and message.","func (r *CustomRunStatus) MarkCustomRunRunning(reason, messageFormat string, messageA ...interface{}) {","\tcustomRunCondSet.Manage(r).MarkUnknown(apis.ConditionSucceeded, reason, messageFormat, messageA...)","}","","// DecodeExtraFields deserializes the extra fields in the CustomRun status.","func (r *CustomRunStatus) DecodeExtraFields(into interface{}) error {","\tif len(r.ExtraFields.Raw) == 0 {","\t\treturn nil","\t}","\treturn json.Unmarshal(r.ExtraFields.Raw, into)","}","","// EncodeExtraFields serializes the extra fields in the CustomRun status.","func (r *CustomRunStatus) EncodeExtraFields(from interface{}) error {","\tdata, err := json.Marshal(from)","\tif err != nil {","\t\treturn err","\t}","\tr.ExtraFields = runtime.RawExtension{","\t\tRaw: data,","\t}","\treturn nil","}","","// FromRunStatus converts a v1alpha1.RunStatus into a corresponding v1beta1.CustomRunStatus","func FromRunStatus(orig v1alpha1.RunStatus) CustomRunStatus {","\tcrs := CustomRunStatus{","\t\tStatus: orig.Status,","\t\tCustomRunStatusFields: CustomRunStatusFields{","\t\t\tStartTime:      orig.StartTime,","\t\t\tCompletionTime: orig.CompletionTime,","\t\t\tExtraFields:    orig.ExtraFields,","\t\t},","\t}","","\tfor _, origRes := range orig.Results {","\t\tcrs.Results = append(crs.Results, CustomRunResult{","\t\t\tName:  origRes.Name,","\t\t\tValue: origRes.Value,","\t\t})","\t}","","\tfor _, origRetryStatus := range orig.RetriesStatus {","\t\tcrs.RetriesStatus = append(crs.RetriesStatus, FromRunStatus(origRetryStatus))","\t}","","\treturn crs","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,0,0,1,1,1,1,1,0,0,1,1,1,0,0,1,1,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,0,2,0]},{"id":133,"path":"pkg/apis/validate/metadata.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package validate","","import (","\t\"fmt\"","","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/util/validation\"","\t\"knative.dev/pkg/apis\"",")","","// MaxLength is the maximum length that an object's name can be","const MaxLength = validation.DNS1123LabelMaxLength","","// ObjectMetadata validates that the given object's name is a valid DNS name and isn't longer than the max length","func ObjectMetadata(meta metav1.Object) *apis.FieldError {","\tname := meta.GetName()","","\tif err := validation.IsDNS1123Subdomain(name); len(err) \u003e 0 {","\t\treturn \u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(\"invalid resource name %q: must be a valid DNS label\", name),","\t\t\tPaths:   []string{\"name\"},","\t\t}","\t}","","\tif len(name) \u003e MaxLength {","\t\treturn \u0026apis.FieldError{","\t\t\tMessage: \"Invalid resource name: length must be no more than 63 characters\",","\t\t\tPaths:   []string{\"name\"},","\t\t}","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,1,0]},{"id":134,"path":"pkg/apis/version/conversion.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package version","","import (","\t\"encoding/json\"","\t\"fmt\"","","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"",")","","// SerializeToMetadata serializes the input field and adds it as an annotation to","// the metadata under the input key.","func SerializeToMetadata(meta *metav1.ObjectMeta, field interface{}, key string) error {","\tbytes, err := json.Marshal(field)","\tif err != nil {","\t\treturn fmt.Errorf(\"error serializing field: %w\", err)","\t}","\tif meta.Annotations == nil {","\t\tmeta.Annotations = make(map[string]string)","\t}","\tmeta.Annotations[key] = string(bytes)","\treturn nil","}","","// DeserializeFromMetadata takes the value of the input key from the metadata's annotations,","// deserializes it into \"to\", and removes the key from the metadata's annotations.","// Returns nil if the key is not present in the annotations.","func DeserializeFromMetadata(meta *metav1.ObjectMeta, to interface{}, key string) error {","\tif meta == nil || meta.Annotations == nil {","\t\treturn nil","\t}","\tif str, ok := meta.Annotations[key]; ok {","\t\tif err := json.Unmarshal([]byte(str), to); err != nil {","\t\t\treturn fmt.Errorf(\"error deserializing key %s from metadata: %w\", key, err)","\t\t}","\t\tdelete(meta.Annotations, key)","\t\tif len(meta.Annotations) == 0 {","\t\t\tmeta.Annotations = nil","\t\t}","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,1,1,2,2,2,2,2,0,0,0,0,0,2,2,1,1,2,2,1,1,2,2,2,2,0,2,0]},{"id":135,"path":"pkg/container/container_replacements.go","lines":["/*"," Copyright 2019 The Tekton Authors",""," Licensed under the Apache License, Version 2.0 (the \"License\");"," you may not use this file except in compliance with the License."," You may obtain a copy of the License at","","     http://www.apache.org/licenses/LICENSE-2.0",""," Unless required by applicable law or agreed to in writing, software"," distributed under the License is distributed on an \"AS IS\" BASIS,"," WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied."," See the License for the specific language governing permissions and"," limitations under the License.","*/","","package container","","import (","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\tcorev1 \"k8s.io/api/core/v1\"",")","","// applyStepReplacements returns a StepContainer with variable interpolation applied.","func applyStepReplacements(step *v1.Step, stringReplacements map[string]string, arrayReplacements map[string][]string) {","\tc := step.ToK8sContainer()","\tapplyContainerReplacements(c, stringReplacements, arrayReplacements)","\tstep.SetContainerFields(*c)","}","","// applySidecarReplacements returns a SidecarContainer with variable interpolation applied.","func applySidecarReplacements(sidecar *v1.Sidecar, stringReplacements map[string]string, arrayReplacements map[string][]string) {","\tc := sidecar.ToK8sContainer()","\tapplyContainerReplacements(c, stringReplacements, arrayReplacements)","\tsidecar.SetContainerFields(*c)","}","","func applyContainerReplacements(c *corev1.Container, stringReplacements map[string]string, arrayReplacements map[string][]string) {","\tc.Name = substitution.ApplyReplacements(c.Name, stringReplacements)","\tc.Image = substitution.ApplyReplacements(c.Image, stringReplacements)","\tc.ImagePullPolicy = corev1.PullPolicy(substitution.ApplyReplacements(string(c.ImagePullPolicy), stringReplacements))","","\t// Use ApplyArrayReplacements here, as additional args may be added via an array parameter.","\tvar newArgs []string","\tfor _, a := range c.Args {","\t\tnewArgs = append(newArgs, substitution.ApplyArrayReplacements(a, stringReplacements, arrayReplacements)...)","\t}","\tc.Args = newArgs","","\tfor ie, e := range c.Env {","\t\tc.Env[ie].Value = substitution.ApplyReplacements(e.Value, stringReplacements)","\t\tif c.Env[ie].ValueFrom != nil {","\t\t\tif e.ValueFrom.SecretKeyRef != nil {","\t\t\t\tc.Env[ie].ValueFrom.SecretKeyRef.LocalObjectReference.Name = substitution.ApplyReplacements(e.ValueFrom.SecretKeyRef.LocalObjectReference.Name, stringReplacements)","\t\t\t\tc.Env[ie].ValueFrom.SecretKeyRef.Key = substitution.ApplyReplacements(e.ValueFrom.SecretKeyRef.Key, stringReplacements)","\t\t\t}","\t\t\tif e.ValueFrom.ConfigMapKeyRef != nil {","\t\t\t\tc.Env[ie].ValueFrom.ConfigMapKeyRef.LocalObjectReference.Name = substitution.ApplyReplacements(e.ValueFrom.ConfigMapKeyRef.LocalObjectReference.Name, stringReplacements)","\t\t\t\tc.Env[ie].ValueFrom.ConfigMapKeyRef.Key = substitution.ApplyReplacements(e.ValueFrom.ConfigMapKeyRef.Key, stringReplacements)","\t\t\t}","\t\t}","\t}","","\tfor ie, e := range c.EnvFrom {","\t\tc.EnvFrom[ie].Prefix = substitution.ApplyReplacements(e.Prefix, stringReplacements)","\t\tif e.ConfigMapRef != nil {","\t\t\tc.EnvFrom[ie].ConfigMapRef.LocalObjectReference.Name = substitution.ApplyReplacements(e.ConfigMapRef.LocalObjectReference.Name, stringReplacements)","\t\t}","\t\tif e.SecretRef != nil {","\t\t\tc.EnvFrom[ie].SecretRef.LocalObjectReference.Name = substitution.ApplyReplacements(e.SecretRef.LocalObjectReference.Name, stringReplacements)","\t\t}","\t}","\tc.WorkingDir = substitution.ApplyReplacements(c.WorkingDir, stringReplacements)","","\t// Use ApplyArrayReplacements here, as additional commands may be added via an array parameter.","\tvar newCommand []string","\tfor _, c := range c.Command {","\t\tnewCommand = append(newCommand, substitution.ApplyArrayReplacements(c, stringReplacements, arrayReplacements)...)","\t}","\tc.Command = newCommand","","\tfor iv, v := range c.VolumeMounts {","\t\tc.VolumeMounts[iv].Name = substitution.ApplyReplacements(v.Name, stringReplacements)","\t\tc.VolumeMounts[iv].MountPath = substitution.ApplyReplacements(v.MountPath, stringReplacements)","\t\tc.VolumeMounts[iv].SubPath = substitution.ApplyReplacements(v.SubPath, stringReplacements)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0]},{"id":136,"path":"pkg/container/sidecar_replacements.go","lines":["/*"," Copyright 2020 The Tekton Authors",""," Licensed under the Apache License, Version 2.0 (the \"License\");"," you may not use this file except in compliance with the License."," You may obtain a copy of the License at","","     http://www.apache.org/licenses/LICENSE-2.0",""," Unless required by applicable law or agreed to in writing, software"," distributed under the License is distributed on an \"AS IS\" BASIS,"," WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied."," See the License for the specific language governing permissions and"," limitations under the License.","*/","","package container","","import (","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"",")","","// ApplySidecarReplacements applies variable interpolation on a Sidecar.","func ApplySidecarReplacements(sidecar *v1.Sidecar, stringReplacements map[string]string, arrayReplacements map[string][]string) {","\tsidecar.Script = substitution.ApplyReplacements(sidecar.Script, stringReplacements)","\tapplySidecarReplacements(sidecar, stringReplacements, arrayReplacements)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2]},{"id":137,"path":"pkg/container/step_replacements.go","lines":["/*"," Copyright 2019 The Tekton Authors",""," Licensed under the Apache License, Version 2.0 (the \"License\");"," you may not use this file except in compliance with the License."," You may obtain a copy of the License at","","     http://www.apache.org/licenses/LICENSE-2.0",""," Unless required by applicable law or agreed to in writing, software"," distributed under the License is distributed on an \"AS IS\" BASIS,"," WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied."," See the License for the specific language governing permissions and"," limitations under the License.","*/","","package container","","import (","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"",")","","// ApplyStepReplacements applies variable interpolation on a Step.","func ApplyStepReplacements(step *v1.Step, stringReplacements map[string]string, arrayReplacements map[string][]string) {","\tstep.Script = substitution.ApplyReplacements(step.Script, stringReplacements)","\tstep.OnError = (v1.OnErrorType)(substitution.ApplyReplacements(string(step.OnError), stringReplacements))","\tif step.StdoutConfig != nil {","\t\tstep.StdoutConfig.Path = substitution.ApplyReplacements(step.StdoutConfig.Path, stringReplacements)","\t}","\tif step.StderrConfig != nil {","\t\tstep.StderrConfig.Path = substitution.ApplyReplacements(step.StderrConfig.Path, stringReplacements)","\t}","\tstep.When = step.When.ReplaceVariables(stringReplacements, arrayReplacements)","\tapplyStepReplacements(step, stringReplacements, arrayReplacements)","}","","// ApplyStepTemplateReplacements applies variable interpolation on a StepTemplate (aka a container)","func ApplyStepTemplateReplacements(stepTemplate *v1.StepTemplate, stringReplacements map[string]string, arrayReplacements map[string][]string) {","\tcontainer := stepTemplate.ToK8sContainer()","\tapplyContainerReplacements(container, stringReplacements, arrayReplacements)","\tstepTemplate.SetContainerFields(*container)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,0,1,1,1,1,1]},{"id":138,"path":"pkg/controller/errors.go","lines":["/*","Copyright 2025 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","// Package controller provides helper methods for external controllers for","// Custom Task types.","package controller","","import (","\t\"errors\"","\t\"net/http\"","\t\"strings\"","","\tapierrors \"k8s.io/apimachinery/pkg/api/errors\"",")","","// IsWebhookTimeout checks if the error is due to a mutating admission webhook timeout.","// This function is used to determine if an error should trigger exponential backoff retry logic.","func IsWebhookTimeout(err error) bool {","\tvar statusErr *apierrors.StatusError","\tif errors.As(err, \u0026statusErr) {","\t\treturn statusErr.ErrStatus.Code == http.StatusInternalServerError \u0026\u0026","\t\t\tstrings.Contains(statusErr.ErrStatus.Message, \"timeout\")","\t}","\treturn false","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,0]},{"id":139,"path":"pkg/controller/filter.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","// Package controller provides helper methods for external controllers for","// Custom Task types.","package controller","","import (","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\tlistersbeta \"github.com/tektoncd/pipeline/pkg/client/listers/pipeline/v1beta1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"",")","","// FilterCustomRunRef returns a filter that can be passed to a CustomRun Informer, which","// filters out CustomRuns for apiVersion and kinds that a controller doesn't care","// about.","//","// For example, a controller impl that wants to be notified of updates to CustomRuns","// which reference a Task with apiVersion \"example.dev/v0\" and kind \"Example\":","//","//\tcustomruninformer.Get(ctx).Informer().AddEventHandler(cache.FilteringResourceEventHandler{","//\t  FilterFunc: FilterCustomRunRef(\"example.dev/v0\", \"Example\"),","//\t  Handler:    controller.HandleAll(impl.Enqueue),","//\t})","func FilterCustomRunRef(apiVersion, kind string) func(interface{}) bool {","\treturn func(obj interface{}) bool {","\t\tr, ok := obj.(*v1beta1.CustomRun)","\t\tif !ok {","\t\t\t// Somehow got informed of a non-CustomRun object.","\t\t\t// Ignore.","\t\t\treturn false","\t\t}","\t\tif r == nil || (r.Spec.CustomRef == nil \u0026\u0026 r.Spec.CustomSpec == nil) {","\t\t\t// These are invalid, but just in case they get","\t\t\t// created somehow, don't panic.","\t\t\treturn false","\t\t}","\t\tresult := false","\t\tif r.Spec.CustomRef != nil {","\t\t\tresult = r.Spec.CustomRef.APIVersion == apiVersion \u0026\u0026 r.Spec.CustomRef.Kind == v1beta1.TaskKind(kind)","\t\t} else if r.Spec.CustomSpec != nil {","\t\t\tresult = r.Spec.CustomSpec.APIVersion == apiVersion \u0026\u0026 r.Spec.CustomSpec.Kind == kind","\t\t}","\t\treturn result","\t}","}","","// FilterOwnerCustomRunRef returns a filter that can be passed to an Informer for any runtime object, which","// filters out objects that aren't controlled by a CustomRun that references a particular apiVersion and kind.","//","// For example, a controller impl that wants to be notified of updates to TaskRuns that are controlled by","// a CustomRun which references a custom task with apiVersion \"example.dev/v0\" and kind \"Example\":","//","//\ttaskruninformer.Get(ctx).Informer().AddEventHandler(cache.FilteringResourceEventHandler{","//\t  FilterFunc: FilterOwnerCustomRunRef(\"example.dev/v0\", \"Example\"),","//\t  Handler:    controller.HandleAll(impl.Enqueue),","//\t})","func FilterOwnerCustomRunRef(customRunLister listersbeta.CustomRunLister, apiVersion, kind string) func(interface{}) bool {","\treturn func(obj interface{}) bool {","\t\tobject, ok := obj.(metav1.Object)","\t\tif !ok {","\t\t\treturn false","\t\t}","\t\towner := metav1.GetControllerOf(object)","\t\tif owner == nil {","\t\t\treturn false","\t\t}","\t\tif owner.APIVersion != v1beta1.SchemeGroupVersion.String() || owner.Kind != pipeline.CustomRunControllerName {","\t\t\t// Not owned by a CustomRun","\t\t\treturn false","\t\t}","\t\trun, err := customRunLister.CustomRuns(object.GetNamespace()).Get(owner.Name)","\t\tif err != nil {","\t\t\treturn false","\t\t}","\t\tif run.Spec.CustomRef == nil \u0026\u0026 run.Spec.CustomSpec == nil {","\t\t\t// These are invalid, but just in case they get created somehow, don't panic.","\t\t\treturn false","\t\t}","\t\tif run.Spec.CustomRef != nil \u0026\u0026 run.Spec.CustomSpec != nil {","\t\t\t// These are invalid.","\t\t\treturn false","\t\t}","\t\tresult := false","\t\tif run.Spec.CustomRef != nil {","\t\t\tresult = run.Spec.CustomRef.APIVersion == apiVersion \u0026\u0026 run.Spec.CustomRef.Kind == v1beta1.TaskKind(kind)","\t\t} else if run.Spec.CustomSpec != nil {","\t\t\tresult = run.Spec.CustomSpec.APIVersion == apiVersion \u0026\u0026 run.Spec.CustomSpec.Kind == kind","\t\t}","\t\treturn result","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0]},{"id":140,"path":"pkg/credentials/dockercreds/creds.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package dockercreds","","import (","\t\"encoding/base64\"","\t\"encoding/json\"","\t\"flag\"","\t\"fmt\"","\t\"os\"","\t\"path/filepath\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/credentials/common\"","\tcredmatcher \"github.com/tektoncd/pipeline/pkg/credentials/matcher\"","\tcredwriter \"github.com/tektoncd/pipeline/pkg/credentials/writer\"",")","","const annotationPrefix = \"tekton.dev/docker-\"","","var (","\tconfig       basicDocker","\tdockerConfig arrayArg","\tdockerCfg    arrayArg",")","","// AddFlags adds CLI flags that dockercreds supports to a given flag.FlagSet.","func AddFlags(flagSet *flag.FlagSet) {","\tflags(flagSet)","}","","func flags(fs *flag.FlagSet) {","\tconfig = basicDocker{make(map[string]entry)}","\tdockerConfig = arrayArg{[]string{}}","\tdockerCfg = arrayArg{[]string{}}","\tfs.Var(\u0026config, \"basic-docker\", \"List of secret=url pairs.\")","\tfs.Var(\u0026dockerConfig, \"docker-config\", \"Docker config.json secret file.\")","\tfs.Var(\u0026dockerCfg, \"docker-cfg\", \"Docker .dockercfg secret file.\")","}","","// As the flag is read, this status is populated.","// basicDocker implements flag.Value","type basicDocker struct {","\tEntries map[string]entry `json:\"auths\"`","}","","func (dc *basicDocker) String() string {","\tif dc == nil {","\t\t// According to flag.Value this can happen.","\t\treturn \"\"","\t}","\tvar urls []string","\tfor k, v := range dc.Entries {","\t\turls = append(urls, fmt.Sprintf(\"%s=%s\", v.Secret, k))","\t}","\treturn strings.Join(urls, \",\")","}","","// Set sets a secret for a URL from a value in the format of \"secret=url\"","func (dc *basicDocker) Set(value string) error {","\tparts := strings.Split(value, \"=\")","\tif len(parts) != 2 {","\t\treturn fmt.Errorf(\"expect entries of the form secret=url, got: %v\", value)","\t}","\tsecret := parts[0]","\turl := parts[1]","","\tif _, ok := dc.Entries[url]; ok {","\t\treturn fmt.Errorf(\"multiple entries for url: %v\", url)","\t}","","\te, err := newEntry(secret)","\tif err != nil {","\t\treturn err","\t}","\tdc.Entries[url] = *e","\treturn nil","}","","type arrayArg struct {","\tValues []string","}","","// Set adds a value to the arrayArg's value slice","func (aa *arrayArg) Set(value string) error {","\taa.Values = append(aa.Values, value)","\treturn nil","}","","func (aa *arrayArg) String() string {","\treturn strings.Join(aa.Values, \",\")","}","","type configFile struct {","\tAuth map[string]entry `json:\"auths\"`","}","","type entry struct {","\tSecret   string `json:\"-\"`","\tUsername string `json:\"username,omitempty\"`","\tPassword string `json:\"password,omitempty\"`","\tAuth     string `json:\"auth\"`","\tEmail    string `json:\"email,omitempty\"`","}","","func newEntry(secret string) (*entry, error) {","\tsecretPath := credmatcher.VolumeName(secret)","","\tub, err := os.ReadFile(filepath.Join(secretPath, common.BasicAuthUsernameKey))","\tif err != nil {","\t\treturn nil, err","\t}","\tusername := string(ub)","","\tpb, err := os.ReadFile(filepath.Join(secretPath, common.BasicAuthPasswordKey))","\tif err != nil {","\t\treturn nil, err","\t}","\tpassword := string(pb)","","\treturn \u0026entry{","\t\tSecret:   secret,","\t\tUsername: username,","\t\tPassword: password,","\t\tAuth:     base64.StdEncoding.EncodeToString([]byte(fmt.Sprintf(\"%s:%s\", username, password))),","\t\tEmail:    \"not@val.id\",","\t}, nil","}","","type basicDockerBuilder struct{}","","// NewBuilder returns a new builder for Docker credentials.","func NewBuilder() interface {","\tcredmatcher.Matcher","\tcredwriter.Writer","} {","\treturn \u0026basicDockerBuilder{}","}","","// MatchingAnnotations extracts flags for the credential helper","// from the supplied secret and returns a slice (of length 0 or","// greater) of applicable domains.","func (*basicDockerBuilder) MatchingAnnotations(secret credmatcher.Secret) []string {","\tvar flags []string","\tswitch credmatcher.GetSecretType(secret) {","\tcase common.SecretTypeBasicAuth:","\t\tfor _, v := range credwriter.SortAnnotations(secret.GetAnnotations(), annotationPrefix) {","\t\t\tflags = append(flags, fmt.Sprintf(\"-basic-docker=%s=%s\", secret.GetName(), v))","\t\t}","\tcase common.SecretTypeDockerConfigJson:","\t\tflags = append(flags, \"-docker-config=\"+secret.GetName())","\tcase common.SecretTypeDockercfg:","\t\tflags = append(flags, \"-docker-cfg=\"+secret.GetName())","","\tcase common.SecretTypeOpaque, common.SecretTypeServiceAccountToken, common.SecretTypeSSHAuth, common.SecretTypeTLS, common.SecretTypeBootstrapToken:","\t\tfallthrough","","\tdefault:","\t\treturn flags","\t}","","\treturn flags","}","","// Write builds a .docker/config.json file from a combination","// of kubernetes docker registry secrets and tekton docker","// secret entries and writes it to the given directory. If","// no entries exist then nothing will be written to disk.","func (*basicDockerBuilder) Write(directory string) error {","\tdockerDir := filepath.Join(directory, \".docker\")","\tbasicDocker := filepath.Join(dockerDir, \"config.json\")","\tcf := configFile{Auth: config.Entries}","\tauth := map[string]entry{}","","\tfor _, secretName := range dockerCfg.Values {","\t\tdockerConfigAuthMap, err := authsFromDockerCfg(secretName)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tfor k, v := range dockerConfigAuthMap {","\t\t\tauth[k] = v","\t\t}","\t}","","\tfor _, secretName := range dockerConfig.Values {","\t\tdockerConfigAuthMap, err := authsFromDockerConfig(secretName)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tfor k, v := range dockerConfigAuthMap {","\t\t\tauth[k] = v","\t\t}","\t}","\tfor k, v := range config.Entries {","\t\tauth[k] = v","\t}","\tif len(auth) == 0 {","\t\treturn nil","\t}","\tif err := os.MkdirAll(dockerDir, os.ModePerm); err != nil {","\t\treturn err","\t}","","\tcf.Auth = auth","\tcontent, err := json.Marshal(cf)","\tif err != nil {","\t\treturn err","\t}","\treturn os.WriteFile(basicDocker, content, 0o600)","}","","func authsFromDockerCfg(secret string) (map[string]entry, error) {","\tsecretPath := credmatcher.VolumeName(secret)","\tm := make(map[string]entry)","\tdata, err := os.ReadFile(filepath.Join(secretPath, common.DockerConfigKey))","\tif err != nil {","\t\treturn m, err","\t}","\terr = json.Unmarshal(data, \u0026m)","\treturn m, err","}","","func authsFromDockerConfig(secret string) (map[string]entry, error) {","\tsecretPath := credmatcher.VolumeName(secret)","\tm := make(map[string]entry)","\tc := configFile{}","\tdata, err := os.ReadFile(filepath.Join(secretPath, common.DockerConfigJsonKey))","\tif err != nil {","\t\treturn m, err","\t}","\tif err := json.Unmarshal(data, \u0026c); err != nil {","\t\treturn m, err","\t}","\tfor k, v := range c.Auth {","\t\tm[k] = v","\t}","\treturn m, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,2,2,1,1,1,2,2,1,1,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,0,0,0,0,0,0,2,2,2,2,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,0,2,2,0,0,2,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,1,1,2,2,2,0,0,2,2,2,1,1,2,2,2,0,2,2,2,2,2,2,2,1,1,0,2,2,2,1,1,2,0,0,2,2,2,2,2,1,1,2,2,0,0,2,2,2,2,2,2,1,1,2,1,1,2,2,2,2,0]},{"id":141,"path":"pkg/credentials/gitcreds/basic.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package gitcreds","","import (","\t\"fmt\"","\t\"net/url\"","\t\"os\"","\t\"path/filepath\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/credentials/common\"","\tcredmatcher \"github.com/tektoncd/pipeline/pkg/credentials/matcher\"",")","","// As the flag is read, this status is populated.","// basicGitConfig implements flag.Value","type basicGitConfig struct {","\tentries map[string]basicEntry","\t// The order we see things, for iterating over the above.","\torder []string","}","","func (dc *basicGitConfig) String() string {","\tif dc == nil {","\t\t// According to flag.Value this can happen.","\t\treturn \"\"","\t}","\tvar urls []string","\tfor _, k := range dc.order {","\t\tv := dc.entries[k]","\t\turls = append(urls, fmt.Sprintf(\"%s=%s\", v.secret, k))","\t}","\treturn strings.Join(urls, \",\")","}","","// Set sets a secret for a given URL from a \"secret=url\" value.","func (dc *basicGitConfig) Set(value string) error {","\tparts := strings.Split(value, \"=\")","\tif len(parts) != 2 {","\t\treturn fmt.Errorf(\"expect entries of the form secret=url, got: %v\", value)","\t}","\tsecret := parts[0]","\turl := parts[1]","","\tif _, ok := dc.entries[url]; ok {","\t\treturn fmt.Errorf(\"multiple entries for url: %v\", url)","\t}","","\te, err := newBasicEntry(url, secret)","\tif err != nil {","\t\treturn err","\t}","\tdc.entries[url] = *e","\tdc.order = append(dc.order, url)","\treturn nil","}","","// Write builds a .gitconfig file from dc.entries and writes it to disk","// in the directory provided. If dc.entries is empty then nothing is","// written.","func (dc *basicGitConfig) Write(directory string) error {","\tif len(dc.entries) == 0 {","\t\treturn nil","\t}","\tgitConfigPath := filepath.Join(directory, \".gitconfig\")","\tgitConfigs := []string{","\t\t\"[credential]\\n\thelper = store\\n\",","\t}","\tfor _, k := range dc.order {","\t\tv := dc.entries[k]","\t\tgitConfigs = append(gitConfigs, v.configBlurb(k))","\t}","\tgitConfigContent := strings.Join(gitConfigs, \"\")","\tif err := os.WriteFile(gitConfigPath, []byte(gitConfigContent), 0600); err != nil {","\t\treturn err","\t}","","\tgitCredentialsPath := filepath.Join(directory, \".git-credentials\")","\tvar gitCredentials []string","\tfor _, k := range dc.order {","\t\tv := dc.entries[k]","\t\tgitCredentials = append(gitCredentials, v.authURL.String())","\t}","\tgitCredentials = append(gitCredentials, \"\") // Get a trailing newline","\tgitCredentialsContent := strings.Join(gitCredentials, \"\\n\")","\treturn os.WriteFile(gitCredentialsPath, []byte(gitCredentialsContent), 0600)","}","","type basicEntry struct {","\tsecret   string","\tusername string","\tpassword string","\t// Has the form: https://user:pass@url.com","\tauthURL *url.URL","}","","func (be *basicEntry) configBlurb(u string) string {","\treturn fmt.Sprintf(\"[credential %q]\\n\tusername = %s\\n\", u, be.escapedUsername())","}","","func (be *basicEntry) escapedUsername() string {","\tif strings.Contains(be.username, \"\\\\\") {","\t\treturn strings.ReplaceAll(be.username, \"\\\\\", \"\\\\\\\\\")","\t}","\treturn be.username","}","","func newBasicEntry(u, secret string) (*basicEntry, error) {","\tsecretPath := credmatcher.VolumeName(secret)","","\tub, err := os.ReadFile(filepath.Join(secretPath, common.BasicAuthUsernameKey))","\tif err != nil {","\t\treturn nil, err","\t}","\tusername := string(ub)","","\tpb, err := os.ReadFile(filepath.Join(secretPath, common.BasicAuthPasswordKey))","\tif err != nil {","\t\treturn nil, err","\t}","\tpassword := string(pb)","","\tpu, err := url.Parse(u)","\tif err != nil {","\t\treturn nil, err","\t}","\tpu.User = url.UserPassword(username, password)","","\treturn \u0026basicEntry{","\t\tsecret:   secret,","\t\tusername: username,","\t\tpassword: password,","\t\tauthURL:  pu,","\t}, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,1,2,2,1,1,1,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,2,2,2,0,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,1,1,2,2,2,2,2,2,2,2,0]},{"id":142,"path":"pkg/credentials/gitcreds/creds.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package gitcreds","","import (","\t\"flag\"","\t\"fmt\"","","\t\"github.com/tektoncd/pipeline/pkg/credentials/common\"","\tcredmatcher \"github.com/tektoncd/pipeline/pkg/credentials/matcher\"","\tcredwriter \"github.com/tektoncd/pipeline/pkg/credentials/writer\"",")","","const (","\tannotationPrefix = \"tekton.dev/git-\"","\tbasicAuthFlag    = \"basic-git\"","\tsshFlag          = \"ssh-git\"",")","","var (","\tbasicConfig basicGitConfig","\tsshConfig   sshGitConfig",")","","// AddFlags adds CLI flags that gitcreds supports to a given flag.FlagSet.","func AddFlags(flagSet *flag.FlagSet) {","\tflags(flagSet)","}","","func flags(fs *flag.FlagSet) {","\tbasicConfig = basicGitConfig{","\t\tentries: make(map[string]basicEntry),","\t\torder:   []string{},","\t}","\tsshConfig = sshGitConfig{","\t\tentries: make(map[string][]sshEntry),","\t\torder:   []string{},","\t}","\tfs.Var(\u0026basicConfig, basicAuthFlag, \"List of secret=url pairs.\")","\tfs.Var(\u0026sshConfig, sshFlag, \"List of secret=url pairs.\")","}","","type gitBuilder struct{}","","// NewBuilder returns a new builder for Git credentials.","func NewBuilder() interface {","\tcredmatcher.Matcher","\tcredwriter.Writer","} {","\treturn \u0026gitBuilder{}","}","","// MatchingAnnotations extracts flags for the credential helper","// from the supplied secret and returns a slice (of length 0 or","// greater) of applicable domains.","func (*gitBuilder) MatchingAnnotations(secret credmatcher.Secret) []string {","\tvar flagName string","\tvar flags []string","\tswitch credmatcher.GetSecretType(secret) {","\tcase common.SecretTypeBasicAuth:","\t\tflagName = basicAuthFlag","\tcase common.SecretTypeSSHAuth:","\t\tflagName = sshFlag","\tcase common.SecretTypeOpaque, common.SecretTypeServiceAccountToken, common.SecretTypeDockercfg, common.SecretTypeDockerConfigJson, common.SecretTypeTLS, common.SecretTypeBootstrapToken:","\t\tfallthrough","\tdefault:","\t\treturn flags","\t}","","\tfor _, v := range credwriter.SortAnnotations(secret.GetAnnotations(), annotationPrefix) {","\t\tflags = append(flags, fmt.Sprintf(\"-%s=%s=%s\", flagName, secret.GetName(), v))","\t}","","\treturn flags","}","","// Write writes the credentials to the provided directory.","func (*gitBuilder) Write(directory string) error {","\tif err := basicConfig.Write(directory); err != nil {","\t\treturn err","\t}","\treturn sshConfig.Write(directory)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,2,0,0,0,2,2,1,1,2,0]},{"id":143,"path":"pkg/credentials/gitcreds/ssh.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package gitcreds","","import (","\t\"fmt\"","\t\"net\"","\t\"os\"","\t\"path/filepath\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/credentials/common\"","\tcredmatcher \"github.com/tektoncd/pipeline/pkg/credentials/matcher\"",")","","const sshKnownHosts = \"known_hosts\"","","// As the flag is read, this status is populated.","// sshGitConfig implements flag.Value","type sshGitConfig struct {","\tentries map[string][]sshEntry","\t// The order we see things, for iterating over the above.","\torder []string","}","","func (dc *sshGitConfig) String() string {","\tif dc == nil {","\t\t// According to flag.Value this can happen.","\t\treturn \"\"","\t}","\tvar urls []string","\tfor _, k := range dc.order {","\t\tfor _, e := range dc.entries[k] {","\t\t\turls = append(urls, fmt.Sprintf(\"%s=%s\", e.secretName, k))","\t\t}","\t}","\treturn strings.Join(urls, \",\")","}","","// Set sets a secret for a given URL from a \"secret=url\" value.","func (dc *sshGitConfig) Set(value string) error {","\tparts := strings.Split(value, \"=\")","\tif len(parts) != 2 {","\t\treturn fmt.Errorf(\"expect entries of the form secret=url, got: %v\", value)","\t}","\tsecretName := parts[0]","\turl := parts[1]","","\te, err := newSSHEntry(url, secretName)","\tif err != nil {","\t\treturn err","\t}","\tif _, exists := dc.entries[url]; !exists {","\t\tdc.order = append(dc.order, url)","\t}","\tdc.entries[url] = append(dc.entries[url], *e)","\treturn nil","}","","// Write puts dc's ssh entries into files in a .ssh directory, under","// the given directory. If dc has no entries then nothing is written.","func (dc *sshGitConfig) Write(directory string) error {","\tif len(dc.entries) == 0 {","\t\treturn nil","\t}","\tsshDir := filepath.Join(directory, \".ssh\")","\tif err := os.MkdirAll(sshDir, os.ModePerm); err != nil {","\t\treturn err","\t}","","\t// Walk each of the entries and for each do three things:","\t//  1. Write out: ~/.ssh/id_{secretName} with the secret key","\t//  2. Compute its part of \"~/.ssh/config\"","\t//  3. Compute its part of \"~/.ssh/known_hosts\"","\tvar configEntries []string","\tvar defaultPort = \"22\"","\tvar knownHosts []string","\tfor _, k := range dc.order {","\t\tvar host, port string","\t\tvar err error","\t\tif host, port, err = net.SplitHostPort(k); err != nil {","\t\t\thost = k","\t\t\tport = defaultPort","\t\t}","\t\tconfigEntry := fmt.Sprintf(`Host %s","    HostName %s","    Port %s","`, host, host, port)","\t\tfor _, e := range dc.entries[k] {","\t\t\tif err := e.Write(sshDir); err != nil {","\t\t\t\treturn err","\t\t\t}","\t\t\tconfigEntry += fmt.Sprintf(`    IdentityFile %s","`, e.path(sshDir))","\t\t\tif e.knownHosts != \"\" {","\t\t\t\tknownHosts = append(knownHosts, e.knownHosts)","\t\t\t}","\t\t}","\t\tconfigEntries = append(configEntries, configEntry)","\t}","\tconfigPath := filepath.Join(sshDir, \"config\")","\tconfigContent := strings.Join(configEntries, \"\")","\tif err := os.WriteFile(configPath, []byte(configContent), 0600); err != nil {","\t\treturn err","\t}","\tif len(knownHosts) \u003e 0 {","\t\tknownHostsPath := filepath.Join(sshDir, \"known_hosts\")","\t\tknownHostsContent := strings.Join(knownHosts, \"\\n\")","\t\treturn os.WriteFile(knownHostsPath, []byte(knownHostsContent), 0600)","\t}","\treturn nil","}","","type sshEntry struct {","\tsecretName string","\tprivateKey string","\tknownHosts string","}","","func (be *sshEntry) path(sshDir string) string {","\treturn filepath.Join(sshDir, \"id_\"+be.secretName)","}","","func (be *sshEntry) Write(sshDir string) error {","\treturn os.WriteFile(be.path(sshDir), []byte(be.privateKey), 0600)","}","","func newSSHEntry(url, secretName string) (*sshEntry, error) {","\tsecretPath := credmatcher.VolumeName(secretName)","","\tpk, err := os.ReadFile(filepath.Join(secretPath, common.SSHAuthPrivateKey))","\tif err != nil {","\t\treturn nil, err","\t}","\tprivateKey := string(pk)","","\tknownHosts := \"\"","\tif kh, err := os.ReadFile(filepath.Join(secretPath, sshKnownHosts)); err == nil {","\t\tknownHosts = string(kh)","\t}","","\treturn \u0026sshEntry{","\t\tsecretName: secretName,","\t\tprivateKey: privateKey,","\t\tknownHosts: knownHosts,","\t}, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,1,2,2,1,1,1,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,1,1,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,0,2,0,2,2,2,1,1,2,2,2,2,2,1,0,0,0,0,0,0,0,0,2,2,2,0,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,0]},{"id":144,"path":"pkg/credentials/matcher/matcher.go","lines":["/*","Copyright 2025 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package matcher","","import (","\t\"fmt\"","\t\"reflect\"",")","","// VolumePath is the path where build secrets are written.","// It is mutable and exported for testing.","var VolumePath = \"/tekton/creds-secrets\"","","// Secret is the minimal interface needed for credential matching","type Secret interface {","\tGetName() string","\tGetAnnotations() map[string]string","}","","// Matcher is the interface for a credential initializer of any type.","type Matcher interface {","\t// MatchingAnnotations extracts flags for the credential","\t// helper from the supplied secret and returns a slice (of length 0 or greater)","\tMatchingAnnotations(secret Secret) []string","}","","// VolumeName returns the full path to the secret, inside the VolumePath.","func VolumeName(secretName string) string {","\treturn fmt.Sprintf(\"%s/%s\", VolumePath, secretName)","}","","// GetSecretType returns secret type from secret interface using reflection","func GetSecretType(secret Secret) string {","\tif secret == nil {","\t\treturn \"\"","\t}","\tv := reflect.ValueOf(secret)","\t// If a pointer, check if it's nil before dereferencing","\tif v.Kind() == reflect.Ptr {","\t\tif v.IsNil() {","\t\t\treturn \"\"","\t\t}","\t\tv = v.Elem()","\t}","\t// access the Type field for Kubernetes secrets","\tf := v.FieldByName(\"Type\")","\tif !f.IsValid() || !f.CanInterface() {","\t\treturn \"\"","\t}","\treturn fmt.Sprintf(\"%v\", f.Interface())","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,2,2,1,1,2,2,2,2,2,2,2,0,0,2,2,1,1,2,0]},{"id":145,"path":"pkg/credentials/writer/writer.go","lines":["/*","Copyright 2024 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package writer","","import (","\t\"fmt\"","\t\"io\"","\t\"log\"","\t\"os\"","\t\"path/filepath\"","\t\"sort\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"",")","","const (","\t// credsDirPermissions are the persmission bits assigned to the directories","\t// copied out of the /tekton/creds and into a Step's HOME.","\tcredsDirPermissions = 0o700","","\t// credsFilePermissions are the persmission bits assigned to the files","\t// copied out of /tekton/creds and into a Step's HOME.","\tcredsFilePermissions = 0o600",")","","// CredsInitCredentials is the complete list of credentials that the legacy credentials","// helper (aka \"creds-init\") can write to /tekton/creds.","var CredsInitCredentials = []string{\".docker\", \".gitconfig\", \".git-credentials\", \".ssh\"}","","// Writer is the interface for a credential initializer of any type.","type Writer interface {","\t// Write writes the credentials to the provided directory.","\tWrite(folder string) error","}","","// SortAnnotations return sorted array of strings which has annotationPrefix","// as the prefix in secrets key","func SortAnnotations(secrets map[string]string, annotationPrefix string) []string {","\tvar mk []string","\tfor k, v := range secrets {","\t\tif strings.HasPrefix(k, annotationPrefix) {","\t\t\tmk = append(mk, v)","\t\t}","\t}","\tsort.Strings(mk)","\treturn mk","}","","// CopyCredsToHome copies credentials from the /tekton/creds directory into","// the current Step's HOME directory. A list of credential paths to try and","// copy is given as an arg, for example, []string{\".docker\", \".ssh\"}. A missing","// /tekton/creds directory is not considered an error.","func CopyCredsToHome(credPaths []string) error {","\tif info, err := os.Stat(pipeline.CredsDir); err != nil || !info.IsDir() {","\t\treturn nil //nolint:nilerr // safe to ignore error; no credentials available to copy","\t}","","\thomepath, err := os.UserHomeDir()","\tif err != nil {","\t\treturn fmt.Errorf(\"error getting the user's home directory: %w\", err)","\t}","","\tfor _, cred := range credPaths {","\t\tsource := filepath.Join(pipeline.CredsDir, cred)","\t\tdestination := filepath.Join(homepath, cred)","\t\terr := tryCopyCred(source, destination)","\t\tif err != nil {","\t\t\tlog.Printf(\"warning: unsuccessful cred copy: %q from %q to %q: %v\", cred, pipeline.CredsDir, homepath, err)","\t\t}","\t}","\treturn nil","}","","// tryCopyCred will recursively copy a given source path to a given","// destination path. A missing source file is treated as normal behaviour","// and no error is returned.","func tryCopyCred(source, destination string) error {","\tfromInfo, err := os.Lstat(source)","\tif err != nil {","\t\tif os.IsNotExist(err) {","\t\t\treturn nil","\t\t}","\t\treturn fmt.Errorf(\"unable to read source file info: %w\", err)","\t}","","\tfromFile, err := os.Open(filepath.Clean(source))","\tif err != nil {","\t\tif os.IsNotExist(err) {","\t\t\treturn nil","\t\t}","\t\treturn fmt.Errorf(\"unable to open source: %w\", err)","\t}","\tdefer fromFile.Close()","","\tif fromInfo.IsDir() {","\t\terr := os.MkdirAll(destination, credsDirPermissions)","\t\tif err != nil {","\t\t\treturn fmt.Errorf(\"unable to create destination directory: %w\", err)","\t\t}","\t\tsubdirs, err := fromFile.Readdirnames(0)","\t\tif err != nil {","\t\t\treturn fmt.Errorf(\"unable to read subdirectories of source: %w\", err)","\t\t}","\t\tfor _, subdir := range subdirs {","\t\t\tsrc := filepath.Join(source, subdir)","\t\t\tdst := filepath.Join(destination, subdir)","\t\t\tif err := tryCopyCred(src, dst); err != nil {","\t\t\t\treturn err","\t\t\t}","\t\t}","\t} else {","\t\tflags := os.O_RDWR | os.O_CREATE | os.O_TRUNC","\t\ttoFile, err := os.OpenFile(destination, flags, credsFilePermissions)","\t\tif err != nil {","\t\t\treturn fmt.Errorf(\"unable to open destination: %w\", err)","\t\t}","\t\tdefer toFile.Close()","","\t\t_, err = io.Copy(toFile, fromFile)","\t\tif err != nil {","\t\t\treturn fmt.Errorf(\"error copying from source to destination: %w\", err)","\t\t}","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0,1,1,0,0,0,0,0,0,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,0,1,0,0,0,0,0,2,2,2,2,2,2,1,0,0,2,2,1,1,1,1,0,2,2,2,2,2,1,1,2,2,1,1,2,2,2,2,1,1,0,2,2,2,2,1,1,2,2,2,2,1,1,0,2,0]},{"id":146,"path":"pkg/entrypoint/entrypointer.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package entrypoint","","import (","\t\"context\"","\t\"encoding/json\"","\t\"errors\"","\t\"fmt\"","\t\"log/slog\"","","\t\"log\"","\t\"os\"","\t\"os/exec\"","\t\"path/filepath\"","\t\"regexp\"","\t\"strconv\"","\t\"strings\"","\t\"syscall\"","\t\"time\"","","\t\"github.com/google/cel-go/cel\"","\t\"github.com/tektoncd/pipeline/internal/artifactref\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1/types\"","\t\"github.com/tektoncd/pipeline/pkg/entrypoint/pipeline\"","\t\"github.com/tektoncd/pipeline/pkg/internal/resultref\"","\t\"github.com/tektoncd/pipeline/pkg/result\"","\t\"github.com/tektoncd/pipeline/pkg/termination\"",")","","// RFC3339 with millisecond","const (","\ttimeFormat      = \"2006-01-02T15:04:05.000Z07:00\"","\tContinueOnError = \"continue\"","\tFailOnError     = \"stopAndFail\"",")","","const (","\tbreakpointExitSuffix                     = \".breakpointexit\"","\tbreakpointBeforeStepSuffix               = \".beforestepexit\"","\tResultExtractionMethodTerminationMessage = \"termination-message\"","\tTerminationReasonSkipped                 = \"Skipped\"","\tTerminationReasonCancelled               = \"Cancelled\"","\tTerminationReasonTimeoutExceeded         = \"TimeoutExceeded\"","\t// DownwardMountCancelFile is cancellation file mount to step, entrypoint will check this file to cancel the step.","\tdownwardMountPoint      = \"/tekton/downward\"","\tdownwardMountCancelFile = \"cancel\"","\tstepPrefix              = \"step-\"",")","const (","\t// CredsDir is the directory where credentials are placed to meet the legacy credentials","\t// helpers image (aka \"creds-init\") contract","\tCredsDir = \"/tekton/creds\" // #nosec",")","","var DownwardMountCancelFile string","","func init() {","\tDownwardMountCancelFile = filepath.Join(downwardMountPoint, downwardMountCancelFile)","}","","// DebugBeforeStepError is an error means mark before step breakpoint failure","type DebugBeforeStepError string","","func (e DebugBeforeStepError) Error() string {","\treturn string(e)","}","","var (","\terrDebugBeforeStep = DebugBeforeStepError(\"before step breakpoint error file, user decided to skip the current step execution\")",")","","// ScriptDir for testing","var ScriptDir = pipeline.ScriptDir","","// ContextError context error type","type ContextError string","","// Error implements error interface","func (e ContextError) Error() string {","\treturn string(e)","}","","type SkipError string","","func (e SkipError) Error() string {","\treturn string(e)","}","","var (","\t// ErrContextDeadlineExceeded is the error returned when the context deadline is exceeded","\tErrContextDeadlineExceeded = ContextError(context.DeadlineExceeded.Error())","\t// ErrContextCanceled is the error returned when the context is canceled","\tErrContextCanceled = ContextError(context.Canceled.Error())","\t// ErrSkipPreviousStepFailed is the error returned when the step is skipped due to previous step error","\tErrSkipPreviousStepFailed = SkipError(\"error file present, bail and skip the step\")",")","","// IsContextDeadlineError determine whether the error is context deadline","func IsContextDeadlineError(err error) bool {","\treturn errors.Is(err, ErrContextDeadlineExceeded)","}","","// IsContextCanceledError determine whether the error is context canceled","func IsContextCanceledError(err error) bool {","\treturn errors.Is(err, ErrContextCanceled)","}","","// Entrypointer holds fields for running commands with redirected","// entrypoints.","type Entrypointer struct {","\t// Command is the original specified command and args.","\tCommand []string","","\t// WaitFiles is the set of files to wait for. If empty, execution","\t// begins immediately.","\tWaitFiles []string","\t// WaitFileContent indicates the WaitFile should have non-zero size","\t// before continuing with execution.","\tWaitFileContent bool","\t// PostFile is the file to write when complete. If not specified, no","\t// file is written.","\tPostFile string","","\t// Termination path is the path of a file to write the starting time of this endpopint","\tTerminationPath string","","\t// Waiter encapsulates waiting for files to exist.","\tWaiter Waiter","\t// Runner encapsulates running commands.","\tRunner Runner","\t// PostWriter encapsulates writing files when complete.","\tPostWriter PostWriter","","\t// StepResults is the set of files that might contain step results","\tStepResults []string","\t// Results is the set of files that might contain task results","\tResults []string","\t// Timeout is an optional user-specified duration within which the Step must complete","\tTimeout *time.Duration","\t// BreakpointOnFailure helps determine if entrypoint execution needs to adapt debugging requirements","\tBreakpointOnFailure bool","\t// DebugBeforeStep help user attach container before execution","\tDebugBeforeStep bool","\t// OnError defines exiting behavior of the entrypoint","\t// set it to \"stopAndFail\" to indicate the entrypoint to exit the taskRun if the container exits with non zero exit code","\t// set it to \"continue\" to indicate the entrypoint to continue executing the rest of the steps irrespective of the container exit code","\tOnError string","\t// StepMetadataDir is the directory for a step where the step related metadata can be stored","\tStepMetadataDir string","\t// SpireWorkloadAPI connects to spire and does obtains SVID based on taskrun","\tSpireWorkloadAPI EntrypointerAPIClient","\t// ResultsDirectory is the directory to find results, defaults to pipeline.DefaultResultPath","\tResultsDirectory string","\t// ResultExtractionMethod is the method using which the controller extracts the results from the task pod.","\tResultExtractionMethod string","","\t// StepWhenExpressions     a list of when expression to decide if the step should be skipped","\tStepWhenExpressions v1.StepWhenExpressions","","\t// ArtifactsDirectory is the directory to find artifacts, defaults to pipeline.ArtifactsDir","\tArtifactsDirectory string","}","","// Waiter encapsulates waiting for files to exist.","type Waiter interface {","\t// Wait blocks until the specified file exists or the context is done.","\tWait(ctx context.Context, file string, expectContent bool, breakpointOnFailure bool) error","}","","// Runner encapsulates running commands.","type Runner interface {","\tRun(ctx context.Context, args ...string) error","}","","// PostWriter encapsulates writing a file when complete.","type PostWriter interface {","\t// Write writes to the path when complete.","\tWrite(file, content string)","}","","// Go optionally waits for a file, runs the command, and writes a","// post file.","func (e Entrypointer) Go() error {","\toutput := []result.RunResult{}","\tdefer func() {","\t\tif wErr := termination.WriteMessage(e.TerminationPath, output); wErr != nil {","\t\t\tlog.Fatalf(\"Error while writing message: %s\", wErr)","\t\t}","\t}()","","\tif err := os.MkdirAll(filepath.Join(e.StepMetadataDir, \"results\"), os.ModePerm); err != nil {","\t\treturn err","\t}","\tif err := os.MkdirAll(filepath.Join(e.StepMetadataDir, \"artifacts\"), os.ModePerm); err != nil {","\t\treturn err","\t}","\tfor _, f := range e.WaitFiles {","\t\tif err := e.Waiter.Wait(context.Background(), f, e.WaitFileContent, e.BreakpointOnFailure); err != nil {","\t\t\t// An error happened while waiting, so we bail","\t\t\t// *but* we write postfile to make next steps bail too.","\t\t\t// In case of breakpoint on failure do not write post file.","\t\t\tif !e.BreakpointOnFailure {","\t\t\t\te.WritePostFile(e.PostFile, err)","\t\t\t}","\t\t\toutput = append(output, result.RunResult{","\t\t\t\tKey:        \"StartedAt\",","\t\t\t\tValue:      time.Now().Format(timeFormat),","\t\t\t\tResultType: result.InternalTektonResultType,","\t\t\t})","","\t\t\tif errors.Is(err, ErrSkipPreviousStepFailed) {","\t\t\t\toutput = append(output, e.outputRunResult(TerminationReasonSkipped))","\t\t\t}","","\t\t\treturn err","\t\t}","\t}","","\tvar err error","\tif e.DebugBeforeStep {","\t\terr = e.waitBeforeStepDebug()","\t}","","\toutput = append(output, result.RunResult{","\t\tKey:        \"StartedAt\",","\t\tValue:      time.Now().Format(timeFormat),","\t\tResultType: result.InternalTektonResultType,","\t})","","\tif e.Timeout != nil \u0026\u0026 *e.Timeout \u003c time.Duration(0) {","\t\terr = errors.New(\"negative timeout specified\")","\t}","\tctx := context.Background()","\tvar cancel context.CancelFunc","\tif err == nil {","\t\tif err := e.applyStepResultSubstitutions(pipeline.StepsDir); err != nil {","\t\t\tslog.Error(\"Error while substituting step results:\", slog.Any(\"error\", err))","\t\t}","\t\tif err := e.applyStepArtifactSubstitutions(pipeline.StepsDir); err != nil {","\t\t\tslog.Error(\"Error while substituting step artifacts:\", slog.Any(\"error\", err))","\t\t}","","\t\tctx, cancel = context.WithCancel(ctx)","\t\tif e.Timeout != nil \u0026\u0026 *e.Timeout \u003e time.Duration(0) {","\t\t\tctx, cancel = context.WithTimeout(ctx, *e.Timeout)","\t\t}","\t\tdefer cancel()","\t\t// start a goroutine to listen for cancellation file","\t\tgo func() {","\t\t\tif err := e.waitingCancellation(ctx, cancel); err != nil \u0026\u0026 (!IsContextCanceledError(err) \u0026\u0026 !IsContextDeadlineError(err)) {","\t\t\t\tslog.Error(\"Error while waiting for cancellation\", slog.Any(\"error\", err))","\t\t\t}","\t\t}()","\t\tallowExec, err1 := e.allowExec()","","\t\tswitch {","\t\tcase err1 != nil:","\t\t\terr = err1","\t\tcase allowExec:","\t\t\terr = e.Runner.Run(ctx, e.Command...)","\t\tdefault:","\t\t\tslog.Info(\"Step was skipped due to when expressions were evaluated to false.\")","\t\t\toutput = append(output, e.outputRunResult(TerminationReasonSkipped))","\t\t\te.WritePostFile(e.PostFile, nil)","\t\t\te.WriteExitCodeFile(e.StepMetadataDir, \"0\")","\t\t\treturn nil","\t\t}","\t}","","\tvar ee *exec.ExitError","\tswitch {","\tcase err != nil \u0026\u0026 errors.Is(err, errDebugBeforeStep):","\t\te.WritePostFile(e.PostFile, err)","\tcase err != nil \u0026\u0026 errors.Is(err, ErrContextCanceled):","\t\tslog.Info(\"Step was canceling\")","\t\toutput = append(output, e.outputRunResult(TerminationReasonCancelled))","\t\te.WritePostFile(e.PostFile, ErrContextCanceled)","\t\te.WriteExitCodeFile(e.StepMetadataDir, syscall.SIGKILL.String())","\tcase errors.Is(err, ErrContextDeadlineExceeded):","\t\te.WritePostFile(e.PostFile, err)","\t\toutput = append(output, e.outputRunResult(TerminationReasonTimeoutExceeded))","\tcase err != nil \u0026\u0026 e.BreakpointOnFailure:","\t\tslog.Info(\"Skipping writing to PostFile\")","\tcase e.OnError == ContinueOnError \u0026\u0026 errors.As(err, \u0026ee):","\t\t// with continue on error and an ExitError, write non-zero exit code and a post file","\t\texitCode := strconv.Itoa(ee.ExitCode())","\t\toutput = append(output, result.RunResult{","\t\t\tKey:        \"ExitCode\",","\t\t\tValue:      exitCode,","\t\t\tResultType: result.InternalTektonResultType,","\t\t})","\t\te.WritePostFile(e.PostFile, nil)","\t\te.WriteExitCodeFile(e.StepMetadataDir, exitCode)","\tcase err == nil:","\t\t// if err is nil, write zero exit code and a post file","\t\te.WritePostFile(e.PostFile, nil)","\t\te.WriteExitCodeFile(e.StepMetadataDir, \"0\")","\tdefault:","\t\t// for a step without continue on error and any error, write a post file with .err","\t\te.WritePostFile(e.PostFile, err)","\t}","","\t// strings.Split(..) with an empty string returns an array that contains one element, an empty string.","\t// This creates an error when trying to open the result folder as a file.","\tif len(e.Results) \u003e= 1 \u0026\u0026 e.Results[0] != \"\" {","\t\tresultPath := pipeline.DefaultResultPath","\t\tif e.ResultsDirectory != \"\" {","\t\t\tresultPath = e.ResultsDirectory","\t\t}","\t\tif err := e.readResultsFromDisk(ctx, resultPath, result.TaskRunResultType); err != nil {","\t\t\tslog.Error(\"Error while substituting step artifacts:\", slog.Any(\"error\", err))","\t\t\treturn err","\t\t}","\t}","\tif len(e.StepResults) \u003e= 1 \u0026\u0026 e.StepResults[0] != \"\" {","\t\tstepResultPath := filepath.Join(e.StepMetadataDir, \"results\")","\t\tif e.ResultsDirectory != \"\" {","\t\t\tstepResultPath = e.ResultsDirectory","\t\t}","\t\tif err := e.readResultsFromDisk(ctx, stepResultPath, result.StepResultType); err != nil {","\t\t\tslog.Error(\"Error while substituting step artifacts:\", slog.Any(\"error\", err))","\t\t\treturn err","\t\t}","\t}","","\tif e.ResultExtractionMethod == ResultExtractionMethodTerminationMessage {","\t\te.appendArtifactOutputs(\u0026output)","\t}","","\treturn err","}","","func readArtifacts(fp string, resultType result.ResultType) ([]result.RunResult, error) {","\tfile, err := os.ReadFile(fp)","\tif os.IsNotExist(err) {","\t\treturn []result.RunResult{}, nil","\t}","\tif err != nil {","\t\treturn nil, err","\t}","\treturn []result.RunResult{{Key: fp, Value: string(file), ResultType: resultType}}, nil","}","","func (e Entrypointer) appendArtifactOutputs(output *[]result.RunResult) {","\t// step artifacts","\tfp := filepath.Join(e.StepMetadataDir, \"artifacts\", \"provenance.json\")","\tartifacts, err := readArtifacts(fp, result.StepArtifactsResultType)","\tif err != nil {","\t\tlog.Fatalf(\"Error while handling step artifacts: %s\", err)","\t}","\t*output = append(*output, artifacts...)","","\tartifactsDir := pipeline.ArtifactsDir","\t// task artifacts","\tif e.ArtifactsDirectory != \"\" {","\t\tartifactsDir = e.ArtifactsDirectory","\t}","\tfp = filepath.Join(artifactsDir, \"provenance.json\")","\tartifacts, err = readArtifacts(fp, result.TaskRunArtifactsResultType)","\tif err != nil {","\t\tlog.Fatalf(\"Error while handling task artifacts: %s\", err)","\t}","\t*output = append(*output, artifacts...)","}","","func (e Entrypointer) allowExec() (bool, error) {","\twhen := e.StepWhenExpressions","\tm := map[string]bool{}","","\tfor _, we := range when {","\t\tif we.CEL == \"\" {","\t\t\tcontinue","\t\t}","\t\tb, ok := m[we.CEL]","\t\tif ok \u0026\u0026 !b {","\t\t\treturn false, nil","\t\t}","","\t\tenv, err := cel.NewEnv()","\t\tif err != nil {","\t\t\treturn false, err","\t\t}","\t\tast, iss := env.Compile(we.CEL)","\t\tif iss.Err() != nil {","\t\t\treturn false, iss.Err()","\t\t}","\t\t// Generate an evaluable instance of the Ast within the environment","\t\tprg, err := env.Program(ast)","\t\tif err != nil {","\t\t\treturn false, err","\t\t}","\t\t// Evaluate the CEL expression","\t\tout, _, err := prg.Eval(map[string]interface{}{})","\t\tif err != nil {","\t\t\treturn false, err","\t\t}","","\t\tb, ok = out.Value().(bool)","\t\tif !ok {","\t\t\treturn false, fmt.Errorf(\"the CEL expression %s is not evaluated to a boolean\", we.CEL)","\t\t}","\t\tif !b {","\t\t\treturn false, err","\t\t}","\t\tm[we.CEL] = true","\t}","\treturn when.AllowsExecution(m), nil","}","","func (e Entrypointer) waitBeforeStepDebug() error {","\tlog.Println(`debug before step breakpoint has taken effect, waiting for user's decision:","1) continue, use cmd: /tekton/debug/scripts/debug-beforestep-continue","2) fail-continue, use cmd: /tekton/debug/scripts/debug-beforestep-fail-continue`)","\tbreakpointBeforeStepPostFile := e.PostFile + breakpointBeforeStepSuffix","\tif waitErr := e.Waiter.Wait(context.Background(), breakpointBeforeStepPostFile, false, false); waitErr != nil {","\t\tlog.Println(\"error occurred while waiting for \" + breakpointBeforeStepPostFile + \" : \" + errDebugBeforeStep.Error())","\t\treturn errDebugBeforeStep","\t}","\treturn nil","}","","func (e Entrypointer) readResultsFromDisk(ctx context.Context, resultDir string, resultType result.ResultType) error {","\toutput := []result.RunResult{}","\tresults := e.Results","\tif resultType == result.StepResultType {","\t\tresults = e.StepResults","\t}","\tfor _, resultFile := range results {","\t\tif resultFile == \"\" {","\t\t\tcontinue","\t\t}","\t\tfileContents, err := os.ReadFile(filepath.Join(resultDir, resultFile))","\t\tif os.IsNotExist(err) {","\t\t\tcontinue","\t\t} else if err != nil {","\t\t\treturn err","\t\t}","\t\t// if the file doesn't exist, ignore it","\t\toutput = append(output, result.RunResult{","\t\t\tKey:        resultFile,","\t\t\tValue:      string(fileContents),","\t\t\tResultType: resultType,","\t\t})","\t}","","\tsigned, err := signResults(ctx, e.SpireWorkloadAPI, output)","\tif err != nil {","\t\treturn err","\t}","\toutput = append(output, signed...)","","\t// push output to termination path","\tif e.ResultExtractionMethod == ResultExtractionMethodTerminationMessage \u0026\u0026 len(output) != 0 {","\t\tif err := termination.WriteMessage(e.TerminationPath, output); err != nil {","\t\t\treturn err","\t\t}","\t}","\treturn nil","}","","// BreakpointExitCode reads the post file and returns the exit code it contains","func (e Entrypointer) BreakpointExitCode(breakpointExitPostFile string) (int, error) {","\texitCode, err := os.ReadFile(breakpointExitPostFile)","\tif os.IsNotExist(err) {","\t\treturn 0, fmt.Errorf(\"breakpoint postfile %s not found\", breakpointExitPostFile)","\t}","\tstrExitCode := strings.TrimSuffix(string(exitCode), \"\\n\")","\tlog.Println(\"Breakpoint exiting with exit code \" + strExitCode)","","\treturn strconv.Atoi(strExitCode)","}","","// WritePostFile write the postfile","func (e Entrypointer) WritePostFile(postFile string, err error) {","\tif err != nil \u0026\u0026 postFile != \"\" {","\t\tpostFile += \".err\"","\t}","\tif postFile != \"\" {","\t\te.PostWriter.Write(postFile, \"\")","\t}","}","","// WriteExitCodeFile write the exitCodeFile","func (e Entrypointer) WriteExitCodeFile(stepPath, content string) {","\texitCodeFile := filepath.Join(stepPath, \"exitCode\")","\te.PostWriter.Write(exitCodeFile, content)","}","","// waitingCancellation waiting cancellation file, if no error occurs, call cancelFunc to cancel the context","func (e Entrypointer) waitingCancellation(ctx context.Context, cancel context.CancelFunc) error {","\tif err := e.Waiter.Wait(ctx, DownwardMountCancelFile, true, false); err != nil {","\t\treturn err","\t}","\tcancel()","\treturn nil","}","","// CheckForBreakpointOnFailure if step up breakpoint on failure","// waiting breakpointExitPostFile to be written","func (e Entrypointer) CheckForBreakpointOnFailure() {","\tif e.BreakpointOnFailure {","\t\tlog.Println(`debug onFailure breakpoint has taken effect, waiting for user's decision:","1) continue, use cmd: /tekton/debug/scripts/debug-continue","2) fail-continue, use cmd: /tekton/debug/scripts/debug-fail-continue`)","\t\tbreakpointExitPostFile := e.PostFile + breakpointExitSuffix","\t\tif waitErr := e.Waiter.Wait(context.Background(), breakpointExitPostFile, false, false); waitErr != nil {","\t\t\tlog.Println(\"error occurred while waiting for \" + breakpointExitPostFile + \" : \" + waitErr.Error())","\t\t}","\t\t// get exitcode from .breakpointexit","\t\texitCode, readErr := e.BreakpointExitCode(breakpointExitPostFile)","\t\t// if readErr exists, the exitcode with default to 0 as we would like","\t\t// to encourage to continue running the next steps in the taskRun","\t\tif readErr != nil {","\t\t\tlog.Println(\"error occurred while reading breakpoint exit code : \" + readErr.Error())","\t\t}","\t\tos.Exit(exitCode)","\t}","}","","// GetContainerName prefixes the input name with \"step-\"","func GetContainerName(name string) string {","\treturn fmt.Sprintf(\"%s%s\", stepPrefix, name)","}","","// loadStepResult reads the step result file and returns the string, array or object result value.","func loadStepResult(stepDir string, stepName string, resultName string) (v1.ResultValue, error) {","\tv := v1.ResultValue{}","\tfp := getStepResultPath(stepDir, GetContainerName(stepName), resultName)","\tfileContents, err := os.ReadFile(fp)","\tif err != nil {","\t\treturn v, err","\t}","\terr = v.UnmarshalJSON(fileContents)","\tif err != nil {","\t\treturn v, err","\t}","\treturn v, nil","}","","// getStepResultPath gets the path to the step result","func getStepResultPath(stepDir string, stepName string, resultName string) string {","\treturn filepath.Join(stepDir, stepName, \"results\", resultName)","}","","// findReplacement looks for any usage of step results in an input string.","// If found, it loads the results from the previous steps and provides the replacement value.","func findReplacement(stepDir string, s string) (string, []string, error) {","\tvalue := strings.TrimSuffix(strings.TrimPrefix(s, \"$(\"), \")\")","\tpr, err := resultref.ParseStepExpression(value)","\tif err != nil {","\t\treturn \"\", nil, err","\t}","\tresult, err := loadStepResult(stepDir, pr.ResourceName, pr.ResultName)","\tif err != nil {","\t\treturn \"\", nil, err","\t}","\treplaceWithArray := []string{}","\treplaceWithString := \"\"","","\tswitch pr.ResultType {","\tcase \"object\":","\t\tif pr.ObjectKey != \"\" {","\t\t\treplaceWithString = result.ObjectVal[pr.ObjectKey]","\t\t}","\tcase \"array\":","\t\tif pr.ArrayIdx != nil {","\t\t\treplaceWithString = result.ArrayVal[*pr.ArrayIdx]","\t\t} else {","\t\t\treplaceWithArray = append(replaceWithArray, result.ArrayVal...)","\t\t}","\t// \"string\"","\tdefault:","\t\treplaceWithString = result.StringVal","\t}","\treturn replaceWithString, replaceWithArray, nil","}","","// replaceEnv performs replacements for step results in environment variables.","func replaceEnv(stepDir string) error {","\tfor _, e := range os.Environ() {","\t\tpair := strings.SplitN(e, \"=\", 2)","\t\tmatches := resultref.StepResultRegex.FindAllStringSubmatch(pair[1], -1)","\t\tv := pair[1]","\t\tfor _, m := range matches {","\t\t\treplaceWith, _, err := findReplacement(stepDir, m[0])","\t\t\tif err != nil {","\t\t\t\treturn err","\t\t\t}","\t\t\tv = strings.ReplaceAll(v, m[0], replaceWith)","\t\t}","\t\tos.Setenv(pair[0], v)","\t}","\treturn nil","}","","// replaceCommandAndArgs performs replacements for step results in e.Command","func replaceCommandAndArgs(command []string, stepDir string) ([]string, error) {","\tvar newCommand []string","\tfor _, c := range command {","\t\tmatches := resultref.StepResultRegex.FindAllStringSubmatch(c, -1)","\t\tnewC := []string{c}","\t\tfor _, m := range matches {","\t\t\treplaceWithString, replaceWithArray, err := findReplacement(stepDir, m[0])","\t\t\tif err != nil {","\t\t\t\treturn []string{}, fmt.Errorf(\"failed to find replacement for %s to replace %s\", m[0], c)","\t\t\t}","\t\t\t// replaceWithString and replaceWithArray are mutually exclusive","\t\t\tif len(replaceWithArray) \u003e 0 {","\t\t\t\tif c != m[0] {","\t\t\t\t\t// it has to be exact in \"$(steps.\u003cstep-name\u003e.results.\u003cresult-name\u003e[*])\" format, without anything else in the original string","\t\t\t\t\treturn nil, errors.New(\"value must be in \\\"$(steps.\u003cstep-name\u003e.results.\u003cresult-name\u003e[*])\\\" format, when using array results\")","\t\t\t\t}","\t\t\t\tnewC = replaceWithArray","\t\t\t} else {","\t\t\t\tnewC[0] = strings.ReplaceAll(newC[0], m[0], replaceWithString)","\t\t\t}","\t\t}","\t\tnewCommand = append(newCommand, newC...)","\t}","\treturn newCommand, nil","}","","// applyStepResultSubstitutions applies the runtime step result substitutions in env, args and command.","func (e *Entrypointer) applyStepResultSubstitutions(stepDir string) error {","\t// env","\tif err := replaceEnv(stepDir); err != nil {","\t\treturn err","\t}","","\t// replace when","\tnewWhen, err := replaceWhen(stepDir, e.StepWhenExpressions)","\tif err != nil {","\t\treturn err","\t}","\te.StepWhenExpressions = newWhen","\t// command + args","\tnewCommand, err := replaceCommandAndArgs(e.Command, stepDir)","\tif err != nil {","\t\treturn err","\t}","\te.Command = newCommand","\treturn nil","}","","func replaceWhen(stepDir string, when v1.StepWhenExpressions) (v1.StepWhenExpressions, error) {","\tfor i, w := range when {","\t\tvar newValues []string","\tflag:","\t\tfor _, v := range when[i].Values {","\t\t\tmatches := resultref.StepResultRegex.FindAllStringSubmatch(v, -1)","\t\t\tnewV := v","\t\t\tfor _, m := range matches {","\t\t\t\treplaceWithString, replaceWithArray, err := findReplacement(stepDir, m[0])","\t\t\t\tif err != nil {","\t\t\t\t\treturn v1.WhenExpressions{}, err","\t\t\t\t}","\t\t\t\t// replaceWithString and replaceWithArray are mutually exclusive","\t\t\t\tif len(replaceWithArray) \u003e 0 {","\t\t\t\t\tif v != m[0] {","\t\t\t\t\t\t// it has to be exact in \"$(steps.\u003cstep-name\u003e.results.\u003cresult-name\u003e[*])\" format, without anything else in the original string","\t\t\t\t\t\treturn nil, errors.New(\"value must be in \\\"$(steps.\u003cstep-name\u003e.results.\u003cresult-name\u003e[*])\\\" format, when using array results\")","\t\t\t\t\t}","\t\t\t\t\tnewValues = append(newValues, replaceWithArray...)","\t\t\t\t\tcontinue flag","\t\t\t\t}","\t\t\t\tnewV = strings.ReplaceAll(newV, m[0], replaceWithString)","\t\t\t}","\t\t\tnewValues = append(newValues, newV)","\t\t}","\t\twhen[i].Values = newValues","","\t\tmatches := resultref.StepResultRegex.FindAllStringSubmatch(w.Input, -1)","\t\tv := when[i].Input","\t\tfor _, m := range matches {","\t\t\treplaceWith, _, err := findReplacement(stepDir, m[0])","\t\t\tif err != nil {","\t\t\t\treturn v1.StepWhenExpressions{}, err","\t\t\t}","\t\t\tv = strings.ReplaceAll(v, m[0], replaceWith)","\t\t}","\t\twhen[i].Input = v","","\t\tmatches = resultref.StepResultRegex.FindAllStringSubmatch(w.CEL, -1)","\t\tc := when[i].CEL","\t\tfor _, m := range matches {","\t\t\treplaceWith, _, err := findReplacement(stepDir, m[0])","\t\t\tif err != nil {","\t\t\t\treturn v1.StepWhenExpressions{}, err","\t\t\t}","\t\t\tc = strings.ReplaceAll(c, m[0], replaceWith)","\t\t}","\t\twhen[i].CEL = c","\t}","\treturn when, nil","}","","// outputRunResult returns the run reason for a termination","func (e Entrypointer) outputRunResult(terminationReason string) result.RunResult {","\treturn result.RunResult{","\t\tKey:        \"Reason\",","\t\tValue:      terminationReason,","\t\tResultType: result.InternalTektonResultType,","\t}","}","","// getStepArtifactsPath gets the path to the step artifacts","func getStepArtifactsPath(stepDir string, containerName string) string {","\treturn filepath.Join(stepDir, containerName, \"artifacts\", \"provenance.json\")","}","","// loadStepArtifacts loads and parses the artifacts file for a specified step.","func loadStepArtifacts(stepDir string, containerName string) (v1.Artifacts, error) {","\tv := v1.Artifacts{}","\tfp := getStepArtifactsPath(stepDir, containerName)","","\tfileContents, err := os.ReadFile(fp)","\tif err != nil {","\t\treturn v, err","\t}","\terr = json.Unmarshal(fileContents, \u0026v)","\tif err != nil {","\t\treturn v, err","\t}","\treturn v, nil","}","","// getArtifactValues retrieves the values associated with a specified artifact reference.","// It parses the provided artifact template, loads the corresponding step's artifacts, and extracts the relevant values.","// If the artifact name is not specified in the template, the values of the first output are returned.","func getArtifactValues(dir string, template string) (string, error) {","\tartifactTemplate, err := parseArtifactTemplate(template)","","\tif err != nil {","\t\treturn \"\", err","\t}","","\tartifacts, err := loadStepArtifacts(dir, artifactTemplate.ContainerName)","\tif err != nil {","\t\treturn \"\", err","\t}","","\t// $(steps.stepName.outputs.artifactName) \u003c- artifacts.Output[artifactName].Values","\tvar t []v1.Artifact","\tif artifactTemplate.Type == \"outputs\" {","\t\tt = artifacts.Outputs","\t} else {","\t\tt = artifacts.Inputs","\t}","","\tfor _, ar := range t {","\t\tif ar.Name == artifactTemplate.ArtifactName {","\t\t\tmarshal, err := json.Marshal(ar.Values)","\t\t\tif err != nil {","\t\t\t\treturn \"\", err","\t\t\t}","\t\t\treturn string(marshal), err","\t\t}","\t}","\treturn \"\", fmt.Errorf(\"values for template %s not found\", template)","}","","// parseArtifactTemplate parses an artifact template string and extracts relevant information into an ArtifactTemplate struct.","// The artifact template is expected to be in the format \"$(steps.\u003cstep-name\u003e.outputs.\u003cartifact-category-name\u003e)\".","func parseArtifactTemplate(template string) (ArtifactTemplate, error) {","\tif template == \"\" {","\t\treturn ArtifactTemplate{}, errors.New(\"template is empty\")","\t}","\tif artifactref.StepArtifactRegex.FindString(template) != template {","\t\treturn ArtifactTemplate{}, fmt.Errorf(\"invalid artifact template %s\", template)","\t}","\ttemplate = strings.TrimSuffix(strings.TrimPrefix(template, \"$(\"), \")\")","\tsplit := strings.Split(template, \".\")","\tat := ArtifactTemplate{","\t\tContainerName: \"step-\" + split[1],","\t\tType:          split[2],","\t}","\tif len(split) == 4 {","\t\tat.ArtifactName = split[3]","\t}","\treturn at, nil","}","","// ArtifactTemplate holds steps artifacts metadata parsed from step artifacts interpolation","type ArtifactTemplate struct {","\tContainerName string","\tType          string // inputs or outputs","\tArtifactName  string","}","","// applyStepArtifactSubstitutions replaces artifact references within a step's command and environment variables with their corresponding values.","//","// This function is designed to handle artifact substitutions in a script file, inline command, or environment variables.","//","// Args:","//","//\tstepDir: The directory of the executing step.","//","// Returns:","//","//\tAn error object if any issues occur during substitution.","func (e *Entrypointer) applyStepArtifactSubstitutions(stepDir string) error {","\t// Script was re-written into a file, we need to read the file to and substitute the content","\t// and re-write the command.","\t// While param substitution cannot be used in Script from StepAction, allowing artifact substitution doesn't seem bad as","\t// artifacts are unmarshalled, should be safe.","\tif len(e.Command) == 1 \u0026\u0026 filepath.Dir(e.Command[0]) == filepath.Clean(ScriptDir) {","\t\tdataBytes, err := os.ReadFile(e.Command[0])","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tfileContent := string(dataBytes)","\t\tv, err := replaceValue(artifactref.StepArtifactRegex, fileContent, stepDir, getArtifactValues)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tif v != fileContent {","\t\t\ttemp, err := writeToTempFile(v)","\t\t\tif err != nil {","\t\t\t\treturn err","\t\t\t}","\t\t\te.Command = []string{temp.Name()}","\t\t}","\t} else {","\t\tcommand := e.Command","\t\tvar newCmd []string","\t\tfor _, c := range command {","\t\t\tv, err := replaceValue(artifactref.StepArtifactRegex, c, stepDir, getArtifactValues)","\t\t\tif err != nil {","\t\t\t\treturn err","\t\t\t}","\t\t\tnewCmd = append(newCmd, v)","\t\t}","\t\te.Command = newCmd","\t}","","\t// substitute env","\tfor _, e := range os.Environ() {","\t\tpair := strings.SplitN(e, \"=\", 2)","\t\tv, err := replaceValue(artifactref.StepArtifactRegex, pair[1], stepDir, getArtifactValues)","","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tos.Setenv(pair[0], v)","\t}","","\treturn nil","}","","func writeToTempFile(v string) (*os.File, error) {","\ttmp, err := os.CreateTemp(\"\", \"script-*\")","\tif err != nil {","\t\treturn nil, err","\t}","\terr = os.Chmod(tmp.Name(), 0o755)","\tif err != nil {","\t\treturn nil, err","\t}","\t_, err = tmp.WriteString(v)","\tif err != nil {","\t\treturn nil, err","\t}","\terr = tmp.Close()","\tif err != nil {","\t\treturn nil, err","\t}","\treturn tmp, nil","}","","func replaceValue(regex *regexp.Regexp, src string, stepDir string, getValue func(string, string) (string, error)) (string, error) {","\tmatches := regex.FindAllStringSubmatch(src, -1)","\tt := src","\tfor _, m := range matches {","\t\tv, err := getValue(stepDir, m[0])","\t\tif err != nil {","\t\t\treturn \"\", err","\t\t}","\t\tt = strings.ReplaceAll(t, m[0], v)","\t}","\treturn t, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,1,1,0,0,2,1,1,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,1,1,0,2,2,2,2,2,2,2,2,1,1,0,2,2,2,1,1,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,1,1,1,0,2,2,2,2,2,2,1,1,1,0,0,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,1,1,2,2,2,2,2,1,1,2,2,2,1,1,2,0,0,2,2,2,2,2,2,2,0,2,2,1,1,0,2,2,1,1,2,2,2,2,0,2,2,1,1,0,2,2,1,1,0,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,1,0,2,2,2,2,1,1,0,2,2,2,2,2,0,0,2,2,1,1,2,2,2,2,2,1,1,0,2,0,0,0,2,2,2,1,1,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,0,0,2,2,1,1,2,2,0,0,0,0,2,2,2,2,2,2,2,1,1,0,2,2,2,2,1,1,2,0,0,0,0,2,2,2,0,0,2,2,2,2,2,1,1,2,2,1,1,2,0,0,0,2,2,2,0,0,0,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,0,2,0,2,0,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,2,0,2,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,0,2,0,2,0,0,0,2,2,2,2,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,0,2,2,2,2,0,0,2,2,2,2,2,2,0,2,2,2,2,1,1,2,0,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,1,1,2,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,0,0,2,0,0,2,2,2,1,1,2,2,1,1,2,2,1,1,2,2,1,1,2,0,0,2,2,2,2,2,2,2,2,2,0,2,0]},{"id":147,"path":"pkg/entrypoint/spire.go","lines":["//go:build !disable_spire","","/*","Copyright 2025 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package entrypoint","","import (","\t\"context\"","","\t\"github.com/tektoncd/pipeline/pkg/result\"","\t\"github.com/tektoncd/pipeline/pkg/spire\"",")","","// EntrypointerAPIClient defines the interface for SPIRE operations","type EntrypointerAPIClient interface {","\tspire.EntrypointerAPIClient","}","","func signResults(ctx context.Context, api EntrypointerAPIClient, results []result.RunResult) ([]result.RunResult, error) {","\tif api == nil {","\t\treturn nil, nil","\t}","\treturn api.Sign(ctx, results)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0]},{"id":148,"path":"pkg/internal/affinityassistant/affinityassistant_types.go","lines":["/*","Copyright 2023 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package affinityassistant","","import (","\t\"context\"","\t\"fmt\"","","\t\"github.com/tektoncd/pipeline/pkg/pod\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"",")","","type AffinityAssistantBehavior string","","const (","\tAffinityAssistantDisabled                    = AffinityAssistantBehavior(\"AffinityAssistantDisabled\")","\tAffinityAssistantPerWorkspace                = AffinityAssistantBehavior(\"AffinityAssistantPerWorkspace\")","\tAffinityAssistantPerPipelineRun              = AffinityAssistantBehavior(\"AffinityAssistantPerPipelineRun\")","\tAffinityAssistantPerPipelineRunWithIsolation = AffinityAssistantBehavior(\"AffinityAssistantPerPipelineRunWithIsolation\")",")","","// GetAffinityAssistantBehavior returns an AffinityAssistantBehavior based on the \"coschedule\" feature flags","func GetAffinityAssistantBehavior(ctx context.Context) (AffinityAssistantBehavior, error) {","\tcfg := config.FromContextOrDefaults(ctx)","\tcoschedule := cfg.FeatureFlags.Coschedule","","\tswitch coschedule {","\tcase config.CoschedulePipelineRuns:","\t\treturn AffinityAssistantPerPipelineRun, nil","\tcase config.CoscheduleIsolatePipelineRun:","\t\treturn AffinityAssistantPerPipelineRunWithIsolation, nil","\tcase config.CoscheduleWorkspaces:","\t\treturn AffinityAssistantPerWorkspace, nil","\tcase config.CoscheduleDisabled:","\t\treturn AffinityAssistantDisabled, nil","\t}","","\treturn \"\", fmt.Errorf(\"unknown affinity assistant coschedule: %v\", coschedule)","}","","// ContainerConfig defines AffinityAssistant container configuration","type ContainerConfig struct {","\tImage                 string","\tSecurityContextConfig pod.SecurityContextConfig","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,1,0,0,0,0,0,0,0]},{"id":149,"path":"pkg/internal/affinityassistant/transformer.go","lines":["/*","Copyright 2021 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package affinityassistant","","import (","\t\"context\"","","\t\"github.com/tektoncd/pipeline/pkg/pod\"","\t\"github.com/tektoncd/pipeline/pkg/workspace\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"",")","","// NewTransformer returns a pod.Transformer that will pod affinity if needed","func NewTransformer(_ context.Context, annotations map[string]string) pod.Transformer {","\treturn func(p *corev1.Pod) (*corev1.Pod, error) {","\t\t// Using node affinity on taskRuns sharing PVC workspace.  When Affinity Assistant","\t\t// is disabled, an affinityAssistantName is not set.","\t\tif affinityAssistantName := annotations[workspace.AnnotationAffinityAssistantName]; affinityAssistantName != \"\" {","\t\t\tif p.Spec.Affinity == nil {","\t\t\t\tp.Spec.Affinity = \u0026corev1.Affinity{}","\t\t\t}","\t\t\tmergeAffinityWithAffinityAssistant(p.Spec.Affinity, affinityAssistantName)","\t\t}","\t\treturn p, nil","\t}","}","","func mergeAffinityWithAffinityAssistant(affinity *corev1.Affinity, affinityAssistantName string) {","\tpodAffinityTerm := podAffinityTermUsingAffinityAssistant(affinityAssistantName)","","\tif affinity.PodAffinity == nil {","\t\taffinity.PodAffinity = \u0026corev1.PodAffinity{}","\t}","","\taffinity.PodAffinity.RequiredDuringSchedulingIgnoredDuringExecution =","\t\tappend(affinity.PodAffinity.RequiredDuringSchedulingIgnoredDuringExecution, *podAffinityTerm)","}","","// podAffinityTermUsingAffinityAssistant achieves pod Affinity term for taskRun","// pods so that the taskRun is scheduled to the Node where the Affinity Assistant pod","// is scheduled.","func podAffinityTermUsingAffinityAssistant(affinityAssistantName string) *corev1.PodAffinityTerm {","\treturn \u0026corev1.PodAffinityTerm{LabelSelector: \u0026metav1.LabelSelector{","\t\tMatchLabels: map[string]string{","\t\t\tworkspace.LabelInstance:  affinityAssistantName,","\t\t\tworkspace.LabelComponent: workspace.ComponentNameAffinityAssistant,","\t\t},","\t},","\t\tTopologyKey: \"kubernetes.io/hostname\",","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,0,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2]},{"id":150,"path":"pkg/internal/computeresources/compare/compare.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","package compare","","import (","\t\"github.com/google/go-cmp/cmp\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/api/resource\"",")","","// IsZero returns true if the resource quantity has a zero value","func IsZero(q resource.Quantity) bool {","\treturn (\u0026q).IsZero()","}","","// MaxRequest returns the largest resource request","// A zero request is considered the smallest request","func MaxRequest(quantities ...resource.Quantity) resource.Quantity {","\tmax := resource.Quantity{}","\tfor _, q := range quantities {","\t\tif q.Cmp(max) \u003e 0 {","\t\t\tmax = q","\t\t}","\t}","\treturn max","}","","// MinLimit returns the smallest resource limit","// A zero limit is considered higher than any other resource limit.","func MinLimit(quantities ...resource.Quantity) resource.Quantity {","\tmin := resource.Quantity{}","\tfor _, q := range quantities {","\t\tif min.IsZero() {","\t\t\tmin = q","\t\t} else if q.Cmp(min) \u003c 0 {","\t\t\tmin = q","\t\t}","\t}","\treturn min","}","","// ResourceQuantityCmp allows resource quantities to be compared in tests","var ResourceQuantityCmp = cmp.Comparer(func(x, y resource.Quantity) bool {","\treturn x.Cmp(y) == 0","})","","func equateAlways(_, _ interface{}) bool { return true }","","// EquateEmptyResourceList returns a comparison option that will equate resource lists","// if neither contains non-empty resource quantities.","func EquateEmptyResourceList() cmp.Option {","\treturn cmp.FilterValues(func(x, y corev1.ResourceList) bool { return IsEmpty(x) \u0026\u0026 IsEmpty(y) }, cmp.Comparer(equateAlways))","}","","// IsEmpty returns false if the ResourceList contains non-empty resource quantities.","func IsEmpty(x corev1.ResourceList) bool {","\tif len(x) == 0 {","\t\treturn true","\t}","\tfor _, q := range x {","\t\tif !q.IsZero() {","\t\t\treturn false","\t\t}","\t}","\treturn true","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,1,1,1,1,1,1,0,1,0,0,0,0,1,1,1,1,1,1,1,1,0,1,0,0,0,1,1,1,0,1,0,0,0,1,1,0,0,0,1,1,1,1,1,1,1,1,0,1,0]},{"id":151,"path":"pkg/internal/computeresources/limitrange/limitrange.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package limitrange","","import (","\t\"github.com/tektoncd/pipeline/pkg/internal/computeresources/compare\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/api/resource\"","\t\"k8s.io/apimachinery/pkg/labels\"","\tcorev1listers \"k8s.io/client-go/listers/core/v1\"",")","","// GetVirtualLimitRange returns a pointer to a single LimitRange representing the most restrictive","// requirements of all LimitRanges present in the namespace, or a nil pointer if there are no LimitRanges.","// This LimitRange meets the following constraints:","// - Its max is the smallest max of all the LimitRanges","// - Its min is the largest min of all the LimitRanges","// - Its maxLimitRequestRatio is the smallest maxLimitRequestRatio of all the LimitRanges","// - Its default is the smallest default of any of the LimitRanges that fits within the minimum and maximum","// - Its defaultRequest is the smallest defaultRequest of any of the LimitRanges that fits within the minimum and maximum","//","// This function isn't guaranteed to return a LimitRange with consistent constraints.","// For example, the minimum could be greater than the maximum.","func GetVirtualLimitRange(namespace string, lister corev1listers.LimitRangeLister) (*corev1.LimitRange, error) {","\tlimitRanges, err := lister.LimitRanges(namespace).List(labels.Everything())","\tif err != nil {","\t\treturn nil, err","\t}","\tvar limitRange *corev1.LimitRange","\tswitch {","\tcase len(limitRanges) == 0:","\t\t// No LimitRange defined","\t\tbreak","\tcase len(limitRanges) == 1:","\t\t// One LimitRange defined","\t\tlimitRange = limitRanges[0]","\tdefault:","\t\t// Several LimitRange defined","\t\tlimitRange = \u0026corev1.LimitRange{}","\t\tm := map[corev1.LimitType]corev1.LimitRangeItem{}","\t\tfor _, lr := range limitRanges {","\t\t\tfor _, item := range lr.Spec.Limits {","\t\t\t\t_, exists := m[item.Type]","\t\t\t\tif !exists {","\t\t\t\t\tm[item.Type] = corev1.LimitRangeItem{","\t\t\t\t\t\tType:                 item.Type,","\t\t\t\t\t\tMin:                  corev1.ResourceList{},","\t\t\t\t\t\tMax:                  corev1.ResourceList{},","\t\t\t\t\t\tDefault:              corev1.ResourceList{},","\t\t\t\t\t\tDefaultRequest:       corev1.ResourceList{},","\t\t\t\t\t\tMaxLimitRequestRatio: corev1.ResourceList{},","\t\t\t\t\t}","\t\t\t\t}","\t\t\t\t// Min","\t\t\t\tm[item.Type].Min[corev1.ResourceCPU] = compare.MaxRequest(m[item.Type].Min[corev1.ResourceCPU], item.Min[corev1.ResourceCPU])","\t\t\t\tm[item.Type].Min[corev1.ResourceMemory] = compare.MaxRequest(m[item.Type].Min[corev1.ResourceMemory], item.Min[corev1.ResourceMemory])","\t\t\t\tm[item.Type].Min[corev1.ResourceEphemeralStorage] = compare.MaxRequest(m[item.Type].Min[corev1.ResourceEphemeralStorage], item.Min[corev1.ResourceEphemeralStorage])","\t\t\t\t// Max","\t\t\t\tm[item.Type].Max[corev1.ResourceCPU] = compare.MinLimit(m[item.Type].Max[corev1.ResourceCPU], item.Max[corev1.ResourceCPU])","\t\t\t\tm[item.Type].Max[corev1.ResourceMemory] = compare.MinLimit(m[item.Type].Max[corev1.ResourceMemory], item.Max[corev1.ResourceMemory])","\t\t\t\tm[item.Type].Max[corev1.ResourceEphemeralStorage] = compare.MinLimit(m[item.Type].Max[corev1.ResourceEphemeralStorage], item.Max[corev1.ResourceEphemeralStorage])","\t\t\t\t// MaxLimitRequestRatio","\t\t\t\t// The smallest ratio is the most restrictive","\t\t\t\tm[item.Type].MaxLimitRequestRatio[corev1.ResourceCPU] = compare.MinLimit(m[item.Type].MaxLimitRequestRatio[corev1.ResourceCPU], item.MaxLimitRequestRatio[corev1.ResourceCPU])","\t\t\t\tm[item.Type].MaxLimitRequestRatio[corev1.ResourceMemory] = compare.MinLimit(m[item.Type].MaxLimitRequestRatio[corev1.ResourceMemory], item.MaxLimitRequestRatio[corev1.ResourceMemory])","\t\t\t\tm[item.Type].MaxLimitRequestRatio[corev1.ResourceEphemeralStorage] = compare.MinLimit(m[item.Type].MaxLimitRequestRatio[corev1.ResourceEphemeralStorage], item.MaxLimitRequestRatio[corev1.ResourceEphemeralStorage])","\t\t\t}","\t\t}","\t\t// Handle Default and DefaultRequest","\t\tfor _, lr := range limitRanges {","\t\t\tfor _, item := range lr.Spec.Limits {","\t\t\t\t// Default","\t\t\t\tm[item.Type].Default[corev1.ResourceCPU] = minOfBetween(m[item.Type].Default[corev1.ResourceCPU], item.Default[corev1.ResourceCPU], m[item.Type].Min[corev1.ResourceCPU], m[item.Type].Max[corev1.ResourceCPU])","\t\t\t\tm[item.Type].Default[corev1.ResourceMemory] = minOfBetween(m[item.Type].Default[corev1.ResourceMemory], item.Default[corev1.ResourceMemory], m[item.Type].Min[corev1.ResourceMemory], m[item.Type].Max[corev1.ResourceMemory])","\t\t\t\tm[item.Type].Default[corev1.ResourceEphemeralStorage] = minOfBetween(m[item.Type].Default[corev1.ResourceEphemeralStorage], item.Default[corev1.ResourceEphemeralStorage], m[item.Type].Min[corev1.ResourceEphemeralStorage], m[item.Type].Max[corev1.ResourceEphemeralStorage])","\t\t\t\t// DefaultRequest","\t\t\t\tm[item.Type].DefaultRequest[corev1.ResourceCPU] = minOfBetween(m[item.Type].DefaultRequest[corev1.ResourceCPU], item.DefaultRequest[corev1.ResourceCPU], m[item.Type].Min[corev1.ResourceCPU], m[item.Type].Max[corev1.ResourceCPU])","\t\t\t\tm[item.Type].DefaultRequest[corev1.ResourceMemory] = minOfBetween(m[item.Type].DefaultRequest[corev1.ResourceMemory], item.DefaultRequest[corev1.ResourceMemory], m[item.Type].Min[corev1.ResourceMemory], m[item.Type].Max[corev1.ResourceMemory])","\t\t\t\tm[item.Type].DefaultRequest[corev1.ResourceEphemeralStorage] = minOfBetween(m[item.Type].DefaultRequest[corev1.ResourceEphemeralStorage], item.DefaultRequest[corev1.ResourceEphemeralStorage], m[item.Type].Min[corev1.ResourceCPU], m[item.Type].Max[corev1.ResourceCPU])","\t\t\t}","\t\t}","\t\tfor _, v := range m {","\t\t\tlimitRange.Spec.Limits = append(limitRange.Spec.Limits, v)","\t\t}","\t}","\treturn limitRange, nil","}","","func minOfBetween(a, b, min, max resource.Quantity) resource.Quantity {","\tif compare.IsZero(a) || (\u0026a).Cmp(b) \u003e 0 {","\t\treturn b","\t}","\treturn a","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,0,2,0,0,2,2,2,2,2,0]},{"id":152,"path":"pkg/internal/computeresources/tasklevel/tasklevel.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package tasklevel","","import (","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/api/resource\"",")","","// ApplyTaskLevelComputeResources applies the task-level compute resource requirements to each Step.","func ApplyTaskLevelComputeResources(steps []v1.Step, computeResources *corev1.ResourceRequirements) {","\tif computeResources == nil {","\t\treturn","\t}","\tif computeResources.Requests == nil \u0026\u0026 computeResources.Limits == nil {","\t\treturn","\t}","\taverageRequests := computeAverageRequests(computeResources.Requests, len(steps))","\taverageLimits := computeAverageRequests(computeResources.Limits, len(steps))","\tfor i := range steps {","\t\t// if no requests are specified in step or task level, the limits are used to avoid","\t\t// unnecessary higher requests by Kubernetes default behavior.","\t\tif steps[i].ComputeResources.Requests == nil \u0026\u0026 computeResources.Requests == nil {","\t\t\tsteps[i].ComputeResources.Requests = averageLimits","\t\t} else {","\t\t\tsteps[i].ComputeResources.Requests = averageRequests","\t\t}","\t\tsteps[i].ComputeResources.Limits = computeResources.Limits","\t}","}","","// computeAverageRequests computes the average of the requests of all the steps.","func computeAverageRequests(requests corev1.ResourceList, steps int) corev1.ResourceList {","\tif len(requests) == 0 || steps == 0 {","\t\treturn nil","\t}","\taverageRequests := corev1.ResourceList{}","\tfor k, v := range requests {","\t\tif k == corev1.ResourceMemory || k == corev1.ResourceEphemeralStorage {","\t\t\taverageRequests[k] = *resource.NewQuantity(v.Value()/int64(steps), requests[k].Format)","\t\t\tcontinue","\t\t}","\t\taverageRequests[k] = *resource.NewMilliQuantity(v.MilliValue()/int64(steps), requests[k].Format)","\t}","\treturn averageRequests","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,0,2,0]},{"id":153,"path":"pkg/internal/computeresources/transformer.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package computeresources","","import (","\t\"context\"","","\t\"github.com/tektoncd/pipeline/pkg/internal/computeresources/compare\"","\t\"github.com/tektoncd/pipeline/pkg/internal/computeresources/limitrange\"","\t\"github.com/tektoncd/pipeline/pkg/pod\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/api/resource\"","\tcorev1listers \"k8s.io/client-go/listers/core/v1\"",")","","var resourceNames = []corev1.ResourceName{corev1.ResourceCPU, corev1.ResourceMemory, corev1.ResourceEphemeralStorage}","","// NewTransformer returns a pod.Transformer that will modify limits if needed","func NewTransformer(ctx context.Context, namespace string, lister corev1listers.LimitRangeLister) pod.Transformer {","\treturn func(p *corev1.Pod) (*corev1.Pod, error) {","\t\tlimitRange, err := limitrange.GetVirtualLimitRange(namespace, lister)","\t\tif err != nil {","\t\t\treturn p, err","\t\t}","\t\treturn transformPodBasedOnLimitRange(p, limitRange), nil","\t}","}","","// transformPodBasedOnLimitRange modifies the pod's containers' resource requirements to meet the constraints of the LimitRange.","// The only supported type of LimitRange is \"Container\".","// For any container:","// - If the container has requests, they are set to the max of (requests, limitRange minimum).","// - If the container doesn't have requests, they are set to the max of (limitRange minimum, \"default\"),","// where \"default\" is the LimitRange defaultRequest (for init containers) or the LimitRange defaultRequest / # of app containers","// (for app containers).","// - If the container has limits, they are set to the min of (limits, limitRange maximum).","// - If the container doesn't have limits, they are set to the min of (limitRange maximum, limitRange default).","func transformPodBasedOnLimitRange(p *corev1.Pod, limitRange *corev1.LimitRange) *corev1.Pod {","\t// No LimitRange defined, nothing to transform, bail early we don't have anything to transform.","\tif limitRange == nil {","\t\treturn p","\t}","","\t// The assumption here is that the min, max, default, ratio have already been","\t// computed if there is multiple LimitRange to satisfy the most (if we can).","\t// Count the number of step containers in the Pod.","\t// This should help us find the smallest request to apply to containers","\tnbStepContainers := 0","\tfor _, c := range p.Spec.Containers {","\t\tif pod.IsContainerStep(c.Name) {","\t\t\tnbStepContainers++","\t\t}","\t}","","\t// FIXME(#4230) maxLimitRequestRatio to support later","\tdefaultStepContainerRequests := getDefaultStepContainerRequest(limitRange, nbStepContainers)","","\tfor i, c := range p.Spec.Containers {","\t\tif !pod.IsContainerStep(c.Name) {","\t\t\tcontinue","\t\t}","\t\tif p.Spec.Containers[i].Resources.Requests == nil {","\t\t\tp.Spec.Containers[i].Resources.Requests = defaultStepContainerRequests","\t\t} else {","\t\t\tfor _, name := range resourceNames {","\t\t\t\tsetRequests(name, p.Spec.Containers[i].Resources.Requests, defaultStepContainerRequests)","\t\t\t}","\t\t}","\t}","\treturn p","}","","func setRequests(name corev1.ResourceName, dst, src corev1.ResourceList) {","\tif compare.IsZero(dst[name]) \u0026\u0026 !compare.IsZero(src[name]) {","\t\tdst[name] = src[name]","\t}","}","","// Returns the default requests to use for each step container, determined by dividing the LimitRange default requests","// among the step containers, and applying the LimitRange minimum if necessary","func getDefaultStepContainerRequest(limitRange *corev1.LimitRange, nbContainers int) corev1.ResourceList {","\t// Support only Type Container to start with","\tvar r corev1.ResourceList = map[corev1.ResourceName]resource.Quantity{}","\tfor _, item := range limitRange.Spec.Limits {","\t\t// Only support LimitTypeContainer","\t\tif item.Type == corev1.LimitTypeContainer {","\t\t\tfor _, name := range resourceNames {","\t\t\t\tvar defaultRequest resource.Quantity","\t\t\t\tvar min resource.Quantity","\t\t\t\trequest := r[name]","\t\t\t\tif item.DefaultRequest != nil {","\t\t\t\t\tdefaultRequest = item.DefaultRequest[name]","\t\t\t\t}","\t\t\t\tif item.Min != nil {","\t\t\t\t\tmin = item.Min[name]","\t\t\t\t}","","\t\t\t\tvar result resource.Quantity","\t\t\t\tif name == corev1.ResourceMemory || name == corev1.ResourceEphemeralStorage {","\t\t\t\t\tresult = compare.MaxRequest(request, *resource.NewQuantity(defaultRequest.Value()/int64(nbContainers), defaultRequest.Format), min)","\t\t\t\t} else {","\t\t\t\t\tresult = compare.MaxRequest(request, *resource.NewMilliQuantity(defaultRequest.MilliValue()/int64(nbContainers), defaultRequest.Format), min)","\t\t\t\t}","\t\t\t\t// only set non-zero request values","\t\t\t\tif !compare.IsZero(result) {","\t\t\t\t\tr[name] = result","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\t// return nil if the resource list is empty to avoid setting an empty defaultrequest","\tif len(r) == 0 {","\t\treturn nil","\t}","\treturn r","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,1,1,0,0,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,0,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,0,0,0,0,2,2,2,2,0]},{"id":154,"path":"pkg/internal/defaultresourcerequirements/transformer.go","lines":["/*","Copyright 2024 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package defaultresourcerequirements","","import (","\t\"context\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/pod\"","\tcorev1 \"k8s.io/api/core/v1\"",")","","// NewTransformer returns a pod.Transformer that will modify container resources if needed","func NewTransformer(ctx context.Context) pod.Transformer {","\t// update init container and containers resource requirements","\t// resource limits and requests values are taken from a config map","\tconfigDefaults := config.FromContextOrDefaults(ctx).Defaults","\treturn func(pod *corev1.Pod) (*corev1.Pod, error) {","\t\treturn updateResourceRequirements(configDefaults.DefaultContainerResourceRequirements, pod), nil","\t}","}","","// updates init containers and containers resource requirements of a pod base of config_defaults configmap.","func updateResourceRequirements(resourceRequirementsMap map[string]corev1.ResourceRequirements, pod *corev1.Pod) *corev1.Pod {","\tif len(resourceRequirementsMap) == 0 {","\t\treturn pod","\t}","","\t// collect all the available container names from the resource requirement map","\t// some of the container names: place-scripts, prepare, working-dir-initializer","\t// some of the container names with prefix: prefix-scripts, prefix-sidecar-scripts","\tcontainerNames := []string{}","\tcontainerNamesWithPrefix := []string{}","\tfor containerName := range resourceRequirementsMap {","\t\t// skip the default key","\t\tif containerName == config.ResourceRequirementDefaultContainerKey {","\t\t\tcontinue","\t\t}","","\t\tif strings.HasPrefix(containerName, \"prefix-\") {","\t\t\tcontainerNamesWithPrefix = append(containerNamesWithPrefix, containerName)","\t\t} else {","\t\t\tcontainerNames = append(containerNames, containerName)","\t\t}","\t}","","\t// update the containers resource requirements which does not have resource requirements","\tfor _, containerName := range containerNames {","\t\tresourceRequirements := resourceRequirementsMap[containerName]","\t\tif resourceRequirements.Size() == 0 {","\t\t\tcontinue","\t\t}","","\t\t// update init containers","\t\tfor index := range pod.Spec.InitContainers {","\t\t\ttargetContainer := pod.Spec.InitContainers[index]","\t\t\tif containerName == targetContainer.Name \u0026\u0026 targetContainer.Resources.Size() == 0 {","\t\t\t\tpod.Spec.InitContainers[index].Resources = resourceRequirements","\t\t\t}","\t\t}","\t\t// update containers","\t\tfor index := range pod.Spec.Containers {","\t\t\ttargetContainer := pod.Spec.Containers[index]","\t\t\tif containerName == targetContainer.Name \u0026\u0026 targetContainer.Resources.Size() == 0 {","\t\t\t\tpod.Spec.Containers[index].Resources = resourceRequirements","\t\t\t}","\t\t}","\t}","","\t// update the containers resource requirements which does not have resource requirements with the mentioned prefix","\tfor _, containerPrefix := range containerNamesWithPrefix {","\t\tresourceRequirements := resourceRequirementsMap[containerPrefix]","\t\tif resourceRequirements.Size() == 0 {","\t\t\tcontinue","\t\t}","","\t\t// get actual container name, remove \"prefix-\" string and append \"-\" at the end","\t\t// append '-' in the container prefix","\t\tcontainerPrefix = strings.Replace(containerPrefix, \"prefix-\", \"\", 1)","\t\tcontainerPrefix += \"-\"","","\t\t// update init containers","\t\tfor index := range pod.Spec.InitContainers {","\t\t\ttargetContainer := pod.Spec.InitContainers[index]","\t\t\tif strings.HasPrefix(targetContainer.Name, containerPrefix) \u0026\u0026 targetContainer.Resources.Size() == 0 {","\t\t\t\tpod.Spec.InitContainers[index].Resources = resourceRequirements","\t\t\t}","\t\t}","\t\t// update containers","\t\tfor index := range pod.Spec.Containers {","\t\t\ttargetContainer := pod.Spec.Containers[index]","\t\t\tif strings.HasPrefix(targetContainer.Name, containerPrefix) \u0026\u0026 targetContainer.Resources.Size() == 0 {","\t\t\t\tpod.Spec.Containers[index].Resources = resourceRequirements","\t\t\t}","\t\t}","\t}","","\t// reset of the containers resource requirements which has empty resource requirements","\tif resourceRequirements, found := resourceRequirementsMap[config.ResourceRequirementDefaultContainerKey]; found \u0026\u0026 resourceRequirements.Size() != 0 {","\t\t// update init containers","\t\tfor index := range pod.Spec.InitContainers {","\t\t\tif pod.Spec.InitContainers[index].Resources.Size() == 0 {","\t\t\t\tpod.Spec.InitContainers[index].Resources = resourceRequirements","\t\t\t}","\t\t}","\t\t// update containers","\t\tfor index := range pod.Spec.Containers {","\t\t\tif pod.Spec.Containers[index].Resources.Size() == 0 {","\t\t\t\tpod.Spec.Containers[index].Resources = resourceRequirements","\t\t\t}","\t\t}","\t}","","\treturn pod","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,0,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,0,0,0,2,2,2,2,0,0,0,2,2,2,2,2,0,0,2,2,2,2,2,0,0,0,0,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,0,0,0,2,0]},{"id":155,"path":"pkg/internal/resolution/resolutionrequest.go","lines":["/*"," Copyright 2022 The Tekton Authors",""," Licensed under the Apache License, Version 2.0 (the \"License\");"," you may not use this file except in compliance with the License."," You may obtain a copy of the License at","","     http://www.apache.org/licenses/LICENSE-2.0",""," Unless required by applicable law or agreed to in writing, software"," distributed under the License is distributed on an \"AS IS\" BASIS,"," WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied."," See the License for the specific language governing permissions and"," limitations under the License.","*/","","package resolution","","import (","\t\"encoding/base64\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\tcommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"knative.dev/pkg/apis\"","\tduckv1 \"knative.dev/pkg/apis/duck/v1\"",")","","// CreateResolutionRequestStatusWithData returns a ResolutionRequestStatus with the resolved content.","func CreateResolutionRequestStatusWithData(content []byte) *v1beta1.ResolutionRequestStatus {","\treturn \u0026v1beta1.ResolutionRequestStatus{","\t\tStatus: duckv1.Status{},","\t\tResolutionRequestStatusFields: v1beta1.ResolutionRequestStatusFields{","\t\t\tData: base64.StdEncoding.Strict().EncodeToString(content),","\t\t},","\t}","}","","// CreateResolutionRequestFailureStatus returns a ResolutionRequestStatus with failure.","func CreateResolutionRequestFailureStatus() *v1beta1.ResolutionRequestStatus {","\treturn \u0026v1beta1.ResolutionRequestStatus{","\t\tStatus: duckv1.Status{","\t\t\tConditions: duckv1.Conditions{{","\t\t\t\tType:   apis.ConditionSucceeded,","\t\t\t\tStatus: corev1.ConditionFalse,","\t\t\t\tReason: common.ReasonResolutionFailed,","\t\t\t}},","\t\t},","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1]},{"id":156,"path":"pkg/internal/resultref/resultref.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resultref","","import (","\t\"fmt\"","\t\"regexp\"","\t\"strconv\"","\t\"strings\"",")","","const (","\tresultExpressionFormat     = \"tasks.\u003ctaskName\u003e.results.\u003cresultName\u003e\"","\tstepResultExpressionFormat = \"steps.\u003cstepName\u003e.results.\u003cresultName\u003e\"","\t// Result expressions of the form \u003cresultName\u003e.\u003cattribute\u003e will be treated as object results.","\t// If a string result name contains a dot, brackets should be used to differentiate it from an object result.","\t// https://github.com/tektoncd/community/blob/main/teps/0075-object-param-and-result-types.md#collisions-with-builtin-variable-replacement","\tobjectResultExpressionFormat     = \"tasks.\u003ctaskName\u003e.results.\u003cobjectResultName\u003e.\u003cindividualAttribute\u003e\"","\tobjectStepResultExpressionFormat = \"steps.\u003cstepName\u003e.results.\u003cobjectResultName\u003e.\u003cindividualAttribute\u003e\"","\t// ResultStepPart Constant used to define the \"steps\" part of a step result reference","\tResultStepPart = \"steps\"","\t// ResultTaskPart Constant used to define the \"tasks\" part of a pipeline result reference","\tResultTaskPart = \"tasks\"","\t// ResultFinallyPart Constant used to define the \"finally\" part of a pipeline result reference","\tResultFinallyPart = \"finally\"","\t// ResultResultPart Constant used to define the \"results\" part of a pipeline result reference","\tResultResultPart = \"results\"","","\t// arrayIndexing will match all `[int]` and `[*]` for parseExpression","\tarrayIndexing          = `\\[([0-9])*\\*?\\]`","\tstepResultUsagePattern = `\\$\\(steps\\..*?\\.results\\..*?\\)`",")","","// arrayIndexingRegex is used to match `[int]` and `[*]`","var arrayIndexingRegex = regexp.MustCompile(arrayIndexing)","","// StepResultRegex compiles the regex pattern for the usage of step results.","var StepResultRegex = regexp.MustCompile(stepResultUsagePattern)","","// LooksLikeResultRef attempts to check if the given string looks like it contains any","// result references. Returns true if it does, false otherwise","func LooksLikeResultRef(expression string) bool {","\tsubExpressions := strings.Split(expression, \".\")","\treturn len(subExpressions) \u003e= 4 \u0026\u0026 (subExpressions[0] == ResultTaskPart || subExpressions[0] == ResultFinallyPart) \u0026\u0026 subExpressions[2] == ResultResultPart","}","","// looksLikeStepResultRef attempts to check if the given string looks like it contains any","// step result references. Returns true if it does, false otherwise","func looksLikeStepResultRef(expression string) bool {","\tsubExpressions := strings.Split(expression, \".\")","\treturn len(subExpressions) \u003e= 4 \u0026\u0026 subExpressions[0] == ResultStepPart \u0026\u0026 subExpressions[2] == ResultResultPart","}","","// ParsedResult captures the task/step name, result name, type,","// array idx (in case of array result) and","// object key (in case of an object result).","// This is generated by parsing expressions that use","// $(tasks.taskName.results.resultName...) or $(steps.stepName.results.resultName...)","type ParsedResult struct {","\tResourceName string","\tResultName   string","\tResultType   string","\tArrayIdx     *int","\tObjectKey    string","}","","// parseExpression parses \"task name\", \"result name\", \"array index\" (iff it's an array result) and \"object key name\" (iff it's an object result)","// 1. Reference string result","// - Input: tasks.myTask.results.aStringResult","// - Output: \"myTask\", \"aStringResult\", nil, \"\", nil","// 2. Reference Object value with key:","// - Input: tasks.myTask.results.anObjectResult.key1","// - Output: \"myTask\", \"anObjectResult\", nil, \"key1\", nil","// 3. Reference array elements with array indexing :","// - Input: tasks.myTask.results.anArrayResult[1]","// - Output: \"myTask\", \"anArrayResult\", 1, \"\", nil","// 4. Referencing whole array or object result:","// - Input: tasks.myTask.results.Result[*]","// - Output: \"myTask\", \"Result\", nil, \"\", nil","// Invalid Case:","// - Input: tasks.myTask.results.resultName.foo.bar","// - Output: \"\", \"\", nil, \"\", error","// TODO: may use regex for each type to handle possible reference formats","func parseExpression(substitutionExpression string) (ParsedResult, error) {","\tif LooksLikeResultRef(substitutionExpression) || looksLikeStepResultRef(substitutionExpression) {","\t\tsubExpressions := strings.Split(substitutionExpression, \".\")","\t\t// For string result: tasks.\u003ctaskName\u003e.results.\u003cstringResultName\u003e","\t\t// For string step result: steps.\u003cstepName\u003e.results.\u003cstringResultName\u003e","\t\t// For array result: tasks.\u003ctaskName\u003e.results.\u003carrayResultName\u003e[index]","\t\t// For array step result: steps.\u003cstepName\u003e.results.\u003carrayResultName\u003e[index]","\t\tif len(subExpressions) == 4 {","\t\t\tresultName, stringIdx := ParseResultName(subExpressions[3])","\t\t\tif stringIdx != \"\" {","\t\t\t\tif stringIdx == \"*\" {","\t\t\t\t\tpr := ParsedResult{","\t\t\t\t\t\tResourceName: subExpressions[1],","\t\t\t\t\t\tResultName:   resultName,","\t\t\t\t\t\tResultType:   \"array\",","\t\t\t\t\t}","\t\t\t\t\treturn pr, nil","\t\t\t\t}","\t\t\t\tintIdx, _ := strconv.Atoi(stringIdx)","\t\t\t\tpr := ParsedResult{","\t\t\t\t\tResourceName: subExpressions[1],","\t\t\t\t\tResultName:   resultName,","\t\t\t\t\tResultType:   \"array\",","\t\t\t\t\tArrayIdx:     \u0026intIdx,","\t\t\t\t}","\t\t\t\treturn pr, nil","\t\t\t}","\t\t\tpr := ParsedResult{","\t\t\t\tResourceName: subExpressions[1],","\t\t\t\tResultName:   resultName,","\t\t\t\tResultType:   \"string\",","\t\t\t}","\t\t\treturn pr, nil","\t\t} else if len(subExpressions) == 5 {","\t\t\t// For object type result: tasks.\u003ctaskName\u003e.results.\u003cobjectResultName\u003e.\u003cindividualAttribute\u003e","\t\t\t// For object type step result: steps.\u003cstepName\u003e.results.\u003cobjectResultName\u003e.\u003cindividualAttribute\u003e","\t\t\tpr := ParsedResult{","\t\t\t\tResourceName: subExpressions[1],","\t\t\t\tResultName:   subExpressions[3],","\t\t\t\tResultType:   \"object\",","\t\t\t\tObjectKey:    subExpressions[4],","\t\t\t}","\t\t\treturn pr, nil","\t\t}","\t}","\treturn ParsedResult{}, fmt.Errorf(\"must be one of the form 1). %q; 2). %q; 3). %q; 4). %q\", resultExpressionFormat, objectResultExpressionFormat, stepResultExpressionFormat, objectStepResultExpressionFormat)","}","","// ParseTaskExpression parses the input string and searches for the use of task result usage.","func ParseTaskExpression(substitutionExpression string) (ParsedResult, error) {","\tif LooksLikeResultRef(substitutionExpression) {","\t\treturn parseExpression(substitutionExpression)","\t}","\treturn ParsedResult{}, fmt.Errorf(\"must be one of the form 1). %q; 2). %q\", resultExpressionFormat, objectResultExpressionFormat)","}","","// ParseStepExpression parses the input string and searches for the use of step result usage.","func ParseStepExpression(substitutionExpression string) (ParsedResult, error) {","\tif looksLikeStepResultRef(substitutionExpression) {","\t\treturn parseExpression(substitutionExpression)","\t}","\treturn ParsedResult{}, fmt.Errorf(\"must be one of the form 1). %q; 2). %q\", stepResultExpressionFormat, objectStepResultExpressionFormat)","}","","// ParseResultName parse the input string to extract resultName and result index.","// Array indexing:","// Input:  anArrayResult[1]","// Output: anArrayResult, \"1\"","// Array star reference:","// Input:  anArrayResult[*]","// Output: anArrayResult, \"*\"","func ParseResultName(resultName string) (string, string) {","\tstringIdx := strings.TrimSuffix(strings.TrimPrefix(arrayIndexingRegex.FindString(resultName), \"[\"), \"]\")","\tresultName = arrayIndexingRegex.ReplaceAllString(resultName, \"\")","\treturn resultName, stringIdx","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,0,0,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,0,0,0,0,0,0,0,2,2,2,2,2]},{"id":157,"path":"pkg/list/diff.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package list","","import \"fmt\"","","// IsSame will return an error indicating if there are extra or missing strings","// between the required and provided strings, or will return no error if the two","// contain the same values.","func IsSame(required, provided []string) error {","\tmissing := DiffLeft(required, provided)","\tif len(missing) \u003e 0 {","\t\treturn fmt.Errorf(\"didn't provide required values: %s\", missing)","\t}","\textra := DiffLeft(provided, required)","\tif len(extra) \u003e 0 {","\t\treturn fmt.Errorf(\"provided extra values: %s\", extra)","\t}","\treturn nil","}","","// DiffLeft will return all strings which are in the left slice of strings but","// not in the right.","func DiffLeft(left, right []string) []string {","\textra := []string{}","\tfor _, s := range left {","\t\tfound := false","\t\tfor _, s2 := range right {","\t\t\tif s == s2 {","\t\t\t\tfound = true","\t\t\t}","\t\t}","\t\tif !found {","\t\t\textra = append(extra, s)","\t\t}","\t}","\treturn extra","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,0,2,0]},{"id":158,"path":"pkg/names/generate.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package names","","import (","\t\"fmt\"","\t\"hash/fnv\"","\t\"regexp\"","\t\"strconv\"","\t\"strings\"","","\tutilrand \"k8s.io/apimachinery/pkg/util/rand\"",")","","// NameGenerator generates names for objects. Some backends may have more information","// available to guide selection of new names and this interface hides those details.","type NameGenerator interface {","\t// RestrictLengthWithRandomSuffix generates a valid name from the base name, adding a random suffix to","\t// the base. If base is valid, the returned name must also be valid. The generator is","\t// responsible for knowing the maximum valid name length.","\tRestrictLengthWithRandomSuffix(base string) string","","\t// RestrictLength generates a valid name from the name of a step specified in a Task,","\t// shortening it to the maximum valid name length if needed.","\tRestrictLength(base string) string","}","","// simpleNameGenerator generates random names.","type simpleNameGenerator struct{}","","// SimpleNameGenerator is a generator that returns the name plus a random suffix of five alphanumerics","// when a name is requested. The string is guaranteed to not exceed the length of a standard Kubernetes","// name (63 characters)","var SimpleNameGenerator NameGenerator = simpleNameGenerator{}","","const (","\t// TODO: make this flexible for non-core resources with alternate naming rules.","\tmaxNameLength          = 63","\trandomLength           = 5","\tmaxGeneratedNameLength = maxNameLength - randomLength - 1",")","","// RestrictLengthWithRandomSuffix takes a base name and returns a potentially shortened version of that name with","// a random suffix, with the whole string no longer than 63 characters.","func (simpleNameGenerator) RestrictLengthWithRandomSuffix(base string) string {","\tif len(base) \u003e maxGeneratedNameLength {","\t\tbase = base[:maxGeneratedNameLength]","\t}","\treturn fmt.Sprintf(\"%s-%s\", base, utilrand.String(randomLength))","}","","var alphaNumericRE = regexp.MustCompile(`^[a-zA-Z0-9]+$`)","","// RestrictLength takes a base name and returns a potentially shortened version of that name, no longer than 63 characters.","func (simpleNameGenerator) RestrictLength(base string) string {","\tif len(base) \u003e maxNameLength {","\t\tbase = base[:maxNameLength]","\t}","","\tfor !alphaNumericRE.MatchString(base[len(base)-1:]) {","\t\tbase = base[:len(base)-1]","\t}","\treturn base","}","","// GenerateHashedName creates a unique name with a hashed suffix.","func GenerateHashedName(prefix, name string, hashedLength int) string {","\tif hashedLength \u003c= 0 {","\t\thashedLength = randomLength","\t}","\th := fnv.New32a()","\th.Write([]byte(name))","\tsuffix := strconv.FormatUint(uint64(h.Sum32()), 16)","\tif ln := len(suffix); ln \u003e hashedLength {","\t\tsuffix = suffix[:hashedLength]","\t} else if ln \u003c hashedLength {","\t\tsuffix += strings.Repeat(\"0\", hashedLength-ln)","\t}","\treturn fmt.Sprintf(\"%s-%s\", prefix, suffix)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,0,0,0,2,2,2,2,0,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0]},{"id":159,"path":"pkg/pipelinerunmetrics/fake/fake.go","lines":["/*","Copyright 2021 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package fake","","import (","\t\"context\"","","\t_ \"github.com/tektoncd/pipeline/pkg/client/injection/informers/pipeline/v1/pipelinerun/fake\" // Make sure the fake pipelinerun informer is setup","\t\"github.com/tektoncd/pipeline/pkg/pipelinerunmetrics\"","\t\"k8s.io/client-go/rest\"","\t\"knative.dev/pkg/injection\"",")","","func init() {","\tinjection.Fake.RegisterClient(func(ctx context.Context, _ *rest.Config) context.Context { return pipelinerunmetrics.WithClient(ctx) })","\tinjection.Fake.RegisterInformer(pipelinerunmetrics.WithInformer)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0]},{"id":160,"path":"pkg/pipelinerunmetrics/injection.go","lines":["/*","Copyright 2021 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pipelinerunmetrics","","import (","\t\"context\"","","\tpipelineruninformer \"github.com/tektoncd/pipeline/pkg/client/injection/informers/pipeline/v1/pipelinerun\"","\tlisters \"github.com/tektoncd/pipeline/pkg/client/listers/pipeline/v1\"","\t\"k8s.io/client-go/rest\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/injection\"","\t\"knative.dev/pkg/logging\"",")","","func init() {","\tinjection.Default.RegisterClient(func(ctx context.Context, _ *rest.Config) context.Context { return WithClient(ctx) })","\tinjection.Default.RegisterInformer(WithInformer)","}","","// RecorderKey is used for associating the Recorder inside the context.Context.","type RecorderKey struct{}","","// WithClient adds a metrics recorder to the given context","func WithClient(ctx context.Context) context.Context {","\trec, err := NewRecorder(ctx)","\tif err != nil {","\t\tlogging.FromContext(ctx).Errorf(\"Failed to create pipelinerun metrics recorder %v\", err)","\t}","\treturn context.WithValue(ctx, RecorderKey{}, rec)","}","","// Get extracts the pipelinerunmetrics.Recorder from the context.","func Get(ctx context.Context) *Recorder {","\tuntyped := ctx.Value(RecorderKey{})","\tif untyped == nil {","\t\tlogging.FromContext(ctx).Panic(\"Unable to fetch *pipelinerunmetrics.Recorder from context.\")","\t}","\treturn untyped.(*Recorder)","}","","// InformerKey is used for associating the Informer inside the context.Context.","type InformerKey struct{}","","// WithInformer returns the given context, and a configured informer","func WithInformer(ctx context.Context) (context.Context, controller.Informer) {","\treturn ctx, \u0026recorderInformer{","\t\tctx:     ctx,","\t\tmetrics: Get(ctx),","\t\tlister:  pipelineruninformer.Get(ctx).Lister(),","\t}","}","","type recorderInformer struct {","\tctx     context.Context","\tmetrics *Recorder","\tlister  listers.PipelineRunLister","}","","var _ controller.Informer = (*recorderInformer)(nil)","","// Run starts the recorder informer in a goroutine","func (ri *recorderInformer) Run(stopCh \u003c-chan struct{}) {","\t// Turn the stopCh into a context for reporting metrics.","\tctx, cancel := context.WithCancel(ri.ctx)","\tgo func() {","\t\t\u003c-stopCh","\t\tcancel()","\t}()","","\tgo ri.metrics.ReportRunningPipelineRuns(ctx, ri.lister)","}","","// HasSynced returns whether the informer has synced, which in this case will always be true.","func (ri *recorderInformer) HasSynced() bool {","\treturn true","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,1,0,0,0,1,1,1]},{"id":161,"path":"pkg/pipelinerunmetrics/metrics.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pipelinerunmetrics","","import (","\t\"context\"","\t\"encoding/hex\"","\t\"errors\"","\t\"fmt\"","\t\"sync\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tlisters \"github.com/tektoncd/pipeline/pkg/client/listers/pipeline/v1\"","\t\"go.opencensus.io/stats\"","\t\"go.opencensus.io/stats/view\"","\t\"go.opencensus.io/tag\"","\t\"go.uber.org/zap\"","\t\"golang.org/x/crypto/blake2b\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/api/equality\"","\t\"k8s.io/apimachinery/pkg/labels\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/logging\"","\t\"knative.dev/pkg/metrics\"",")","","const (","\trunningPRLevelPipelinerun = \"pipelinerun\"","\trunningPRLevelPipeline    = \"pipeline\"","\trunningPRLevelNamespace   = \"namespace\"","\trunningPRLevelCluster     = \"\"",")","","var (","\tpipelinerunTag = tag.MustNewKey(\"pipelinerun\")","\tpipelineTag    = tag.MustNewKey(\"pipeline\")","\tnamespaceTag   = tag.MustNewKey(\"namespace\")","\tstatusTag      = tag.MustNewKey(\"status\")","\treasonTag      = tag.MustNewKey(\"reason\")","","\tprDuration = stats.Float64(","\t\t\"pipelinerun_duration_seconds\",","\t\t\"The pipelinerun execution time in seconds\",","\t\tstats.UnitDimensionless)","\tprDurationView *view.View","","\tprTotal = stats.Float64(\"pipelinerun_total\",","\t\t\"Number of pipelineruns\",","\t\tstats.UnitDimensionless)","\tprTotalView *view.View","","\trunningPRs = stats.Float64(\"running_pipelineruns\",","\t\t\"Number of pipelineruns executing currently\",","\t\tstats.UnitDimensionless)","\trunningPRsView *view.View","","\trunningPRsWaitingOnPipelineResolution = stats.Float64(\"running_pipelineruns_waiting_on_pipeline_resolution\",","\t\t\"Number of pipelineruns executing currently that are waiting on resolution requests for their pipeline references.\",","\t\tstats.UnitDimensionless)","\trunningPRsWaitingOnPipelineResolutionView *view.View","","\trunningPRsWaitingOnTaskResolution = stats.Float64(\"running_pipelineruns_waiting_on_task_resolution\",","\t\t\"Number of pipelineruns executing currently that are waiting on resolution requests for the task references of their taskrun children.\",","\t\tstats.UnitDimensionless)","\trunningPRsWaitingOnTaskResolutionView *view.View",")","","const (","\t// ReasonCancelled indicates that a PipelineRun was cancelled.","\t// Aliased for backwards compatibility; additional reasons should not be added here.","\tReasonCancelled = v1.PipelineRunReasonCancelled","","\tanonymous = \"anonymous\"",")","","// Recorder holds keys for Tekton metrics","type Recorder struct {","\tmutex       sync.Mutex","\tinitialized bool","\tcfg         *config.Metrics","","\tinsertTag func(pipeline,","\t\tpipelinerun string) []tag.Mutator","","\tReportingPeriod time.Duration","","\thash string","}","","// We cannot register the view multiple times, so NewRecorder lazily","// initializes this singleton and returns the same recorder across any","// subsequent invocations.","var (","\tonce           sync.Once","\tr              *Recorder","\terrRegistering error",")","","// NewRecorder creates a new metrics recorder instance","// to log the PipelineRun related metrics","func NewRecorder(ctx context.Context) (*Recorder, error) {","\tonce.Do(func() {","\t\tr = \u0026Recorder{","\t\t\tinitialized: true,","","\t\t\t// Default to 30s intervals.","\t\t\tReportingPeriod: 30 * time.Second,","\t\t}","","\t\tcfg := config.FromContextOrDefaults(ctx)","\t\tr.cfg = cfg.Metrics","\t\terrRegistering = viewRegister(cfg.Metrics)","\t\tif errRegistering != nil {","\t\t\tr.initialized = false","\t\t\treturn","\t\t}","\t})","","\treturn r, errRegistering","}","","func viewRegister(cfg *config.Metrics) error {","\tr.mutex.Lock()","\tdefer r.mutex.Unlock()","","\tvar prunTag []tag.Key","\tswitch cfg.PipelinerunLevel {","\tcase config.PipelinerunLevelAtPipelinerun:","\t\tprunTag = []tag.Key{pipelinerunTag, pipelineTag}","\t\tr.insertTag = pipelinerunInsertTag","\tcase config.PipelinerunLevelAtPipeline:","\t\tprunTag = []tag.Key{pipelineTag}","\t\tr.insertTag = pipelineInsertTag","\tcase config.PipelinerunLevelAtNS:","\t\tprunTag = []tag.Key{}","\t\tr.insertTag = nilInsertTag","\tdefault:","\t\treturn errors.New(\"invalid config for PipelinerunLevel: \" + cfg.PipelinerunLevel)","\t}","","\tvar runningPRTag []tag.Key","\tswitch cfg.RunningPipelinerunLevel {","\tcase config.PipelinerunLevelAtPipelinerun:","\t\trunningPRTag = []tag.Key{pipelinerunTag, pipelineTag, namespaceTag}","\tcase config.PipelinerunLevelAtPipeline:","\t\trunningPRTag = []tag.Key{pipelineTag, namespaceTag}","\tcase config.PipelinerunLevelAtNS:","\t\trunningPRTag = []tag.Key{namespaceTag}","\tdefault:","\t\trunningPRTag = []tag.Key{}","\t}","","\tdistribution := view.Distribution(10, 30, 60, 300, 900, 1800, 3600, 5400, 10800, 21600, 43200, 86400)","","\tif cfg.PipelinerunLevel == config.PipelinerunLevelAtPipelinerun {","\t\tdistribution = view.LastValue()","\t} else {","\t\tswitch cfg.DurationPipelinerunType {","\t\tcase config.DurationTaskrunTypeHistogram:","\t\tcase config.DurationTaskrunTypeLastValue:","\t\t\tdistribution = view.LastValue()","\t\tdefault:","\t\t\treturn errors.New(\"invalid config for DurationTaskrunType: \" + cfg.DurationTaskrunType)","\t\t}","\t}","","\tif cfg.CountWithReason {","\t\tprunTag = append(prunTag, reasonTag)","\t}","","\tprDurationView = \u0026view.View{","\t\tDescription: prDuration.Description(),","\t\tMeasure:     prDuration,","\t\tAggregation: distribution,","\t\tTagKeys:     append([]tag.Key{statusTag, namespaceTag}, prunTag...),","\t}","","\tprTotalView = \u0026view.View{","\t\tDescription: prTotal.Description(),","\t\tMeasure:     prTotal,","\t\tAggregation: view.Count(),","\t\tTagKeys:     []tag.Key{statusTag},","\t}","","\trunningPRsView = \u0026view.View{","\t\tDescription: runningPRs.Description(),","\t\tMeasure:     runningPRs,","\t\tAggregation: view.LastValue(),","\t\tTagKeys:     runningPRTag,","\t}","","\trunningPRsWaitingOnPipelineResolutionView = \u0026view.View{","\t\tDescription: runningPRsWaitingOnPipelineResolution.Description(),","\t\tMeasure:     runningPRsWaitingOnPipelineResolution,","\t\tAggregation: view.LastValue(),","\t}","","\trunningPRsWaitingOnTaskResolutionView = \u0026view.View{","\t\tDescription: runningPRsWaitingOnTaskResolution.Description(),","\t\tMeasure:     runningPRsWaitingOnTaskResolution,","\t\tAggregation: view.LastValue(),","\t}","","\treturn view.Register(","\t\tprDurationView,","\t\tprTotalView,","\t\trunningPRsView,","\t\trunningPRsWaitingOnPipelineResolutionView,","\t\trunningPRsWaitingOnTaskResolutionView,","\t)","}","","func viewUnregister() {","\tview.Unregister(prDurationView,","\t\tprTotalView,","\t\trunningPRsView,","\t\trunningPRsWaitingOnPipelineResolutionView,","\t\trunningPRsWaitingOnTaskResolutionView)","}","","// OnStore returns a function that checks if metrics are configured for a config.Store, and registers it if so","func OnStore(logger *zap.SugaredLogger, r *Recorder) func(name string,","\tvalue interface{}) {","\treturn func(name string, value interface{}) {","\t\tif name == config.GetMetricsConfigName() {","\t\t\tcfg, ok := value.(*config.Metrics)","\t\t\tif !ok {","\t\t\t\tlogger.Error(\"Failed to do type insertion for extracting metrics config\")","\t\t\t\treturn","\t\t\t}","\t\t\tupdated := r.updateConfig(cfg)","\t\t\tif !updated {","\t\t\t\treturn","\t\t\t}","\t\t\t// Update metrics according to configuration","\t\t\tviewUnregister()","\t\t\terr := viewRegister(cfg)","\t\t\tif err != nil {","\t\t\t\tlogger.Errorf(\"Failed to register View %v \", err)","\t\t\t\treturn","\t\t\t}","\t\t}","\t}","}","","func pipelinerunInsertTag(pipeline, pipelinerun string) []tag.Mutator {","\treturn []tag.Mutator{","\t\ttag.Insert(pipelineTag, pipeline),","\t\ttag.Insert(pipelinerunTag, pipelinerun),","\t}","}","","func pipelineInsertTag(pipeline, pipelinerun string) []tag.Mutator {","\treturn []tag.Mutator{tag.Insert(pipelineTag, pipeline)}","}","","func nilInsertTag(task, taskrun string) []tag.Mutator {","\treturn []tag.Mutator{}","}","","func getPipelineTagName(pr *v1.PipelineRun) string {","\tpipelineName := anonymous","\tswitch {","\tcase pr.Spec.PipelineRef != nil \u0026\u0026 pr.Spec.PipelineRef.Name != \"\":","\t\tpipelineName = pr.Spec.PipelineRef.Name","\tcase pr.Spec.PipelineSpec != nil:","\tdefault:","\t\tif len(pr.Labels) \u003e 0 {","\t\t\tpipelineLabel, hasPipelineLabel := pr.Labels[pipeline.PipelineLabelKey]","\t\t\tif hasPipelineLabel \u0026\u0026 len(pipelineLabel) \u003e 0 {","\t\t\t\tpipelineName = pipelineLabel","\t\t\t}","\t\t}","\t}","","\treturn pipelineName","}","","func (r *Recorder) updateConfig(cfg *config.Metrics) bool {","\tr.mutex.Lock()","\tdefer r.mutex.Unlock()","\tvar hash string","\tif cfg != nil {","\t\ts := fmt.Sprintf(\"%v\", *cfg)","\t\tsum := blake2b.Sum256([]byte(s))","\t\thash = hex.EncodeToString(sum[:])","\t}","","\tif r.hash == hash {","\t\treturn false","\t}","","\tr.cfg = cfg","\tr.hash = hash","","\treturn true","}","","// DurationAndCount logs the duration of PipelineRun execution and","// count for number of PipelineRuns succeed or failed","// returns an error if it fails to log the metrics","func (r *Recorder) DurationAndCount(pr *v1.PipelineRun, beforeCondition *apis.Condition) error {","\tif !r.initialized {","\t\treturn fmt.Errorf(\"ignoring the metrics recording for %s , failed to initialize the metrics recorder\", pr.Name)","\t}","","\tafterCondition := pr.Status.GetCondition(apis.ConditionSucceeded)","\t// To avoid recount","\tif equality.Semantic.DeepEqual(beforeCondition, afterCondition) {","\t\treturn nil","\t}","","\tr.mutex.Lock()","\tdefer r.mutex.Unlock()","","\tduration := time.Duration(0)","\tif pr.Status.StartTime != nil {","\t\tduration = time.Since(pr.Status.StartTime.Time)","\t\tif pr.Status.CompletionTime != nil {","\t\t\tduration = pr.Status.CompletionTime.Sub(pr.Status.StartTime.Time)","\t\t}","\t}","","\tcond := pr.Status.GetCondition(apis.ConditionSucceeded)","\tstatus := \"success\"","\tif cond.Status == corev1.ConditionFalse {","\t\tstatus = \"failed\"","\t\tif cond.Reason == v1.PipelineRunReasonCancelled.String() {","\t\t\tstatus = \"cancelled\"","\t\t}","\t}","\treason := cond.Reason","","\tpipelineName := getPipelineTagName(pr)","","\tctx, err := tag.New(","\t\tcontext.Background(),","\t\tappend([]tag.Mutator{","\t\t\ttag.Insert(namespaceTag, pr.Namespace),","\t\t\ttag.Insert(statusTag, status), tag.Insert(reasonTag, reason),","\t\t}, r.insertTag(pipelineName, pr.Name)...)...)","\tif err != nil {","\t\treturn err","\t}","","\tmetrics.Record(ctx, prDuration.M(duration.Seconds()))","\tmetrics.Record(ctx, prTotal.M(1))","","\treturn nil","}","","// RunningPipelineRuns logs the number of PipelineRuns running right now","// returns an error if it fails to log the metrics","func (r *Recorder) RunningPipelineRuns(lister listers.PipelineRunLister) error {","\tr.mutex.Lock()","\tdefer r.mutex.Unlock()","\tif !r.initialized {","\t\treturn errors.New(\"ignoring the metrics recording, failed to initialize the metrics recorder\")","\t}","","\tprs, err := lister.List(labels.Everything())","\tif err != nil {","\t\treturn fmt.Errorf(\"failed to list pipelineruns while generating metrics : %w\", err)","\t}","","\tvar runningPipelineRuns int","\tvar trsWaitResolvingTaskRef int","\tvar prsWaitResolvingPipelineRef int","\tcountMap := map[string]int{}","","\tfor _, pr := range prs {","\t\tpipelineName := getPipelineTagName(pr)","\t\tpipelineRunKey := \"\"","\t\tmutators := []tag.Mutator{","\t\t\ttag.Insert(namespaceTag, pr.Namespace),","\t\t\ttag.Insert(pipelineTag, pipelineName),","\t\t\ttag.Insert(pipelinerunTag, pr.Name),","\t\t}","\t\tif r.cfg != nil {","\t\t\tswitch r.cfg.RunningPipelinerunLevel {","\t\t\tcase runningPRLevelPipelinerun:","\t\t\t\tpipelineRunKey = pipelineRunKey + \"#\" + pr.Name","\t\t\t\tfallthrough","\t\t\tcase runningPRLevelPipeline:","\t\t\t\tpipelineRunKey = pipelineRunKey + \"#\" + pipelineName","\t\t\t\tfallthrough","\t\t\tcase runningPRLevelNamespace:","\t\t\t\tpipelineRunKey = pipelineRunKey + \"#\" + pr.Namespace","\t\t\tcase runningPRLevelCluster:","\t\t\tdefault:","\t\t\t\treturn fmt.Errorf(\"RunningPipelineRunLevel value \\\"%s\\\" is not valid \", r.cfg.RunningPipelinerunLevel)","\t\t\t}","\t\t}","\t\tctx_, err_ := tag.New(context.Background(), mutators...)","\t\tif err_ != nil {","\t\t\treturn err","\t\t}","\t\tif !pr.IsDone() \u0026\u0026 !pr.IsPending() {","\t\t\tcountMap[pipelineRunKey]++","\t\t\tmetrics.Record(ctx_, runningPRs.M(float64(countMap[pipelineRunKey])))","\t\t\trunningPipelineRuns++","\t\t\tsucceedCondition := pr.Status.GetCondition(apis.ConditionSucceeded)","\t\t\tif succeedCondition != nil \u0026\u0026 succeedCondition.Status == corev1.ConditionUnknown {","\t\t\t\tswitch succeedCondition.Reason {","\t\t\t\tcase v1.TaskRunReasonResolvingTaskRef:","\t\t\t\t\ttrsWaitResolvingTaskRef++","\t\t\t\tcase v1.PipelineRunReasonResolvingPipelineRef.String():","\t\t\t\t\tprsWaitResolvingPipelineRef++","\t\t\t\t}","\t\t\t}","\t\t} else {","\t\t\t// In case there are no running PipelineRuns for the pipelineRunKey, set the metric value to 0 to ensure","\t\t\t//  the metric is set for the key.","\t\t\tif _, exists := countMap[pipelineRunKey]; !exists {","\t\t\t\tcountMap[pipelineRunKey] = 0","\t\t\t\tmetrics.Record(ctx_, runningPRs.M(0))","\t\t\t}","\t\t}","\t}","","\tctx, err := tag.New(context.Background())","\tif err != nil {","\t\treturn err","\t}","\tmetrics.Record(ctx, runningPRsWaitingOnPipelineResolution.M(float64(prsWaitResolvingPipelineRef)))","\tmetrics.Record(ctx, runningPRsWaitingOnTaskResolution.M(float64(trsWaitResolvingTaskRef)))","\tmetrics.Record(ctx, runningPRs.M(float64(runningPipelineRuns)))","","\treturn nil","}","","// ReportRunningPipelineRuns invokes RunningPipelineRuns on our configured PeriodSeconds","// until the context is cancelled.","func (r *Recorder) ReportRunningPipelineRuns(ctx context.Context, lister listers.PipelineRunLister) {","\tlogger := logging.FromContext(ctx)","","\tfor {","\t\tdelay := time.NewTimer(r.ReportingPeriod)","\t\tselect {","\t\tcase \u003c-ctx.Done():","\t\t\t// When the context is cancelled, stop reporting.","\t\t\tif !delay.Stop() {","\t\t\t\t\u003c-delay.C","\t\t\t}","\t\t\treturn","","\t\tcase \u003c-delay.C:","\t\t\t// Every 30s surface a metric for the number of running pipelines.","\t\t\tif err := r.RunningPipelineRuns(lister); err != nil {","\t\t\t\tlogger.Warnf(\"Failed to log the metrics : %v\", err)","\t\t\t}","\t\t}","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,0,0,2,0,0,2,2,2,2,2,2,2,2,2,1,1,1,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,2,2,1,1,0,0,0,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,0,1,1,1,0,1,1,1,0,2,2,2,2,2,0,2,2,2,2,2,2,0,0,0,2,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,2,0,0,0,0,0,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,0,0,0,0,2,2,2,2,2,2,0,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,1,1,0,0,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,0,2,2,1,1,2,2,2,2,2,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,0,0]},{"id":162,"path":"pkg/platforms/platforms.go","lines":["/*","Copyright 2025 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package platforms","","import (","\t\"errors\"","\t\"fmt\"","\t\"log/slog\"","\t\"path\"","\t\"runtime\"","\t\"sync\"",")","","var (","\terrNotImplemented = errors.New(\"not implemented\")",")","","const (","\tUnknown = \"unknown\"","\tArm     = \"arm\"","\tArm64   = \"arm64\"","\tWindows = \"windows\"","\tDarwin  = \"darwin\"","\tFreeBSD = \"freebsd\"","\tLinux   = \"linux\"",")","","// Platform describes the platform which the image in the manifest runs on.","type Platform struct {","\t// Architecture field specifies the CPU architecture, for example","\t// `amd64` or `ppc64le`.","\tArchitecture string `json:\"architecture\"`","","\t// OS specifies the operating system, for example `linux` or `windows`.","\tOS string `json:\"os\"`","","\t// OSVersion is an optional field specifying the operating system","\t// version, for example on Windows `10.0.14393.1066`.","\tOSVersion string `json:\"os.version,omitempty\"`","","\t// OSFeatures is an optional field specifying an array of strings,","\t// each listing a required OS feature (for example on Windows `win32k`).","\tOSFeatures []string `json:\"os.features,omitempty\"`","","\t// Variant is an optional field specifying a variant of the CPU, for","\t// example `v7` to specify ARMv7 when architecture is `arm`.","\tVariant string `json:\"variant,omitempty\"`","}","","func NewPlatform() *Platform {","\tp := \u0026Platform{","\t\tOS:           runtime.GOOS,","\t\tArchitecture: runtime.GOARCH,","\t\tVariant:      cpuVariant(),","\t}","\treturn p","}","","func (p *Platform) Format() string {","\tif p.OS == \"\" {","\t\treturn Unknown","\t}","","\treturn path.Join(p.OS, p.Architecture, p.Variant)","}","","// Present the ARM instruction set architecture, eg: v7, v8","// Don't use this value directly; call cpuVariant() instead.","var cpuVariantValue string","","var cpuVariantOnce sync.Once","","func cpuVariant() string {","\tcpuVariantOnce.Do(func() {","\t\tif isArmArch(runtime.GOARCH) {","\t\t\tvar err error","\t\t\tcpuVariantValue, err = getCPUVariant()","\t\t\tif err != nil {","\t\t\t\tslog.Error(\"failed to get CPU variant\", \"os\", runtime.GOOS, \"error\", err)","\t\t\t}","\t\t}","\t})","\treturn cpuVariantValue","}","","// isArmArch returns true if the architecture is ARM.","//","// The arch value should be normalized before being passed to this function.","func isArmArch(arch string) bool {","\tswitch arch {","\tcase Arm, Arm64:","\t\treturn true","\t}","\treturn false","}","","func getCPUVariant() (string, error) {","\tvar variant string","","\tswitch runtime.GOOS {","\tcase Windows, Darwin:","\t\t// Windows/Darwin only supports v7 for ARM32 and v8 for ARM64","\t\tswitch runtime.GOARCH {","\t\tcase Arm64:","\t\t\tvariant = \"v8\"","\t\tcase Arm:","\t\t\tvariant = \"v7\"","\t\tdefault:","\t\t\tvariant = Unknown","\t\t}","\tcase Linux, FreeBSD:","\t\t// FreeBSD supports ARMv6 and ARMv7 as well as ARMv4 and ARMv5 (though deprecated)","\t\t// detecting those variants is currently unimplemented","\t\tswitch runtime.GOARCH {","\t\tcase Arm64:","\t\t\tvariant = \"v8\"","\t\tdefault:","\t\t\tvariant = Unknown","\t\t}","\tdefault:","\t\treturn \"\", fmt.Errorf(\"getCPUVariant for OS %s: %w\", runtime.GOOS, errNotImplemented)","\t}","","\treturn variant, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,0,2,2,1,1,0,2,0,0,0,0,0,0,0,0,2,2,2,1,1,1,1,1,0,0,2,0,0,0,0,0,2,2,2,2,0,2,0,0,2,2,2,2,1,1,1,1,1,1,1,1,1,0,2,2,2,2,1,1,2,2,0,1,1,0,0,2,0]},{"id":163,"path":"pkg/pod/creds_init.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pod","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","\t\"regexp\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\t\"github.com/tektoncd/pipeline/pkg/credentials/dockercreds\"","\t\"github.com/tektoncd/pipeline/pkg/credentials/gitcreds\"","\tcredmatcher \"github.com/tektoncd/pipeline/pkg/credentials/matcher\"","\tcredwriter \"github.com/tektoncd/pipeline/pkg/credentials/writer\"","\t\"github.com/tektoncd/pipeline/pkg/names\"","\tcorev1 \"k8s.io/api/core/v1\"","\tk8serrors \"k8s.io/apimachinery/pkg/api/errors\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/client-go/kubernetes\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/logging\"",")","","const (","\tcredsInitHomeMountPrefix = \"tekton-creds-init-home\" // #nosec","\tsshKnownHosts            = \"known_hosts\"",")","","var dnsLabel1123Forbidden = regexp.MustCompile(\"[^a-zA-Z0-9-]+\")","","// credsInit reads secrets available to the given service account and","// searches for annotations matching a specific format (documented in","// docs/auth.md). Matching secrets are turned into Volumes for the Pod","// and VolumeMounts to be given to each Step. Additionally, a list of","// entrypointer arguments are returned, each with a meaning specific to","// the credential type it describes: git credentials expect one set of","// args while docker credentials expect another.","//","// Any errors encountered during this process are returned to the","// caller. If no matching annotated secrets are found, nil lists with a","// nil error are returned.","func credsInit(ctx context.Context, obj runtime.Object, serviceAccountName, namespace string, kubeclient kubernetes.Interface) ([]string, []corev1.Volume, []corev1.VolumeMount, error) {","\tlogger := logging.FromContext(ctx)","\tcfg := config.FromContextOrDefaults(ctx)","\tif cfg != nil \u0026\u0026 cfg.FeatureFlags != nil \u0026\u0026 cfg.FeatureFlags.DisableCredsInit {","\t\treturn nil, nil, nil, nil","\t}","","\t// service account if not specified in pipeline/task spec, read it from the ConfigMap","\t// and defaults to `default` if its missing from the ConfigMap as well","\tif serviceAccountName == \"\" {","\t\tserviceAccountName = config.DefaultServiceAccountValue","\t}","","\tsa, err := kubeclient.CoreV1().ServiceAccounts(namespace).Get(ctx, serviceAccountName, metav1.GetOptions{})","\tif err != nil {","\t\treturn nil, nil, nil, err","\t}","","\tbuilders := []interface {","\t\tcredmatcher.Matcher","\t\tcredwriter.Writer","\t}{dockercreds.NewBuilder(), gitcreds.NewBuilder()}","","\tvar volumeMounts []corev1.VolumeMount","\tvar volumes []corev1.Volume","\tvar args []string","\tvar missingSecrets []string","","\tdefer func() {","\t\trecorder := controller.GetEventRecorder(ctx)","\t\tif len(missingSecrets) \u003e 0 \u0026\u0026 recorder != nil \u0026\u0026 obj != nil {","\t\t\trecorder.Eventf(obj, corev1.EventTypeWarning, \"FailedToRetrieveSecret\",","\t\t\t\t\"Unable to retrieve some secrets (%s); attempting to use them may not succeed.\",","\t\t\t\tstrings.Join(missingSecrets, \", \"))","\t\t}","\t}()","","\t// Track duplicated secrets, prevent errors like this:","\t//  Pod \"xxx\" is invalid: spec.containers[0].volumeMounts[12].mountPath: Invalid value:","\t//  \"/tekton/creds-secrets/demo-docker-credentials\": must be unique","\tvisitedSecrets := make(map[string]struct{})","\tfor _, secretEntry := range sa.Secrets {","\t\tif secretEntry.Name == \"\" {","\t\t\tcontinue","\t\t}","\t\tif _, ok := visitedSecrets[secretEntry.Name]; ok {","\t\t\tcontinue","\t\t}","\t\tvisitedSecrets[secretEntry.Name] = struct{}{}","","\t\tsecret, err := kubeclient.CoreV1().Secrets(namespace).Get(ctx, secretEntry.Name, metav1.GetOptions{})","\t\tif k8serrors.IsNotFound(err) {","\t\t\tmissingSecrets = append(missingSecrets, secretEntry.Name)","\t\t\tlogger.Warnf(\"Secret %q in ServiceAccount %s/%s not found, skipping\", secretEntry.Name, namespace, serviceAccountName)","\t\t\tcontinue","\t\t}","\t\tif err != nil {","\t\t\treturn nil, nil, nil, err","\t\t}","","\t\tif err := checkGitSSHSecret(ctx, secret); err != nil {","\t\t\treturn nil, nil, nil, err","\t\t}","","\t\tmatched := false","\t\tfor _, b := range builders {","\t\t\tif sa := b.MatchingAnnotations(secret); len(sa) \u003e 0 {","\t\t\t\tmatched = true","\t\t\t\targs = append(args, sa...)","\t\t\t}","\t\t}","","\t\tif matched {","\t\t\t// While secret names can use RFC1123 DNS subdomain name rules, the volume mount","\t\t\t// name required the stricter DNS label standard, for example no dots anymore.","\t\t\tsanitizedName := dnsLabel1123Forbidden.ReplaceAllString(secret.Name, \"-\")","\t\t\tname := names.SimpleNameGenerator.RestrictLengthWithRandomSuffix(\"tekton-internal-secret-volume-\" + sanitizedName)","\t\t\tvolumeMounts = append(volumeMounts, corev1.VolumeMount{","\t\t\t\tName:      name,","\t\t\t\tMountPath: credmatcher.VolumeName(secret.Name),","\t\t\t})","\t\t\tvolumes = append(volumes, corev1.Volume{","\t\t\t\tName: name,","\t\t\t\tVolumeSource: corev1.VolumeSource{","\t\t\t\t\tSecret: \u0026corev1.SecretVolumeSource{","\t\t\t\t\t\tSecretName: secret.Name,","\t\t\t\t\t},","\t\t\t\t},","\t\t\t})","\t\t}","\t}","","\tif len(args) == 0 {","\t\t// There are no creds to initialize.","\t\treturn nil, nil, nil, nil","\t}","","\treturn args, volumes, volumeMounts, nil","}","","// getCredsInitVolume returns a Volume and VolumeMount for /tekton/creds. Each call","// will return a new volume and volume mount. Takes an integer index to append to","// the name of the volume.","func getCredsInitVolume(ctx context.Context, idx int) (*corev1.Volume, *corev1.VolumeMount) {","\tcfg := config.FromContextOrDefaults(ctx)","\tif cfg != nil \u0026\u0026 cfg.FeatureFlags != nil \u0026\u0026 cfg.FeatureFlags.DisableCredsInit {","\t\treturn nil, nil","\t}","\tname := fmt.Sprintf(\"%s-%d\", credsInitHomeMountPrefix, idx)","\tv := corev1.Volume{","\t\tName: name,","\t\tVolumeSource: corev1.VolumeSource{EmptyDir: \u0026corev1.EmptyDirVolumeSource{","\t\t\tMedium: corev1.StorageMediumMemory,","\t\t}},","\t}","\tvm := corev1.VolumeMount{","\t\tName:      name,","\t\tMountPath: pipeline.CredsDir,","\t}","\treturn \u0026v, \u0026vm","}","","// checkGitSSHSecret requires `known_host` field must be included in Git SSH Secret when feature flag","// `require-git-ssh-secret-known-hosts` is true.","func checkGitSSHSecret(ctx context.Context, secret *corev1.Secret) error {","\tcfg := config.FromContextOrDefaults(ctx)","","\tif secret.Type == corev1.SecretTypeSSHAuth \u0026\u0026 cfg.FeatureFlags.RequireGitSSHSecretKnownHosts {","\t\tif _, ok := secret.Data[sshKnownHosts]; !ok {","\t\t\treturn errors.New(\"TaskRun validation failed. Git SSH Secret must have \\\"known_hosts\\\" included \" +","\t\t\t\t\"when feature flag \\\"require-git-ssh-secret-known-hosts\\\" is set to true\")","\t\t}","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,0,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,0,2,2,0,2,2,2,2,2,2,2,0,2,1,1,0,2,1,1,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,0,2,0]},{"id":164,"path":"pkg/pod/entrypoint.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pod","","import (","\t\"context\"","\t\"encoding/json\"","\t\"errors\"","\t\"fmt\"","\t\"log\"","\t\"path/filepath\"","\t\"strconv\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"gomodules.xyz/jsonpatch/v2\"","\tcorev1 \"k8s.io/api/core/v1\"","\tk8serrors \"k8s.io/apimachinery/pkg/api/errors\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/types\"","\t\"k8s.io/client-go/kubernetes\"",")","","const (","\tbinVolumeName    = \"tekton-internal-bin\"","\tbinDir           = \"/tekton/bin\"","\tentrypointBinary = binDir + \"/entrypoint\"","","\trunVolumeName = \"tekton-internal-run\"","","\t// RunDir is the directory that contains runtime variable data for TaskRuns.","\t// This includes files for handling container ordering, exit status codes, and more.","\t// See [https://github.com/tektoncd/pipeline/blob/main/docs/developers/taskruns.md#tekton]","\t// for more details.","\tRunDir = \"/tekton/run\"","","\tdownwardVolumeName     = \"tekton-internal-downward\"","\tdownwardMountPoint     = \"/tekton/downward\"","\tterminationPath        = \"/tekton/termination\"","\tdownwardMountReadyFile = \"ready\"","\treadyAnnotation        = \"tekton.dev/ready\"","\treadyAnnotationValue   = \"READY\"","","\tstepPrefix    = \"step-\"","\tsidecarPrefix = \"sidecar-\"","","\tdownwardMountCancelFile = \"cancel\"","\tcancelAnnotation        = \"tekton.dev/cancel\"","\tcancelAnnotationValue   = \"CANCEL\"",")","","var (","\t// TODO(#1605): Generate volumeMount names, to avoid collisions.","\tbinMount = corev1.VolumeMount{","\t\tName:      binVolumeName,","\t\tMountPath: binDir,","\t}","\tbinROMount = corev1.VolumeMount{","\t\tName:      binVolumeName,","\t\tMountPath: binDir,","\t\tReadOnly:  true,","\t}","\tbinVolume = corev1.Volume{","\t\tName:         binVolumeName,","\t\tVolumeSource: corev1.VolumeSource{EmptyDir: \u0026corev1.EmptyDirVolumeSource{}},","\t}","\tinternalStepsMount = corev1.VolumeMount{","\t\tName:      \"tekton-internal-steps\",","\t\tMountPath: pipeline.StepsDir,","\t}","","\tdownwardCancelVolumeItem = corev1.DownwardAPIVolumeFile{","\t\tPath: downwardMountCancelFile,","\t\tFieldRef: \u0026corev1.ObjectFieldSelector{","\t\t\tFieldPath: fmt.Sprintf(\"metadata.annotations['%s']\", cancelAnnotation),","\t\t},","\t}","\t// TODO(#1605): Signal sidecar readiness by injecting entrypoint,","\t// remove dependency on Downward API.","\tdownwardVolume = corev1.Volume{","\t\tName: downwardVolumeName,","\t\tVolumeSource: corev1.VolumeSource{","\t\t\tDownwardAPI: \u0026corev1.DownwardAPIVolumeSource{","\t\t\t\tItems: []corev1.DownwardAPIVolumeFile{{","\t\t\t\t\tPath: downwardMountReadyFile,","\t\t\t\t\tFieldRef: \u0026corev1.ObjectFieldSelector{","\t\t\t\t\t\tFieldPath: fmt.Sprintf(\"metadata.annotations['%s']\", readyAnnotation),","\t\t\t\t\t},","\t\t\t\t}},","\t\t\t},","\t\t},","\t}","\tdownwardMount = corev1.VolumeMount{","\t\tName:      downwardVolumeName,","\t\tMountPath: downwardMountPoint,","\t\t// Marking this volume mount readonly is technically redundant,","\t\t// since the volume itself is readonly, but including for completeness.","\t\tReadOnly: true,","\t}","\t// DownwardMountCancelFile is cancellation file mount to step, entrypoint will check this file to cancel the step.","\tDownwardMountCancelFile = filepath.Join(downwardMountPoint, downwardMountCancelFile)",")","","// orderContainers returns the specified steps, modified so that they are","// executed in order by overriding the entrypoint binary.","//","// Containers must have Command specified; if the user didn't specify a","// command, we must have fetched the image's ENTRYPOINT before calling this","// method, using entrypoint_lookup.go.","// Additionally, Step timeouts are added as entrypoint flag.","func orderContainers(ctx context.Context, commonExtraEntrypointArgs []string, steps []corev1.Container, taskSpec *v1.TaskSpec, breakpointConfig *v1.TaskRunDebug, waitForReadyAnnotation, enableKeepPodOnCancel bool) ([]corev1.Container, error) {","\tif len(steps) == 0 {","\t\treturn nil, errors.New(\"no steps specified\")","\t}","","\tfor i, s := range steps {","\t\tvar argsForEntrypoint = []string{}","\t\tidx := strconv.Itoa(i)","\t\tif i == 0 {","\t\t\tif waitForReadyAnnotation {","\t\t\t\targsForEntrypoint = append(argsForEntrypoint,","\t\t\t\t\t// First step waits for the Downward volume file.","\t\t\t\t\t\"-wait_file\", filepath.Join(downwardMountPoint, downwardMountReadyFile),","\t\t\t\t\t\"-wait_file_content\", // Wait for file contents, not just an empty file.","\t\t\t\t)","\t\t\t}","\t\t} else { // Not the first step - wait for previous","\t\t\targsForEntrypoint = append(argsForEntrypoint, \"-wait_file\", filepath.Join(RunDir, strconv.Itoa(i-1), \"out\"))","\t\t}","\t\targsForEntrypoint = append(argsForEntrypoint,","\t\t\t// Start next step.","\t\t\t\"-post_file\", filepath.Join(RunDir, idx, \"out\"),","\t\t\t\"-termination_path\", terminationPath,","\t\t\t\"-step_metadata_dir\", filepath.Join(RunDir, idx, \"status\"),","\t\t)","","\t\targsForEntrypoint = append(argsForEntrypoint, commonExtraEntrypointArgs...)","\t\tif taskSpec != nil {","\t\t\tif taskSpec.Steps != nil \u0026\u0026 len(taskSpec.Steps) \u003e= i+1 {","\t\t\t\tif taskSpec.Steps[i].OnError != \"\" {","\t\t\t\t\tif taskSpec.Steps[i].OnError != v1.Continue \u0026\u0026 taskSpec.Steps[i].OnError != v1.StopAndFail {","\t\t\t\t\t\treturn nil, fmt.Errorf(\"task step onError must be either \\\"%s\\\" or \\\"%s\\\" but it is set to an invalid value \\\"%s\\\"\",","\t\t\t\t\t\t\tv1.Continue, v1.StopAndFail, taskSpec.Steps[i].OnError)","\t\t\t\t\t}","\t\t\t\t\targsForEntrypoint = append(argsForEntrypoint, \"-on_error\", string(taskSpec.Steps[i].OnError))","\t\t\t\t}","\t\t\t\tif taskSpec.Steps[i].Timeout != nil {","\t\t\t\t\targsForEntrypoint = append(argsForEntrypoint, \"-timeout\", taskSpec.Steps[i].Timeout.Duration.String())","\t\t\t\t}","\t\t\t\tif taskSpec.Steps[i].StdoutConfig != nil {","\t\t\t\t\targsForEntrypoint = append(argsForEntrypoint, \"-stdout_path\", taskSpec.Steps[i].StdoutConfig.Path)","\t\t\t\t}","\t\t\t\tif taskSpec.Steps[i].StderrConfig != nil {","\t\t\t\t\targsForEntrypoint = append(argsForEntrypoint, \"-stderr_path\", taskSpec.Steps[i].StderrConfig.Path)","\t\t\t\t}","\t\t\t\t// add step results","\t\t\t\tstepResultArgs := stepResultArgument(taskSpec.Steps[i].Results)","","\t\t\t\targsForEntrypoint = append(argsForEntrypoint, stepResultArgs...)","\t\t\t\tif len(taskSpec.Steps[i].When) \u003e 0 {","\t\t\t\t\t// marshal and pass to the entrypoint and unmarshal it there.","\t\t\t\t\tmarshal, err := json.Marshal(taskSpec.Steps[i].When)","","\t\t\t\t\tif err != nil {","\t\t\t\t\t\treturn nil, fmt.Errorf(\"faile to resolve when %w\", err)","\t\t\t\t\t}","\t\t\t\t\targsForEntrypoint = append(argsForEntrypoint, \"--when_expressions\", string(marshal))","\t\t\t\t}","\t\t\t}","\t\t\targsForEntrypoint = append(argsForEntrypoint, resultArgument(steps, taskSpec.Results)...)","\t\t}","","\t\tif breakpointConfig != nil \u0026\u0026 breakpointConfig.NeedsDebugOnFailure() {","\t\t\targsForEntrypoint = append(argsForEntrypoint, \"-breakpoint_on_failure\")","\t\t}","\t\tif breakpointConfig != nil \u0026\u0026 breakpointConfig.NeedsDebugBeforeStep(s.Name) {","\t\t\targsForEntrypoint = append(argsForEntrypoint, \"-debug_before_step\")","\t\t}","","\t\tcmd, args := s.Command, s.Args","\t\tif len(cmd) \u003e 0 {","\t\t\targsForEntrypoint = append(argsForEntrypoint, \"-entrypoint\", cmd[0])","\t\t}","\t\tif len(cmd) \u003e 1 {","\t\t\targs = append(cmd[1:], args...)","\t\t}","\t\targsForEntrypoint = append(argsForEntrypoint, \"--\")","\t\targsForEntrypoint = append(argsForEntrypoint, args...)","","\t\tsteps[i].Command = []string{entrypointBinary}","\t\tsteps[i].Args = argsForEntrypoint","\t\tsteps[i].TerminationMessagePath = terminationPath","\t\tif (i == 0 \u0026\u0026 waitForReadyAnnotation) || enableKeepPodOnCancel {","\t\t\t// Mount the Downward volume into the first step container.","\t\t\t// if enableKeepPodOnCancel is true, mount the Downward volume into all the steps.","\t\t\tsteps[i].VolumeMounts = append(steps[i].VolumeMounts, downwardMount)","\t\t}","\t}","","\treturn steps, nil","}","","// stepResultArgument creates the cli arguments for step results to the entrypointer.","func stepResultArgument(stepResults []v1.StepResult) []string {","\tif len(stepResults) == 0 {","\t\treturn nil","\t}","\tstepResultNames := []string{}","\tfor _, r := range stepResults {","\t\tstepResultNames = append(stepResultNames, r.Name)","\t}","\treturn []string{\"-step_results\", strings.Join(stepResultNames, \",\")}","}","","func resultArgument(steps []corev1.Container, results []v1.TaskResult) []string {","\tif len(results) == 0 {","\t\treturn nil","\t}","\treturn []string{\"-results\", collectResultsName(results)}","}","","func collectResultsName(results []v1.TaskResult) string {","\tvar resultNames []string","\tfor _, r := range results {","\t\tif r.Value == nil {","\t\t\tresultNames = append(resultNames, r.Name)","\t\t}","\t}","\treturn strings.Join(resultNames, \",\")","}","","var replaceReadyPatchBytes, replaceCancelPatchBytes []byte","","func init() {","\t// https://stackoverflow.com/questions/55573724/create-a-patch-to-add-a-kubernetes-annotation","\treadyAnnotationPath := \"/metadata/annotations/\" + strings.Replace(readyAnnotation, \"/\", \"~1\", 1)","\tvar err error","\treplaceReadyPatchBytes, err = json.Marshal([]jsonpatch.JsonPatchOperation{{","\t\tOperation: \"replace\",","\t\tPath:      readyAnnotationPath,","\t\tValue:     readyAnnotationValue,","\t}})","\tif err != nil {","\t\tlog.Fatalf(\"failed to marshal replace ready patch bytes: %v\", err)","\t}","","\tcancelAnnotationPath := \"/metadata/annotations/\" + strings.Replace(cancelAnnotation, \"/\", \"~1\", 1)","\treplaceCancelPatchBytes, err = json.Marshal([]jsonpatch.JsonPatchOperation{{","\t\tOperation: \"replace\",","\t\tPath:      cancelAnnotationPath,","\t\tValue:     cancelAnnotationValue,","\t}})","\tif err != nil {","\t\tlog.Fatalf(\"failed to marshal replace cancel patch bytes: %v\", err)","\t}","}","","// buildSidecarStopPatch creates a JSON Patch to replace sidecar container images with nop image","func buildSidecarStopPatch(pod *corev1.Pod, nopImage string, ctx context.Context) ([]byte, error) {","\tvar patchOps []jsonpatch.JsonPatchOperation","","\t// Iterate over container statuses to find running sidecars","\tfor _, s := range pod.Status.ContainerStatuses {","\t\t// If the results-from is set to sidecar logs,","\t\t// a sidecar container with name `sidecar-log-results` is injected by the reconciler.","\t\t// Do not kill this sidecar. Let it exit gracefully.","\t\tif config.FromContextOrDefaults(ctx).FeatureFlags.ResultExtractionMethod == config.ResultExtractionMethodSidecarLogs \u0026\u0026 s.Name == pipeline.ReservedResultsSidecarContainerName {","\t\t\tcontinue","\t\t}","\t\t// Stop any running container that isn't a step.","\t\t// An injected sidecar container might not have the","\t\t// \"sidecar-\" prefix, so we can't just look for that prefix.","\t\tif !IsContainerStep(s.Name) \u0026\u0026 s.State.Running != nil {","\t\t\t// Find the corresponding container in the spec by name to get the correct index","\t\t\tfor i, c := range pod.Spec.Containers {","\t\t\t\tif c.Name == s.Name \u0026\u0026 c.Image != nopImage {","\t\t\t\t\tpatchOps = append(patchOps, jsonpatch.JsonPatchOperation{","\t\t\t\t\t\tOperation: \"replace\",","\t\t\t\t\t\tPath:      fmt.Sprintf(\"/spec/containers/%d/image\", i),","\t\t\t\t\t\tValue:     nopImage,","\t\t\t\t\t})","\t\t\t\t\tbreak","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\tif len(patchOps) == 0 {","\t\treturn nil, nil","\t}","","\treturn json.Marshal(patchOps)","}","","// CancelPod cancels the pod","func CancelPod(ctx context.Context, kubeClient kubernetes.Interface, namespace, podName string) error {","\t// PATCH the Pod's annotations to replace the cancel annotation with the","\t// \"CANCEL\" value, to signal the pod to be cancelled.","\t_, err := kubeClient.CoreV1().Pods(namespace).Patch(ctx, podName, types.JSONPatchType, replaceCancelPatchBytes, metav1.PatchOptions{})","\treturn err","}","","// UpdateReady updates the Pod's annotations to signal the first step to start","// by projecting the ready annotation via the Downward API.","func UpdateReady(ctx context.Context, kubeclient kubernetes.Interface, pod corev1.Pod) error {","\t// Don't PATCH if the annotation is already Ready.","\tif pod.Annotations[readyAnnotation] == readyAnnotationValue {","\t\treturn nil","\t}","","\t// PATCH the Pod's annotations to replace the ready annotation with the","\t// \"READY\" value, to signal the first step to start.","\t_, err := kubeclient.CoreV1().Pods(pod.Namespace).Patch(ctx, pod.Name, types.JSONPatchType, replaceReadyPatchBytes, metav1.PatchOptions{})","\treturn err","}","","// StopSidecars updates sidecar containers in the Pod to a nop image, which","// exits successfully immediately.","func StopSidecars(ctx context.Context, nopImage string, kubeclient kubernetes.Interface, namespace, name string) (*corev1.Pod, error) {","\tpod, err := kubeclient.CoreV1().Pods(namespace).Get(ctx, name, metav1.GetOptions{})","\tif k8serrors.IsNotFound(err) {","\t\t// return NotFound as-is, since the K8s error checks don't handle wrapping.","\t\treturn nil, err","\t} else if err != nil {","\t\treturn nil, fmt.Errorf(\"error getting Pod %q when stopping sidecars: %w\", name, err)","\t}","","\t// Only attempt to stop sidecars if pod is running","\tif pod.Status.Phase != corev1.PodRunning {","\t\treturn pod, nil","\t}","","\t// Build JSON Patch operations to replace sidecar images","\tpatchBytes, err := buildSidecarStopPatch(pod, nopImage, ctx)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"error building patch for stopping sidecars of Pod %q: %w\", name, err)","\t}","","\t// If no sidecars need to be stopped, return early","\tif patchBytes == nil {","\t\treturn pod, nil","\t}","","\t// PATCH the Pod's container images to stop sidecars, using the same pattern as UpdateReady and CancelPod","\tpatchedPod, err := kubeclient.CoreV1().Pods(namespace).Patch(ctx, name, types.JSONPatchType, patchBytes, metav1.PatchOptions{})","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"error stopping sidecars of Pod %q: %w\", name, err)","\t}","","\treturn patchedPod, nil","}","","// IsSidecarStatusRunning determines if any SidecarStatus on a TaskRun","// is still running.","func IsSidecarStatusRunning(tr *v1.TaskRun) bool {","\tfor _, sidecar := range tr.Status.Sidecars {","\t\tif sidecar.Terminated == nil {","\t\t\treturn true","\t\t}","\t}","","\treturn false","}","","// IsContainerStep returns true if the container name indicates that it","// represents a step.","func IsContainerStep(name string) bool { return strings.HasPrefix(name, stepPrefix) }","","// IsContainerSidecar returns true if the container name indicates that it","// represents a sidecar.","func IsContainerSidecar(name string) bool { return strings.HasPrefix(name, sidecarPrefix) }","","// TrimStepPrefix returns the container name, stripped of its step prefix.","func TrimStepPrefix(name string) string { return strings.TrimPrefix(name, stepPrefix) }","","// TrimSidecarPrefix returns the container name, stripped of its sidecar","// prefix.","func TrimSidecarPrefix(name string) string { return strings.TrimPrefix(name, sidecarPrefix) }","","// StepName returns the step name after adding \"step-\" prefix to the actual step name or","// returns \"step-unnamed-\u003cstep-index\u003e\" if not specified","func StepName(name string, i int) string {","\tif name != \"\" {","\t\treturn GetContainerName(name)","\t}","\treturn fmt.Sprintf(\"%sunnamed-%d\", stepPrefix, i)","}","","// GetContainerName prefixes the input name with \"step-\"","func GetContainerName(name string) string {","\treturn fmt.Sprintf(\"%s%s\", stepPrefix, name)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,1,1,2,0,0,2,0,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,1,1,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,0,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,0,2,2,0,0,0,0,2,2,2,1,1,2,1,1,0,0,2,2,2,0,0,2,2,1,1,0,0,2,2,2,0,0,2,2,1,1,0,2,0,0,0,0,2,2,2,2,2,0,0,2,0,0,0,0,2,0,0,0,2,0,0,2,0,0,0,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2]},{"id":165,"path":"pkg/pod/entrypoint_lookup.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pod","","import (","\t\"context\"","\t\"encoding/json\"","","\t\"github.com/google/go-containerregistry/pkg/name\"","\tv1 \"github.com/google/go-containerregistry/pkg/v1\"","\tcorev1 \"k8s.io/api/core/v1\"",")","","// EntrypointCache looks up an image's entrypoint (command) in a container","// image registry, possibly using the given service account's credentials.","type EntrypointCache interface {","\t// get the Image data for the given image reference. If the value is","\t// not found in the cache, it will be fetched from the image registry,","\t// possibly using K8s service account imagePullSecrets.","\t//","\t// It also returns the digest associated with the given reference. If","\t// the reference referred to an index, the returned digest will be the","\t// index's digest, not any platform-specific image contained by the","\t// index.","\tget(ctx context.Context, ref name.Reference, namespace, serviceAccountName string, imagePullSecrets []corev1.LocalObjectReference, hasArgs bool) (*imageData, error)","}","","// imageData contains information looked up about an image or multi-platform image index.","type imageData struct {","\tdigest   v1.Hash","\tcommands map[string][]string // map of platform -\u003e []command","}","","// resolveEntrypoints looks up container image ENTRYPOINTs for all steps that","// don't specify a Command.","//","// Images that are not specified by digest will be specified by digest after","// lookup in the resulting list of containers.","func resolveEntrypoints(ctx context.Context, cache EntrypointCache, namespace, serviceAccountName string, imagePullSecrets []corev1.LocalObjectReference, steps []corev1.Container) ([]corev1.Container, error) {","\t// Keep a local cache of name-\u003eimageData lookups, just for the scope of","\t// resolving this set of steps. If the image is pushed to before the","\t// next run, we need to resolve its digest and commands again, but we","\t// can skip lookups while resolving the same TaskRun.","\tlocalCache := map[name.Reference]imageData{}","\tfor i, s := range steps {","\t\t// If the command is already specified, there's nothing to resolve.","\t\tif len(s.Command) \u003e 0 {","\t\t\tcontinue","\t\t}","\t\thasArgs := len(s.Args) \u003e 0","","\t\tref, err := name.ParseReference(s.Image, name.WeakValidation)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tvar id imageData","\t\tif cid, found := localCache[ref]; found {","\t\t\tid = cid","\t\t} else {","\t\t\t// Look it up for real.","\t\t\tlid, err := cache.get(ctx, ref, namespace, serviceAccountName, imagePullSecrets, hasArgs)","\t\t\tif err != nil {","\t\t\t\treturn nil, err","\t\t\t}","\t\t\tid = *lid","","\t\t\t// Cache it locally in case another step in this task specifies the same image.","\t\t\tlocalCache[ref] = *lid","\t\t}","","\t\t// Resolve the original reference to a reference by digest.","\t\tsteps[i].Image = ref.Context().Digest(id.digest.String()).String()","","\t\t// Encode the map of platform-\u003ecommand to JSON and pass it via env var.","\t\tb, err := json.Marshal(id.commands)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tsteps[i].Env = append(steps[i].Env, corev1.EnvVar{","\t\t\tName:  \"TEKTON_PLATFORM_COMMANDS\",","\t\t\tValue: string(b),","\t\t})","\t}","\treturn steps, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,1,1,2,2,2,2,2,2,2,1,1,2,2,2,2,0,0,0,2,2,2,2,2,1,1,2,2,2,2,0,2,0]},{"id":166,"path":"pkg/pod/entrypoint_lookup_impl.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pod","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","","\t\"github.com/google/go-containerregistry/pkg/authn/k8schain\"","\t\"github.com/google/go-containerregistry/pkg/name\"","\tv1 \"github.com/google/go-containerregistry/pkg/v1\"","\t\"github.com/google/go-containerregistry/pkg/v1/remote\"","\tlru \"github.com/hashicorp/golang-lru\"","\t\"github.com/tektoncd/pipeline/pkg/platforms\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/client-go/kubernetes\"",")","","const cacheSize = 1024","","type entrypointCache struct {","\tkubeclient kubernetes.Interface","\tlru        *lru.Cache // cache of digest-\u003emap[string][]string commands","}","","// NewEntrypointCache returns a new entrypoint cache implementation that uses","// K8s credentials to pull image metadata from a container image registry.","func NewEntrypointCache(kubeclient kubernetes.Interface) (EntrypointCache, error) {","\tlru, err := lru.New(cacheSize)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn \u0026entrypointCache{","\t\tkubeclient: kubeclient,","\t\tlru:        lru,","\t}, nil","}","","// Get gets the image from the cache for the given ref, namespace, and SA.","//","// It also returns the digest associated with the given reference. If the","// reference referred to an index, the returned digest will be the index's","// digest, not any platform-specific image contained by the index.","func (e *entrypointCache) get(ctx context.Context, ref name.Reference, namespace, serviceAccountName string, imagePullSecrets []corev1.LocalObjectReference, hasArgs bool) (*imageData, error) {","\t// If image is specified by digest, check the local cache.","\tif digest, ok := ref.(name.Digest); ok {","\t\tif id, ok := e.lru.Get(digest.String()); ok {","\t\t\treturn id.(*imageData), nil","\t\t}","\t}","","\tpullSecretsNames := make([]string, 0, len(imagePullSecrets))","\tfor _, ps := range imagePullSecrets {","\t\tpullSecretsNames = append(pullSecretsNames, ps.Name)","\t}","\t// Consult the remote registry, using imagePullSecrets.","\tkc, err := k8schain.New(ctx, e.kubeclient, k8schain.Options{","\t\tNamespace:          namespace,","\t\tServiceAccountName: serviceAccountName,","\t\tImagePullSecrets:   pullSecretsNames,","\t})","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"error creating k8schain: %w\", err)","\t}","","\tdesc, err := remote.Get(ref, remote.WithAuthFromKeychain(kc))","\tif err != nil {","\t\treturn nil, err","\t}","","\t// Check the cache for this ref@digest, in case we've seen it before.","\t// This saves looking up each constinuent image's commands if we've seen","\t// the multi-platform image before.","\trefByDigest := ref.Context().Digest(desc.Digest.String()).String()","\tif id, ok := e.lru.Get(refByDigest); ok {","\t\treturn id.(*imageData), nil","\t}","","\tid := \u0026imageData{","\t\tdigest:   desc.Digest,","\t\tcommands: map[string][]string{},","\t}","\tswitch {","\tcase desc.MediaType.IsImage():","\t\timg, err := desc.Image()","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tep, plat, err := imageInfo(img, hasArgs)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tid.commands[plat] = ep","\tcase desc.MediaType.IsIndex():","\t\tidx, err := desc.ImageIndex()","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tid.commands, err = buildCommandMap(idx, hasArgs)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\tdefault:","\t\treturn nil, errors.New(\"unsupported media type for image reference\")","\t}","","\t// Cache the digest-\u003ecommands for future lookup.","\te.lru.Add(refByDigest, id)","","\treturn id, nil","}","","func buildCommandMap(idx v1.ImageIndex, hasArgs bool) (map[string][]string, error) {","\t// Map platform strings to digest, to handle some ~malformed images","\t// that specify the same manifest multiple times.","\tplatToDigest := map[string]v1.Hash{}","","\tcmds := map[string][]string{}","","\tmf, err := idx.IndexManifest()","\tif err != nil {","\t\treturn nil, err","\t}","\tfor _, desc := range mf.Manifests {","\t\tplat := desc.Platform.String()","\t\t// skip unknown platforms.","\t\t// Docker uses these to store attestation data: https://docs.docker.com/build/attestations/attestation-storage/#examples","\t\tif plat == \"unknown/unknown\" {","\t\t\tcontinue","\t\t}","\t\tif got, found := platToDigest[plat]; found \u0026\u0026 got != desc.Digest {","\t\t\treturn nil, fmt.Errorf(\"duplicate unique image found for platform: %s: found %s and %s\", plat, got, desc.Digest)","\t\t}","\t\tplatToDigest[plat] = desc.Digest","\t\timg, err := idx.Image(desc.Digest)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tcmds[plat], _, err = imageInfo(img, hasArgs)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t}","\treturn cmds, nil","}","","func imageInfo(img v1.Image, hasArgs bool) (cmd []string, platform string, err error) {","\tcf, err := img.ConfigFile()","\tif err != nil {","\t\treturn nil, \"\", err","\t}","","\tep := cf.Config.Entrypoint","\tif len(ep) == 0 {","\t\tep = cf.Config.Cmd","\t} else if !hasArgs {","\t\t// If no args, join Cmd to Entrypoint","\t\tep = append(ep, cf.Config.Cmd...)","\t}","","\tplatformObj := platforms.NewPlatform()","\tplatformObj.OS = cf.OS","\tplatformObj.Architecture = cf.Architecture","\t// A single image's config metadata doesn't include the CPU","\t// architecture variant, but we'll assume this is okay since","\t// the runtime node's image selection will also select the same","\t// image. This will only be a problem if the image is a","\t// single-platform image that happens to specify a variant, and","\t// the runtime node it gets assigned to has a value for","\t// runtime.GOARM.","\tplatform = platformObj.Format()","","\treturn ep, platform, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,1,1,2,2,2,2,0,0,0,0,0,0,0,2,2,2,2,1,1,0,0,2,2,2,2,0,2,2,2,2,2,2,1,1,0,2,2,2,2,0,0,0,0,2,2,1,1,0,2,2,2,2,2,2,2,2,1,1,2,2,1,1,2,1,1,1,1,1,1,1,1,1,1,1,0,0,0,2,2,2,0,0,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,0,2,2,2,2,2,2,1,1,2,2,1,1,0,2,0,0,2,2,2,1,1,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0]},{"id":167,"path":"pkg/pod/pod.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pod","","import (","\t\"context\"","\t\"encoding/json\"","\t\"fmt\"","\t\"log\"","\t\"math\"","\t\"path/filepath\"","\t\"strconv\"","\t\"strings\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/internal/artifactref\"","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/pod\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/internal/computeresources/tasklevel\"","\t\"github.com/tektoncd/pipeline/pkg/names\"","\ttknreconciler \"github.com/tektoncd/pipeline/pkg/reconciler\"","\t\"github.com/tektoncd/pipeline/pkg/spire\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"","\t\"k8s.io/apimachinery/pkg/version\"","\t\"k8s.io/client-go/kubernetes\"","\t\"k8s.io/utils/strings/slices\"","\t\"knative.dev/pkg/changeset\"","\t\"knative.dev/pkg/kmap\"","\t\"knative.dev/pkg/kmeta\"",")","","const (","\t// TektonHermeticEnvVar is the env var we set in containers to indicate they should be run hermetically","\tTektonHermeticEnvVar = \"TEKTON_HERMETIC\"","","\t// ExecutionModeAnnotation is an experimental optional annotation to set the execution mode on a TaskRun","\tExecutionModeAnnotation = \"experimental.tekton.dev/execution-mode\"","","\t// ExecutionModeHermetic indicates hermetic execution mode","\tExecutionModeHermetic = \"hermetic\"","","\t// deadlineFactor is the factor we multiply the taskrun timeout with to determine the activeDeadlineSeconds of the Pod.","\t// It has to be higher than the timeout (to not be killed before)","\tdeadlineFactor = 1.5","","\t// SpiffeCsiDriver is the CSI storage plugin needed for injection of SPIFFE workload api.","\tSpiffeCsiDriver = \"csi.spiffe.io\"","","\t// OsSelectorLabel is the label Kubernetes uses for OS-specific workloads (https://kubernetes.io/docs/reference/labels-annotations-taints/#kubernetes-io-os)","\tOsSelectorLabel = \"kubernetes.io/os\"","","\t// TerminationReasonTimeoutExceeded indicates a step execution timed out.","\tTerminationReasonTimeoutExceeded = \"TimeoutExceeded\"","","\t// TerminationReasonSkipped indicates a step execution was skipped due to previous step failed.","\tTerminationReasonSkipped = \"Skipped\"","","\t// TerminationReasonContinued indicates a step errored but was ignored since onError was set to continue.","\tTerminationReasonContinued = \"Continued\"","","\t// TerminationReasonCancelled indicates a step was cancelled.","\tTerminationReasonCancelled = \"Cancelled\"","","\tStepArtifactPathPattern = \"step.artifacts.path\"","","\t// K8s version to determine if to use native k8s sidecar or Tekton sidecar","\tSidecarK8sMinorVersionCheck = 29",")","","// These are effectively const, but Go doesn't have such an annotation.","var (","\tReleaseAnnotation = \"pipeline.tekton.dev/release\"","","\tgroupVersionKind = schema.GroupVersionKind{","\t\tGroup:   v1.SchemeGroupVersion.Group,","\t\tVersion: v1.SchemeGroupVersion.Version,","\t\tKind:    \"TaskRun\",","\t}","\t// These are injected into all of the source/step containers.","\timplicitVolumeMounts = []corev1.VolumeMount{{","\t\tName:      \"tekton-internal-workspace\",","\t\tMountPath: pipeline.WorkspaceDir,","\t}, {","\t\tName:      \"tekton-internal-home\",","\t\tMountPath: pipeline.HomeDir,","\t}, {","\t\tName:      \"tekton-internal-results\",","\t\tMountPath: pipeline.DefaultResultPath,","\t}, {","\t\tName:      \"tekton-internal-steps\",","\t\tMountPath: pipeline.StepsDir,","\t\tReadOnly:  true,","\t}, {","\t\tName:      \"tekton-internal-artifacts\",","\t\tMountPath: pipeline.ArtifactsDir,","\t}}","\timplicitVolumes = []corev1.Volume{{","\t\tName:         \"tekton-internal-workspace\",","\t\tVolumeSource: corev1.VolumeSource{EmptyDir: \u0026corev1.EmptyDirVolumeSource{}},","\t}, {","\t\tName:         \"tekton-internal-home\",","\t\tVolumeSource: corev1.VolumeSource{EmptyDir: \u0026corev1.EmptyDirVolumeSource{}},","\t}, {","\t\tName:         \"tekton-internal-results\",","\t\tVolumeSource: corev1.VolumeSource{EmptyDir: \u0026corev1.EmptyDirVolumeSource{}},","\t}, {","\t\tName:         \"tekton-internal-steps\",","\t\tVolumeSource: corev1.VolumeSource{EmptyDir: \u0026corev1.EmptyDirVolumeSource{}},","\t}, {","\t\tName:         \"tekton-internal-artifacts\",","\t\tVolumeSource: corev1.VolumeSource{EmptyDir: \u0026corev1.EmptyDirVolumeSource{}},","\t}}","","\t// MaxActiveDeadlineSeconds is a maximum permitted value to be used for a task with no timeout","\tMaxActiveDeadlineSeconds = int64(math.MaxInt32)",")","","// Builder exposes options to configure Pod construction from TaskSpecs/Runs.","type Builder struct {","\tImages          pipeline.Images","\tKubeClient      kubernetes.Interface","\tEntrypointCache EntrypointCache","}","","// Transformer is a function that will transform a Pod. This can be used to mutate","// a Pod generated by Tekton after it got generated.","type Transformer func(*corev1.Pod) (*corev1.Pod, error)","","// Build creates a Pod using the configuration options set on b and the TaskRun","// and TaskSpec provided in its arguments. An error is returned if there are","// any problems during the conversion.","func (b *Builder) Build(ctx context.Context, taskRun *v1.TaskRun, taskSpec v1.TaskSpec, transformers ...Transformer) (*corev1.Pod, error) {","\tvar (","\t\tscriptsInit                                       *corev1.Container","\t\tinitContainers, stepContainers, sidecarContainers []corev1.Container","\t\tvolumes                                           []corev1.Volume","\t)","\tvolumeMounts := []corev1.VolumeMount{binROMount}","\timplicitEnvVars := []corev1.EnvVar{}","\tfeatureFlags := config.FromContextOrDefaults(ctx).FeatureFlags","\tdefaultForbiddenEnv := config.FromContextOrDefaults(ctx).Defaults.DefaultForbiddenEnv","\talphaAPIEnabled := featureFlags.EnableAPIFields == config.AlphaAPIFields","\tsidecarLogsResultsEnabled := config.FromContextOrDefaults(ctx).FeatureFlags.ResultExtractionMethod == config.ResultExtractionMethodSidecarLogs","\tenableKeepPodOnCancel := featureFlags.EnableKeepPodOnCancel","\tsetSecurityContext := config.FromContextOrDefaults(ctx).FeatureFlags.SetSecurityContext","\tsetSecurityContextReadOnlyRootFilesystem := config.FromContextOrDefaults(ctx).FeatureFlags.SetSecurityContextReadOnlyRootFilesystem","\tdefaultManagedByLabelValue := config.FromContextOrDefaults(ctx).Defaults.DefaultManagedByLabelValue","","\t// Add our implicit volumes first, so they can be overridden by the user if they prefer.","\tvolumes = append(volumes, implicitVolumes...)","\tvolumeMounts = append(volumeMounts, implicitVolumeMounts...)","","\t// Create Volumes and VolumeMounts for any credentials found in annotated","\t// Secrets, along with any arguments needed by Step entrypoints to process","\t// those secrets.","\tcommonExtraEntrypointArgs := []string{}","\t// Entrypoint arg to enable or disable spire","\tif config.IsSpireEnabled(ctx) {","\t\tcommonExtraEntrypointArgs = append(commonExtraEntrypointArgs, \"-enable_spire\")","\t}","\tcredEntrypointArgs, credVolumes, credVolumeMounts, err := credsInit(ctx, taskRun, taskRun.Spec.ServiceAccountName, taskRun.Namespace, b.KubeClient)","\tif err != nil {","\t\treturn nil, err","\t}","\tcommonExtraEntrypointArgs = append(commonExtraEntrypointArgs, credEntrypointArgs...)","\tvolumes = append(volumes, credVolumes...)","\tvolumeMounts = append(volumeMounts, credVolumeMounts...)","","\t// Merge step template with steps.","\t// TODO(#1605): Move MergeSteps to pkg/pod","\tsteps, err := v1.MergeStepsWithStepTemplate(taskSpec.StepTemplate, taskSpec.Steps)","\tif err != nil {","\t\treturn nil, err","\t}","\tsteps, err = v1.MergeStepsWithSpecs(steps, taskRun.Spec.StepSpecs)","\tif err != nil {","\t\treturn nil, err","\t}","\tif taskRun.Spec.ComputeResources != nil {","\t\ttasklevel.ApplyTaskLevelComputeResources(steps, taskRun.Spec.ComputeResources)","\t}","","\tsecurityContextConfig := SecurityContextConfig{","\t\tSetSecurityContext:        setSecurityContext,","\t\tSetReadOnlyRootFilesystem: setSecurityContextReadOnlyRootFilesystem,","\t}","","\twindows := usesWindows(taskRun)","\tpollingInterval := config.FromContextOrDefaults(ctx).Defaults.DefaultSidecarLogPollingInterval","\tif sidecarLogsResultsEnabled {","\t\tif taskSpec.Results != nil || artifactsPathReferenced(steps) {","\t\t\t// create a results sidecar","\t\t\tresultsSidecar, err := createResultsSidecar(taskSpec, b.Images.SidecarLogResultsImage, securityContextConfig, windows, pollingInterval)","\t\t\tif err != nil {","\t\t\t\treturn nil, err","\t\t\t}","\t\t\ttaskSpec.Sidecars = append(taskSpec.Sidecars, resultsSidecar)","\t\t\tcommonExtraEntrypointArgs = append(commonExtraEntrypointArgs, \"-result_from\", config.ResultExtractionMethodSidecarLogs)","\t\t}","\t}","","\tsidecars, err := v1.MergeSidecarsWithSpecs(taskSpec.Sidecars, taskRun.Spec.SidecarSpecs)","\tif err != nil {","\t\treturn nil, err","\t}","","\tinitContainers = []corev1.Container{","\t\tentrypointInitContainer(b.Images.EntrypointImage, steps, securityContextConfig, windows),","\t}","","\t// Convert any steps with Script to command+args.","\t// If any are found, append an init container to initialize scripts.","\tif alphaAPIEnabled {","\t\tscriptsInit, stepContainers, sidecarContainers = convertScripts(b.Images.ShellImage, b.Images.ShellImageWin, steps, sidecars, taskRun.Spec.Debug, securityContextConfig)","\t} else {","\t\tscriptsInit, stepContainers, sidecarContainers = convertScripts(b.Images.ShellImage, \"\", steps, sidecars, nil, securityContextConfig)","\t}","","\tif scriptsInit != nil {","\t\tinitContainers = append(initContainers, *scriptsInit)","\t\tvolumes = append(volumes, scriptsVolume)","\t}","\tif alphaAPIEnabled \u0026\u0026 taskRun.Spec.Debug != nil \u0026\u0026 taskRun.Spec.Debug.NeedsDebug() {","\t\tvolumes = append(volumes, debugScriptsVolume, debugInfoVolume)","\t}","\t// Initialize any workingDirs under /workspace.","\tif workingDirInit := workingDirInit(b.Images.WorkingDirInitImage, stepContainers, securityContextConfig, windows); workingDirInit != nil {","\t\tinitContainers = append(initContainers, *workingDirInit)","\t}","","\t// By default, use an empty pod template and take the one defined in the task run spec if any","\tpodTemplate := pod.Template{}","","\tif taskRun.Spec.PodTemplate != nil {","\t\tpodTemplate = *taskRun.Spec.PodTemplate","\t}","","\t// Resolve entrypoint for any steps that don't specify command.","\tstepContainers, err = resolveEntrypoints(ctx, b.EntrypointCache, taskRun.Namespace, taskRun.Spec.ServiceAccountName, podTemplate.ImagePullSecrets, stepContainers)","\tif err != nil {","\t\treturn nil, err","\t}","","\treadyImmediately := isPodReadyImmediately(*featureFlags, taskSpec.Sidecars)","","\tif alphaAPIEnabled {","\t\tstepContainers, err = orderContainers(ctx, commonExtraEntrypointArgs, stepContainers, \u0026taskSpec, taskRun.Spec.Debug, !readyImmediately, enableKeepPodOnCancel)","\t} else {","\t\tstepContainers, err = orderContainers(ctx, commonExtraEntrypointArgs, stepContainers, \u0026taskSpec, nil, !readyImmediately, enableKeepPodOnCancel)","\t}","\tif err != nil {","\t\treturn nil, err","\t}","\tvolumes = append(volumes, binVolume)","\tif !readyImmediately || enableKeepPodOnCancel {","\t\tdownwardVolumeDup := downwardVolume.DeepCopy()","\t\tif enableKeepPodOnCancel {","\t\t\tdownwardVolumeDup.VolumeSource.DownwardAPI.Items = append(downwardVolumeDup.VolumeSource.DownwardAPI.Items, downwardCancelVolumeItem)","\t\t}","\t\tvolumes = append(volumes, *downwardVolumeDup)","\t}","","\t// Order of precedence for envs","\t// implicit env vars","\t// Superceded by step env vars","\t// Superceded by config-default default-pod-template envs","\t// Superceded by podTemplate envs","\tif len(implicitEnvVars) \u003e 0 {","\t\tfor i, s := range stepContainers {","\t\t\tenv := append(implicitEnvVars, s.Env...) //nolint:gocritic","\t\t\tstepContainers[i].Env = env","\t\t}","\t}","\tfilteredEnvs := []corev1.EnvVar{}","\tfor _, e := range podTemplate.Env {","\t\tif !slices.Contains(defaultForbiddenEnv, e.Name) {","\t\t\tfilteredEnvs = append(filteredEnvs, e)","\t\t}","\t}","\tif len(podTemplate.Env) \u003e 0 {","\t\tfor i, s := range stepContainers {","\t\t\tenv := append(s.Env, filteredEnvs...) //nolint:gocritic","\t\t\tstepContainers[i].Env = env","\t\t}","\t}","\t// Add env var if hermetic execution was requested \u0026 if the alpha API is enabled","\tif taskRun.Annotations[ExecutionModeAnnotation] == ExecutionModeHermetic \u0026\u0026 alphaAPIEnabled {","\t\tfor i, s := range stepContainers {","\t\t\t// Add it at the end so it overrides","\t\t\tenv := append(s.Env, corev1.EnvVar{Name: TektonHermeticEnvVar, Value: \"1\"}) //nolint:gocritic","\t\t\tstepContainers[i].Env = env","\t\t}","\t}","","\t// Add implicit volume mounts to each step, unless the step specifies","\t// its own volume mount at that path.","\tfor i, s := range stepContainers {","\t\t// Mount /tekton/creds with a fresh volume for each Step. It needs to","\t\t// be world-writeable and empty so creds can be initialized in there. Cant","\t\t// guarantee what UID container runs with. If legacy credential helper (creds-init)","\t\t// is disabled via feature flag then these can be nil since we don't want to mount","\t\t// the automatic credential volume.","\t\tv, vm := getCredsInitVolume(ctx, i)","\t\tif v != nil \u0026\u0026 vm != nil {","\t\t\tvolumes = append(volumes, *v)","\t\t\ts.VolumeMounts = append(s.VolumeMounts, *vm)","\t\t}","","\t\t// Add /tekton/run state volumes.","\t\t// Each step should only mount their own volume as RW,","\t\t// all other steps should be mounted RO.","\t\tvolumes = append(volumes, runVolume(i))","\t\tfor j := range stepContainers {","\t\t\ts.VolumeMounts = append(s.VolumeMounts, runMount(j, i != j))","\t\t}","","\t\trequestedVolumeMounts := map[string]bool{}","\t\tfor _, vm := range s.VolumeMounts {","\t\t\trequestedVolumeMounts[filepath.Clean(vm.MountPath)] = true","\t\t}","\t\tvar toAdd []corev1.VolumeMount","\t\tfor _, imp := range volumeMounts {","\t\t\tif !requestedVolumeMounts[filepath.Clean(imp.MountPath)] {","\t\t\t\ttoAdd = append(toAdd, imp)","\t\t\t}","\t\t}","\t\tvms := append(s.VolumeMounts, toAdd...) //nolint:gocritic","\t\tstepContainers[i].VolumeMounts = vms","\t}","","\tif sidecarLogsResultsEnabled {","\t\t// Mount implicit volumes onto sidecarContainers","\t\t// so that they can access /tekton/results and /tekton/run.","\t\tif taskSpec.Results != nil || artifactsPathReferenced(steps) {","\t\t\tfor i, s := range sidecarContainers {","\t\t\t\tif s.Name != pipeline.ReservedResultsSidecarName {","\t\t\t\t\tcontinue","\t\t\t\t}","\t\t\t\tfor j := range stepContainers {","\t\t\t\t\ts.VolumeMounts = append(s.VolumeMounts, runMount(j, true))","\t\t\t\t}","\t\t\t\trequestedVolumeMounts := map[string]bool{}","\t\t\t\tfor _, vm := range s.VolumeMounts {","\t\t\t\t\trequestedVolumeMounts[filepath.Clean(vm.MountPath)] = true","\t\t\t\t}","\t\t\t\tvar toAdd []corev1.VolumeMount","\t\t\t\tfor _, imp := range volumeMounts {","\t\t\t\t\tif !requestedVolumeMounts[filepath.Clean(imp.MountPath)] {","\t\t\t\t\t\ttoAdd = append(toAdd, imp)","\t\t\t\t\t}","\t\t\t\t}","\t\t\t\tvms := append(s.VolumeMounts, toAdd...) //nolint:gocritic","\t\t\t\tsidecarContainers[i].VolumeMounts = vms","\t\t\t}","\t\t}","\t}","","\t// This loop:","\t// - sets container name to add \"step-\" prefix or \"step-unnamed-#\" if not specified.","\t// TODO(#1605): Remove this loop and make each transformation in","\t// isolation.","\tfor i, s := range stepContainers {","\t\tstepContainers[i].Name = names.SimpleNameGenerator.RestrictLength(StepName(s.Name, i))","\t}","","\t// Add podTemplate Volumes to the explicitly declared use volumes","\tvolumes = append(volumes, taskSpec.Volumes...)","\tvolumes = append(volumes, podTemplate.Volumes...)","","\tif err := v1.ValidateVolumes(volumes); err != nil {","\t\treturn nil, err","\t}","","\treadonly := true","\tif config.IsSpireEnabled(ctx) {","\t\t// add SPIRE's CSI volume to the explicitly declared use volumes","\t\tvolumes = append(volumes, corev1.Volume{","\t\t\tName: spire.WorkloadAPI,","\t\t\tVolumeSource: corev1.VolumeSource{","\t\t\t\tCSI: \u0026corev1.CSIVolumeSource{","\t\t\t\t\tDriver:   SpiffeCsiDriver,","\t\t\t\t\tReadOnly: \u0026readonly,","\t\t\t\t},","\t\t\t},","\t\t})","","\t\t// mount SPIRE's CSI volume to each Step Container","\t\tfor i := range stepContainers {","\t\t\tc := \u0026stepContainers[i]","\t\t\tc.VolumeMounts = append(c.VolumeMounts, corev1.VolumeMount{","\t\t\t\tName:      spire.WorkloadAPI,","\t\t\t\tMountPath: spire.VolumeMountPath,","\t\t\t\tReadOnly:  readonly,","\t\t\t})","\t\t}","\t\tfor i := range initContainers {","\t\t\t// mount SPIRE's CSI volume to each Init Container","\t\t\tc := \u0026initContainers[i]","\t\t\tc.VolumeMounts = append(c.VolumeMounts, corev1.VolumeMount{","\t\t\t\tName:      spire.WorkloadAPI,","\t\t\t\tMountPath: spire.VolumeMountPath,","\t\t\t\tReadOnly:  readonly,","\t\t\t})","\t\t}","\t}","","\tmergedPodContainers := stepContainers","\tmergedPodInitContainers := initContainers","","\tuseTektonSidecar := true","\tif config.FromContextOrDefaults(ctx).FeatureFlags.EnableKubernetesSidecar {","\t\t// Go through the logic for enable-kubernetes feature flag","\t\t// Kubernetes Version","\t\tdc := b.KubeClient.Discovery()","\t\tsv, err := dc.ServerVersion()","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tif IsNativeSidecarSupport(sv) {","\t\t\t// Add RestartPolicy and Merge into initContainer","\t\t\tuseTektonSidecar = false","\t\t\tfor i := range sidecarContainers {","\t\t\t\tsc := \u0026sidecarContainers[i]","\t\t\t\talways := corev1.ContainerRestartPolicyAlways","\t\t\t\tsc.RestartPolicy = \u0026always","","\t\t\t\t// For the results sidecar specifically, ensure it has the kubernetes-sidecar-mode flag","\t\t\t\t// to prevent it from exiting and restarting","\t\t\t\tif sc.Name == pipeline.ReservedResultsSidecarName {","\t\t\t\t\tkubernetesSidecarModeFound := false","\t\t\t\t\tfor j, arg := range sc.Command {","\t\t\t\t\t\tif arg == \"-kubernetes-sidecar-mode\" \u0026\u0026 j+1 \u003c len(sc.Command) {","\t\t\t\t\t\t\tkubernetesSidecarModeFound = true","\t\t\t\t\t\t\tbreak","\t\t\t\t\t\t}","\t\t\t\t\t}","\t\t\t\t\tif !kubernetesSidecarModeFound {","\t\t\t\t\t\tsc.Command = append(sc.Command, \"-kubernetes-sidecar-mode\", \"true\")","\t\t\t\t\t}","\t\t\t\t}","","\t\t\t\tsc.Name = names.SimpleNameGenerator.RestrictLength(fmt.Sprintf(\"%v%v\", sidecarPrefix, sc.Name))","\t\t\t\tmergedPodInitContainers = append(mergedPodInitContainers, *sc)","\t\t\t}","\t\t}","\t}","\tif useTektonSidecar {","\t\t// Merge sidecar containers with step containers.","\t\tfor _, sc := range sidecarContainers {","\t\t\tsc.Name = names.SimpleNameGenerator.RestrictLength(fmt.Sprintf(\"%v%v\", sidecarPrefix, sc.Name))","\t\t\tmergedPodContainers = append(mergedPodContainers, sc)","\t\t}","\t}","","\tvar dnsPolicy corev1.DNSPolicy","\tif podTemplate.DNSPolicy != nil {","\t\tdnsPolicy = *podTemplate.DNSPolicy","\t}","","\tvar priorityClassName string","\tif podTemplate.PriorityClassName != nil {","\t\tpriorityClassName = *podTemplate.PriorityClassName","\t}","","\tpodAnnotations := kmap.ExcludeKeys(kmeta.CopyMap(taskRun.Annotations), tknreconciler.KubernetesManagedByAnnotationKey)","\tpodAnnotations[ReleaseAnnotation] = changeset.Get()","","\tif readyImmediately {","\t\tpodAnnotations[readyAnnotation] = readyAnnotationValue","\t}","","\t// calculate the activeDeadlineSeconds based on the specified timeout (uses default timeout if it's not specified)","\tactiveDeadlineSeconds := int64(taskRun.GetTimeout(ctx).Seconds() * deadlineFactor)","\t// set activeDeadlineSeconds to the max. allowed value i.e. max int32 when timeout is explicitly set to 0","\tif taskRun.GetTimeout(ctx) == config.NoTimeoutDuration {","\t\tactiveDeadlineSeconds = MaxActiveDeadlineSeconds","\t}","","\tpodNameSuffix := \"-pod\"","\tif taskRunRetries := len(taskRun.Status.RetriesStatus); taskRunRetries \u003e 0 {","\t\tpodNameSuffix = fmt.Sprintf(\"%s-retry%d\", podNameSuffix, taskRunRetries)","\t}","\tnewPod := \u0026corev1.Pod{","\t\tObjectMeta: metav1.ObjectMeta{","\t\t\t// We execute the build's pod in the same namespace as where the build was","\t\t\t// created so that it can access colocated resources.","\t\t\tNamespace: taskRun.Namespace,","\t\t\t// Generate a unique name based on the build's name.","\t\t\t// The name is univocally generated so that in case of","\t\t\t// stale informer cache, we never create duplicate Pods","\t\t\tName: kmeta.ChildName(taskRun.Name, podNameSuffix),","\t\t\t// If our parent TaskRun is deleted, then we should be as well.","\t\t\tOwnerReferences: []metav1.OwnerReference{","\t\t\t\t*metav1.NewControllerRef(taskRun, groupVersionKind),","\t\t\t},","\t\t\tAnnotations: podAnnotations,","\t\t\tLabels:      makeLabels(taskRun, defaultManagedByLabelValue),","\t\t},","\t\tSpec: corev1.PodSpec{","\t\t\tRestartPolicy:                corev1.RestartPolicyNever,","\t\t\tInitContainers:               mergedPodInitContainers,","\t\t\tContainers:                   mergedPodContainers,","\t\t\tServiceAccountName:           taskRun.Spec.ServiceAccountName,","\t\t\tVolumes:                      volumes,","\t\t\tNodeSelector:                 podTemplate.NodeSelector,","\t\t\tTolerations:                  podTemplate.Tolerations,","\t\t\tAffinity:                     podTemplate.Affinity,","\t\t\tSecurityContext:              podTemplate.SecurityContext,","\t\t\tRuntimeClassName:             podTemplate.RuntimeClassName,","\t\t\tAutomountServiceAccountToken: podTemplate.AutomountServiceAccountToken,","\t\t\tSchedulerName:                podTemplate.SchedulerName,","\t\t\tHostNetwork:                  podTemplate.HostNetwork,","\t\t\tHostUsers:                    podTemplate.HostUsers,","\t\t\tDNSPolicy:                    dnsPolicy,","\t\t\tDNSConfig:                    podTemplate.DNSConfig,","\t\t\tEnableServiceLinks:           podTemplate.EnableServiceLinks,","\t\t\tPriorityClassName:            priorityClassName,","\t\t\tImagePullSecrets:             podTemplate.ImagePullSecrets,","\t\t\tHostAliases:                  podTemplate.HostAliases,","\t\t\tTopologySpreadConstraints:    podTemplate.TopologySpreadConstraints,","\t\t\tActiveDeadlineSeconds:        \u0026activeDeadlineSeconds, // Set ActiveDeadlineSeconds to mark the pod as \"terminating\" (like a Job)","\t\t},","\t}","","\tfor _, f := range transformers {","\t\tnewPod, err = f(newPod)","\t\tif err != nil {","\t\t\treturn newPod, err","\t\t}","\t}","","\treturn newPod, nil","}","","// makeLabels constructs the labels we will propagate from TaskRuns to Pods.","func makeLabels(s *v1.TaskRun, defaultManagedByLabelValue string) map[string]string {","\tlabels := make(map[string]string, len(s.ObjectMeta.Labels)+1)","\t// NB: Set this *before* passing through TaskRun labels. If the TaskRun","\t// has a managed-by label, it should override this default.","","\t// Copy through the TaskRun's labels to the underlying Pod's.","\tfor k, v := range s.ObjectMeta.Labels {","\t\tlabels[k] = v","\t}","","\t// NB: Set this *after* passing through TaskRun Labels. If the TaskRun","\t// specifies this label, it should be overridden by this value.","\tlabels[pipeline.TaskRunLabelKey] = s.Name","\tlabels[pipeline.TaskRunUIDLabelKey] = string(s.UID)","\t// Enforce app.kubernetes.io/managed-by to be the value configured","\tlabels[tknreconciler.KubernetesManagedByAnnotationKey] = defaultManagedByLabelValue","\treturn labels","}","","// isPodReadyImmediately returns a bool indicating whether the","// controller should consider the Pod \"Ready\" as soon as it's deployed.","// This will add the `Ready` annotation when creating the Pod,","// and prevent the first step from waiting for the annotation to appear before starting.","func isPodReadyImmediately(featureFlags config.FeatureFlags, sidecars []v1.Sidecar) bool {","\t// If the TaskRun has sidecars, we must wait for them","\tif len(sidecars) \u003e 0 || featureFlags.RunningInEnvWithInjectedSidecars {","\t\tif featureFlags.AwaitSidecarReadiness {","\t\t\treturn false","\t\t}","\t\tlog.Printf(\"warning: not waiting for sidecars before starting first Step of Task pod\")","\t}","\treturn true","}","","func runMount(i int, ro bool) corev1.VolumeMount {","\treturn corev1.VolumeMount{","\t\tName:      fmt.Sprintf(\"%s-%d\", runVolumeName, i),","\t\tMountPath: filepath.Join(RunDir, strconv.Itoa(i)),","\t\tReadOnly:  ro,","\t}","}","","func runVolume(i int) corev1.Volume {","\treturn corev1.Volume{","\t\tName:         fmt.Sprintf(\"%s-%d\", runVolumeName, i),","\t\tVolumeSource: corev1.VolumeSource{EmptyDir: \u0026corev1.EmptyDirVolumeSource{}},","\t}","}","","// entrypointInitContainer generates a few init containers based of a set of command (in images), volumes to run, and whether the pod will run on a windows node","// This should effectively merge multiple command and volumes together.","// If setSecurityContext is true, the init container will include a security context","// allowing it to run in namespaces with restriced pod security admission.","func entrypointInitContainer(image string, steps []v1.Step, securityContext SecurityContextConfig, windows bool) corev1.Container {","\t// Invoke the entrypoint binary in \"cp mode\" to copy itself","\t// into the correct location for later steps and initialize steps folder","\tcommand := []string{\"/ko-app/entrypoint\", \"init\", \"/ko-app/entrypoint\", entrypointBinary}","\tfor i, s := range steps {","\t\tcommand = append(command, StepName(s.Name, i))","\t}","\tvolumeMounts := []corev1.VolumeMount{binMount, internalStepsMount}","","\t// Rewrite steps with entrypoint binary. Append the entrypoint init","\t// container to place the entrypoint binary. Also add timeout flags","\t// to entrypoint binary.","\tprepareInitContainer := corev1.Container{","\t\tName:  \"prepare\",","\t\tImage: image,","\t\t// Rewrite default WorkingDir from \"/home/nonroot\" to \"/\"","\t\t// as suggested at https://github.com/GoogleContainerTools/distroless/issues/718","\t\t// to avoid permission errors with nonroot users not equal to `65532`","\t\tWorkingDir:   \"/\",","\t\tCommand:      command,","\t\tVolumeMounts: volumeMounts,","\t}","\tif securityContext.SetSecurityContext {","\t\tprepareInitContainer.SecurityContext = securityContext.GetSecurityContext(windows)","\t}","\treturn prepareInitContainer","}","","// createResultsSidecar creates a sidecar that will run the sidecarlogresults binary,","// based on the spec of the Task, the image that should run in the results sidecar,","// whether it will run on a windows node, and whether the sidecar should include a security context","// that will allow it to run in namespaces with \"restricted\" pod security admission.","// It will also provide arguments to the binary that allow it to surface the step results.","func createResultsSidecar(taskSpec v1.TaskSpec, image string, securityContext SecurityContextConfig, windows bool, pollingInterval time.Duration) (v1.Sidecar, error) {","\tnames := make([]string, 0, len(taskSpec.Results))","\tfor _, r := range taskSpec.Results {","\t\tnames = append(names, r.Name)","\t}","","\tstepNames := make([]string, 0, len(taskSpec.Steps))","\tvar artifactProducerSteps []string","\tfor i, s := range taskSpec.Steps {","\t\tstepName := StepName(s.Name, i)","\t\tstepNames = append(stepNames, stepName)","\t\tif artifactPathReferencedInStep(s) {","\t\t\tartifactProducerSteps = append(artifactProducerSteps, GetContainerName(s.Name))","\t\t}","\t}","","\tresultsStr := strings.Join(names, \",\")","\tcommand := []string{\"/ko-app/sidecarlogresults\", \"-results-dir\", pipeline.DefaultResultPath, \"-result-names\", resultsStr, \"-step-names\", strings.Join(artifactProducerSteps, \",\")}","","\t// create a map of container Name to step results","\tstepResults := map[string][]string{}","\tfor i, s := range taskSpec.Steps {","\t\tif len(s.Results) \u003e 0 {","\t\t\tstepName := StepName(s.Name, i)","\t\t\tstepResults[stepName] = make([]string, 0, len(s.Results))","\t\t\tfor _, r := range s.Results {","\t\t\t\tstepResults[stepName] = append(stepResults[stepName], r.Name)","\t\t\t}","\t\t}","\t}","","\tstepResultsBytes, err := json.Marshal(stepResults)","\tif err != nil {","\t\treturn v1.Sidecar{}, err","\t}","\tif len(stepResultsBytes) \u003e 0 {","\t\tcommand = append(command, \"-step-results\", string(stepResultsBytes))","\t}","","\t// When using Kubernetes native sidecar support, add the kubernetes-sidecar-mode flag","\t// to prevent the sidecar from exiting after processing results","\tif config.FromContextOrDefaults(context.Background()).FeatureFlags.EnableKubernetesSidecar {","\t\tcommand = append(command, \"-kubernetes-sidecar-mode\", \"true\")","\t}","","\tsidecar := v1.Sidecar{","\t\tName:    pipeline.ReservedResultsSidecarName,","\t\tImage:   image,","\t\tCommand: command,","\t\tEnv: []corev1.EnvVar{","\t\t\t{","\t\t\t\tName:  \"SIDECAR_LOG_POLLING_INTERVAL\",","\t\t\t\tValue: pollingInterval.String(),","\t\t\t},","\t\t},","\t}","","\tif securityContext.SetSecurityContext {","\t\tsidecar.SecurityContext = securityContext.GetSecurityContext(windows)","\t}","","\treturn sidecar, nil","}","","// usesWindows returns true if the TaskRun will run on a windows node,","// based on its node selector.","// See https://kubernetes.io/docs/concepts/windows/user-guide/ for more info.","func usesWindows(tr *v1.TaskRun) bool {","\tif tr.Spec.PodTemplate == nil || tr.Spec.PodTemplate.NodeSelector == nil {","\t\treturn false","\t}","\tosSelector := tr.Spec.PodTemplate.NodeSelector[OsSelectorLabel]","\treturn osSelector == \"windows\"","}","","func artifactsPathReferenced(steps []v1.Step) bool {","\tfor _, step := range steps {","\t\tif artifactPathReferencedInStep(step) {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","func artifactPathReferencedInStep(step v1.Step) bool {","\t// `$(step.artifacts.path)` in  taskRun.Spec.TaskSpec.Steps and `taskSpec.steps` are substituted when building the pod while when setting status for taskRun","\t// neither of them is substituted, so we need two forms to check if artifactsPath is referenced in steps.","\tunresolvedPath := \"$(\" + artifactref.StepArtifactPathPattern + \")\"","","\tpath := filepath.Join(pipeline.StepsDir, GetContainerName(step.Name), \"artifacts\", \"provenance.json\")","\tif strings.Contains(step.Script, path) || strings.Contains(step.Script, unresolvedPath) {","\t\treturn true","\t}","\tfor _, arg := range step.Args {","\t\tif strings.Contains(arg, path) || strings.Contains(arg, unresolvedPath) {","\t\t\treturn true","\t\t}","\t}","\tfor _, c := range step.Command {","\t\tif strings.Contains(c, path) || strings.Contains(c, unresolvedPath) {","\t\t\treturn true","\t\t}","\t}","\tfor _, e := range step.Env {","\t\tif strings.Contains(e.Value, path) || strings.Contains(e.Value, unresolvedPath) {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// isNativeSidecarSupport returns true if k8s api has native sidecar support","// based on the k8s version (1.29+).","// See https://kubernetes.io/docs/concepts/workloads/pods/sidecar-containers/ for more info.","func IsNativeSidecarSupport(serverVersion *version.Info) bool {","\tminor := strings.TrimSuffix(serverVersion.Minor, \"+\") // Remove '+' if present","\tmajorInt, _ := strconv.Atoi(serverVersion.Major)","\tminorInt, _ := strconv.Atoi(minor)","\tif (majorInt == 1 \u0026\u0026 minorInt \u003e= SidecarK8sMinorVersionCheck) || majorInt \u003e 1 {","\t\treturn true","\t}","\treturn false","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,1,1,2,2,1,1,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,0,0,0,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,0,0,2,2,2,2,2,0,0,2,2,1,1,0,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,0,0,0,0,0,0,0,2,1,1,1,1,0,2,2,2,2,2,0,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,0,2,2,2,2,2,2,2,2,2,0,2,2,0,0,2,2,2,2,2,2,1,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,0,0,0,0,0,0,0,0,2,2,2,0,0,2,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,0,2,2,2,0,0,2,2,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,0,2,2,2,2,0,2,2,2,2,2,2,0,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,0,0,0,0,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,1,1,2,2,2,0,0,0,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,2,2,2,2,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,0]},{"id":168,"path":"pkg/pod/script.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pod","","import (","\t\"encoding/base64\"","\t\"fmt\"","\t\"path/filepath\"","\t\"strconv\"","\t\"strings\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/names\"","\tcorev1 \"k8s.io/api/core/v1\"",")","","const (","\tscriptsVolumeName      = \"tekton-internal-scripts\"","\tdebugScriptsVolumeName = \"tekton-internal-debug-scripts\"","\tdebugInfoVolumeName    = \"tekton-internal-debug-info\"","\tscriptsDir             = \"/tekton/scripts\"","\tdebugScriptsDir        = \"/tekton/debug/scripts\"","\tdefaultScriptPreamble  = \"#!/bin/sh\\nset -e\\n\"","\tdebugInfoDir           = \"/tekton/debug/info\"",")","","var (","\t// Volume definition attached to Pods generated from TaskRuns that have","\t// steps that specify a Script.","\tscriptsVolume = corev1.Volume{","\t\tName:         scriptsVolumeName,","\t\tVolumeSource: corev1.VolumeSource{EmptyDir: \u0026corev1.EmptyDirVolumeSource{}},","\t}","\tscriptsVolumeMount = corev1.VolumeMount{","\t\tName:      scriptsVolumeName,","\t\tMountPath: scriptsDir,","\t\tReadOnly:  true,","\t}","\twriteScriptsVolumeMount = corev1.VolumeMount{","\t\tName:      scriptsVolumeName,","\t\tMountPath: scriptsDir,","\t\tReadOnly:  false,","\t}","\tdebugScriptsVolume = corev1.Volume{","\t\tName:         debugScriptsVolumeName,","\t\tVolumeSource: corev1.VolumeSource{EmptyDir: \u0026corev1.EmptyDirVolumeSource{}},","\t}","\tdebugScriptsVolumeMount = corev1.VolumeMount{","\t\tName:      debugScriptsVolumeName,","\t\tMountPath: debugScriptsDir,","\t}","\tdebugInfoVolume = corev1.Volume{","\t\tName:         debugInfoVolumeName,","\t\tVolumeSource: corev1.VolumeSource{EmptyDir: \u0026corev1.EmptyDirVolumeSource{}},","\t}",")","","// convertScripts creates an init container that mounts any Scripts specified by","// the input Steps and Sidecars. It returns the init container, plus two slices of Containers","// representing the Steps and Sidecars, respectively, that use the scripts from the init container.","// Other inputs:","//   - shellImageLinux and shellImageWindows: the images that should be used by the init container,","//     depending on the OS the Task will run on","//   - debugConfig: the TaskRun's debug configuration","//   - setSecurityContext: whether the init container should include a security context that will","//     allow it to run in a namespace with \"restricted\" pod security admission","func convertScripts(shellImageLinux string, shellImageWin string, steps []v1.Step, sidecars []v1.Sidecar, debugConfig *v1.TaskRunDebug, securityContext SecurityContextConfig) (*corev1.Container, []corev1.Container, []corev1.Container) {","\t// Place scripts is an init container used for creating scripts in the","\t// /tekton/scripts directory which would be later used by the step containers","\t// as a Command","\trequiresWindows := checkWindowsRequirement(steps, sidecars)","","\tshellImage := shellImageLinux","\tshellCommand := \"sh\"","\tshellArg := \"-c\"","","\t// Set windows variants for Image, Command and Args","\tif requiresWindows {","\t\tshellImage = shellImageWin","\t\tshellCommand = \"pwsh\"","\t\tshellArg = \"-Command\"","\t}","","\tplaceScriptsInit := corev1.Container{","\t\tName:         \"place-scripts\",","\t\tImage:        shellImage,","\t\tCommand:      []string{shellCommand},","\t\tArgs:         []string{shellArg, \"\"},","\t\tVolumeMounts: []corev1.VolumeMount{writeScriptsVolumeMount, binMount},","\t}","","\tif securityContext.SetSecurityContext {","\t\tplaceScriptsInit.SecurityContext = securityContext.GetSecurityContext(requiresWindows)","\t}","","\t// Add mounts for debug","\tif debugConfig != nil \u0026\u0026 debugConfig.NeedsDebug() {","\t\tplaceScriptsInit.VolumeMounts = append(placeScriptsInit.VolumeMounts, debugScriptsVolumeMount)","\t}","","\tconvertedStepContainers := convertListOfSteps(steps, \u0026placeScriptsInit, debugConfig, \"script\")","\tsidecarContainers := convertListOfSidecars(sidecars, \u0026placeScriptsInit, \"sidecar-script\")","","\tif hasScripts(steps, sidecars, debugConfig) {","\t\treturn \u0026placeScriptsInit, convertedStepContainers, sidecarContainers","\t}","\treturn nil, convertedStepContainers, sidecarContainers","}","","// convertListOfSidecars iterates through the list of sidecars, generates the script file name and heredoc termination string,","// adds an entry to the init container args, sets up the step container to run the script, and sets the volume mounts.","func convertListOfSidecars(sidecars []v1.Sidecar, initContainer *corev1.Container, namePrefix string) []corev1.Container {","\tcontainers := []corev1.Container{}","\tfor i, s := range sidecars {","\t\tc := s.ToK8sContainer()","\t\tif s.Script != \"\" {","\t\t\tplaceScriptInContainer(s.Script, getScriptFile(scriptsDir, fmt.Sprintf(\"%s-%d\", namePrefix, i)), c, initContainer)","\t\t}","\t\tcontainers = append(containers, *c)","\t}","\treturn containers","}","","// convertListOfSteps iterates through the list of steps, generates the script file name and heredoc termination string,","// adds an entry to the init container args, sets up the step container to run the script, and sets the volume mounts.","func convertListOfSteps(steps []v1.Step, initContainer *corev1.Container, debugConfig *v1.TaskRunDebug, namePrefix string) []corev1.Container {","\tcontainers := []corev1.Container{}","\tfor i, s := range steps {","\t\tc := steps[i].ToK8sContainer()","\t\tif s.Script != \"\" {","\t\t\tplaceScriptInContainer(s.Script, getScriptFile(scriptsDir, fmt.Sprintf(\"%s-%d\", namePrefix, i)), c, initContainer)","\t\t}","\t\tcontainers = append(containers, *c)","\t}","\tplaceDebugScriptInContainers(containers, initContainer, debugConfig)","\treturn containers","}","","func getScriptFile(scriptsDir, scriptName string) string {","\treturn filepath.Join(scriptsDir, names.SimpleNameGenerator.RestrictLengthWithRandomSuffix(scriptName))","}","","// placeScriptInContainer given a piece of script to be executed, placeScriptInContainer firstly modifies initContainer","// so that it capsules the target script into scriptFile, then it modifies the container so that it can execute the scriptFile","// in runtime.","func placeScriptInContainer(script, scriptFile string, c *corev1.Container, initContainer *corev1.Container) {","\tif script == \"\" {","\t\treturn","\t}","\tcleaned := strings.TrimSpace(script)","\thasShebang := strings.HasPrefix(cleaned, \"#!\")","\trequiresWindows := strings.HasPrefix(cleaned, \"#!win\")","","\tif !hasShebang {","\t\tscript = defaultScriptPreamble + script","\t}","","\t// Append to the place-scripts script to place the","\t// script file in a known location in the scripts volume.","\tif requiresWindows {","\t\tcommand, args, script, scriptFile := extractWindowsScriptComponents(script, scriptFile)","\t\tinitContainer.Args[1] += fmt.Sprintf(`@\"","%s","\"@ | Out-File -FilePath %s","`, script, scriptFile)","","\t\tc.Command = command","\t\t// Append existing args field to end of derived args","\t\targs = append(args, c.Args...)","\t\tc.Args = args","\t} else {","\t\t// Only encode the script for linux scripts","\t\t// The decode-script subcommand of the entrypoint does not work under windows","\t\tscript = encodeScript(script)","\t\theredoc := \"_EOF_\" // underscores because base64 doesn't include them in its alphabet","\t\tinitContainer.Args[1] += fmt.Sprintf(`scriptfile=\"%s\"","touch ${scriptfile} \u0026\u0026 chmod +x ${scriptfile}","cat \u003e ${scriptfile} \u003c\u003c '%s'","%s","%s","/tekton/bin/entrypoint decode-script \"${scriptfile}\"","`, scriptFile, heredoc, script, heredoc)","","\t\t// Set the command to execute the correct script in the mounted volume.","\t\t// A previous merge with stepTemplate may have populated","\t\t// Command and Args, even though this is not normally valid, so","\t\t// we'll clear out the Args and overwrite Command.","\t\tc.Command = []string{scriptFile}","\t}","\tc.VolumeMounts = append(c.VolumeMounts, scriptsVolumeMount)","}","","// encodeScript encodes a script field into a format that avoids kubernetes' built-in processing of container args,","// which can mangle dollar signs and unexpectedly replace variable references in the user's script.","func encodeScript(script string) string {","\treturn base64.StdEncoding.EncodeToString([]byte(script))","}","","// placeDebugScriptInContainers inserts debug scripts into containers. It capsules those scripts to files in initContainer,","// then executes those scripts in target containers.","func placeDebugScriptInContainers(containers []corev1.Container, initContainer *corev1.Container, debugConfig *v1.TaskRunDebug) {","\tif debugConfig == nil || !debugConfig.NeedsDebug() {","\t\treturn","\t}","","\tisDebugOnFailure := debugConfig != nil \u0026\u0026 debugConfig.NeedsDebugOnFailure()","\tvar needDebugBeforeStep bool","","\tfor i := range containers {","\t\tdebugInfoVolumeMount := corev1.VolumeMount{","\t\t\tName:      debugInfoVolumeName,","\t\t\tMountPath: filepath.Join(debugInfoDir, strconv.Itoa(i)),","\t\t}","\t\t(\u0026containers[i]).VolumeMounts = append((\u0026containers[i]).VolumeMounts, debugScriptsVolumeMount, debugInfoVolumeMount)","\t\tif debugConfig != nil \u0026\u0026 debugConfig.NeedsDebugBeforeStep(containers[i].Name) {","\t\t\tneedDebugBeforeStep = true","\t\t}","\t}","","\ttype script struct {","\t\tname    string","\t\tcontent string","\t}","\tdebugScripts := make([]script, 0)","\tif isDebugOnFailure {","\t\tdebugScripts = append(debugScripts, []script{{","\t\t\tname:    \"continue\",","\t\t\tcontent: defaultScriptPreamble + fmt.Sprintf(debugContinueScriptTemplate, len(containers), debugInfoDir, RunDir),","\t\t}, {","\t\t\tname:    \"fail-continue\",","\t\t\tcontent: defaultScriptPreamble + fmt.Sprintf(debugFailScriptTemplate, len(containers), debugInfoDir, RunDir),","\t\t}}...)","\t}","\tif needDebugBeforeStep {","\t\tdebugScripts = append(debugScripts, []script{{","\t\t\tname:    \"beforestep-continue\",","\t\t\tcontent: defaultScriptPreamble + fmt.Sprintf(debugBeforeStepContinueScriptTemplate, len(containers), debugInfoDir, RunDir),","\t\t}, {","\t\t\tname:    \"beforestep-fail-continue\",","\t\t\tcontent: defaultScriptPreamble + fmt.Sprintf(debugBeforeStepFailScriptTemplate, len(containers), debugInfoDir, RunDir),","\t\t}}...)","\t}","","\t// Add debug or breakpoint related scripts to /tekton/debug/scripts","\t// Iterate through the debugScripts and add routine for each of them in the initContainer for their creation","\tfor _, debugScript := range debugScripts {","\t\ttmpFile := filepath.Join(debugScriptsDir, fmt.Sprintf(\"%s-%s\", \"debug\", debugScript.name))","\t\theredoc := names.SimpleNameGenerator.RestrictLengthWithRandomSuffix(fmt.Sprintf(\"%s-%s-heredoc-randomly-generated\", \"debug\", debugScript.name))","","\t\tinitContainer.Args[1] += fmt.Sprintf(initScriptDirective, tmpFile, heredoc, debugScript.content, heredoc)","\t}","}","","// hasScripts determines if we need to generate scripts in InitContainer given steps, sidecars and breakpoints.","func hasScripts(steps []v1.Step, sidecars []v1.Sidecar, debugConfig *v1.TaskRunDebug) bool {","\tfor _, s := range steps {","\t\tif s.Script != \"\" {","\t\t\treturn true","\t\t}","\t}","\tfor _, s := range sidecars {","\t\tif s.Script != \"\" {","\t\t\treturn true","\t\t}","\t}","\treturn debugConfig != nil \u0026\u0026 debugConfig.NeedsDebug()","}","","func checkWindowsRequirement(steps []v1.Step, sidecars []v1.Sidecar) bool {","\t// Detect windows shebangs","\tfor _, step := range steps {","\t\tcleaned := strings.TrimSpace(step.Script)","\t\tif strings.HasPrefix(cleaned, \"#!win\") {","\t\t\treturn true","\t\t}","\t}","\t// If no step needs windows, then check sidecars to be sure","\tfor _, sidecar := range sidecars {","\t\tcleaned := strings.TrimSpace(sidecar.Script)","\t\tif strings.HasPrefix(cleaned, \"#!win\") {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","func extractWindowsScriptComponents(script string, fileName string) ([]string, []string, string, string) {","\t// Set the command to execute the correct script in the mounted volume.","\tshebangLine := strings.Split(script, \"\\n\")[0]","\tsplitLine := strings.Split(shebangLine, \" \")","\tvar command, args []string","\tif len(splitLine) \u003e 1 {","\t\tstrippedCommand := splitLine[1:]","\t\tcommand = strippedCommand[0:1]","\t\t// Handle legacy powershell limitation","\t\tif strings.HasPrefix(command[0], \"powershell\") {","\t\t\tfileName += \".ps1\"","\t\t}","\t\tif len(strippedCommand) \u003e 1 {","\t\t\targs = strippedCommand[1:]","\t\t\targs = append(args, fileName)","\t\t} else {","\t\t\targs = []string{fileName}","\t\t}","\t} else {","\t\t// If no interpreter is specified then strip the shebang and","\t\t// create a .cmd file","\t\tfileName += \".cmd\"","\t\tcommandLines := strings.Split(script, \"\\n\")[1:]","\t\tscript = strings.Join(commandLines, \"\\n\")","\t\tcommand = []string{fileName}","\t\targs = []string{}","\t}","","\treturn command, args, script, fileName","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,0,2,2,0,0,2,2,2,0,0,0,0,2,2,1,1,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,0,0,0,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,0,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0]},{"id":169,"path":"pkg/pod/security_context_config.go","lines":["/*","Copyright 2024 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pod","","import (","\tcorev1 \"k8s.io/api/core/v1\"",")","","var (","\t// Used in security context of pod init containers","\tallowPrivilegeEscalation = false","\trunAsNonRoot             = true","\treadOnlyRootFilesystem   = true","","\t// LinuxSecurityContext allow init containers to run in namespaces","\t// with \"restricted\" pod security admission","\t// See https://kubernetes.io/docs/concepts/security/pod-security-standards/#restricted","\tLinuxSecurityContext = \u0026corev1.SecurityContext{","\t\tAllowPrivilegeEscalation: \u0026allowPrivilegeEscalation,","\t\tCapabilities: \u0026corev1.Capabilities{","\t\t\tDrop: []corev1.Capability{\"ALL\"},","\t\t},","\t\tRunAsNonRoot: \u0026runAsNonRoot,","\t\tSeccompProfile: \u0026corev1.SeccompProfile{","\t\t\tType: corev1.SeccompProfileTypeRuntimeDefault,","\t\t},","\t}","","\t// WindowsSecurityContext adds securityContext that is supported by Windows OS.","\tWindowsSecurityContext = \u0026corev1.SecurityContext{","\t\tRunAsNonRoot: \u0026runAsNonRoot,","\t}",")","","// SecurityContextConfig is configuration for setting security context for init containers and affinity assistant container.","type SecurityContextConfig struct {","\tSetSecurityContext        bool","\tSetReadOnlyRootFilesystem bool","}","","func (c SecurityContextConfig) GetSecurityContext(isWindows bool) *corev1.SecurityContext {","\tif isWindows {","\t\treturn WindowsSecurityContext","\t}","","\tif !c.SetReadOnlyRootFilesystem {","\t\treturn LinuxSecurityContext","\t}","","\tsecurityContext := LinuxSecurityContext.DeepCopy()","\tsecurityContext.ReadOnlyRootFilesystem = \u0026readOnlyRootFilesystem","\treturn securityContext","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,2,2,2,0,2,2,2,0]},{"id":170,"path":"pkg/pod/status.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pod","","import (","\t\"context\"","\t\"encoding/json\"","\t\"errors\"","\t\"fmt\"","\t\"strconv\"","\t\"strings\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/internal/sidecarlogresults\"","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/result\"","\t\"github.com/tektoncd/pipeline/pkg/termination\"","\t\"go.uber.org/zap\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/client-go/kubernetes\"","\t\"knative.dev/pkg/apis\"",")","","// Aliased for backwards compatibility; do not add additional TaskRun reasons here","var (","\t// ReasonFailedResolution indicated that the reason for failure status is","\t// that references within the TaskRun could not be resolved","\tReasonFailedResolution = v1.TaskRunReasonFailedResolution.String()","\t// ReasonFailedValidation indicated that the reason for failure status is","\t// that taskrun failed runtime validation","\tReasonFailedValidation = v1.TaskRunReasonFailedValidation.String()","\t// ReasonTaskFailedValidation indicated that the reason for failure status is","\t// that task failed runtime validation","\tReasonTaskFailedValidation = v1.TaskRunReasonTaskFailedValidation.String()","\t// ReasonResourceVerificationFailed indicates that the task fails the trusted resource verification,","\t// it could be the content has changed, signature is invalid or public key is invalid","\tReasonResourceVerificationFailed = v1.TaskRunReasonResourceVerificationFailed.String()",")","","const (","\t// ReasonExceededResourceQuota indicates that the TaskRun failed to create a pod due to","\t// a ResourceQuota in the namespace","\tReasonExceededResourceQuota = \"ExceededResourceQuota\"","","\t// ReasonExceededNodeResources indicates that the TaskRun's pod has failed to start due","\t// to resource constraints on the node","\tReasonExceededNodeResources = \"ExceededNodeResources\"","","\t// ReasonPullImageFailed indicates that the TaskRun's pod failed to pull image","\tReasonPullImageFailed = \"PullImageFailed\"","","\t// ReasonCreateContainerConfigError indicates that the TaskRun failed to create a pod due to","\t// config error of container","\tReasonCreateContainerConfigError = \"CreateContainerConfigError\"","","\t// ReasonPodCreationFailed indicates that the reason for the current condition","\t// is that the creation of the pod backing the TaskRun failed","\tReasonPodCreationFailed = \"PodCreationFailed\"","","\t// ReasonPodAdmissionFailed indicates that the TaskRun's pod failed to pass admission validation","\tReasonPodAdmissionFailed = \"PodAdmissionFailed\"","","\t// ReasonPending indicates that the pod is in corev1.Pending, and the reason is not","\t// ReasonExceededNodeResources or isPodHitConfigError","\tReasonPodPending = \"Pending\"","","\t// timeFormat is RFC3339 with millisecond","\ttimeFormat = \"2006-01-02T15:04:05.000Z07:00\"",")","","const (","\toomKilled = \"OOMKilled\"","\tevicted   = \"Evicted\"",")","","// SidecarsReady returns true if all of the Pod's sidecars are Ready or","// Terminated.","func SidecarsReady(podStatus corev1.PodStatus) bool {","\tif podStatus.Phase != corev1.PodRunning {","\t\treturn false","\t}","\tfor _, s := range podStatus.ContainerStatuses {","\t\t// If the step indicates that it's a step, skip it.","\t\t// An injected sidecar might not have the \"sidecar-\" prefix, so","\t\t// we can't just look for that prefix, we need to look at any","\t\t// non-step container.","\t\tif IsContainerStep(s.Name) {","\t\t\tcontinue","\t\t}","\t\tif s.State.Running != nil \u0026\u0026 s.Ready {","\t\t\tcontinue","\t\t}","\t\tif s.State.Terminated != nil {","\t\t\tcontinue","\t\t}","\t\treturn false","\t}","\treturn true","}","","// MakeTaskRunStatus returns a TaskRunStatus based on the Pod's status.","func MakeTaskRunStatus(ctx context.Context, logger *zap.SugaredLogger, tr v1.TaskRun, pod *corev1.Pod, kubeclient kubernetes.Interface, ts *v1.TaskSpec) (v1.TaskRunStatus, error) {","\ttrs := \u0026tr.Status","\tif trs.GetCondition(apis.ConditionSucceeded) == nil || trs.GetCondition(apis.ConditionSucceeded).Status == corev1.ConditionUnknown {","\t\t// If the taskRunStatus doesn't exist yet, it's because we just started running","\t\tmarkStatusRunning(trs, v1.TaskRunReasonRunning.String(), \"Not all Steps in the Task have finished executing\")","\t}","","\tsortPodContainerStatuses(pod.Status.ContainerStatuses, pod.Spec.Containers)","","\tcomplete := areContainersCompleted(ctx, pod) || isPodCompleted(pod)","","\t// When EnableKubernetesSidecar is true, we need to ensure all init containers","\t// are completed before considering the taskRun complete, in addition to the regular containers.","\t// This is because sidecars in Kubernetes can keep running after the main containers complete.","\tif config.FromContextOrDefaults(ctx).FeatureFlags.EnableKubernetesSidecar {","\t\tcomplete = complete \u0026\u0026 areInitContainersCompleted(ctx, pod)","\t}","","\tif complete {","\t\tonError, ok := tr.Annotations[v1.PipelineTaskOnErrorAnnotation]","\t\tif ok {","\t\t\tupdateCompletedTaskRunStatus(logger, trs, pod, v1.PipelineTaskOnErrorType(onError))","\t\t} else {","\t\t\tupdateCompletedTaskRunStatus(logger, trs, pod, \"\")","\t\t}","\t} else {","\t\tupdateIncompleteTaskRunStatus(trs, pod)","\t}","","\ttrs.PodName = pod.Name","\ttrs.Sidecars = []v1.SidecarState{}","","\tvar stepStatuses []corev1.ContainerStatus","\tvar sidecarStatuses []corev1.ContainerStatus","\tfor _, s := range pod.Status.ContainerStatuses {","\t\tif IsContainerStep(s.Name) {","\t\t\tstepStatuses = append(stepStatuses, s)","\t\t} else if IsContainerSidecar(s.Name) {","\t\t\tsidecarStatuses = append(sidecarStatuses, s)","\t\t}","\t}","\tfor _, s := range pod.Status.InitContainerStatuses {","\t\tif IsContainerSidecar(s.Name) {","\t\t\tsidecarStatuses = append(sidecarStatuses, s)","\t\t}","\t}","","\terr := setTaskRunStatusBasedOnStepStatus(ctx, logger, stepStatuses, \u0026tr, pod.Status.Phase, kubeclient, ts)","","\tsetTaskRunStatusBasedOnSidecarStatus(sidecarStatuses, trs)","","\ttrs.Results = removeDuplicateResults(trs.Results)","","\treturn *trs, err","}","","func createTaskResultsFromStepResults(stepRunRes []v1.TaskRunStepResult, neededStepResults map[string]string) []v1.TaskRunResult {","\ttaskResults := []v1.TaskRunResult{}","\tfor _, r := range stepRunRes {","\t\t// this result was requested by the Task","\t\tif _, ok := neededStepResults[r.Name]; ok {","\t\t\ttaskRunResult := v1.TaskRunResult{","\t\t\t\tName:  neededStepResults[r.Name],","\t\t\t\tType:  r.Type,","\t\t\t\tValue: r.Value,","\t\t\t}","\t\t\ttaskResults = append(taskResults, taskRunResult)","\t\t}","\t}","\treturn taskResults","}","","func setTaskRunArtifactsFromRunResult(runResults []result.RunResult, artifacts *v1.Artifacts) error {","\tfor _, slr := range runResults {","\t\tif slr.ResultType == result.TaskRunArtifactsResultType {","\t\t\treturn json.Unmarshal([]byte(slr.Value), artifacts)","\t\t}","\t}","\treturn nil","}","","func getTaskResultsFromSidecarLogs(runResults []result.RunResult) []result.RunResult {","\ttaskResultsFromSidecarLogs := []result.RunResult{}","\tfor _, slr := range runResults {","\t\tif slr.ResultType == result.TaskRunResultType {","\t\t\ttaskResultsFromSidecarLogs = append(taskResultsFromSidecarLogs, slr)","\t\t}","\t}","\treturn taskResultsFromSidecarLogs","}","","func getStepResultsFromSidecarLogs(sidecarLogResults []result.RunResult, containerName string) ([]result.RunResult, error) {","\tstepResultsFromSidecarLogs := []result.RunResult{}","\tfor _, slr := range sidecarLogResults {","\t\tif slr.ResultType == result.StepResultType {","\t\t\tstepName, resultName, err := sidecarlogresults.ExtractStepAndResultFromSidecarResultName(slr.Key)","\t\t\tif err != nil {","\t\t\t\treturn []result.RunResult{}, err","\t\t\t}","\t\t\tif stepName == containerName {","\t\t\t\tslr.Key = resultName","\t\t\t\tstepResultsFromSidecarLogs = append(stepResultsFromSidecarLogs, slr)","\t\t\t}","\t\t}","\t}","\treturn stepResultsFromSidecarLogs, nil","}","","func setTaskRunStatusBasedOnStepStatus(ctx context.Context, logger *zap.SugaredLogger, stepStatuses []corev1.ContainerStatus, tr *v1.TaskRun, podPhase corev1.PodPhase, kubeclient kubernetes.Interface, ts *v1.TaskSpec) error {","\ttrs := \u0026tr.Status","\tvar errs []error","","\t// collect results from taskrun spec and taskspec","\tspecResults := []v1.TaskResult{}","\tif tr.Spec.TaskSpec != nil {","\t\tspecResults = append(specResults, tr.Spec.TaskSpec.Results...)","\t}","\tif ts != nil {","\t\tspecResults = append(specResults, ts.Results...)","\t}","","\t// Extract results from sidecar logs","\tsidecarLogsResultsEnabled := config.FromContextOrDefaults(ctx).FeatureFlags.ResultExtractionMethod == config.ResultExtractionMethodSidecarLogs","\t// temporary solution to check if artifacts sidecar created in taskRun as we don't have the api for users to declare if a step/task is producing artifacts yet","\tartifactsSidecarCreated := artifactsPathReferenced(ts.Steps)","\tsidecarLogResults := []result.RunResult{}","","\tif sidecarLogsResultsEnabled {","\t\t// extraction of results from sidecar logs","\t\tif tr.Status.TaskSpec.Results != nil || artifactsSidecarCreated {","\t\t\tslr, err := sidecarlogresults.GetResultsFromSidecarLogs(ctx, kubeclient, tr.Namespace, tr.Status.PodName, pipeline.ReservedResultsSidecarContainerName, podPhase)","\t\t\tif err != nil {","\t\t\t\terrs = append(errs, err)","\t\t\t}","\t\t\tsidecarLogResults = append(sidecarLogResults, slr...)","\t\t}","\t}","\t// Populate Task results from sidecar logs","\ttaskResultsFromSidecarLogs := getTaskResultsFromSidecarLogs(sidecarLogResults)","\ttaskResults, _, _ := filterResults(taskResultsFromSidecarLogs, specResults, nil)","\tif tr.IsDone() {","\t\ttrs.Results = append(trs.Results, taskResults...)","\t\tvar tras v1.Artifacts","\t\terr := setTaskRunArtifactsFromRunResult(sidecarLogResults, \u0026tras)","\t\tif err != nil {","\t\t\tlogger.Errorf(\"Failed to set artifacts value from sidecar logs: %v\", err)","\t\t\terrs = append(errs, err)","\t\t} else {","\t\t\ttrs.Artifacts = \u0026tras","\t\t}","\t}","","\t// Build a lookup map for step state provenances.","\tstepStateProvenances := make(map[string]*v1.Provenance)","\tfor _, ss := range trs.Steps {","\t\tstepStateProvenances[ss.Name] = ss.Provenance","\t}","","\t// Continue with extraction of termination messages","\torderedStepStates := make([]v1.StepState, len(stepStatuses))","\tfor i, s := range stepStatuses {","\t\t// Avoid changing the original value by modifying the pointer value.","\t\tstate := s.State.DeepCopy()","\t\ttaskRunStepResults := []v1.TaskRunStepResult{}","","\t\t// Identify Step Results","\t\tstepResults := []v1.StepResult{}","\t\tif ts != nil {","\t\t\tfor _, step := range ts.Steps {","\t\t\t\tif GetContainerName(step.Name) == s.Name {","\t\t\t\t\tstepResults = append(stepResults, step.Results...)","\t\t\t\t}","\t\t\t}","\t\t}","\t\t// Identify StepResults needed by the Task Results","\t\tneededStepResults, err := findStepResultsFetchedByTask(s.Name, specResults)","\t\tif err != nil {","\t\t\terrs = append(errs, err)","\t\t}","","\t\t// populate step results from sidecar logs","\t\tstepResultsFromSidecarLogs, err := getStepResultsFromSidecarLogs(sidecarLogResults, s.Name)","\t\tif err != nil {","\t\t\terrs = append(errs, err)","\t\t}","\t\t_, stepRunRes, _ := filterResults(stepResultsFromSidecarLogs, specResults, stepResults)","\t\tif tr.IsDone() {","\t\t\ttaskRunStepResults = append(taskRunStepResults, stepRunRes...)","\t\t\t// Set TaskResults from StepResults","\t\t\ttrs.Results = append(trs.Results, createTaskResultsFromStepResults(stepRunRes, neededStepResults)...)","\t\t}","\t\tvar sas v1.Artifacts","","\t\terr = setStepArtifactsValueFromSidecarLogResult(sidecarLogResults, s.Name, \u0026sas)","\t\tif err != nil {","\t\t\tlogger.Errorf(\"Failed to set artifacts value from sidecar logs: %v\", err)","\t\t\terrs = append(errs, err)","\t\t}","","\t\t// Parse termination messages","\t\tterminationReason := \"\"","\t\tif state.Terminated != nil \u0026\u0026 len(state.Terminated.Message) != 0 {","\t\t\tmsg := state.Terminated.Message","","\t\t\tresults, err := termination.ParseMessage(logger, msg)","\t\t\tif err != nil {","\t\t\t\tlogger.Errorf(\"termination message could not be parsed sas JSON: %v\", err)","\t\t\t\terrs = append(errs, err)","\t\t\t} else {","\t\t\t\terr := setStepArtifactsValueFromTerminationMessageRunResult(results, \u0026sas)","\t\t\t\tif err != nil {","\t\t\t\t\tlogger.Errorf(\"error setting step artifacts of step %q in taskrun %q: %v\", s.Name, tr.Name, err)","\t\t\t\t\terrs = append(errs, err)","\t\t\t\t}","\t\t\t\ttime, err := extractStartedAtTimeFromResults(results)","\t\t\t\tif err != nil {","\t\t\t\t\tlogger.Errorf(\"error setting the start time of step %q in taskrun %q: %v\", s.Name, tr.Name, err)","\t\t\t\t\terrs = append(errs, err)","\t\t\t\t}","\t\t\t\texitCode, err := extractExitCodeFromResults(results)","\t\t\t\tif err != nil {","\t\t\t\t\tlogger.Errorf(\"error extracting the exit code of step %q in taskrun %q: %v\", s.Name, tr.Name, err)","\t\t\t\t\terrs = append(errs, err)","\t\t\t\t}","","\t\t\t\ttaskResults, stepRunRes, filteredResults := filterResults(results, specResults, stepResults)","\t\t\t\tif tr.IsDone() {","\t\t\t\t\ttaskRunStepResults = append(taskRunStepResults, stepRunRes...)","\t\t\t\t\t// Set TaskResults from StepResults","\t\t\t\t\ttaskResults = append(taskResults, createTaskResultsFromStepResults(stepRunRes, neededStepResults)...)","\t\t\t\t\ttrs.Results = append(trs.Results, taskResults...)","","\t\t\t\t\tvar tras v1.Artifacts","\t\t\t\t\terr := setTaskRunArtifactsFromRunResult(filteredResults, \u0026tras)","\t\t\t\t\tif err != nil {","\t\t\t\t\t\tlogger.Errorf(\"error setting step artifacts in taskrun %q: %v\", tr.Name, err)","\t\t\t\t\t\terrs = append(errs, err)","\t\t\t\t\t}","\t\t\t\t\ttrs.Artifacts.Merge(\u0026tras)","\t\t\t\t\ttrs.Artifacts.Merge(\u0026sas)","\t\t\t\t}","\t\t\t\tmsg, err = createMessageFromResults(filteredResults)","\t\t\t\tif err != nil {","\t\t\t\t\tlogger.Errorf(\"%v\", err)","\t\t\t\t\terrs = append(errs, err)","\t\t\t\t} else {","\t\t\t\t\tstate.Terminated.Message = msg","\t\t\t\t}","\t\t\t\tif time != nil {","\t\t\t\t\tstate.Terminated.StartedAt = *time","\t\t\t\t}","\t\t\t\tif exitCode != nil {","\t\t\t\t\tstate.Terminated.ExitCode = *exitCode","\t\t\t\t}","","\t\t\t\tterminationFromResults := extractTerminationReasonFromResults(results)","\t\t\t\tterminationReason = getTerminationReason(state.Terminated.Reason, terminationFromResults, exitCode)","\t\t\t}","\t\t}","\t\tstepState := v1.StepState{","\t\t\tContainerState:    *state.DeepCopy(),","\t\t\tName:              TrimStepPrefix(s.Name),","\t\t\tContainer:         s.Name,","\t\t\tImageID:           s.ImageID,","\t\t\tResults:           taskRunStepResults,","\t\t\tTerminationReason: terminationReason,","\t\t\tInputs:            sas.Inputs,","\t\t\tOutputs:           sas.Outputs,","\t\t}","\t\tif stepStateProvenance, exist := stepStateProvenances[stepState.Name]; exist {","\t\t\tstepState.Provenance = stepStateProvenance","\t\t}","\t\torderedStepStates[i] = stepState","\t}","\tif len(orderedStepStates) \u003e 0 {","\t\ttrs.Steps = orderedStepStates","\t}","","\treturn errors.Join(errs...)","}","","func setStepArtifactsValueFromSidecarLogResult(results []result.RunResult, name string, artifacts *v1.Artifacts) error {","\tfor _, r := range results {","\t\tif r.Key == name \u0026\u0026 r.ResultType == result.StepArtifactsResultType {","\t\t\treturn json.Unmarshal([]byte(r.Value), artifacts)","\t\t}","\t}","\treturn nil","}","","func setStepArtifactsValueFromTerminationMessageRunResult(results []result.RunResult, artifacts *v1.Artifacts) error {","\tfor _, r := range results {","\t\tif r.ResultType == result.StepArtifactsResultType {","\t\t\treturn json.Unmarshal([]byte(r.Value), artifacts)","\t\t}","\t}","\treturn nil","}","","func setTaskRunStatusBasedOnSidecarStatus(sidecarStatuses []corev1.ContainerStatus, trs *v1.TaskRunStatus) {","\tfor _, s := range sidecarStatuses {","\t\ttrs.Sidecars = append(trs.Sidecars, v1.SidecarState{","\t\t\tContainerState: *s.State.DeepCopy(),","\t\t\tName:           TrimSidecarPrefix(s.Name),","\t\t\tContainer:      s.Name,","\t\t\tImageID:        s.ImageID,","\t\t})","\t}","}","","func createMessageFromResults(results []result.RunResult) (string, error) {","\tif len(results) == 0 {","\t\treturn \"\", nil","\t}","\tbytes, err := json.Marshal(results)","\tif err != nil {","\t\treturn \"\", fmt.Errorf(\"error marshalling remaining results back into termination message: %w\", err)","\t}","\treturn string(bytes), nil","}","","// findStepResultsFetchedByTask fetches step results that the Task needs.","// It accepts a container name and the TaskResults as input and outputs","// a map with the name of the step result as the key and the name of the task result that is fetching it as value.","func findStepResultsFetchedByTask(containerName string, specResults []v1.TaskResult) (map[string]string, error) {","\tneededStepResults := map[string]string{}","\tfor _, r := range specResults {","\t\tif r.Value != nil {","\t\t\tif r.Value.StringVal != \"\" {","\t\t\t\tsName, resultName, err := v1.ExtractStepResultName(r.Value.StringVal)","\t\t\t\tif err != nil {","\t\t\t\t\treturn nil, err","\t\t\t\t}","\t\t\t\t// Only look at named results - referencing unnamed steps is unsupported.","\t\t\t\tif GetContainerName(sName) == containerName {","\t\t\t\t\tneededStepResults[resultName] = r.Name","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn neededStepResults, nil","}","","// filterResults filters the RunResults and TaskResults based on the results declared in the task spec.","// It returns a slice of any of the input results that are defined in the task spec, converted to TaskRunResults,","// and a slice of any of the RunResults that don't represent internal values (i.e. those that should not be displayed in the TaskRun status.","func filterResults(results []result.RunResult, specResults []v1.TaskResult, stepResults []v1.StepResult) ([]v1.TaskRunResult, []v1.TaskRunStepResult, []result.RunResult) {","\tvar taskResults []v1.TaskRunResult","\tvar taskRunStepResults []v1.TaskRunStepResult","\tvar filteredResults []result.RunResult","\tneededTypes := make(map[string]v1.ResultsType)","\tneededStepTypes := make(map[string]v1.ResultsType)","\tfor _, r := range specResults {","\t\tneededTypes[r.Name] = r.Type","\t}","\tfor _, r := range stepResults {","\t\tneededStepTypes[r.Name] = r.Type","\t}","\tfor _, r := range results {","\t\tswitch r.ResultType {","\t\tcase result.TaskRunResultType:","\t\t\tvar taskRunResult v1.TaskRunResult","\t\t\tif neededTypes[r.Key] == v1.ResultsTypeString {","\t\t\t\ttaskRunResult = v1.TaskRunResult{","\t\t\t\t\tName:  r.Key,","\t\t\t\t\tType:  v1.ResultsTypeString,","\t\t\t\t\tValue: *v1.NewStructuredValues(r.Value),","\t\t\t\t}","\t\t\t} else {","\t\t\t\tv := v1.ResultValue{}","\t\t\t\terr := v.UnmarshalJSON([]byte(r.Value))","\t\t\t\tif err != nil {","\t\t\t\t\tcontinue","\t\t\t\t}","\t\t\t\ttaskRunResult = v1.TaskRunResult{","\t\t\t\t\tName:  r.Key,","\t\t\t\t\tType:  v1.ResultsType(v.Type),","\t\t\t\t\tValue: v,","\t\t\t\t}","\t\t\t}","\t\t\ttaskResults = append(taskResults, taskRunResult)","\t\t\tfilteredResults = append(filteredResults, r)","\t\tcase result.StepResultType:","\t\t\tvar taskRunStepResult v1.TaskRunStepResult","\t\t\tif neededStepTypes[r.Key] == v1.ResultsTypeString {","\t\t\t\ttaskRunStepResult = v1.TaskRunStepResult{","\t\t\t\t\tName:  r.Key,","\t\t\t\t\tType:  v1.ResultsTypeString,","\t\t\t\t\tValue: *v1.NewStructuredValues(r.Value),","\t\t\t\t}","\t\t\t} else {","\t\t\t\tv := v1.ResultValue{}","\t\t\t\terr := v.UnmarshalJSON([]byte(r.Value))","\t\t\t\tif err != nil {","\t\t\t\t\tcontinue","\t\t\t\t}","\t\t\t\ttaskRunStepResult = v1.TaskRunStepResult{","\t\t\t\t\tName:  r.Key,","\t\t\t\t\tType:  v1.ResultsType(v.Type),","\t\t\t\t\tValue: v,","\t\t\t\t}","\t\t\t}","\t\t\ttaskRunStepResults = append(taskRunStepResults, taskRunStepResult)","\t\t\tfilteredResults = append(filteredResults, r)","\t\tcase result.StepArtifactsResultType:","\t\t\tfilteredResults = append(filteredResults, r)","\t\t\tcontinue","\t\tcase result.TaskRunArtifactsResultType:","\t\t\tfilteredResults = append(filteredResults, r)","\t\t\tcontinue","\t\tcase result.InternalTektonResultType:","\t\t\t// Internal messages are ignored because they're not used as external result","\t\t\tcontinue","\t\tdefault:","\t\t\tfilteredResults = append(filteredResults, r)","\t\t}","\t}","\treturn taskResults, taskRunStepResults, filteredResults","}","","func removeDuplicateResults(taskRunResult []v1.TaskRunResult) []v1.TaskRunResult {","\tif len(taskRunResult) == 0 {","\t\treturn nil","\t}","","\tuniq := make([]v1.TaskRunResult, 0)","\tlatest := make(map[string]v1.TaskRunResult, 0)","\tfor _, res := range taskRunResult {","\t\tif _, seen := latest[res.Name]; !seen {","\t\t\tuniq = append(uniq, res)","\t\t}","\t\tlatest[res.Name] = res","\t}","\tfor i, res := range uniq {","\t\tuniq[i] = latest[res.Name]","\t}","\treturn uniq","}","","func extractStartedAtTimeFromResults(results []result.RunResult) (*metav1.Time, error) {","\tfor _, result := range results {","\t\tif result.Key == \"StartedAt\" {","\t\t\tt, err := time.Parse(timeFormat, result.Value)","\t\t\tif err != nil {","\t\t\t\treturn nil, fmt.Errorf(\"could not parse time value %q in StartedAt field: %w\", result.Value, err)","\t\t\t}","\t\t\tstartedAt := metav1.NewTime(t)","\t\t\treturn \u0026startedAt, nil","\t\t}","\t}","\treturn nil, nil //nolint:nilnil // would be more ergonomic to return a sentinel error","}","","func extractExitCodeFromResults(results []result.RunResult) (*int32, error) {","\tfor _, result := range results {","\t\tif result.Key == \"ExitCode\" {","\t\t\t// We could just pass the string through but this provides extra validation","\t\t\ti, err := strconv.ParseInt(result.Value, 10, 32)","\t\t\tif err != nil {","\t\t\t\treturn nil, fmt.Errorf(\"could not parse int value %q in ExitCode field: %w\", result.Value, err)","\t\t\t}","\t\t\texitCode := int32(i) // #nosec G115: ParseInt was called with bit size 32, so this is safe","\t\t\treturn \u0026exitCode, nil","\t\t}","\t}","\treturn nil, nil //nolint:nilnil // would be more ergonomic to return a sentinel error","}","","func extractTerminationReasonFromResults(results []result.RunResult) string {","\tfor _, r := range results {","\t\tif r.ResultType == result.InternalTektonResultType \u0026\u0026 r.Key == \"Reason\" {","\t\t\treturn r.Value","\t\t}","\t}","\treturn \"\"","}","","func getTerminationReason(terminatedStateReason string, terminationFromResults string, exitCodeFromResults *int32) string {","\tif terminationFromResults != \"\" {","\t\treturn terminationFromResults","\t}","","\tif exitCodeFromResults != nil {","\t\treturn TerminationReasonContinued","\t}","","\treturn terminatedStateReason","}","","func updateCompletedTaskRunStatus(logger *zap.SugaredLogger, trs *v1.TaskRunStatus, pod *corev1.Pod, onError v1.PipelineTaskOnErrorType) {","\tif DidTaskRunFail(pod) {","\t\tmsg := getFailureMessage(logger, pod)","\t\tif onError == v1.PipelineTaskContinue {","\t\t\tmarkStatusFailure(trs, v1.TaskRunReasonFailureIgnored.String(), msg)","\t\t} else {","\t\t\tmarkStatusFailure(trs, v1.TaskRunReasonFailed.String(), msg)","\t\t}","\t} else {","\t\tmarkStatusSuccess(trs)","\t}","","\t// update tr completed time","\ttrs.CompletionTime = \u0026metav1.Time{Time: time.Now()}","}","","func updateIncompleteTaskRunStatus(trs *v1.TaskRunStatus, pod *corev1.Pod) {","\tswitch pod.Status.Phase {","\tcase corev1.PodRunning:","\t\tmarkStatusRunning(trs, v1.TaskRunReasonRunning.String(), \"Not all Steps in the Task have finished executing\")","\tcase corev1.PodPending:","\t\tswitch {","\t\tcase IsPodExceedingNodeResources(pod):","\t\t\tmarkStatusRunning(trs, ReasonExceededNodeResources, \"TaskRun Pod exceeded available resources\")","\t\tcase isSubPathDirectoryError(pod):","\t\t\t// if subPath directory creation errors, mark as running and wait for recovery","\t\t\tmarkStatusRunning(trs, ReasonPodPending, \"Waiting for subPath directory creation to complete\")","\t\tcase isPodHitConfigError(pod):","\t\t\tmarkStatusFailure(trs, ReasonCreateContainerConfigError, \"Failed to create pod due to config error\")","\t\tcase isPullImageError(pod):","\t\t\tmarkStatusRunning(trs, ReasonPullImageFailed, getWaitingMessage(pod))","\t\tdefault:","\t\t\tmarkStatusRunning(trs, ReasonPodPending, getWaitingMessage(pod))","\t\t}","\tcase corev1.PodSucceeded, corev1.PodFailed, corev1.PodUnknown:","\t\t// Do nothing; pod has completed or is in an unknown state.","\t}","}","","// isPodCompleted checks if the given pod is completed.","// A pod is considered completed if its phase is either \"Succeeded\" or \"Failed\".","//","// If it is foreseeable that the pod will eventually be in a failed state,","// but it remains in a Running status for a visible period of time, it should be considered completed in advance.","//","// For example, when certain steps encounter OOM, only the pods that have timed out will change to a failed state,","// we should consider them completed in advance.","func isPodCompleted(pod *corev1.Pod) bool {","\tif pod.Status.Phase == corev1.PodSucceeded || pod.Status.Phase == corev1.PodFailed {","\t\treturn true","\t}","\tfor _, s := range pod.Status.ContainerStatuses {","\t\tif IsContainerStep(s.Name) {","\t\t\tif s.State.Terminated != nil {","\t\t\t\tif isOOMKilled(s) {","\t\t\t\t\treturn true","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn false","}","","// DidTaskRunFail check the status of pod to decide if related taskrun is failed","func DidTaskRunFail(pod *corev1.Pod) bool {","\tif pod.Status.Phase == corev1.PodFailed {","\t\treturn true","\t}","","\tfor _, s := range pod.Status.ContainerStatuses {","\t\tif IsContainerStep(s.Name) {","\t\t\tif s.State.Terminated != nil {","\t\t\t\tif s.State.Terminated.ExitCode != 0 || isOOMKilled(s) {","\t\t\t\t\treturn true","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn false","}","","// IsPodArchived indicates if a pod is archived in the retriesStatus.","func IsPodArchived(pod *corev1.Pod, trs *v1.TaskRunStatus) bool {","\tfor _, retryStatus := range trs.RetriesStatus {","\t\tif retryStatus.PodName == pod.GetName() {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// containerNameFilter is a function that filters container names.","type containerNameFilter func(name string) bool","","// isMatchingAnyFilter returns true if the container name matches any of the filters.","func isMatchingAnyFilter(name string, filters []containerNameFilter) bool {","\tfor _, filter := range filters {","\t\tif filter(name) {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// areInitContainersCompleted returns true if all init containers in the pod are completed.","func areInitContainersCompleted(ctx context.Context, pod *corev1.Pod) bool {","\tif len(pod.Status.InitContainerStatuses) == 0 ||","\t\t!(pod.Status.Phase == corev1.PodRunning || pod.Status.Phase == corev1.PodSucceeded) {","\t\treturn false","\t}","\tfor _, containerStatus := range pod.Status.InitContainerStatuses {","\t\tif containerStatus.State.Terminated == nil {","\t\t\t// if any init container is not completed, return false","\t\t\treturn false","\t\t}","\t}","\treturn true","}","","// areContainersCompleted returns true if all related containers in the pod are completed.","func areContainersCompleted(ctx context.Context, pod *corev1.Pod) bool {","\tnameFilters := []containerNameFilter{IsContainerStep}","\tif config.FromContextOrDefaults(ctx).FeatureFlags.ResultExtractionMethod == config.ResultExtractionMethodSidecarLogs {","\t\t// If we are using sidecar logs to extract results, we need to wait for the sidecar to complete.","\t\t// Avoid failing to obtain the final result from the sidecar because the sidecar is not yet complete.","\t\tnameFilters = append(nameFilters, func(name string) bool {","\t\t\treturn name == pipeline.ReservedResultsSidecarContainerName","\t\t})","\t}","\treturn checkContainersCompleted(pod, nameFilters)","}","","// checkContainersCompleted returns true if containers in the pod are completed.","func checkContainersCompleted(pod *corev1.Pod, nameFilters []containerNameFilter) bool {","\tif len(pod.Status.ContainerStatuses) == 0 ||","\t\t!(pod.Status.Phase == corev1.PodRunning || pod.Status.Phase == corev1.PodSucceeded) {","\t\treturn false","\t}","\tfor _, containerStatus := range pod.Status.ContainerStatuses {","\t\tif isMatchingAnyFilter(containerStatus.Name, nameFilters) \u0026\u0026 containerStatus.State.Terminated == nil {","\t\t\t// if any container is not completed, return false","\t\t\treturn false","\t\t}","\t}","\treturn true","}","","func getFailureMessage(logger *zap.SugaredLogger, pod *corev1.Pod) string {","\t// If a pod was evicted, use the pods status message before trying to","\t// determine a failure message from the pod's container statuses. A","\t// container may have a generic exit code that contains less information,","\t// such as an exit code and message related to not being located.","\tif pod.Status.Reason == evicted {","\t\treturn pod.Status.Message","\t}","","\t// First, try to surface an error about the actual init container that failed.","\tfor _, status := range pod.Status.InitContainerStatuses {","\t\tif msg := extractContainerFailureMessage(logger, status, pod.ObjectMeta); len(msg) \u003e 0 {","\t\t\treturn \"init container failed, \" + msg","\t\t}","\t}","","\t// Next, try to surface an error about the actual build step that failed.","\tfor _, status := range pod.Status.ContainerStatuses {","\t\tif msg := extractContainerFailureMessage(logger, status, pod.ObjectMeta); len(msg) \u003e 0 {","\t\t\treturn msg","\t\t}","\t}","\t// Next, return the Pod's status message if it has one.","\tif pod.Status.Message != \"\" {","\t\treturn pod.Status.Message","\t}","","\tfor _, s := range pod.Status.ContainerStatuses {","\t\tif IsContainerStep(s.Name) {","\t\t\tif s.State.Terminated != nil {","\t\t\t\tif isOOMKilled(s) {","\t\t\t\t\treturn oomKilled","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\t// Lastly fall back on a generic error message.","\treturn \"build failed for unspecified reasons.\"","}","","// extractContainerFailureMessage returns the container failure message by container status or init container status.","func extractContainerFailureMessage(logger *zap.SugaredLogger, status corev1.ContainerStatus, podMetaData metav1.ObjectMeta) string {","\tterm := status.State.Terminated","\tif term != nil {","\t\tmsg := status.State.Terminated.Message","\t\tr, _ := termination.ParseMessage(logger, msg)","\t\tfor _, runResult := range r {","\t\t\tif runResult.ResultType == result.InternalTektonResultType \u0026\u0026 runResult.Key == \"Reason\" \u0026\u0026 runResult.Value == TerminationReasonTimeoutExceeded {","\t\t\t\treturn fmt.Sprintf(\"%q exited because the step exceeded the specified timeout limit\", status.Name)","\t\t\t}","\t\t}","\t\tif term.ExitCode != 0 {","\t\t\t// Include the termination reason, if available to add clarity for causes such as external signals, e.g. OOM","\t\t\tif term.Reason != \"\" {","\t\t\t\treturn fmt.Sprintf(\"%q exited with code %d: %s\", status.Name, term.ExitCode, term.Reason)","\t\t\t}","\t\t\treturn fmt.Sprintf(\"%q exited with code %d\", status.Name, term.ExitCode)","\t\t}","\t}","","\treturn \"\"","}","","// IsPodExceedingNodeResources returns true if the Pod's status indicates there","// are insufficient resources to schedule the Pod.","func IsPodExceedingNodeResources(pod *corev1.Pod) bool {","\tfor _, podStatus := range pod.Status.Conditions {","\t\tif podStatus.Reason == corev1.PodReasonUnschedulable \u0026\u0026 strings.Contains(podStatus.Message, \"Insufficient\") {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// hasContainerWaitingReason checks if any container (init or regular) is waiting with a reason","// that matches the provided predicate function","func hasContainerWaitingReason(pod *corev1.Pod, predicate func(corev1.ContainerStateWaiting) bool) bool {","\t// Check init containers first","\tfor _, containerStatus := range pod.Status.InitContainerStatuses {","\t\tif containerStatus.State.Waiting != nil \u0026\u0026 predicate(*containerStatus.State.Waiting) {","\t\t\treturn true","\t\t}","\t}","\t// Check regular containers","\tfor _, containerStatus := range pod.Status.ContainerStatuses {","\t\tif containerStatus.State.Waiting != nil \u0026\u0026 predicate(*containerStatus.State.Waiting) {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// isPodHitConfigError returns true if the Pod's status indicates there are config error raised","func isPodHitConfigError(pod *corev1.Pod) bool {","\treturn hasContainerWaitingReason(pod, func(waiting corev1.ContainerStateWaiting) bool {","\t\tif waiting.Reason != ReasonCreateContainerConfigError {","\t\t\treturn false","\t\t}","\t\t// for subPath directory creation errors, we want to allow recovery","\t\tif strings.Contains(waiting.Message, \"failed to create subPath directory\") {","\t\t\treturn false","\t\t}","\t\treturn true","\t})","}","","// isPullImageError returns true if the Pod's status indicates there are any error when pulling image","func isPullImageError(pod *corev1.Pod) bool {","\treturn hasContainerWaitingReason(pod, func(waiting corev1.ContainerStateWaiting) bool {","\t\treturn isImageErrorReason(waiting.Reason)","\t})","}","","func isImageErrorReason(reason string) bool {","\t// Reference from https://github.com/kubernetes/kubernetes/blob/a1c8e9386af844757333733714fa1757489735b3/pkg/kubelet/images/types.go#L26","\timageErrorReasons := []string{","\t\t\"ImagePullBackOff\",","\t\t\"ImageInspectError\",","\t\t\"ErrImagePull\",","\t\t\"ErrImageNeverPull\",","\t\t\"RegistryUnavailable\",","\t\t\"InvalidImageName\",","\t}","\tfor _, imageReason := range imageErrorReasons {","\t\tif imageReason == reason {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","func getWaitingMessage(pod *corev1.Pod) string {","\t// First, try to surface reason for pending/unknown about the actual build step.","\tfor _, status := range pod.Status.ContainerStatuses {","\t\twait := status.State.Waiting","\t\tif wait != nil \u0026\u0026 wait.Message != \"\" {","\t\t\treturn fmt.Sprintf(\"build step %q is pending with reason %q\",","\t\t\t\tstatus.Name, wait.Message)","\t\t}","\t}","\t// Try to surface underlying reason by inspecting pod's recent status if condition is not true","\tfor i, podStatus := range pod.Status.Conditions {","\t\tif podStatus.Status != corev1.ConditionTrue {","\t\t\treturn fmt.Sprintf(\"pod status %q:%q; message: %q\",","\t\t\t\tpod.Status.Conditions[i].Type,","\t\t\t\tpod.Status.Conditions[i].Status,","\t\t\t\tpod.Status.Conditions[i].Message)","\t\t}","\t}","\t// Next, return the Pod's status message if it has one.","\tif pod.Status.Message != \"\" {","\t\treturn pod.Status.Message","\t}","","\t// Lastly fall back on a generic pending message.","\treturn \"Pending\"","}","","// markStatusRunning sets taskrun status to running","func markStatusRunning(trs *v1.TaskRunStatus, reason, message string) {","\ttrs.SetCondition(\u0026apis.Condition{","\t\tType:    apis.ConditionSucceeded,","\t\tStatus:  corev1.ConditionUnknown,","\t\tReason:  reason,","\t\tMessage: message,","\t})","}","","// markStatusFailure sets taskrun status to failure with specified reason","func markStatusFailure(trs *v1.TaskRunStatus, reason string, message string) {","\ttrs.SetCondition(\u0026apis.Condition{","\t\tType:    apis.ConditionSucceeded,","\t\tStatus:  corev1.ConditionFalse,","\t\tReason:  reason,","\t\tMessage: message,","\t})","}","","// markStatusSuccess sets taskrun status to success","func markStatusSuccess(trs *v1.TaskRunStatus) {","\ttrs.SetCondition(\u0026apis.Condition{","\t\tType:    apis.ConditionSucceeded,","\t\tStatus:  corev1.ConditionTrue,","\t\tReason:  v1.TaskRunReasonSuccessful.String(),","\t\tMessage: \"All Steps have completed executing\",","\t})","}","","// sortPodContainerStatuses reorders a pod's container statuses so that","// they're in the same order as the step containers from the TaskSpec.","func sortPodContainerStatuses(podContainerStatuses []corev1.ContainerStatus, podSpecContainers []corev1.Container) {","\tstatuses := map[string]corev1.ContainerStatus{}","\tfor _, status := range podContainerStatuses {","\t\tstatuses[status.Name] = status","\t}","\tfor i, c := range podSpecContainers {","\t\t// prevent out-of-bounds panic on incorrectly formed lists","\t\tif i \u003c len(podContainerStatuses) {","\t\t\tpodContainerStatuses[i] = statuses[c.Name]","\t\t}","\t}","}","","func isOOMKilled(s corev1.ContainerStatus) bool {","\treturn s.State.Terminated.Reason == oomKilled","}","","func isSubPathDirectoryError(pod *corev1.Pod) bool {","\tfor _, containerStatus := range pod.Status.ContainerStatuses {","\t\tif containerStatus.State.Waiting != nil \u0026\u0026","\t\t\tcontainerStatus.State.Waiting.Reason == ReasonCreateContainerConfigError \u0026\u0026","\t\t\tstrings.Contains(containerStatus.State.Waiting.Message, \"failed to create subPath directory\") {","\t\t\treturn true","\t\t}","\t}","\treturn false","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,2,2,2,2,2,2,2,0,2,2,0,2,2,0,2,0,2,0,0,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,1,1,0,2,0,0,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,1,1,2,2,2,0,0,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,1,1,0,0,2,2,1,1,2,2,2,2,2,2,2,2,2,2,1,1,1,0,0,2,2,2,2,2,2,2,2,2,2,2,1,1,1,2,2,1,1,1,2,2,1,1,1,0,2,2,2,2,2,2,2,2,2,2,1,1,1,2,2,0,2,2,1,1,2,2,2,2,2,2,2,2,2,0,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,0,2,0,0,2,2,1,1,1,0,2,0,0,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,1,1,2,0,0,0,0,0,2,2,2,2,2,2,2,1,1,0,2,2,2,0,0,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,0,2,2,2,2,2,0,2,2,2,2,2,1,1,1,2,2,2,2,2,0,0,2,0,0,2,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,2,0,0,2,2,2,2,2,1,1,2,2,0,0,2,0,0,2,2,2,2,2,2,1,1,2,2,0,0,2,0,0,2,2,2,2,2,0,2,0,0,2,2,2,2,0,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,2,2,2,2,0,2,2,2,2,2,2,0,0,0,2,0,0,0,2,2,2,2,2,0,2,0,0,0,0,0,0,2,2,2,2,2,0,2,0,0,0,2,2,2,1,1,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,0,0,2,2,2,2,0,0,2,2,2,0,2,2,2,2,2,2,0,0,0,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,0,0,2,0,0,0,0,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,1,1,0,0,2,2,2,2,0,2,0,0,0,2,2,2,2,2,0,2,1,1,2,0,0,0,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,0,0,2,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,0,2,2,2,2,2,2,2,0,2,0]},{"id":171,"path":"pkg/pod/workingdir_init.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pod","","import (","\t\"path/filepath\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/util/sets\"",")","","// workingDirInit returns a Container that should be run as an init","// container to ensure that all steps' workingDirs relative to the workspace","// exist.","//","// If no such directories need to be created (i.e., no relative workingDirs","// are specified), this method returns nil, as no init container is necessary.","// If setSecurityContext is true, the init container will include a security context","// allowing it to run in namespaces with restriced pod security admission.","// If the init container will run on windows, `windows` should be set to `true`,","// so that the correct security context can be applied.","func workingDirInit(workingdirinitImage string, stepContainers []corev1.Container, securityContext SecurityContextConfig, windows bool) *corev1.Container {","\t// Gather all unique workingDirs.","\tworkingDirs := sets.NewString()","\tfor _, step := range stepContainers {","\t\tif step.WorkingDir != \"\" {","\t\t\tworkingDirs.Insert(step.WorkingDir)","\t\t}","\t}","\tif workingDirs.Len() == 0 {","\t\treturn nil","\t}","","\t// Clean and append each relative workingDir.","\tvar relativeDirs []string","\tfor _, wd := range workingDirs.List() {","\t\tp := filepath.Clean(wd)","\t\tif !filepath.IsAbs(p) || strings.HasPrefix(p, \"/workspace/\") {","\t\t\trelativeDirs = append(relativeDirs, p)","\t\t}","\t}","","\tif len(relativeDirs) == 0 {","\t\t// There are no workingDirs to initialize.","\t\treturn nil","\t}","","\tc := \u0026corev1.Container{","\t\tName:         \"working-dir-initializer\",","\t\tImage:        workingdirinitImage,","\t\tCommand:      []string{\"/ko-app/workingdirinit\"},","\t\tArgs:         relativeDirs,","\t\tWorkingDir:   pipeline.WorkspaceDir,","\t\tVolumeMounts: implicitVolumeMounts,","\t}","\tif securityContext.SetSecurityContext {","\t\tc.SecurityContext = securityContext.GetSecurityContext(windows)","\t}","","\treturn c","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,0,2,2,2,0,0,2,2,2,2,2,2,0,0,2,1,1,1,0,2,2,2,2,2,2,2,2,2,2,2,0,2,0]},{"id":172,"path":"pkg/reconciler/apiserver/apiserver.go","lines":["package apiserver","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","","\t\"github.com/google/uuid\"","\tpipelineErrors \"github.com/tektoncd/pipeline/pkg/apis/pipeline/errors\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1alpha1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\tclientset \"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"","\tapierrors \"k8s.io/apimachinery/pkg/api/errors\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"",")","","var (","\tErrReferencedObjectValidationFailed = errors.New(\"validation failed for referenced object\")","\tErrCouldntValidateObjectRetryable   = errors.New(\"retryable error validating referenced object\")","\tErrCouldntValidateObjectPermanent   = errors.New(\"permanent error validating referenced object\")",")","","// DryRunValidate validates the obj by issuing a dry-run create request for it in the given namespace.","// This allows validating admission webhooks to process the object without actually creating it.","// obj must be a v1/v1beta1 Task or Pipeline.","func DryRunValidate(ctx context.Context, namespace string, obj runtime.Object, tekton clientset.Interface) (runtime.Object, error) {","\tdryRunObjName := uuid.NewString() // Use a randomized name for the Pipeline/Task in case there is already another Pipeline/Task of the same name","","\tswitch obj := obj.(type) {","\tcase *v1.Pipeline:","\t\tdryRunObj := obj.DeepCopy()","\t\tdryRunObj.Name = dryRunObjName","\t\tdryRunObj.Namespace = namespace // Make sure the namespace is the same as the PipelineRun","\t\tmutatedObj, err := tekton.TektonV1().Pipelines(namespace).Create(ctx, dryRunObj, metav1.CreateOptions{DryRun: []string{metav1.DryRunAll}})","\t\tif err != nil {","\t\t\treturn nil, handleDryRunCreateErr(err, obj.Name)","\t\t}","\t\treturn mutatedObj, nil","\tcase *v1beta1.Pipeline:","\t\tdryRunObj := obj.DeepCopy()","\t\tdryRunObj.Name = dryRunObjName","\t\tdryRunObj.Namespace = namespace // Make sure the namespace is the same as the PipelineRun","\t\tmutatedObj, err := tekton.TektonV1beta1().Pipelines(namespace).Create(ctx, dryRunObj, metav1.CreateOptions{DryRun: []string{metav1.DryRunAll}})","\t\tif err != nil {","\t\t\treturn nil, handleDryRunCreateErr(err, obj.Name)","\t\t}","\t\treturn mutatedObj, nil","\tcase *v1.Task:","\t\tdryRunObj := obj.DeepCopy()","\t\tdryRunObj.Name = dryRunObjName","\t\tdryRunObj.Namespace = namespace // Make sure the namespace is the same as the TaskRun","\t\tmutatedObj, err := tekton.TektonV1().Tasks(namespace).Create(ctx, dryRunObj, metav1.CreateOptions{DryRun: []string{metav1.DryRunAll}})","\t\tif err != nil {","\t\t\treturn nil, handleDryRunCreateErr(err, obj.Name)","\t\t}","\t\treturn mutatedObj, nil","\tcase *v1beta1.Task:","\t\tdryRunObj := obj.DeepCopy()","\t\tdryRunObj.Name = dryRunObjName","\t\tdryRunObj.Namespace = namespace // Make sure the namespace is the same as the TaskRun","\t\tmutatedObj, err := tekton.TektonV1beta1().Tasks(namespace).Create(ctx, dryRunObj, metav1.CreateOptions{DryRun: []string{metav1.DryRunAll}})","\t\tif err != nil {","\t\t\treturn nil, handleDryRunCreateErr(err, obj.Name)","\t\t}","\t\treturn mutatedObj, nil","\tcase *v1alpha1.StepAction:","\t\tdryRunObj := obj.DeepCopy()","\t\tdryRunObj.Name = dryRunObjName","\t\tdryRunObj.Namespace = namespace // Make sure the namespace is the same as the StepAction","\t\tmutatedObj, err := tekton.TektonV1alpha1().StepActions(namespace).Create(ctx, dryRunObj, metav1.CreateOptions{DryRun: []string{metav1.DryRunAll}})","\t\tif err != nil {","\t\t\treturn nil, handleDryRunCreateErr(err, obj.Name)","\t\t}","\t\treturn mutatedObj, nil","","\tcase *v1beta1.StepAction:","\t\tdryRunObj := obj.DeepCopy()","\t\tdryRunObj.Name = dryRunObjName","\t\tdryRunObj.Namespace = namespace // Make sure the namespace is the same as the StepAction","\t\tmutatedObj, err := tekton.TektonV1beta1().StepActions(namespace).Create(ctx, dryRunObj, metav1.CreateOptions{DryRun: []string{metav1.DryRunAll}})","\t\tif err != nil {","\t\t\treturn nil, handleDryRunCreateErr(err, obj.Name)","\t\t}","\t\treturn mutatedObj, nil","","\tdefault:","\t\treturn nil, fmt.Errorf(\"unsupported object GVK %s\", obj.GetObjectKind().GroupVersionKind())","\t}","}","","func handleDryRunCreateErr(err error, objectName string) error {","\tvar errType error","\tswitch {","\tcase apierrors.IsBadRequest(err): // Object rejected by validating webhook","\t\terrType = ErrReferencedObjectValidationFailed","\tcase apierrors.IsInvalid(err), apierrors.IsMethodNotSupported(err):","\t\terrType = pipelineErrors.WrapUserError(ErrCouldntValidateObjectPermanent)","\tcase apierrors.IsTimeout(err), apierrors.IsServerTimeout(err), apierrors.IsTooManyRequests(err):","\t\terrType = ErrCouldntValidateObjectRetryable","\tdefault:","\t\t// Assume unknown errors are retryable","\t\t// Additional errors can be added to the switch statements as needed","\t\terrType = ErrCouldntValidateObjectRetryable","\t}","\treturn fmt.Errorf(\"%w %s: %w\", errType, objectName, err)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,0,1,1,0,0,0,2,2,2,2,2,2,2,2,2,1,1,1,1,0,2,0]},{"id":173,"path":"pkg/reconciler/events/cache/cache.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package cache","","import (","\t\"encoding/json\"","\t\"errors\"","\t\"fmt\"","","\tcloudevents \"github.com/cloudevents/sdk-go/v2\"","\tlru \"github.com/hashicorp/golang-lru\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"",")","","// Struct to unmarshal the event data","type eventData struct {","\tCustomRun *v1beta1.CustomRun `json:\"customRun,omitempty\"`","}","","// ContainsOrAddCloudEvent checks if the event exists in the cache","func ContainsOrAddCloudEvent(cacheClient *lru.Cache, event *cloudevents.Event) (bool, error) {","\tif cacheClient == nil {","\t\treturn false, errors.New(\"cache client is nil\")","\t}","\teventKey, err := EventKey(event)","\tif err != nil {","\t\treturn false, err","\t}","\tisPresent, _ := cacheClient.ContainsOrAdd(eventKey, nil)","\treturn isPresent, nil","}","","// EventKey defines whether an event is considered different from another","// in future we might want to let specific event types override this","func EventKey(event *cloudevents.Event) (string, error) {","\tvar (","\t\tdata              eventData","\t\tresourceName      string","\t\tresourceNamespace string","\t\tresourceKind      string","\t)","\terr := json.Unmarshal(event.Data(), \u0026data)","\tif err != nil {","\t\treturn \"\", err","\t}","\tif data.CustomRun == nil {","\t\treturn \"\", fmt.Errorf(\"invalid CustomRun data in %v\", event)","\t}","\tresourceName = data.CustomRun.Name","\tresourceNamespace = data.CustomRun.Namespace","\tresourceKind = \"customrun\"","\teventType := event.Type()","\treturn fmt.Sprintf(\"%s/%s/%s/%s\", eventType, resourceKind, resourceNamespace, resourceName), nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,2,2,1,1,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,0]},{"id":174,"path":"pkg/reconciler/events/cache/cacheclient.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package cache","","import (","\t\"context\"","","\tlru \"github.com/hashicorp/golang-lru\"","\t\"k8s.io/client-go/rest\"","\t\"knative.dev/pkg/injection\"","\t\"knative.dev/pkg/logging\"",")","","// With 4 events per Run, we can store events for 1024 concurrent Runs","const bufferSize = 4096","","func init() {","\tinjection.Default.RegisterClient(withCacheClient)","}","","// cacheKey is a way to associate the Cache from inside the context.Context","type cacheKey struct{}","","func withCacheClientFromSize(ctx context.Context, size int) context.Context {","\tlogger := logging.FromContext(ctx)","","\tcacheClient, err := lru.New(size)","\tlogger.Infof(\"CACHE CLIENT %+v\", cacheClient)","\tif err != nil {","\t\tlogger.Error(\"unable to create cacheClient :\" + err.Error())","\t}","","\treturn ToContext(ctx, cacheClient)","}","","func withCacheClient(ctx context.Context, cfg *rest.Config) context.Context {","\treturn withCacheClientFromSize(ctx, bufferSize)","}","","// Get extracts the cloudEventClient client from the context.","func Get(ctx context.Context) *lru.Cache {","\tuntyped := ctx.Value(cacheKey{})","\tif untyped == nil {","\t\tlogging.FromContext(ctx).Errorf(\"Unable to fetch client from context.\")","\t\treturn nil","\t}","\treturn untyped.(*lru.Cache)","}","","// ToContext adds the cloud events client to the context","func ToContext(ctx context.Context, c *lru.Cache) context.Context {","\treturn context.WithValue(ctx, cacheKey{}, c)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,1,1,1,1,1,1,1,1,0,1,0,0,1,1,1,0,0,1,1,1,1,1,1,1,0,0,0,1,1,1]},{"id":175,"path":"pkg/reconciler/events/cache/cachefakeclient.go","lines":["/*","Copyright 2021 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package cache","","import (","\t\"context\"","","\t\"k8s.io/client-go/rest\"","\t\"knative.dev/pkg/injection\"",")","","const fakeBufferSize = 128","","func init() {","\tinjection.Fake.RegisterClient(withFakeCacheClient)","}","","func withFakeCacheClient(ctx context.Context, cfg *rest.Config) context.Context {","\treturn withCacheClientFromSize(ctx, fakeBufferSize)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,1,1,1]},{"id":176,"path":"pkg/reconciler/events/cloudevent/cloud_event_controller.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package cloudevent","","import (","\t\"context\"","\t\"errors\"","\t\"time\"","","\tcloudevents \"github.com/cloudevents/sdk-go/v2\"","\tlru \"github.com/hashicorp/golang-lru\"","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/events/cache\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/api/equality\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"knative.dev/pkg/apis\"","\tcontroller \"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/logging\"",")","","func cloudEventsSink(ctx context.Context) string {","\tconfigs := config.FromContextOrDefaults(ctx)","\t// Try the sink configuration first","\tsink := configs.Events.Sink","\tif sink == \"\" {","\t\t// Fall back to the deprecated flag is the new one is not set","\t\t// This ensures no changes in behaviour for existing users of the deprecated flag","\t\tsink = configs.Defaults.DefaultCloudEventsSink","\t}","\treturn sink","}","","// EmitCloudEvents emits CloudEvents (only) for object","func EmitCloudEvents(ctx context.Context, object runtime.Object) {","\tlogger := logging.FromContext(ctx)","\tif sink := cloudEventsSink(ctx); sink != \"\" {","\t\tctx = cloudevents.ContextWithTarget(ctx, sink)","\t\terr := SendCloudEventWithRetries(ctx, object)","\t\tif err != nil {","\t\t\tlogger.Warnf(\"Failed to emit cloud events %v\", err.Error())","\t\t}","\t}","}","","// EmitCloudEventsWhenConditionChange emits CloudEvents when there is a change in condition","func EmitCloudEventsWhenConditionChange(ctx context.Context, beforeCondition *apis.Condition, afterCondition *apis.Condition, object runtime.Object) {","\tlogger := logging.FromContext(ctx)","\tif sink := cloudEventsSink(ctx); sink != \"\" {","\t\tctx = cloudevents.ContextWithTarget(ctx, sink)","","\t\t// Only send events if the new condition represents a change","\t\tif !equality.Semantic.DeepEqual(beforeCondition, afterCondition) {","\t\t\terr := SendCloudEventWithRetries(ctx, object)","\t\t\tif err != nil {","\t\t\t\tlogger.Warnf(\"Failed to emit cloud events %v\", err.Error())","\t\t\t}","\t\t}","\t}","}","","// SendCloudEventWithRetries sends a cloud event for the specified resource.","// It does not block and it perform retries with backoff using the cloudevents","// sdk-go capabilities.","// It accepts a runtime.Object to avoid making objectWithCondition public since","// it's only used within the events/cloudevents packages.","func SendCloudEventWithRetries(ctx context.Context, object runtime.Object) error {","\tvar (","\t\to           objectWithCondition","\t\tok          bool","\t\tcacheClient *lru.Cache","\t)","\tif o, ok = object.(objectWithCondition); !ok {","\t\treturn errors.New(\"input object does not satisfy objectWithCondition\")","\t}","\tlogger := logging.FromContext(ctx)","\tceClient := Get(ctx)","\tif ceClient == nil {","\t\treturn errors.New(\"no cloud events client found in the context\")","\t}","\tevent, err := EventForObjectWithCondition(ctx, o)","\tif err != nil {","\t\treturn err","\t}","\t// Events for CustomRuns require a cache of events that have been sent","\t_, isCustomRun := object.(*v1beta1.CustomRun)","\tif isCustomRun {","\t\tcacheClient = cache.Get(ctx)","\t}","","\twasIn := make(chan error)","","\tceClient.addCount()","\tgo func() {","\t\tdefer ceClient.decreaseCount()","\t\twasIn \u003c- nil","\t\tlogger.Debugf(\"Sending cloudevent of type %q\", event.Type())","\t\t// In case of Run event, check cache if cloudevent is already sent","\t\tif isCustomRun {","\t\t\tcloudEventSent, err := cache.ContainsOrAddCloudEvent(cacheClient, event)","\t\t\tif err != nil {","\t\t\t\tlogger.Errorf(\"Error while checking cache: %s\", err)","\t\t\t}","\t\t\tif cloudEventSent {","\t\t\t\tlogger.Infof(\"cloudevent %v already sent\", event)","\t\t\t\treturn","\t\t\t}","\t\t}","\t\tif result := ceClient.Send(cloudevents.ContextWithRetriesExponentialBackoff(ctx, 10*time.Millisecond, 10), *event); !cloudevents.IsACK(result) {","\t\t\tlogger.Warnf(\"Failed to send cloudevent: %s\", result.Error())","\t\t\trecorder := controller.GetEventRecorder(ctx)","\t\t\tif recorder == nil {","\t\t\t\tlogger.Warnf(\"No recorder in context, cannot emit error event\")","\t\t\t\treturn","\t\t\t}","\t\t\trecorder.Event(object, corev1.EventTypeWarning, \"Cloud Event Failure\", result.Error())","\t\t}","\t}()","","\treturn \u003c-wasIn","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,1,1,0,0,0,0,2,2,2,2,2,2,2,2,2,1,1,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,1,1,2,1,1,1,0,2,2,2,2,1,1,1,2,0,0,0,2,0]},{"id":177,"path":"pkg/reconciler/events/cloudevent/cloudevent.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package cloudevent","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","\t\"strings\"","","\tcloudevents \"github.com/cloudevents/sdk-go/v2\"","\t\"github.com/google/go-cmp/cmp\"","\t\"github.com/google/go-cmp/cmp/cmpopts\"","\t\"github.com/google/uuid\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\t\"knative.dev/pkg/apis\"",")","","// TektonEventType holds the types of cloud events sent by Tekton","type TektonEventType string","","const (","\t// TaskRunStartedEventV1 is sent for TaskRuns with \"ConditionSucceeded\" \"Unknown\"","\t// the first time they are picked up by the reconciler","\tTaskRunStartedEventV1 TektonEventType = \"dev.tekton.event.taskrun.started.v1\"","\t// TaskRunRunningEventV1 is sent for TaskRuns with \"ConditionSucceeded\" \"Unknown\"","\t// once the TaskRun is validated and Pod created","\tTaskRunRunningEventV1 TektonEventType = \"dev.tekton.event.taskrun.running.v1\"","\t// TaskRunUnknownEventV1 is sent for TaskRuns with \"ConditionSucceeded\" \"Unknown\"","\t// It can be used as a confirmation that the TaskRun is still running.","\tTaskRunUnknownEventV1 TektonEventType = \"dev.tekton.event.taskrun.unknown.v1\"","\t// TaskRunSuccessfulEventV1 is sent for TaskRuns with \"ConditionSucceeded\" \"True\"","\tTaskRunSuccessfulEventV1 TektonEventType = \"dev.tekton.event.taskrun.successful.v1\"","\t// TaskRunFailedEventV1 is sent for TaskRuns with \"ConditionSucceeded\" \"False\"","\tTaskRunFailedEventV1 TektonEventType = \"dev.tekton.event.taskrun.failed.v1\"","\t// PipelineRunStartedEventV1 is sent for PipelineRuns with \"ConditionSucceeded\" \"Unknown\"","\t// the first time they are picked up by the reconciler","\tPipelineRunStartedEventV1 TektonEventType = \"dev.tekton.event.pipelinerun.started.v1\"","\t// PipelineRunRunningEventV1 is sent for PipelineRuns with \"ConditionSucceeded\" \"Unknown\"","\t// once the PipelineRun is validated and Pod created","\tPipelineRunRunningEventV1 TektonEventType = \"dev.tekton.event.pipelinerun.running.v1\"","\t// PipelineRunUnknownEventV1 is sent for PipelineRuns with \"ConditionSucceeded\" \"Unknown\"","\t// It can be used as a confirmation that the PipelineRun is still running.","\tPipelineRunUnknownEventV1 TektonEventType = \"dev.tekton.event.pipelinerun.unknown.v1\"","\t// PipelineRunSuccessfulEventV1 is sent for PipelineRuns with \"ConditionSucceeded\" \"True\"","\tPipelineRunSuccessfulEventV1 TektonEventType = \"dev.tekton.event.pipelinerun.successful.v1\"","\t// PipelineRunFailedEventV1 is sent for PipelineRuns with \"ConditionSucceeded\" \"False\"","\tPipelineRunFailedEventV1 TektonEventType = \"dev.tekton.event.pipelinerun.failed.v1\"","\t// CustomRunStartedEventV1 is sent for CustomRuns with \"ConditionSucceeded\" \"Unknown\"","\t// the first time they are picked up by the reconciler","\tCustomRunStartedEventV1 TektonEventType = \"dev.tekton.event.customrun.started.v1\"","\t// CustomRunRunningEventV1 is sent for CustomRuns with \"ConditionSucceeded\" \"Unknown\"","\t// once the CustomRun is validated and Pod created","\tCustomRunRunningEventV1 TektonEventType = \"dev.tekton.event.customrun.running.v1\"","\t// CustomRunSuccessfulEventV1 is sent for CustomRuns with \"ConditionSucceeded\" \"True\"","\tCustomRunSuccessfulEventV1 TektonEventType = \"dev.tekton.event.customrun.successful.v1\"","\t// CustomRunFailedEventV1 is sent for CustomRuns with \"ConditionSucceeded\" \"False\"","\tCustomRunFailedEventV1 TektonEventType = \"dev.tekton.event.customrun.failed.v1\"",")","","func (t TektonEventType) String() string {","\treturn string(t)","}","","// CEClient wraps the `Client` interface from github.com/cloudevents/sdk-go/v2/cloudevents","// and has methods to count the cloud events being sent, those methods are for testing purposes.","type CEClient interface {","\tcloudevents.Client","\t// addCount increments the count of events to be sent","\taddCount()","\t// decreaseCount decrements the count of events to be sent, indicating the event has been sent","\tdecreaseCount()","}","","// TektonCloudEventData type is used to marshal and unmarshal the payload of","// a Tekton cloud event. It can include a TaskRun or a PipelineRun","type TektonCloudEventData struct {","\tTaskRun     *v1beta1.TaskRun     `json:\"taskRun,omitempty\"`","\tPipelineRun *v1beta1.PipelineRun `json:\"pipelineRun,omitempty\"`","\tCustomRun   *v1beta1.CustomRun   `json:\"customRun,omitempty\"`","}","","// newTektonCloudEventData returns a new instance of TektonCloudEventData","func newTektonCloudEventData(ctx context.Context, runObject objectWithCondition) (TektonCloudEventData, error) {","\ttektonCloudEventData := TektonCloudEventData{}","\tswitch v := runObject.(type) {","\tcase *v1beta1.TaskRun:","\t\ttektonCloudEventData.TaskRun = v","\tcase *v1beta1.PipelineRun:","\t\ttektonCloudEventData.PipelineRun = v","\tcase *v1.TaskRun:","\t\tv1beta1TaskRun := \u0026v1beta1.TaskRun{}","\t\tif err := v1beta1TaskRun.ConvertFrom(ctx, v); err != nil {","\t\t\treturn TektonCloudEventData{}, err","\t\t}","\t\ttektonCloudEventData.TaskRun = v1beta1TaskRun","\tcase *v1.PipelineRun:","\t\tv1beta1PipelineRun := \u0026v1beta1.PipelineRun{}","\t\tif err := v1beta1PipelineRun.ConvertFrom(ctx, v); err != nil {","\t\t\treturn TektonCloudEventData{}, err","\t\t}","\t\ttektonCloudEventData.PipelineRun = v1beta1PipelineRun","\tcase *v1beta1.CustomRun:","\t\ttektonCloudEventData.CustomRun = v","\t}","\treturn tektonCloudEventData, nil","}","","// EventForObjectWithCondition creates a new event based for an objectWithCondition,","// or returns an error if not possible.","func EventForObjectWithCondition(ctx context.Context, runObject objectWithCondition) (*cloudevents.Event, error) {","\tevent := cloudevents.NewEvent()","\tevent.SetID(uuid.New().String())","\tevent.SetSubject(runObject.GetObjectMeta().GetName())","\t// TODO: SelfLink is deprecated https://github.com/tektoncd/pipeline/issues/2676","\tsource := runObject.GetObjectMeta().GetSelfLink()","\tif source == \"\" {","\t\tgvk := runObject.GetObjectKind().GroupVersionKind()","\t\tsource = fmt.Sprintf(\"/apis/%s/%s/namespaces/%s/%s/%s\",","\t\t\tgvk.Group,","\t\t\tgvk.Version,","\t\t\trunObject.GetObjectMeta().GetNamespace(),","\t\t\tgvk.Kind,","\t\t\trunObject.GetObjectMeta().GetName())","\t}","\tevent.SetSource(source)","\teventType, err := getEventType(runObject)","\tif err != nil {","\t\treturn nil, err","\t}","\tif eventType == nil {","\t\treturn nil, errors.New(\"no matching event type found\")","\t}","\tevent.SetType(eventType.String())","","\ttektonCloudEventData, err := newTektonCloudEventData(ctx, runObject)","\tif err != nil {","\t\treturn nil, err","\t}","","\tif err := event.SetData(cloudevents.ApplicationJSON, tektonCloudEventData); err != nil {","\t\treturn nil, err","\t}","\treturn \u0026event, nil","}","","func getEventType(runObject objectWithCondition) (*TektonEventType, error) {","\tvar eventType TektonEventType","\tc := runObject.GetStatusCondition().GetCondition(apis.ConditionSucceeded)","\tif c == nil {","\t\t// When the `Run` is created, it may not have any condition until it's","\t\t// picked up by the `Run` reconciler. In that case we consider the run","\t\t// as started. In all other cases, conditions have to be initialised","\t\tswitch runObject.(type) {","\t\tcase *v1beta1.CustomRun:","\t\t\teventType = CustomRunStartedEventV1","\t\t\treturn \u0026eventType, nil","\t\tdefault:","\t\t\treturn nil, fmt.Errorf(\"no condition for ConditionSucceeded in %T\", runObject)","\t\t}","\t}","\tswitch {","\tcase c.IsUnknown():","\t\tswitch runObject.(type) {","\t\tcase *v1beta1.TaskRun:","\t\t\tswitch c.Reason {","\t\t\tcase v1beta1.TaskRunReasonStarted.String():","\t\t\t\teventType = TaskRunStartedEventV1","\t\t\tcase v1beta1.TaskRunReasonRunning.String():","\t\t\t\teventType = TaskRunRunningEventV1","\t\t\tdefault:","\t\t\t\teventType = TaskRunUnknownEventV1","\t\t\t}","\t\tcase *v1.TaskRun:","\t\t\tswitch c.Reason {","\t\t\tcase v1.TaskRunReasonStarted.String():","\t\t\t\teventType = TaskRunStartedEventV1","\t\t\tcase v1.TaskRunReasonRunning.String():","\t\t\t\teventType = TaskRunRunningEventV1","\t\t\tdefault:","\t\t\t\teventType = TaskRunUnknownEventV1","\t\t\t}","\t\tcase *v1beta1.PipelineRun:","\t\t\tswitch c.Reason {","\t\t\tcase v1beta1.PipelineRunReasonStarted.String():","\t\t\t\teventType = PipelineRunStartedEventV1","\t\t\tcase v1beta1.PipelineRunReasonRunning.String():","\t\t\t\teventType = PipelineRunRunningEventV1","\t\t\tdefault:","\t\t\t\teventType = PipelineRunUnknownEventV1","\t\t\t}","\t\tcase *v1.PipelineRun:","\t\t\tswitch c.Reason {","\t\t\tcase v1.PipelineRunReasonStarted.String():","\t\t\t\teventType = PipelineRunStartedEventV1","\t\t\tcase v1.PipelineRunReasonRunning.String():","\t\t\t\teventType = PipelineRunRunningEventV1","\t\t\tdefault:","\t\t\t\teventType = PipelineRunUnknownEventV1","\t\t\t}","","\t\tcase *v1beta1.CustomRun:","\t\t\t// CustomRun controller have the freedom of setting reasons as they wish","\t\t\t// so we cannot make many assumptions here. If a condition is set","\t\t\t// to unknown (not finished), we sent the running event","\t\t\teventType = CustomRunRunningEventV1","\t\t}","\tcase c.IsFalse():","\t\tswitch runObject.(type) {","\t\tcase *v1.TaskRun:","\t\t\teventType = TaskRunFailedEventV1","\t\tcase *v1.PipelineRun:","\t\t\teventType = PipelineRunFailedEventV1","\t\tcase *v1beta1.TaskRun:","\t\t\teventType = TaskRunFailedEventV1","\t\tcase *v1beta1.PipelineRun:","\t\t\teventType = PipelineRunFailedEventV1","\t\tcase *v1beta1.CustomRun:","\t\t\teventType = CustomRunFailedEventV1","\t\t}","\tcase c.IsTrue():","\t\tswitch runObject.(type) {","\t\tcase *v1beta1.TaskRun:","\t\t\teventType = TaskRunSuccessfulEventV1","\t\tcase *v1beta1.PipelineRun:","\t\t\teventType = PipelineRunSuccessfulEventV1","\t\tcase *v1.TaskRun:","\t\t\teventType = TaskRunSuccessfulEventV1","\t\tcase *v1.PipelineRun:","\t\t\teventType = PipelineRunSuccessfulEventV1","\t\tcase *v1beta1.CustomRun:","\t\t\teventType = CustomRunSuccessfulEventV1","\t\t}","\tdefault:","\t\treturn nil, fmt.Errorf(\"unknown condition for in %T.Status %s\", runObject, c.Status)","\t}","\treturn \u0026eventType, nil","}","","// GetCloudEventDeliveryCompareOptions returns compare options to sort","// and compare a list of CloudEventDelivery","func GetCloudEventDeliveryCompareOptions() []cmp.Option {","\t// Setup cmp options","\tcloudDeliveryStateCompare := func(x, y v1beta1.CloudEventDeliveryState) bool {","\t\treturn cmp.Equal(x.Condition, y.Condition) \u0026\u0026 cmp.Equal(x.RetryCount, y.RetryCount)","\t}","\tless := func(x, y v1beta1.CloudEventDelivery) bool {","\t\treturn strings.Compare(x.Target, y.Target) \u003c 0 || (strings.Compare(x.Target, y.Target) == 0 \u0026\u0026 x.Status.SentAt.Before(y.Status.SentAt))","\t}","\treturn []cmp.Option{","\t\tcmpopts.SortSlices(less),","\t\tcmp.Comparer(func(x, y v1beta1.CloudEventDelivery) bool {","\t\t\treturn (strings.Compare(x.Target, y.Target) == 0) \u0026\u0026 cloudDeliveryStateCompare(x.Status, y.Status)","\t\t}),","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,1,1,1,1,2,2,2,1,1,2,2,2,2,1,1,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,1,1,0,2,1,1,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,2,2,2,2,1,1,1,1,0,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,2,2,1,1,1,1,2,2,2,2,1,1,0,1,1,0,2,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0]},{"id":178,"path":"pkg/reconciler/events/cloudevent/cloudeventclient.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package cloudevent","","import (","\t\"context\"","\t\"net/http\"","","\tcloudevents \"github.com/cloudevents/sdk-go/v2\"","\t\"github.com/cloudevents/sdk-go/v2/client\"","\t\"github.com/cloudevents/sdk-go/v2/event\"","\t\"github.com/cloudevents/sdk-go/v2/protocol\"","\t\"k8s.io/client-go/rest\"","\t\"knative.dev/pkg/injection\"","\t\"knative.dev/pkg/logging\"",")","","func init() {","\tinjection.Default.RegisterClient(func(ctx context.Context, _ *rest.Config) context.Context {","\t\treturn withCloudEventClient(ctx)","\t})","}","","// ceKey is used to associate the CloudEventClient inside the context.Context","type ceKey struct{}","","func withCloudEventClient(ctx context.Context) context.Context {","\tlogger := logging.FromContext(ctx)","","\t// When KeepAlive is enabled the connections are not reused - see","\t// Bug https://github.com/tektoncd/pipeline/issues/3190. This causes the","\t// number of connections to keep growing, even if when we limit max idle","\t// connections in the transport.","\t// TODO(afrittoli) Re-enable keep alive and ensure connections are reused","\t// See feature https://github.com/tektoncd/pipeline/issues/3204","\tvar useOnceTransport http.RoundTripper = \u0026http.Transport{","\t\tDisableKeepAlives: true,","\t}","","\tp, err := cloudevents.NewHTTP(cloudevents.WithRoundTripper(useOnceTransport))","\tif err != nil {","\t\tlogger.Panicf(\"Error creating the cloudevents http protocol: %s\", err)","\t}","","\tcloudEventClient, err := cloudevents.NewClient(p, cloudevents.WithUUIDs(), cloudevents.WithTimeNow())","\tif err != nil {","\t\tlogger.Panicf(\"Error creating the cloudevents client: %s\", err)","\t}","","\tcelient := CloudClient{","\t\tclient: cloudEventClient,","\t}","\treturn context.WithValue(ctx, ceKey{}, celient)","}","","// CloudClient is a wrapper of CloudEvents client and implements addCount and decreaseCount","type CloudClient struct {","\tclient client.Client","}","","// AddCount does nothing","func (c CloudClient) addCount() {","}","","// DecreaseCount does nothing","func (c CloudClient) decreaseCount() {","}","","// Send invokes call client.Send","func (c CloudClient) Send(ctx context.Context, event cloudevents.Event) protocol.Result {","\treturn c.client.Send(ctx, event)","}","","// Request invokes client.Request","func (c CloudClient) Request(ctx context.Context, event event.Event) (*cloudevents.Event, protocol.Result) {","\treturn c.client.Request(ctx, event)","}","","// StartReceiver invokes client.StartReceiver","func (c CloudClient) StartReceiver(ctx context.Context, fn interface{}) error {","\treturn c.client.StartReceiver(ctx, fn)","}","","// Get extracts the cloudEventClient client from the context.","func Get(ctx context.Context) CEClient {","\tuntyped := ctx.Value(ceKey{})","\tif untyped == nil {","\t\tlogging.FromContext(ctx).Errorf(","\t\t\t\"Unable to fetch client from context.\")","\t\treturn nil","\t}","\treturn untyped.(CEClient)","}","","// ToContext adds the cloud events client to the context","func ToContext(ctx context.Context, cec CEClient) context.Context {","\treturn context.WithValue(ctx, ceKey{}, cec)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,2,2,2,2,2,2,2,2,0,0,0,1,1,1]},{"id":179,"path":"pkg/reconciler/events/cloudevent/cloudeventsfakeclient.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package cloudevent","","import (","\t\"context\"","\t\"fmt\"","\t\"regexp\"","\t\"sync\"","\t\"testing\"","","\tcloudevents \"github.com/cloudevents/sdk-go/v2\"","\t\"github.com/cloudevents/sdk-go/v2/protocol\"",")","","// FakeClientBehaviour defines how the client will behave","type FakeClientBehaviour struct {","\tSendSuccessfully bool","}","","// FakeClient is a fake CloudEvent client for unit testing","// Holding a pointer to the behaviour allows to change the behaviour of a client","type FakeClient struct {","\tbehaviour *FakeClientBehaviour","\t// Modelled after k8s.io/client-go fake recorder","\tevents chan string","\t// waitGroup is used to block until all events have been sent","\twaitGroup *sync.WaitGroup","}","","// newFakeClient is a FakeClient factory, it returns a client for the target","func newFakeClient(behaviour *FakeClientBehaviour, expectedEventCount int) CEClient {","\treturn FakeClient{","\t\tbehaviour: behaviour,","\t\t// set buffersize to length of want events to make sure no extra events are sent","\t\tevents:    make(chan string, expectedEventCount),","\t\twaitGroup: \u0026sync.WaitGroup{},","\t}","}","","var _ cloudevents.Client = (*FakeClient)(nil)","","// Send fakes the Send method from cloudevents.Client","func (c FakeClient) Send(ctx context.Context, event cloudevents.Event) protocol.Result {","\tif c.behaviour.SendSuccessfully {","\t\t// This is to prevent extra events are sent. We don't read events from channel before we call CheckCloudEventsUnordered","\t\tif len(c.events) \u003c cap(c.events) {","\t\t\tc.events \u003c- event.String()","\t\t\treturn nil","\t\t}","\t\treturn fmt.Errorf(\"channel is full of size:%v, but extra event wants to be sent:%v\", cap(c.events), event)","\t}","\treturn fmt.Errorf(\"had to fail. Event ID: %s\", event.ID())","}","","// Request fakes the Request method from cloudevents.Client","func (c FakeClient) Request(ctx context.Context, event cloudevents.Event) (*cloudevents.Event, protocol.Result) {","\tif c.behaviour.SendSuccessfully {","\t\tif len(c.events) \u003c cap(c.events) {","\t\t\tc.events \u003c- event.String()","\t\t\treturn \u0026event, nil","\t\t}","\t\treturn nil, fmt.Errorf(\"channel is full of size:%v, but extra event wants to be sent:%v\", cap(c.events), event)","\t}","\treturn nil, fmt.Errorf(\"had to fail. Event ID: %s\", event.ID())","}","","// StartReceiver fakes StartReceiver method from cloudevents.Client","func (c FakeClient) StartReceiver(ctx context.Context, fn interface{}) error {","\treturn nil","}","","// addCount can be used to add the count when each event is going to be sent","func (c FakeClient) addCount() {","\tc.waitGroup.Add(1)","}","","// decreaseCount can be used to the decrease the count when each event is sent","func (c FakeClient) decreaseCount() {","\tc.waitGroup.Done()","}","","// WithFakeClient adds to the context a fake client with the desired behaviour and expectedEventCount","func WithFakeClient(ctx context.Context, behaviour *FakeClientBehaviour, expectedEventCount int) context.Context {","\treturn context.WithValue(ctx, ceKey{}, newFakeClient(behaviour, expectedEventCount))","}","","// CheckCloudEventsUnordered checks that all events in wantEvents, and no others,","// were received via the given chan, in any order.","// Block until all events have been sent.","func (c *FakeClient) CheckCloudEventsUnordered(t *testing.T, testName string, wantEvents []string) {","\tt.Helper()","\tc.waitGroup.Wait()","\texpected := append([]string{}, wantEvents...)","\tchannelEvents := len(c.events)","","\t// extra events are prevented in FakeClient's Send function.","\t// fewer events are detected because we collect all events from channel and compare with wantEvents","","\tfor range channelEvents {","\t\tevent := \u003c-c.events","\t\tif len(expected) == 0 {","\t\t\tt.Errorf(\"extra event received: %q\", event)","\t\t}","\t\tfound := false","\t\tfor wantIdx, want := range expected {","\t\t\tmatching, err := regexp.MatchString(want, event)","\t\t\tif err != nil {","\t\t\t\tt.Errorf(\"something went wrong matching an event: %s\", err)","\t\t\t}","\t\t\tif matching {","\t\t\t\tfound = true","\t\t\t\t// Remove event from list of those we expect to receive","\t\t\t\texpected[wantIdx] = expected[len(expected)-1]","\t\t\t\texpected = expected[:len(expected)-1]","\t\t\t\tbreak","\t\t\t}","\t\t}","\t\tif !found {","\t\t\tt.Errorf(\"unexpected event received: %q\", event)","\t\t}","\t}","\tif len(expected) != 0 {","\t\tt.Errorf(\"%d events %#v are not received\", len(expected), expected)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,0,1,1,1,1,1,1,1,0,1,0,0,0,1,1,1,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,1,1,2,2,2,2,2,2,0,0,2,1,1,0,2,1,1,0]},{"id":180,"path":"pkg/reconciler/events/event.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package events","","import (","\t\"context\"","","\t\"github.com/tektoncd/pipeline/pkg/reconciler/events/cloudevent\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/events/k8sevent\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"knative.dev/pkg/apis\"",")","","// Emit emits events for object","// Two types of events are supported, k8s and cloud events.","//","// k8s events are always sent if afterCondition is different from beforeCondition","// Cloud events are always sent if enabled, i.e. if a sink is available","func Emit(ctx context.Context, beforeCondition *apis.Condition, afterCondition *apis.Condition, object runtime.Object) {","\tk8sevent.EmitK8sEvents(ctx, beforeCondition, afterCondition, object)","\tcloudevent.EmitCloudEventsWhenConditionChange(ctx, beforeCondition, afterCondition, object)","}","","// EmitCloudEvents is refactored to cloudevent, this is to avoid breaking change","var EmitCloudEvents = cloudevent.EmitCloudEvents","","// EmitError is refactored to k8sevent, this is to avoid breaking change","var EmitError = k8sevent.EmitError"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,0,0,0,0,0]},{"id":181,"path":"pkg/reconciler/events/k8sevent/event.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package k8sevent","","import (","\t\"context\"","","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/api/equality\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/client-go/tools/record\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/controller\"",")","","const (","\t// EventReasonSucceded is the reason set for events about successful completion of TaskRuns / PipelineRuns","\tEventReasonSucceded = \"Succeeded\"","\t// EventReasonFailed is the reason set for events about unsuccessful completion of TaskRuns / PipelineRuns","\tEventReasonFailed = \"Failed\"","\t// EventReasonStarted is the reason set for events about the start of TaskRuns / PipelineRuns","\tEventReasonStarted = \"Started\"","\t// EventReasonError is the reason set for events related to TaskRuns / PipelineRuns reconcile errors","\tEventReasonError = \"Error\"",")","","// EmitK8sEvents emits kubernetes events for object","// k8s events are always sent if afterCondition is different from beforeCondition","func EmitK8sEvents(ctx context.Context, beforeCondition *apis.Condition, afterCondition *apis.Condition, object runtime.Object) {","\trecorder := controller.GetEventRecorder(ctx)","\t// Events that are going to be sent","\t//","\t// Status \"ConditionUnknown\":","\t//   beforeCondition == nil, emit EventReasonStarted","\t//   beforeCondition != nil, emit afterCondition.Reason","\t//","\t//  Status \"ConditionTrue\": emit EventReasonSucceded","\t//  Status \"ConditionFalse\": emit EventReasonFailed","\tif !equality.Semantic.DeepEqual(beforeCondition, afterCondition) \u0026\u0026 afterCondition != nil {","\t\t// If the condition changed, and the target condition is not empty, we send an event","\t\tswitch afterCondition.Status {","\t\tcase corev1.ConditionTrue:","\t\t\trecorder.Event(object, corev1.EventTypeNormal, EventReasonSucceded, afterCondition.Message)","\t\tcase corev1.ConditionFalse:","\t\t\trecorder.Event(object, corev1.EventTypeWarning, EventReasonFailed, afterCondition.Message)","\t\tcase corev1.ConditionUnknown:","\t\t\tif beforeCondition == nil {","\t\t\t\t// If the condition changed, the status is \"unknown\", and there was no condition before,","\t\t\t\t// we emit the \"Started event\". We ignore further updates of the \"unknown\" status.","\t\t\t\trecorder.Event(object, corev1.EventTypeNormal, EventReasonStarted, \"\")","\t\t\t} else {","\t\t\t\t// If the condition changed, the status is \"unknown\", and there was a condition before,","\t\t\t\t// we emit an event that matches the reason and message of the condition.","\t\t\t\t// This is used for instance to signal the transition from \"started\" to \"running\"","\t\t\t\trecorder.Event(object, corev1.EventTypeNormal, afterCondition.Reason, afterCondition.Message)","\t\t\t}","\t\t}","\t}","}","","// EmitError emits a failure associated to an error","func EmitError(c record.EventRecorder, err error, object runtime.Object) {","\tif err != nil {","\t\tc.Event(object, corev1.EventTypeWarning, EventReasonError, err.Error())","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,0]},{"id":182,"path":"pkg/reconciler/events/k8sevent/events.go","lines":["/*","Copyright 2021 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","package k8sevent","","import (","\t\"fmt\"","\t\"regexp\"","\t\"testing\"","\t\"time\"","","\t\"k8s.io/apimachinery/pkg/util/wait\"",")","","// CheckEventsOrdered checks that the events received via the given chan are the same as wantEvents,","// in the same order.","func CheckEventsOrdered(t *testing.T, eventChan chan string, testName string, wantEvents []string) error {","\tt.Helper()","\terr := eventsFromChannel(eventChan, wantEvents)","\tif err != nil {","\t\treturn fmt.Errorf(\"error in test %s: %w\", testName, err)","\t}","\treturn nil","}","","// eventsFromChannel takes a chan of string, a test name, and a list of events that a test","// expects to receive. The events must be received in the same order they appear in the","// wantEvents list. Any extra or too few received events are considered errors.","func eventsFromChannel(c chan string, wantEvents []string) error {","\t// We get events from a channel, so the timeout is here to avoid waiting","\t// on the channel forever if fewer than expected events are received.","\t// We only hit the timeout in case of failure of the test, so the actual value","\t// of the timeout is not so relevant, it's only used when tests are going to fail.","\t// on the channel forever if fewer than expected events are received","\ttimer := time.After(wait.ForeverTestTimeout)","\tfoundEvents := []string{}","\tfor ii := range wantEvents {","\t\t// We loop over all the events that we expect. Once they are all received","\t\t// we exit the loop. If we never receive enough events, the timeout takes us","\t\t// out of the loop.","\t\tselect {","\t\tcase event := \u003c-c:","\t\t\tfoundEvents = append(foundEvents, event)","\t\t\twantEvent := wantEvents[ii]","\t\t\t// If the event is an exact match, there is no need to use regular expressions for matching.","\t\t\t// This can avoid the need to escape special characters, such as *, in the event to match.","\t\t\tif wantEvent == event {","\t\t\t\tcontinue","\t\t\t}","\t\t\tmatching, err := regexp.MatchString(wantEvent, event)","\t\t\tif err == nil {","\t\t\t\tif !matching {","\t\t\t\t\treturn fmt.Errorf(\"expected event \\\"%s\\\" but got \\\"%s\\\" instead\", wantEvent, event)","\t\t\t\t}","\t\t\t} else {","\t\t\t\treturn fmt.Errorf(\"something went wrong matching the event: %w\", err)","\t\t\t}","\t\tcase \u003c-timer:","\t\t\treturn fmt.Errorf(\"received %d events but %d expected. Found events: %#v\", len(foundEvents), len(wantEvents), foundEvents)","\t\t}","\t}","\t// Check if there are extra events in the channel, return error if found.","\tfor {","\t\tselect {","\t\tcase event := \u003c-c:","\t\t\treturn fmt.Errorf(\"unexpected event: %q\", event)","\t\tdefault:","\t\t\treturn nil","\t\t}","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,1,1,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,1,1,1,1,1,1,1,0,0,0,2,2,1,1,2,2,0,0,0]},{"id":183,"path":"pkg/reconciler/notifications/customrun/controller.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package customrun","","import (","\t\"context\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tcustomruninformer \"github.com/tektoncd/pipeline/pkg/client/injection/informers/pipeline/v1beta1/customrun\"","\tcustomrunreconciler \"github.com/tektoncd/pipeline/pkg/client/injection/reconciler/pipeline/v1beta1/customrun\"","\tcacheclient \"github.com/tektoncd/pipeline/pkg/reconciler/events/cache\"","\tcloudeventclient \"github.com/tektoncd/pipeline/pkg/reconciler/events/cloudevent\"","\t\"knative.dev/pkg/configmap\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/logging\"",")","","// NewController instantiates a new controller.Impl from knative.dev/pkg/controller","// This is a read-only controller, hence the SkipStatusUpdates set to true","func NewController() func(context.Context, configmap.Watcher) *controller.Impl {","\treturn func(ctx context.Context, cmw configmap.Watcher) *controller.Impl {","\t\tlogger := logging.FromContext(ctx)","\t\tcustomRunInformer := customruninformer.Get(ctx)","","\t\tconfigStore := config.NewStore(logger.Named(\"config-store\"))","\t\tconfigStore.WatchConfigs(cmw)","","\t\tc := \u0026Reconciler{","\t\t\tcloudEventClient: cloudeventclient.Get(ctx),","\t\t\tcacheClient:      cacheclient.Get(ctx),","\t\t}","\t\timpl := customrunreconciler.NewImpl(ctx, c, func(impl *controller.Impl) controller.Options {","\t\t\treturn controller.Options{","\t\t\t\tAgentName:         pipeline.CustomRunControllerName,","\t\t\t\tConfigStore:       configStore,","\t\t\t\tSkipStatusUpdates: true,","\t\t\t}","\t\t})","","\t\tif _, err := customRunInformer.Informer().AddEventHandler(controller.HandleAll(impl.Enqueue)); err != nil {","\t\t\tlogging.FromContext(ctx).Panicf(\"Couldn't register CustomRun informer event handler: %w\", err)","\t\t}","","\t\treturn impl","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,1,1,0,2,0,0]},{"id":184,"path":"pkg/reconciler/notifications/customrun/customrun.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package customrun","","import (","\t\"context\"","","\tlru \"github.com/hashicorp/golang-lru\"","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\tcustomrunreconciler \"github.com/tektoncd/pipeline/pkg/client/injection/reconciler/pipeline/v1beta1/customrun\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/events\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/events/cache\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/events/cloudevent\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/logging\"","\tpkgreconciler \"knative.dev/pkg/reconciler\"",")","","// Reconciler implements controller.Reconciler for Configuration resources.","type Reconciler struct {","\tcloudEventClient cloudevent.CEClient","\tcacheClient      *lru.Cache","}","","// Check that our Reconciler implements customrunreconciler.Interface","var (","\t_ customrunreconciler.Interface = (*Reconciler)(nil)",")","","// ReconcileKind compares the actual state with the desired, and attempts to","// converge the two. It then updates the Status block of the CustomRun","// resource with the current status of the resource.","func (c *Reconciler) ReconcileKind(ctx context.Context, customRun *v1beta1.CustomRun) pkgreconciler.Event {","\tlogger := logging.FromContext(ctx)","\tconfigs := config.FromContextOrDefaults(ctx)","\tctx = cloudevent.ToContext(ctx, c.cloudEventClient)","\tctx = cache.ToContext(ctx, c.cacheClient)","\tlogger.Infof(\"Reconciling %s\", customRun.Name)","","\t// Create a copy of the CustomRun object, just in case, to avoid sync'ing changes","\tcustomRunEvents := *customRun.DeepCopy()","","\tif configs.FeatureFlags.SendCloudEventsForRuns {","\t\t// Custom task controllers may be sending events for \"CustomRuns\" associated","\t\t// to the custom tasks they control. To avoid sending duplicate events,","\t\t// CloudEvents for \"CustomRuns\" are only sent when enabled","","\t\t// Read and log the condition","\t\tcondition := customRunEvents.Status.GetCondition(apis.ConditionSucceeded)","\t\tlogger.Debugf(\"Emitting cloudevent for %s, condition: %s\", customRunEvents.Name, condition)","","\t\tevents.EmitCloudEvents(ctx, \u0026customRunEvents)","\t}","","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0]},{"id":185,"path":"pkg/reconciler/pipeline/dag/dag.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package dag","","import (","\t\"errors\"","\t\"fmt\"","\t\"sort\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/list\"","\t\"k8s.io/apimachinery/pkg/util/sets\"",")","","// Task is an interface for all types that could be in a DAG","type Task interface {","\tHashKey() string","\tDeps() []string","}","","// Tasks is an interface for lists of types that could be in a DAG","type Tasks interface {","\tItems() []Task","}","","// Node represents a Task in a pipeline.","type Node struct {","\t// Key represent a unique name of the node in a graph","\tKey string","\t// Prev represent all the Previous task Nodes for the current Task","\tPrev []*Node","\t// Next represent all the Next task Nodes for the current Task","\tNext []*Node","}","","// Graph represents the Pipeline Graph","type Graph struct {","\t// Nodes represent map of PipelineTask name to Node in Pipeline Graph","\tNodes map[string]*Node","}","","// Returns an empty Pipeline Graph","func newGraph() *Graph {","\treturn \u0026Graph{Nodes: map[string]*Node{}}","}","","func (g *Graph) addPipelineTask(t Task) (*Node, error) {","\tif _, ok := g.Nodes[t.HashKey()]; ok {","\t\treturn nil, errors.New(\"duplicate pipeline task\")","\t}","\tnewNode := \u0026Node{","\t\tKey: t.HashKey(),","\t}","\tg.Nodes[t.HashKey()] = newNode","\treturn newNode, nil","}","","// Build returns a valid pipeline Graph. Returns error if the pipeline is invalid","func Build(tasks Tasks, deps map[string][]string) (*Graph, error) {","\td := newGraph()","","\t// Add all Tasks mentioned in the `PipelineSpec`","\tfor _, pt := range tasks.Items() {","\t\tif _, err := d.addPipelineTask(pt); err != nil {","\t\t\treturn nil, fmt.Errorf(\"task %s is already present in Graph, can't add it again: %w\", pt.HashKey(), err)","\t\t}","\t}","","\t// Ensure no cycles in the graph","\tif err := findCyclesInDependencies(deps); err != nil {","\t\treturn nil, fmt.Errorf(\"cycle detected; %w\", err)","\t}","","\t// Process all from and runAfter constraints to add task dependency","\tfor pt, taskDeps := range deps {","\t\tfor _, previousTask := range taskDeps {","\t\t\tif err := addLink(pt, previousTask, d.Nodes); err != nil {","\t\t\t\treturn nil, fmt.Errorf(\"couldn't add link between %s and %s: %w\", pt, previousTask, err)","\t\t\t}","\t\t}","\t}","\treturn d, nil","}","","// GetCandidateTasks returns a set of names of PipelineTasks whose ancestors are all completed,","// given a list of finished doneTasks. If the specified","// doneTasks are invalid (i.e. if it is indicated that a Task is done, but the","// previous Tasks are not done), an error is returned.","func GetCandidateTasks(g *Graph, doneTasks ...string) (sets.String, error) {","\troots := getRoots(g)","\ttm := sets.NewString(doneTasks...)","\td := sets.NewString()","","\tvisited := sets.NewString()","\tfor _, root := range roots {","\t\tschedulable := findSchedulable(root, visited, tm)","\t\tfor _, taskName := range schedulable {","\t\t\td.Insert(taskName)","\t\t}","\t}","","\tvar visitedNames []string","\tfor v := range visited {","\t\tvisitedNames = append(visitedNames, v)","\t}","","\tnotVisited := list.DiffLeft(doneTasks, visitedNames)","\tif len(notVisited) \u003e 0 {","\t\treturn nil, fmt.Errorf(\"invalid list of done tasks; some tasks were indicated completed without ancestors being done: %v\", notVisited)","\t}","","\treturn d, nil","}","","func linkPipelineTasks(prev *Node, next *Node) {","\tnext.Prev = append(next.Prev, prev)","\tprev.Next = append(prev.Next, next)","}","","// use Kahn's algorithm to find cycles in dependencies","func findCyclesInDependencies(deps map[string][]string) error {","\tindependentTasks := sets.NewString()","\tdag := make(map[string]sets.String, len(deps))","\tchildMap := make(map[string]sets.String, len(deps))","\tfor task, taskDeps := range deps {","\t\tif len(taskDeps) == 0 {","\t\t\tcontinue","\t\t}","\t\tdag[task] = sets.NewString(taskDeps...)","\t\tfor _, dep := range taskDeps {","\t\t\tif len(deps[dep]) == 0 {","\t\t\t\tindependentTasks.Insert(dep)","\t\t\t}","\t\t\tif children, ok := childMap[dep]; ok {","\t\t\t\tchildren.Insert(task)","\t\t\t} else {","\t\t\t\tchildMap[dep] = sets.NewString(task)","\t\t\t}","\t\t}","\t}","","\tfor {","\t\tparent, ok := independentTasks.PopAny()","\t\tif !ok {","\t\t\tbreak","\t\t}","\t\tchildren := childMap[parent]","\t\tfor {","\t\t\tchild, ok := children.PopAny()","\t\t\tif !ok {","\t\t\t\tbreak","\t\t\t}","\t\t\tdag[child].Delete(parent)","\t\t\tif dag[child].Len() == 0 {","\t\t\t\tindependentTasks.Insert(child)","\t\t\t\tdelete(dag, child)","\t\t\t}","\t\t}","\t}","","\treturn getInterdependencyError(dag)","}","","func getInterdependencyError(dag map[string]sets.String) error {","\tif len(dag) == 0 {","\t\treturn nil","\t}","\tfirstChild := \"\"","\tfor task := range dag {","\t\tif firstChild == \"\" || firstChild \u003e task {","\t\t\tfirstChild = task","\t\t}","\t}","\tdeps := dag[firstChild].List()","\tdepNames := make([]string, 0, len(deps))","\tsort.Strings(deps)","\tfor _, dep := range deps {","\t\tdepNames = append(depNames, fmt.Sprintf(\"%q\", dep))","\t}","\treturn fmt.Errorf(\"task %q depends on %s\", firstChild, strings.Join(depNames, \", \"))","}","","func addLink(pt string, previousTask string, nodes map[string]*Node) error {","\tprev, ok := nodes[previousTask]","\tif !ok {","\t\treturn fmt.Errorf(\"task %s depends on %s but %s wasn't present in Pipeline\", pt, previousTask, previousTask)","\t}","\tnext := nodes[pt]","\tlinkPipelineTasks(prev, next)","\treturn nil","}","","func getRoots(g *Graph) []*Node {","\tn := []*Node{}","\tfor _, node := range g.Nodes {","\t\tif len(node.Prev) == 0 {","\t\t\tn = append(n, node)","\t\t}","\t}","\treturn n","}","","func findSchedulable(n *Node, visited sets.String, doneTasks sets.String) []string {","\tif visited.Has(n.Key) {","\t\treturn []string{}","\t}","\tvisited.Insert(n.Key)","\tif doneTasks.Has(n.Key) {","\t\tschedulable := []string{}","\t\t// This one is done! Take note of it and look at the next candidate","\t\tfor _, next := range n.Next {","\t\t\tif _, ok := visited[next.Key]; !ok {","\t\t\t\tschedulable = append(schedulable, findSchedulable(next, visited, doneTasks)...)","\t\t\t}","\t\t}","\t\treturn schedulable","\t}","\t// This one isn't done! Return it if it's schedulable","\tif isSchedulable(doneTasks, n.Prev) {","\t\t// FIXME(vdemeester)","\t\treturn []string{n.Key}","\t}","\t// This one isn't done, but it also isn't ready to schedule","\treturn []string{}","}","","func isSchedulable(doneTasks sets.String, prevs []*Node) bool {","\tif len(prevs) == 0 {","\t\treturn true","\t}","\tcollected := []string{}","\tfor _, n := range prevs {","\t\tif doneTasks.Has(n.Key) {","\t\t\tcollected = append(collected, n.Key)","\t\t}","\t}","\treturn len(collected) == len(prevs)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,0,0,2,2,2,2,2,0,0,2,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,2,2,2,2,0,2,0,0,2,2,2,2,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,0,0,0,2,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,2,0,0,2,2,1,1,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,0,2,0]},{"id":186,"path":"pkg/reconciler/pipelinerun/affinity_assistant.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pipelinerun","","import (","\t\"context\"","\t\"crypto/sha256\"","\t\"encoding/hex\"","\t\"errors\"","\t\"fmt\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/pod\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/internal/affinityassistant\"","\taa \"github.com/tektoncd/pipeline/pkg/internal/affinityassistant\"","\tpipelinePod \"github.com/tektoncd/pipeline/pkg/pod\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/volumeclaim\"","\t\"github.com/tektoncd/pipeline/pkg/workspace\"","\tappsv1 \"k8s.io/api/apps/v1\"","\tcorev1 \"k8s.io/api/core/v1\"","\tapierrors \"k8s.io/apimachinery/pkg/api/errors\"","\t\"k8s.io/apimachinery/pkg/api/resource\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\terrorutils \"k8s.io/apimachinery/pkg/util/errors\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"knative.dev/pkg/kmeta\"","\t\"knative.dev/pkg/logging\"",")","","const (","\t// ReasonCouldntCreateOrUpdateAffinityAssistantStatefulSet indicates that a PipelineRun uses workspaces with PersistentVolumeClaim","\t// as a volume source and expect an Assistant StatefulSet in AffinityAssistantPerWorkspace behavior, but couldn't create a StatefulSet.","\tReasonCouldntCreateOrUpdateAffinityAssistantStatefulSet = \"ReasonCouldntCreateOrUpdateAffinityAssistantStatefulSet\"",")","","var (","\t// Deprecated: use volumeclain.ErrPvcCreationFailed instead","\tErrPvcCreationFailed = volumeclaim.ErrPvcCreationFailed","\t// Deprecated: use volumeclaim.ErrAffinityAssistantCreationFailed instead","\tErrPvcCreationFailedRetryable      = volumeclaim.ErrPvcCreationFailedRetryable","\tErrAffinityAssistantCreationFailed = errors.New(\"Affinity Assistant creation error\")",")","","// createOrUpdateAffinityAssistantsAndPVCs creates Affinity Assistant StatefulSets and PVCs based on AffinityAssistantBehavior.","// This is done to achieve Node Affinity for taskruns in a pipelinerun, and make it possible for the taskruns to execute parallel while sharing volume.","// If the AffinityAssistantBehavior is AffinityAssistantPerWorkspace, it creates an Affinity Assistant for","// every taskrun in the pipelinerun that use the same PVC based volume.","// If the AffinityAssistantBehavior is AffinityAssistantPerPipelineRun or AffinityAssistantPerPipelineRunWithIsolation,","// it creates one Affinity Assistant for the pipelinerun.","func (c *Reconciler) createOrUpdateAffinityAssistantsAndPVCs(ctx context.Context, pr *v1.PipelineRun, aaBehavior aa.AffinityAssistantBehavior) error {","\tvar unschedulableNodes sets.Set[string] = nil","","\tvar claimTemplates []corev1.PersistentVolumeClaim","\tvar claimNames []string","\tclaimNameToWorkspaceName := map[string]string{}","\tclaimTemplateToWorkspace := map[*corev1.PersistentVolumeClaim]v1.WorkspaceBinding{}","","\tfor _, w := range pr.Spec.Workspaces {","\t\tif w.PersistentVolumeClaim == nil \u0026\u0026 w.VolumeClaimTemplate == nil {","\t\t\tcontinue","\t\t}","\t\tif w.PersistentVolumeClaim != nil {","\t\t\tclaim := w.PersistentVolumeClaim","\t\t\tclaimNames = append(claimNames, claim.ClaimName)","\t\t\tclaimNameToWorkspaceName[claim.ClaimName] = w.Name","\t\t} else if w.VolumeClaimTemplate != nil {","\t\t\tclaimTemplate := w.VolumeClaimTemplate.DeepCopy()","\t\t\tclaimTemplate.Name = volumeclaim.GeneratePVCNameFromWorkspaceBinding(w.VolumeClaimTemplate.Name, w, *kmeta.NewControllerRef(pr))","\t\t\tclaimTemplates = append(claimTemplates, *claimTemplate)","\t\t\tclaimTemplateToWorkspace[claimTemplate] = w","\t\t}","\t}","\tswitch aaBehavior {","\tcase aa.AffinityAssistantPerWorkspace:","\t\tfor claimName, workspaceName := range claimNameToWorkspaceName {","\t\t\taaName := GetAffinityAssistantName(workspaceName, pr.Name)","\t\t\tif err := c.createOrUpdateAffinityAssistant(ctx, aaName, pr, nil, []string{claimName}, unschedulableNodes); err != nil {","\t\t\t\treturn fmt.Errorf(\"%w: %v\", ErrAffinityAssistantCreationFailed, err)","\t\t\t}","\t\t}","\t\tfor claimTemplate, workspace := range claimTemplateToWorkspace {","\t\t\t// To support PVC auto deletion at pipelinerun deletion time, the OwnerReference of the PVCs should be set to the owning pipelinerun instead of the StatefulSets,","\t\t\t// so we create PVCs from PipelineRuns' VolumeClaimTemplate and pass the PVCs to the Affinity Assistant StatefulSet for volume scheduling.","\t\t\tif err := c.pvcHandler.CreatePVCFromVolumeClaimTemplate(ctx, workspace, *kmeta.NewControllerRef(pr), pr.Namespace); err != nil {","\t\t\t\treturn err","\t\t\t}","\t\t\taaName := GetAffinityAssistantName(workspace.Name, pr.Name)","\t\t\tif err := c.createOrUpdateAffinityAssistant(ctx, aaName, pr, nil, []string{claimTemplate.Name}, unschedulableNodes); err != nil {","\t\t\t\treturn fmt.Errorf(\"%w: %v\", ErrAffinityAssistantCreationFailed, err)","\t\t\t}","\t\t}","\tcase aa.AffinityAssistantPerPipelineRun, aa.AffinityAssistantPerPipelineRunWithIsolation:","\t\taaName := GetAffinityAssistantName(\"\", pr.Name)","\t\t// The PVCs are created via StatefulSet's VolumeClaimTemplate for volume scheduling","\t\t// in AffinityAssistantPerPipelineRun or AffinityAssistantPerPipelineRunWithIsolation modes.","\t\t// This is because PVCs from pipelinerun's VolumeClaimTemplate are enforced to be deleted at pipelinerun completion time in these modes,","\t\t// and there is no requirement of the PVC OwnerReference.","\t\tif err := c.createOrUpdateAffinityAssistant(ctx, aaName, pr, claimTemplates, claimNames, unschedulableNodes); err != nil {","\t\t\treturn fmt.Errorf(\"%w: %v\", ErrAffinityAssistantCreationFailed, err)","\t\t}","\tcase aa.AffinityAssistantDisabled:","\t\tfor _, workspace := range claimTemplateToWorkspace {","\t\t\tif err := c.pvcHandler.CreatePVCFromVolumeClaimTemplate(ctx, workspace, *kmeta.NewControllerRef(pr), pr.Namespace); err != nil {","\t\t\t\treturn err","\t\t\t}","\t\t}","\t}","","\treturn nil","}","","// createOrUpdateAffinityAssistant creates an Affinity Assistant Statefulset with the provided affinityAssistantName and pipelinerun information.","// The VolumeClaimTemplates and Volumes of StatefulSet reference the resolved claimTemplates and claims respectively.","// It maintains a set of unschedulableNodes to detect and recreate Affinity Assistant in case of the node is cordoned to avoid pipelinerun deadlock.","func (c *Reconciler) createOrUpdateAffinityAssistant(ctx context.Context, affinityAssistantName string, pr *v1.PipelineRun, claimTemplates []corev1.PersistentVolumeClaim, claimNames []string, unschedulableNodes sets.Set[string]) []error {","\tlogger := logging.FromContext(ctx)","\tcfg := config.FromContextOrDefaults(ctx)","","\tvar errs []error","\ta, err := c.KubeClientSet.AppsV1().StatefulSets(pr.Namespace).Get(ctx, affinityAssistantName, metav1.GetOptions{})","\tswitch {","\t// check whether the affinity assistant (StatefulSet) exists or not, create one if it does not exist","\tcase apierrors.IsNotFound(err):","\t\taaBehavior, err := aa.GetAffinityAssistantBehavior(ctx)","\t\tif err != nil {","\t\t\treturn []error{err}","\t\t}","","\t\tsecurityContextConfig := pipelinePod.SecurityContextConfig{","\t\t\tSetSecurityContext:        cfg.FeatureFlags.SetSecurityContext,","\t\t\tSetReadOnlyRootFilesystem: cfg.FeatureFlags.SetSecurityContextReadOnlyRootFilesystem,","\t\t}","","\t\tcontainerConfig := aa.ContainerConfig{","\t\t\tImage:                 c.Images.NopImage,","\t\t\tSecurityContextConfig: securityContextConfig,","\t\t}","","\t\taffinityAssistantStatefulSet := affinityAssistantStatefulSet(aaBehavior, affinityAssistantName, pr, claimTemplates, claimNames, containerConfig, cfg.Defaults.DefaultAAPodTemplate)","\t\t_, err = c.KubeClientSet.AppsV1().StatefulSets(pr.Namespace).Create(ctx, affinityAssistantStatefulSet, metav1.CreateOptions{})","\t\tif err != nil {","\t\t\terrs = append(errs, fmt.Errorf(\"failed to create StatefulSet %s: %w\", affinityAssistantName, err))","\t\t}","\t\tif err == nil {","\t\t\tlogger.Infof(\"Created StatefulSet %s in namespace %s\", affinityAssistantName, pr.Namespace)","\t\t}","\t// check whether the affinity assistant (StatefulSet) exists and the affinity assistant pod is created","\t// this check requires the StatefulSet to have the readyReplicas set to 1 to allow for any delay between the StatefulSet creation","\t// and the necessary pod creation, the delay can be caused by any dependency on PVCs and PVs creation","\t// this case addresses issues specified in https://github.com/tektoncd/pipeline/issues/6586","\tcase err == nil \u0026\u0026 a != nil \u0026\u0026 a.Status.ReadyReplicas == 1:","\t\tif unschedulableNodes == nil {","\t\t\tns, err := c.KubeClientSet.CoreV1().Nodes().List(ctx, metav1.ListOptions{","\t\t\t\tFieldSelector: \"spec.unschedulable=true\",","\t\t\t})","\t\t\tif err != nil {","\t\t\t\terrs = append(errs, fmt.Errorf(\"could not get the list of nodes, err: %w\", err))","\t\t\t}","\t\t\tunschedulableNodes = sets.Set[string]{}","\t\t\t// maintain the list of nodes which are unschedulable","\t\t\tfor _, n := range ns.Items {","\t\t\t\tunschedulableNodes.Insert(n.Name)","\t\t\t}","\t\t}","\t\tif unschedulableNodes.Len() \u003e 0 {","\t\t\t// get the pod created for a given StatefulSet, pod is assigned ordinal of 0 with the replicas set to 1","\t\t\tp, err := c.KubeClientSet.CoreV1().Pods(pr.Namespace).Get(ctx, a.Name+\"-0\", metav1.GetOptions{})","\t\t\t// ignore instead of failing if the affinity assistant pod was not found","\t\t\tif err != nil \u0026\u0026 !apierrors.IsNotFound(err) {","\t\t\t\terrs = append(errs, fmt.Errorf(\"could not get the affinity assistant pod for StatefulSet %s: %w\", a.Name, err))","\t\t\t}","\t\t\t// check the node which hosts the affinity assistant pod if it is unschedulable or cordoned","\t\t\tif p != nil \u0026\u0026 unschedulableNodes.Has(p.Spec.NodeName) {","\t\t\t\t// if the node is unschedulable, delete the affinity assistant pod such that a StatefulSet can recreate the same pod on a different node","\t\t\t\terr = c.KubeClientSet.CoreV1().Pods(p.Namespace).Delete(ctx, p.Name, metav1.DeleteOptions{})","\t\t\t\tif err != nil {","\t\t\t\t\terrs = append(errs, fmt.Errorf(\"error deleting affinity assistant pod %s in ns %s: %w\", p.Name, p.Namespace, err))","\t\t\t\t}","\t\t\t}","\t\t}","\tcase err != nil:","\t\terrs = append(errs, fmt.Errorf(\"failed to retrieve StatefulSet %s: %w\", affinityAssistantName, err))","\t}","","\treturn errs","}","","// cleanupAffinityAssistantsAndPVCs deletes Affinity Assistant StatefulSets and PVCs created from VolumeClaimTemplates","func (c *Reconciler) cleanupAffinityAssistantsAndPVCs(ctx context.Context, pr *v1.PipelineRun) error {","\taaBehavior, err := aa.GetAffinityAssistantBehavior(ctx)","\tif err != nil {","\t\treturn err","\t}","","\tvar errs []error","\tswitch aaBehavior {","\tcase aa.AffinityAssistantPerWorkspace:","\t\t// TODO (#5776): support optional PVC deletion behavior for per-workspace mode","\t\tfor _, w := range pr.Spec.Workspaces {","\t\t\tif w.PersistentVolumeClaim != nil || w.VolumeClaimTemplate != nil {","\t\t\t\taffinityAssistantName := GetAffinityAssistantName(w.Name, pr.Name)","\t\t\t\tif err := c.KubeClientSet.AppsV1().StatefulSets(pr.Namespace).Delete(ctx, affinityAssistantName, metav1.DeleteOptions{}); err != nil \u0026\u0026 !apierrors.IsNotFound(err) {","\t\t\t\t\terrs = append(errs, fmt.Errorf(\"failed to delete StatefulSet %s: %w\", affinityAssistantName, err))","\t\t\t\t}","\t\t\t}","\t\t}","\tcase aa.AffinityAssistantPerPipelineRun, aa.AffinityAssistantPerPipelineRunWithIsolation:","\t\taffinityAssistantName := GetAffinityAssistantName(\"\", pr.Name)","\t\tif err := c.KubeClientSet.AppsV1().StatefulSets(pr.Namespace).Delete(ctx, affinityAssistantName, metav1.DeleteOptions{}); err != nil \u0026\u0026 !apierrors.IsNotFound(err) {","\t\t\terrs = append(errs, fmt.Errorf(\"failed to delete StatefulSet %s: %w\", affinityAssistantName, err))","\t\t}","","\t\t// cleanup PVCs created by Affinity Assistants","\t\tfor _, w := range pr.Spec.Workspaces {","\t\t\tif w.VolumeClaimTemplate != nil {","\t\t\t\tpvcName := getPersistentVolumeClaimNameWithAffinityAssistant(\"\", pr.Name, w, *kmeta.NewControllerRef(pr))","\t\t\t\tif err := c.pvcHandler.PurgeFinalizerAndDeletePVCForWorkspace(ctx, pvcName, pr.Namespace); err != nil {","\t\t\t\t\terrs = append(errs, err)","\t\t\t\t}","\t\t\t}","\t\t}","\tcase aa.AffinityAssistantDisabled:","\t\treturn nil","\t}","","\treturn errorutils.NewAggregate(errs)","}","","// getPersistentVolumeClaimNameWithAffinityAssistant returns the PersistentVolumeClaim name that is","// created by the Affinity Assistant StatefulSet VolumeClaimTemplate when Affinity Assistant is enabled.","// The PVCs created by StatefulSet VolumeClaimTemplates follow the format `\u003cpvcName\u003e-\u003caffinityAssistantName\u003e-0`","func getPersistentVolumeClaimNameWithAffinityAssistant(pipelineWorkspaceName, prName string, wb v1.WorkspaceBinding, owner metav1.OwnerReference) string {","\tpvcName := volumeclaim.GeneratePVCNameFromWorkspaceBinding(wb.VolumeClaimTemplate.Name, wb, owner)","\taffinityAssistantName := GetAffinityAssistantName(pipelineWorkspaceName, prName)","\treturn fmt.Sprintf(\"%s-%s-0\", pvcName, affinityAssistantName)","}","","// getAffinityAssistantAnnotationVal generates and returns the value for `pipeline.tekton.dev/affinity-assistant` annotation","// based on aaBehavior, pipelinePVCWorkspaceName and prName","func getAffinityAssistantAnnotationVal(aaBehavior affinityassistant.AffinityAssistantBehavior, pipelinePVCWorkspaceName string, prName string) string {","\tswitch aaBehavior {","\tcase affinityassistant.AffinityAssistantPerWorkspace:","\t\tif pipelinePVCWorkspaceName != \"\" {","\t\t\treturn GetAffinityAssistantName(pipelinePVCWorkspaceName, prName)","\t\t}","\tcase affinityassistant.AffinityAssistantPerPipelineRun, affinityassistant.AffinityAssistantPerPipelineRunWithIsolation:","\t\treturn GetAffinityAssistantName(\"\", prName)","","\tcase affinityassistant.AffinityAssistantDisabled:","\t}","","\treturn \"\"","}","","// GetAffinityAssistantName returns the Affinity Assistant name based on pipelineWorkspaceName and pipelineRunName","func GetAffinityAssistantName(pipelineWorkspaceName string, pipelineRunName string) string {","\thashBytes := sha256.Sum256([]byte(pipelineWorkspaceName + pipelineRunName))","\thashString := hex.EncodeToString(hashBytes[:])","\treturn fmt.Sprintf(\"%s-%s\", workspace.ComponentNameAffinityAssistant, hashString[:10])","}","","func getStatefulSetLabels(pr *v1.PipelineRun, affinityAssistantName string) map[string]string {","\t// Propagate labels from PipelineRun to StatefulSet.","\tlabels := make(map[string]string, len(pr.ObjectMeta.Labels)+1)","\tfor key, val := range pr.ObjectMeta.Labels {","\t\tlabels[key] = val","\t}","\tlabels[pipeline.PipelineRunLabelKey] = pr.Name","","\t// LabelInstance is used to configure PodAffinity for all TaskRuns belonging to this Affinity Assistant","\t// LabelComponent is used to configure PodAntiAffinity to other Affinity Assistants","\tlabels[workspace.LabelInstance] = affinityAssistantName","\tlabels[workspace.LabelComponent] = workspace.ComponentNameAffinityAssistant","\treturn labels","}","","// affinityAssistantStatefulSet returns an Affinity Assistant as a StatefulSet based on the AffinityAssistantBehavior","// with the given AffinityAssistantTemplate applied to the StatefulSet PodTemplateSpec.","// The VolumeClaimTemplates and Volume of StatefulSet reference the PipelineRun WorkspaceBinding VolumeClaimTempalte and the PVCs respectively.","// The PVs created by the StatefulSet are scheduled to the same availability zone which avoids PV scheduling conflict.","func affinityAssistantStatefulSet(aaBehavior aa.AffinityAssistantBehavior, name string, pr *v1.PipelineRun, claimTemplates []corev1.PersistentVolumeClaim, claimNames []string, containerConfig aa.ContainerConfig, defaultAATpl *pod.AffinityAssistantTemplate) *appsv1.StatefulSet {","\t// We want a singleton pod","\treplicas := int32(1)","","\ttpl := \u0026pod.AffinityAssistantTemplate{}","\t// merge pod template from spec and default if any of them are defined","\tif pr.Spec.TaskRunTemplate.PodTemplate != nil || defaultAATpl != nil {","\t\ttpl = pod.MergeAAPodTemplateWithDefault(pr.Spec.TaskRunTemplate.PodTemplate.ToAffinityAssistantTemplate(), defaultAATpl)","\t}","","\tvar mounts []corev1.VolumeMount","\tfor _, claimTemplate := range claimTemplates {","\t\tmounts = append(mounts, corev1.VolumeMount{Name: claimTemplate.Name, MountPath: claimTemplate.Name})","\t}","","\tsecurityContext := \u0026corev1.SecurityContext{}","\tif containerConfig.SecurityContextConfig.SetSecurityContext {","\t\tisWindows := tpl.NodeSelector[pipelinePod.OsSelectorLabel] == \"windows\"","\t\tsecurityContext = containerConfig.SecurityContextConfig.GetSecurityContext(isWindows)","\t}","","\tvar priorityClassName string","\tif tpl.PriorityClassName != nil {","\t\tpriorityClassName = *tpl.PriorityClassName","\t}","","\t// Determine ServiceAccountName with 3-tier priority:","\t// 1. Explicit override from AffinityAssistantTemplate","\t// 2. Inherit from PipelineRun's TaskRunTemplate (default behavior for OpenShift SCC compatibility)","\t// 3. Empty string (Kubernetes defaults to \"default\" ServiceAccount)","\tserviceAccountName := \"\"","\tif tpl.ServiceAccountName != \"\" {","\t\t// Explicit override in AffinityAssistantTemplate","\t\tserviceAccountName = tpl.ServiceAccountName","\t} else if pr.Spec.TaskRunTemplate.ServiceAccountName != \"\" {","\t\t// Inherit from PipelineRun's TaskRunTemplate","\t\tserviceAccountName = pr.Spec.TaskRunTemplate.ServiceAccountName","\t}","","\tcontainers := []corev1.Container{{","\t\tName:  \"affinity-assistant\",","\t\tImage: containerConfig.Image,","\t\tArgs:  []string{\"tekton_run_indefinitely\"},","","\t\t// Set requests == limits to get QoS class _Guaranteed_.","\t\t// See https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/#create-a-pod-that-gets-assigned-a-qos-class-of-guaranteed","\t\t// Affinity Assistant pod is a placeholder; request minimal resources","\t\tResources: corev1.ResourceRequirements{","\t\t\tLimits: corev1.ResourceList{","\t\t\t\t\"cpu\":    resource.MustParse(\"50m\"),","\t\t\t\t\"memory\": resource.MustParse(\"100Mi\"),","\t\t\t},","\t\t\tRequests: corev1.ResourceList{","\t\t\t\t\"cpu\":    resource.MustParse(\"50m\"),","\t\t\t\t\"memory\": resource.MustParse(\"100Mi\"),","\t\t\t},","\t\t},","\t\tVolumeMounts:    mounts,","\t\tSecurityContext: securityContext,","\t}}","","\tvar volumes []corev1.Volume","\tfor i, claimName := range claimNames {","\t\tvolumes = append(volumes, corev1.Volume{","\t\t\tName: fmt.Sprintf(\"workspace-%d\", i),","\t\t\tVolumeSource: corev1.VolumeSource{","\t\t\t\t// A Pod mounting a PersistentVolumeClaim that has a StorageClass with","\t\t\t\t// volumeBindingMode: Immediate","\t\t\t\t// the PV is allocated on a Node first, and then the pod need to be","\t\t\t\t// scheduled to that node.","\t\t\t\t// To support those PVCs, the Affinity Assistant must also mount the","\t\t\t\t// same PersistentVolumeClaim - to be sure that the Affinity Assistant","\t\t\t\t// pod is scheduled to the same Availability Zone as the PV, when using","\t\t\t\t// a regional cluster. This is called VolumeScheduling.","\t\t\t\tPersistentVolumeClaim: \u0026corev1.PersistentVolumeClaimVolumeSource{ClaimName: claimName},","\t\t\t},","\t\t})","\t}","","\treturn \u0026appsv1.StatefulSet{","\t\tTypeMeta: metav1.TypeMeta{","\t\t\tKind:       \"StatefulSet\",","\t\t\tAPIVersion: \"apps/v1\",","\t\t},","\t\tObjectMeta: metav1.ObjectMeta{","\t\t\tName:            name,","\t\t\tLabels:          getStatefulSetLabels(pr, name),","\t\t\tOwnerReferences: []metav1.OwnerReference{*kmeta.NewControllerRef(pr)},","\t\t},","\t\tSpec: appsv1.StatefulSetSpec{","\t\t\tReplicas: \u0026replicas,","\t\t\tSelector: \u0026metav1.LabelSelector{","\t\t\t\tMatchLabels: getStatefulSetLabels(pr, name),","\t\t\t},","\t\t\t// by setting VolumeClaimTemplates from StatefulSet, all the PVs are scheduled to the same Availability Zone as the StatefulSet","\t\t\tVolumeClaimTemplates: claimTemplates,","\t\t\tTemplate: corev1.PodTemplateSpec{","\t\t\t\tObjectMeta: metav1.ObjectMeta{","\t\t\t\t\tLabels: getStatefulSetLabels(pr, name),","\t\t\t\t},","\t\t\t\tSpec: corev1.PodSpec{","\t\t\t\t\tContainers: containers,","","\t\t\t\t\tTolerations:        tpl.Tolerations,","\t\t\t\t\tNodeSelector:       tpl.NodeSelector,","\t\t\t\t\tImagePullSecrets:   tpl.ImagePullSecrets,","\t\t\t\t\tSecurityContext:    tpl.SecurityContext,","\t\t\t\t\tPriorityClassName:  priorityClassName,","\t\t\t\t\tServiceAccountName: serviceAccountName,","","\t\t\t\t\tAffinity: getAssistantAffinityMergedWithPodTemplateAffinity(pr, aaBehavior),","\t\t\t\t\tVolumes:  volumes,","\t\t\t\t},","\t\t\t},","\t\t},","\t}","}","","// getAssistantAffinityMergedWithPodTemplateAffinity return the affinity that merged with PipelineRun PodTemplate affinity.","func getAssistantAffinityMergedWithPodTemplateAffinity(pr *v1.PipelineRun, aaBehavior aa.AffinityAssistantBehavior) *corev1.Affinity {","\taffinityAssistantsAffinity := \u0026corev1.Affinity{}","\tif pr.Spec.TaskRunTemplate.PodTemplate != nil \u0026\u0026 pr.Spec.TaskRunTemplate.PodTemplate.Affinity != nil {","\t\taffinityAssistantsAffinity = pr.Spec.TaskRunTemplate.PodTemplate.Affinity","\t}","\tif affinityAssistantsAffinity.PodAntiAffinity == nil {","\t\taffinityAssistantsAffinity.PodAntiAffinity = \u0026corev1.PodAntiAffinity{}","\t}","","\trepelOtherAffinityAssistantsPodAffinityTerm := corev1.PodAffinityTerm{","\t\tLabelSelector: \u0026metav1.LabelSelector{","\t\t\tMatchLabels: map[string]string{","\t\t\t\tworkspace.LabelComponent: workspace.ComponentNameAffinityAssistant,","\t\t\t},","\t\t},","\t\tTopologyKey: \"kubernetes.io/hostname\",","\t}","","\tif aaBehavior == aa.AffinityAssistantPerPipelineRunWithIsolation {","\t\t// use RequiredDuringSchedulingIgnoredDuringExecution term to enforce only one pipelinerun can run in a node at a time","\t\taffinityAssistantsAffinity.PodAntiAffinity.RequiredDuringSchedulingIgnoredDuringExecution = append(affinityAssistantsAffinity.PodAntiAffinity.RequiredDuringSchedulingIgnoredDuringExecution,","\t\t\trepelOtherAffinityAssistantsPodAffinityTerm)","\t} else {","\t\tpreferredRepelOtherAffinityAssistantsPodAffinityTerm := corev1.WeightedPodAffinityTerm{","\t\t\tWeight:          100,","\t\t\tPodAffinityTerm: repelOtherAffinityAssistantsPodAffinityTerm,","\t\t}","\t\t// use RequiredDuringSchedulingIgnoredDuringExecution term to schedule pipelineruns to different nodes when possible","\t\taffinityAssistantsAffinity.PodAntiAffinity.PreferredDuringSchedulingIgnoredDuringExecution = append(affinityAssistantsAffinity.PodAntiAffinity.PreferredDuringSchedulingIgnoredDuringExecution,","\t\t\tpreferredRepelOtherAffinityAssistantsPodAffinityTerm)","\t}","","\treturn affinityAssistantsAffinity","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,0,0,2,2,2,2,2,2,2,0,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,0,1,1,0,0,2,0,0,0,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,1,1,0,0,2,2,2,2,1,1,0,0,2,2,0,0,2,0,0,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,0,2,0,0,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0]},{"id":187,"path":"pkg/reconciler/pipelinerun/cancel.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pipelinerun","","import (","\t\"context\"","\t\"encoding/json\"","\t\"fmt\"","\t\"log\"","\t\"strings\"","\t\"time\"","","\tpipelineErrors \"github.com/tektoncd/pipeline/pkg/apis/pipeline/errors\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\tclientset \"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"","\t\"go.uber.org/zap\"","\tjsonpatch \"gomodules.xyz/jsonpatch/v2\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/api/errors\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/types\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"knative.dev/pkg/apis\"",")","","var cancelTaskRunPatchBytes, cancelCustomRunPatchBytes []byte","","func init() {","\tvar err error","\tcancelTaskRunPatchBytes, err = json.Marshal([]jsonpatch.JsonPatchOperation{","\t\t{","\t\t\tOperation: \"add\",","\t\t\tPath:      \"/spec/status\",","\t\t\tValue:     v1.TaskRunSpecStatusCancelled,","\t\t},","\t\t{","\t\t\tOperation: \"add\",","\t\t\tPath:      \"/spec/statusMessage\",","\t\t\tValue:     v1.TaskRunCancelledByPipelineMsg,","\t\t}})","\tif err != nil {","\t\tlog.Fatalf(\"failed to marshal TaskRun cancel patch bytes: %v\", err)","\t}","\tcancelCustomRunPatchBytes, err = json.Marshal([]jsonpatch.JsonPatchOperation{","\t\t{","\t\t\tOperation: \"add\",","\t\t\tPath:      \"/spec/status\",","\t\t\tValue:     v1beta1.CustomRunSpecStatusCancelled,","\t\t},","\t\t{","\t\t\tOperation: \"add\",","\t\t\tPath:      \"/spec/statusMessage\",","\t\t\tValue:     v1beta1.CustomRunCancelledByPipelineMsg,","\t\t}})","\tif err != nil {","\t\tlog.Fatalf(\"failed to marshal CustomRun cancel patch bytes: %v\", err)","\t}","}","","func cancelCustomRun(ctx context.Context, runName string, namespace string, clientSet clientset.Interface) error {","\t_, err := clientSet.TektonV1beta1().CustomRuns(namespace).Patch(ctx, runName, types.JSONPatchType, cancelCustomRunPatchBytes, metav1.PatchOptions{}, \"\")","\tif errors.IsNotFound(err) {","\t\t// The resource may have been deleted in the meanwhile, but we should","\t\t// still be able to cancel the PipelineRun","\t\treturn nil","\t}","\treturn err","}","","func cancelTaskRun(ctx context.Context, taskRunName string, namespace string, clientSet clientset.Interface) error {","\t_, err := clientSet.TektonV1().TaskRuns(namespace).Patch(ctx, taskRunName, types.JSONPatchType, cancelTaskRunPatchBytes, metav1.PatchOptions{}, \"\")","\tif errors.IsNotFound(err) {","\t\t// The resource may have been deleted in the meanwhile, but we should","\t\t// still be able to cancel the PipelineRun","\t\treturn nil","\t}","\tif pipelineErrors.IsImmutableTaskRunSpecError(err) {","\t\t// The TaskRun may have completed and the spec field is immutable, we should ignore this error.","\t\treturn nil","\t}","\treturn err","}","","// cancelPipelineRun marks the PipelineRun as cancelled and any resolved TaskRun(s) too.","func cancelPipelineRun(ctx context.Context, logger *zap.SugaredLogger, pr *v1.PipelineRun, clientSet clientset.Interface) error {","\terrs := cancelPipelineTaskRuns(ctx, logger, pr, clientSet)","","\t// If we successfully cancelled all the TaskRuns and Runs, we can consider the PipelineRun cancelled.","\tif len(errs) == 0 {","\t\treason := v1.PipelineRunReasonCancelled","","\t\tpr.Status.SetCondition(\u0026apis.Condition{","\t\t\tType:    apis.ConditionSucceeded,","\t\t\tStatus:  corev1.ConditionFalse,","\t\t\tReason:  reason.String(),","\t\t\tMessage: fmt.Sprintf(\"PipelineRun %q was cancelled\", pr.Name),","\t\t})","\t\t// update pr completed time","\t\tpr.Status.CompletionTime = \u0026metav1.Time{Time: time.Now()}","\t} else {","\t\te := strings.Join(errs, \"\\n\")","\t\t// Indicate that we failed to cancel the PipelineRun","\t\tpr.Status.SetCondition(\u0026apis.Condition{","\t\t\tType:    apis.ConditionSucceeded,","\t\t\tStatus:  corev1.ConditionUnknown,","\t\t\tReason:  v1.PipelineRunReasonCouldntCancel.String(),","\t\t\tMessage: fmt.Sprintf(\"PipelineRun %q was cancelled but had errors trying to cancel TaskRuns and/or Runs: %s\", pr.Name, e),","\t\t})","\t\treturn fmt.Errorf(\"error(s) from cancelling TaskRun(s) from PipelineRun %s: %s\", pr.Name, e)","\t}","\treturn nil","}","","// cancelPipelineTaskRuns patches `TaskRun` and `Run` with canceled status","func cancelPipelineTaskRuns(ctx context.Context, logger *zap.SugaredLogger, pr *v1.PipelineRun, clientSet clientset.Interface) []string {","\treturn cancelPipelineTaskRunsForTaskNames(ctx, logger, pr, clientSet, sets.NewString())","}","","// cancelPipelineTaskRunsForTaskNames patches `TaskRun`s and `Run`s for the given task names, or all if no task names are given, with canceled status","func cancelPipelineTaskRunsForTaskNames(ctx context.Context, logger *zap.SugaredLogger, pr *v1.PipelineRun, clientSet clientset.Interface, taskNames sets.String) []string {","\terrs := []string{}","","\ttrNames, customRunNames, err := getChildObjectsFromPRStatusForTaskNames(ctx, pr.Status, taskNames)","\tif err != nil {","\t\terrs = append(errs, err.Error())","\t}","","\tfor _, taskRunName := range trNames {","\t\tlogger.Infof(\"cancelling TaskRun %s\", taskRunName)","","\t\tif err := cancelTaskRun(ctx, taskRunName, pr.Namespace, clientSet); err != nil {","\t\t\terrs = append(errs, fmt.Errorf(\"failed to patch TaskRun `%s` with cancellation: %w\", taskRunName, err).Error())","\t\t\tcontinue","\t\t}","\t}","","\tfor _, runName := range customRunNames {","\t\tlogger.Infof(\"cancelling CustomRun %s\", runName)","","\t\tif err := cancelCustomRun(ctx, runName, pr.Namespace, clientSet); err != nil {","\t\t\terrs = append(errs, fmt.Errorf(\"failed to patch CustomRun `%s` with cancellation: %w\", runName, err).Error())","\t\t\tcontinue","\t\t}","\t}","\treturn errs","}","","// getChildObjectsFromPRStatusForTaskNames returns taskruns and customruns in the PipelineRunStatus's ChildReferences,","// based on the given set of PipelineTask names. If that set is empty, all are returned.","func getChildObjectsFromPRStatusForTaskNames(ctx context.Context, prs v1.PipelineRunStatus, taskNames sets.String) ([]string, []string, error) {","\tvar trNames []string","\tvar customRunNames []string","\tunknownChildKinds := make(map[string]string)","","\tfor _, cr := range prs.ChildReferences {","\t\tif taskNames.Len() == 0 || taskNames.Has(cr.PipelineTaskName) {","\t\t\tswitch cr.Kind {","\t\t\tcase taskRun:","\t\t\t\ttrNames = append(trNames, cr.Name)","\t\t\tcase customRun:","\t\t\t\tcustomRunNames = append(customRunNames, cr.Name)","\t\t\tdefault:","\t\t\t\tunknownChildKinds[cr.Name] = cr.Kind","\t\t\t}","\t\t}","\t}","","\tvar err error","\tif len(unknownChildKinds) \u003e 0 {","\t\terr = fmt.Errorf(\"found child objects of unknown kinds: %v\", unknownChildKinds)","\t}","","\treturn trNames, customRunNames, err","}","","// gracefullyCancelPipelineRun marks any non-final resolved TaskRun(s) as cancelled and runs finally.","func gracefullyCancelPipelineRun(ctx context.Context, logger *zap.SugaredLogger, pr *v1.PipelineRun, clientSet clientset.Interface) error {","\terrs := cancelPipelineTaskRuns(ctx, logger, pr, clientSet)","","\t// If we successfully cancelled all the TaskRuns and Runs, we can proceed with the PipelineRun reconciliation to trigger finally.","\tif len(errs) \u003e 0 {","\t\te := strings.Join(errs, \"\\n\")","\t\t// Indicate that we failed to cancel the PipelineRun","\t\tpr.Status.SetCondition(\u0026apis.Condition{","\t\t\tType:    apis.ConditionSucceeded,","\t\t\tStatus:  corev1.ConditionUnknown,","\t\t\tReason:  v1.PipelineRunReasonCouldntCancel.String(),","\t\t\tMessage: fmt.Sprintf(\"PipelineRun %q was cancelled but had errors trying to cancel TaskRuns and/or Runs: %s\", pr.Name, e),","\t\t})","\t\treturn fmt.Errorf(\"error(s) from cancelling TaskRun(s) from PipelineRun %s: %s\", pr.Name, e)","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,1,1,1,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,0,0,2,2,2,2,1,1,0,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0]},{"id":188,"path":"pkg/reconciler/pipelinerun/controller.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pipelinerun","","import (","\t\"context\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tpipelineclient \"github.com/tektoncd/pipeline/pkg/client/injection/client\"","\tpipelineruninformer \"github.com/tektoncd/pipeline/pkg/client/injection/informers/pipeline/v1/pipelinerun\"","\ttaskruninformer \"github.com/tektoncd/pipeline/pkg/client/injection/informers/pipeline/v1/taskrun\"","\tverificationpolicyinformer \"github.com/tektoncd/pipeline/pkg/client/injection/informers/pipeline/v1alpha1/verificationpolicy\"","\tcustomruninformer \"github.com/tektoncd/pipeline/pkg/client/injection/informers/pipeline/v1beta1/customrun\"","\tpipelinerunreconciler \"github.com/tektoncd/pipeline/pkg/client/injection/reconciler/pipeline/v1/pipelinerun\"","\tresolutionclient \"github.com/tektoncd/pipeline/pkg/client/resolution/injection/client\"","\tresolutioninformer \"github.com/tektoncd/pipeline/pkg/client/resolution/injection/informers/resolution/v1beta1/resolutionrequest\"","\t\"github.com/tektoncd/pipeline/pkg/pipelinerunmetrics\"","\tcloudeventclient \"github.com/tektoncd/pipeline/pkg/reconciler/events/cloudevent\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/volumeclaim\"","\tresolution \"github.com/tektoncd/pipeline/pkg/remoteresolution/resource\"","\t\"github.com/tektoncd/pipeline/pkg/tracing\"","\t\"k8s.io/client-go/tools/cache\"","\t\"k8s.io/utils/clock\"","\tkubeclient \"knative.dev/pkg/client/injection/kube/client\"","\tsecretinformer \"knative.dev/pkg/client/injection/kube/informers/core/v1/secret\"","\t\"knative.dev/pkg/configmap\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/logging\"",")","","const (","\t// TracerProviderName is the name of TraceProvider","\tTracerProviderName = \"pipelinerun-reconciler\"",")","","var pipelineRunFilterManagedBy = func(obj interface{}) bool {","\tpr, ok := obj.(*v1.PipelineRun)","\tif !ok {","\t\treturn true","\t}","\t// Only promote PipelineRuns that are managed by this controller","\tif pr.Spec.ManagedBy != nil \u0026\u0026 *pr.Spec.ManagedBy != pipeline.ManagedBy {","\t\treturn false","\t}","\treturn true","}","","// NewController instantiates a new controller.Impl from knative.dev/pkg/controller","func NewController(opts *pipeline.Options, clock clock.PassiveClock) func(context.Context, configmap.Watcher) *controller.Impl {","\treturn func(ctx context.Context, cmw configmap.Watcher) *controller.Impl {","\t\tlogger := logging.FromContext(ctx)","\t\tkubeclientset := kubeclient.Get(ctx)","\t\tpipelineclientset := pipelineclient.Get(ctx)","\t\ttaskRunInformer := taskruninformer.Get(ctx)","\t\tcustomRunInformer := customruninformer.Get(ctx)","\t\tpipelineRunInformer := pipelineruninformer.Get(ctx)","\t\tresolutionInformer := resolutioninformer.Get(ctx)","\t\tverificationpolicyInformer := verificationpolicyinformer.Get(ctx)","\t\tsecretinformer := secretinformer.Get(ctx)","\t\ttracerProvider := tracing.New(TracerProviderName, logger.Named(\"tracing\"))","\t\tpipelinerunmetricsRecorder := pipelinerunmetrics.Get(ctx)","\t\t//nolint:contextcheck // OnStore methods does not support context as a parameter","\t\tconfigStore := config.NewStore(logger.Named(\"config-store\"),","\t\t\tpipelinerunmetrics.OnStore(logger, pipelinerunmetricsRecorder),","\t\t\ttracerProvider.OnStore(secretinformer.Lister()),","\t\t)","\t\tconfigStore.WatchConfigs(cmw)","","\t\tc := \u0026Reconciler{","\t\t\tKubeClientSet:            kubeclientset,","\t\t\tPipelineClientSet:        pipelineclientset,","\t\t\tImages:                   opts.Images,","\t\t\tClock:                    clock,","\t\t\tpipelineRunLister:        pipelineRunInformer.Lister(),","\t\t\ttaskRunLister:            taskRunInformer.Lister(),","\t\t\tcustomRunLister:          customRunInformer.Lister(),","\t\t\tverificationPolicyLister: verificationpolicyInformer.Lister(),","\t\t\tcloudEventClient:         cloudeventclient.Get(ctx),","\t\t\tmetrics:                  pipelinerunmetricsRecorder,","\t\t\tpvcHandler:               volumeclaim.NewPVCHandler(kubeclientset, logger),","\t\t\tresolutionRequester:      resolution.NewCRDRequester(resolutionclient.Get(ctx), resolutionInformer.Lister()),","\t\t\ttracerProvider:           tracerProvider,","\t\t}","\t\timpl := pipelinerunreconciler.NewImpl(ctx, c, func(impl *controller.Impl) controller.Options {","\t\t\treturn controller.Options{","\t\t\t\tAgentName:         pipeline.PipelineRunControllerName,","\t\t\t\tConfigStore:       configStore,","\t\t\t\tPromoteFilterFunc: pipelineRunFilterManagedBy,","\t\t\t}","\t\t})","","\t\tif _, err := secretinformer.Informer().AddEventHandler(controller.HandleAll(tracerProvider.Handler)); err != nil {","\t\t\tlogging.FromContext(ctx).Panicf(\"Couldn't register Secret informer event handler: %w\", err)","\t\t}","","\t\tif _, err := pipelineRunInformer.Informer().AddEventHandler(cache.FilteringResourceEventHandler{","\t\t\tFilterFunc: pipelineRunFilterManagedBy,","\t\t\tHandler:    controller.HandleAll(impl.Enqueue),","\t\t}); err != nil {","\t\t\tlogging.FromContext(ctx).Panicf(\"Couldn't register PipelineRun informer event handler: %w\", err)","\t\t}","","\t\tif _, err := pipelineRunInformer.Informer().AddEventHandler(cache.FilteringResourceEventHandler{","\t\t\tFilterFunc: controller.FilterController(\u0026v1.PipelineRun{}),","\t\t\tHandler:    controller.HandleAll(impl.EnqueueControllerOf),","\t\t}); err != nil {","\t\t\tlogging.FromContext(ctx).Panicf(\"Couldn't register PipelineRun informer event handler: %w\", err)","\t\t}","","\t\tif _, err := taskRunInformer.Informer().AddEventHandler(cache.FilteringResourceEventHandler{","\t\t\tFilterFunc: controller.FilterController(\u0026v1.PipelineRun{}),","\t\t\tHandler:    controller.HandleAll(impl.EnqueueControllerOf),","\t\t}); err != nil {","\t\t\tlogging.FromContext(ctx).Panicf(\"Couldn't register TaskRun informer event handler: %w\", err)","\t\t}","","\t\tif _, err := customRunInformer.Informer().AddEventHandler(cache.FilteringResourceEventHandler{","\t\t\tFilterFunc: controller.FilterController(\u0026v1.PipelineRun{}),","\t\t\tHandler:    controller.HandleAll(impl.EnqueueControllerOf),","\t\t}); err != nil {","\t\t\tlogging.FromContext(ctx).Panicf(\"Couldn't register CustomRun informer event handler: %w\", err)","\t\t}","","\t\tif _, err := resolutionInformer.Informer().AddEventHandler(cache.FilteringResourceEventHandler{","\t\t\tFilterFunc: controller.FilterController(\u0026v1.PipelineRun{}),","\t\t\tHandler:    controller.HandleAll(impl.EnqueueControllerOf),","\t\t}); err != nil {","\t\t\tlogging.FromContext(ctx).Panicf(\"Couldn't register ResolutionRequest informer event handler: %w\", err)","\t\t}","","\t\treturn impl","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,1,1,0,2,2,2,2,1,1,0,2,2,2,2,1,1,0,2,2,2,2,1,1,0,2,2,2,2,1,1,0,2,2,2,2,1,1,0,2,0,0]},{"id":189,"path":"pkg/reconciler/pipelinerun/pipelinerun.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pipelinerun","","import (","\t\"context\"","\t\"encoding/json\"","\t\"errors\"","\t\"fmt\"","\t\"path/filepath\"","\t\"reflect\"","\t\"regexp\"","\t\"sort\"","\t\"strings\"","","\t\"k8s.io/apimachinery/pkg/util/wait\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tpipelineErrors \"github.com/tektoncd/pipeline/pkg/apis/pipeline/errors\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\tclientset \"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"","\tpipelinerunreconciler \"github.com/tektoncd/pipeline/pkg/client/injection/reconciler/pipeline/v1/pipelinerun\"","\tlisters \"github.com/tektoncd/pipeline/pkg/client/listers/pipeline/v1\"","\talpha1listers \"github.com/tektoncd/pipeline/pkg/client/listers/pipeline/v1alpha1\"","\tbeta1listers \"github.com/tektoncd/pipeline/pkg/client/listers/pipeline/v1beta1\"","\tctrl \"github.com/tektoncd/pipeline/pkg/controller\"","\t\"github.com/tektoncd/pipeline/pkg/internal/affinityassistant\"","\tresolutionutil \"github.com/tektoncd/pipeline/pkg/internal/resolution\"","\t\"github.com/tektoncd/pipeline/pkg/pipelinerunmetrics\"","\ttknreconciler \"github.com/tektoncd/pipeline/pkg/reconciler\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/apiserver\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/events\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/events/cloudevent\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/pipeline/dag\"","\trprp \"github.com/tektoncd/pipeline/pkg/reconciler/pipelinerun/pipelinespec\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/pipelinerun/resources\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/taskrun\"","\ttresources \"github.com/tektoncd/pipeline/pkg/reconciler/taskrun/resources\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/volumeclaim\"","\t\"github.com/tektoncd/pipeline/pkg/remote\"","\tresolution \"github.com/tektoncd/pipeline/pkg/remoteresolution/resource\"","\tresolutioncommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\t\"github.com/tektoncd/pipeline/pkg/trustedresources\"","\t\"github.com/tektoncd/pipeline/pkg/workspace\"","\t\"go.opentelemetry.io/otel/attribute\"","\t\"go.opentelemetry.io/otel/trace\"","\t\"go.uber.org/zap\"","\tcorev1 \"k8s.io/api/core/v1\"","\tapierrors \"k8s.io/apimachinery/pkg/api/errors\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/labels\"","\tk8slabels \"k8s.io/apimachinery/pkg/labels\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/apimachinery/pkg/runtime/schema\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"k8s.io/client-go/kubernetes\"","\t\"k8s.io/utils/clock\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/kmap\"","\t\"knative.dev/pkg/kmeta\"","\t\"knative.dev/pkg/logging\"","\tpkgreconciler \"knative.dev/pkg/reconciler\"",")","","// Aliased for backwards compatibility; do not add additional reasons here","var (","\t// ReasonCouldntGetPipeline indicates that the reason for the failure status is that the","\t// associated Pipeline couldn't be retrieved","\tReasonCouldntGetPipeline = v1.PipelineRunReasonCouldntGetPipeline.String()","\t// ReasonInvalidBindings indicates that the reason for the failure status is that the","\t// PipelineResources bound in the PipelineRun didn't match those declared in the Pipeline","\tReasonInvalidBindings = v1.PipelineRunReasonInvalidBindings.String()","\t// ReasonInvalidWorkspaceBinding indicates that a Pipeline expects a workspace but a","\t// PipelineRun has provided an invalid binding.","\tReasonInvalidWorkspaceBinding = v1.PipelineRunReasonInvalidWorkspaceBinding.String()","\t// ReasonInvalidTaskRunSpec indicates that PipelineRun.Spec.TaskRunSpecs[].PipelineTaskName is defined with","\t// a not exist taskName in pipelineSpec.","\tReasonInvalidTaskRunSpec = v1.PipelineRunReasonInvalidTaskRunSpec.String()","\t// ReasonParameterTypeMismatch indicates that the reason for the failure status is that","\t// parameter(s) declared in the PipelineRun do not have the some declared type as the","\t// parameters(s) declared in the Pipeline that they are supposed to override.","\tReasonParameterTypeMismatch = v1.PipelineRunReasonParameterTypeMismatch.String()","\t// ReasonObjectParameterMissKeys indicates that the object param value provided from PipelineRun spec","\t// misses some keys required for the object param declared in Pipeline spec.","\tReasonObjectParameterMissKeys = v1.PipelineRunReasonObjectParameterMissKeys.String()","\t// ReasonParamArrayIndexingInvalid indicates that the use of param array indexing is out of bound.","\tReasonParamArrayIndexingInvalid = v1.PipelineRunReasonParamArrayIndexingInvalid.String()","\t// ReasonCouldntGetTask indicates that the reason for the failure status is that the","\t// associated Pipeline's Tasks couldn't all be retrieved","\tReasonCouldntGetTask = v1.PipelineRunReasonCouldntGetTask.String()","\t// ReasonParameterMissing indicates that the reason for the failure status is that the","\t// associated PipelineRun didn't provide all the required parameters","\tReasonParameterMissing = v1.PipelineRunReasonParameterMissing.String()","\t// ReasonFailedValidation indicates that the reason for failure status is","\t// that pipelinerun failed runtime validation","\tReasonFailedValidation = v1.PipelineRunReasonFailedValidation.String()","\t// ReasonInvalidGraph indicates that the reason for the failure status is that the","\t// associated Pipeline is an invalid graph (a.k.a wrong order, cycle, â€¦)","\tReasonInvalidGraph = v1.PipelineRunReasonInvalidGraph.String()","\t// ReasonCancelled indicates that a PipelineRun was cancelled.","\tReasonCancelled = v1.PipelineRunReasonCancelled.String()","\t// ReasonPending indicates that a PipelineRun is pending.","\tReasonPending = v1.PipelineRunReasonPending.String()","\t// ReasonCouldntCancel indicates that a PipelineRun was cancelled but attempting to update","\t// all of the running TaskRuns as cancelled failed.","\tReasonCouldntCancel = v1.PipelineRunReasonCouldntCancel.String()","\t// ReasonCouldntTimeOut indicates that a PipelineRun was timed out but attempting to update","\t// all of the running TaskRuns as timed out failed.","\tReasonCouldntTimeOut = v1.PipelineRunReasonCouldntTimeOut.String()","\t// ReasonInvalidMatrixParameterTypes indicates a matrix contains invalid parameter types","\tReasonInvalidMatrixParameterTypes = v1.PipelineRunReasonInvalidMatrixParameterTypes.String()","\t// ReasonInvalidTaskResultReference indicates a task result was declared","\t// but was not initialized by that task","\tReasonInvalidTaskResultReference = v1.PipelineRunReasonInvalidTaskResultReference.String()","\t// ReasonRequiredWorkspaceMarkedOptional indicates an optional workspace","\t// has been passed to a Task that is expecting a non-optional workspace","\tReasonRequiredWorkspaceMarkedOptional = v1.PipelineRunReasonRequiredWorkspaceMarkedOptional.String()","\t// ReasonResolvingPipelineRef indicates that the PipelineRun is waiting for","\t// its pipelineRef to be asynchronously resolved.","\tReasonResolvingPipelineRef = v1.PipelineRunReasonResolvingPipelineRef.String()","\t// ReasonResourceVerificationFailed indicates that the pipeline fails the trusted resource verification,","\t// it could be the content has changed, signature is invalid or public key is invalid","\tReasonResourceVerificationFailed = v1.PipelineRunReasonResourceVerificationFailed.String()","\t// ReasonCreateRunFailed indicates that the pipeline fails to create the taskrun or other run resources","\tReasonCreateRunFailed = v1.PipelineRunReasonCreateRunFailed.String()",")","","// constants used as kind descriptors for various types of runs; these constants","// match their corresponding controller names. Given that it's odd to use a","// \"ControllerName\" const in describing the type of run, we import these","// constants (for consistency) but rename them (for ergonomic semantics).","const (","\ttaskRun     = pipeline.TaskRunControllerName","\tcustomRun   = pipeline.CustomRunControllerName","\tpipelineRun = pipeline.PipelineRunControllerName",")","","// Reconciler implements controller.Reconciler for Configuration resources.","type Reconciler struct {","\tKubeClientSet     kubernetes.Interface","\tPipelineClientSet clientset.Interface","\tImages            pipeline.Images","\tClock             clock.PassiveClock","","\t// listers index properties about resources","\tpipelineRunLister        listers.PipelineRunLister","\ttaskRunLister            listers.TaskRunLister","\tcustomRunLister          beta1listers.CustomRunLister","\tverificationPolicyLister alpha1listers.VerificationPolicyLister","\tcloudEventClient         cloudevent.CEClient","\tmetrics                  *pipelinerunmetrics.Recorder","\tpvcHandler               volumeclaim.PvcHandler","\tresolutionRequester      resolution.Requester","\ttracerProvider           trace.TracerProvider","}","","var (","\t// Check that our Reconciler implements pipelinerunreconciler.Interface","\t_                              pipelinerunreconciler.Interface = (*Reconciler)(nil)","\tfilterReservedAnnotationRegexp                                 = regexp.MustCompile(pipeline.TektonReservedAnnotationExpr)",")","","// ReconcileKind compares the actual state with the desired, and attempts to","// converge the two. It then updates the Status block of the Pipeline Run","// resource with the current status of the resource.","func (c *Reconciler) ReconcileKind(ctx context.Context, pr *v1.PipelineRun) pkgreconciler.Event {","\tlogger := logging.FromContext(ctx)","\tctx = cloudevent.ToContext(ctx, c.cloudEventClient)","\tctx = initTracing(ctx, c.tracerProvider, pr)","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"PipelineRun:ReconcileKind\")","\tdefer span.End()","","\tspan.SetAttributes(","\t\tattribute.String(\"pipelinerun\", pr.Name), attribute.String(\"namespace\", pr.Namespace),","\t)","","\t// Read the initial condition","\tbefore := pr.Status.GetCondition(apis.ConditionSucceeded)","","\t// Check if we are failing to mark this as timed out for a while. If we are, mark immediately and finish the","\t// reconcile. We are assuming here that if the PipelineRun has timed out for a long time, it had time to run","\t// before and it kept failing. One reason that can happen is exceeding etcd request size limit. Finishing it early","\t// makes sure the request size is manageable","\tif !pr.IsDone() \u0026\u0026 pr.HasTimedOutForALongTime(ctx, c.Clock) \u0026\u0026 !pr.IsTimeoutConditionSet() {","\t\tif err := timeoutPipelineRun(ctx, logger, pr, c.PipelineClientSet); err != nil {","\t\t\treturn err","\t\t}","\t\tif err := c.finishReconcileUpdateEmitEvents(ctx, pr, before, nil); err != nil {","\t\t\treturn err","\t\t}","\t\treturn controller.NewPermanentError(errors.New(\"PipelineRun has timed out for a long time\"))","\t}","","\tif !pr.HasStarted() \u0026\u0026 !pr.IsPending() {","\t\tpr.Status.InitializeConditions(c.Clock)","\t\t// In case node time was not synchronized, when controller has been scheduled to other nodes.","\t\tif pr.Status.StartTime.Sub(pr.CreationTimestamp.Time) \u003c 0 {","\t\t\tlogger.Warnf(\"PipelineRun %s createTimestamp %s is after the pipelineRun started %s\", pr.GetNamespacedName().String(), pr.CreationTimestamp, pr.Status.StartTime)","\t\t\tpr.Status.StartTime = \u0026pr.CreationTimestamp","\t\t}","","\t\t// Emit events. During the first reconcile the status of the PipelineRun may change twice","\t\t// from not Started to Started and then to Running, so we need to sent the event here","\t\t// and at the end of 'Reconcile' again.","\t\t// We also want to send the \"Started\" event as soon as possible for anyone who may be waiting","\t\t// on the event to perform user facing initialisations, such has reset a CI check status","\t\tafterCondition := pr.Status.GetCondition(apis.ConditionSucceeded)","\t\tevents.Emit(ctx, nil, afterCondition, pr)","","\t\t// We already sent an event for start, so update `before` with the current status","\t\tbefore = pr.Status.GetCondition(apis.ConditionSucceeded)","\t}","","\t// list VerificationPolicies for trusted resources","\tvp, err := c.verificationPolicyLister.VerificationPolicies(pr.Namespace).List(labels.Everything())","\tif err != nil {","\t\treturn fmt.Errorf(\"failed to list VerificationPolicies from namespace %s with error %w\", pr.Namespace, err)","\t}","\tgetPipelineFunc := resources.GetPipelineFunc(ctx, c.KubeClientSet, c.PipelineClientSet, c.resolutionRequester, pr, vp)","","\tif pr.IsDone() {","\t\tpr.SetDefaults(ctx)","\t\terr := c.cleanupAffinityAssistantsAndPVCs(ctx, pr)","\t\tif err != nil {","\t\t\tlogger.Errorf(\"Failed to delete StatefulSet or PVC for PipelineRun %s: %v\", pr.Name, err)","\t\t}","\t\treturn c.finishReconcileUpdateEmitEvents(ctx, pr, before, err)","\t}","","\tif err := propagatePipelineNameLabelToPipelineRun(pr); err != nil {","\t\tlogger.Errorf(\"Failed to propagate pipeline name label to pipelinerun %s: %v\", pr.Name, err)","\t\treturn c.finishReconcileUpdateEmitEvents(ctx, pr, before, err)","\t}","","\t// If the pipelinerun is cancelled, cancel tasks and update status","\tif pr.IsCancelled() {","\t\terr := cancelPipelineRun(ctx, logger, pr, c.PipelineClientSet)","\t\treturn c.finishReconcileUpdateEmitEvents(ctx, pr, before, err)","\t}","","\t// Make sure that the PipelineRun status is in sync with the actual TaskRuns","\terr = c.updatePipelineRunStatusFromInformer(ctx, pr)","\tif err != nil {","\t\t// This should not fail. Return the error so we can re-try later.","\t\tlogger.Errorf(\"Error while syncing the pipelinerun status: %v\", err.Error())","\t\treturn c.finishReconcileUpdateEmitEvents(ctx, pr, before, err)","\t}","","\t// Reconcile this copy of the pipelinerun and then write back any status or label","\t// updates regardless of whether the reconciliation errored out.","\tif err = c.reconcile(ctx, pr, getPipelineFunc, before); err != nil {","\t\tlogger.Errorf(\"Reconcile error: %v\", err.Error())","\t}","","\tif err = c.finishReconcileUpdateEmitEvents(ctx, pr, before, err); err != nil {","\t\treturn err","\t}","","\tif pr.Status.StartTime != nil {","\t\t// Compute the time since the pipeline started.","\t\telapsed := c.Clock.Since(pr.Status.StartTime.Time)","\t\t// Snooze this resource until the appropriate timeout has elapsed.","\t\ttimeout := pr.PipelineTimeout(ctx)","\t\ttaskTimeout := pr.TasksTimeout()","","\t\t// If the main pipeline timeout is NoTimeoutDuration (0), it means no timeout is configured.","\t\t// This can happen in two ways:","\t\t// 1. User explicitly set pr.Spec.Timeouts.Pipeline to 0 (wants no timeout)","\t\t// 2. User didn't set pr.Spec.Timeouts.Pipeline (nil) AND default-timeout-minutes config is \"0\"","\t\t// In these cases, check if there are specific task or finally timeouts to enforce.","\t\t// If not, don't requeue - the reconciler will be triggered by watch events.","\t\t// Check which phase we're in and handle timeout accordingly","\t\tif pr.Status.FinallyStartTime != nil {","\t\t\t// We're in finally phase - check for finally-specific timeout","\t\t\tif pr.FinallyTimeout() != nil \u0026\u0026 pr.FinallyTimeout().Duration != config.NoTimeoutDuration {","\t\t\t\tfinallyWaitTime := pr.FinallyTimeout().Duration - c.Clock.Since(pr.Status.FinallyStartTime.Time)","\t\t\t\t// If pipeline timeout is also set, use the most restrictive timeout","\t\t\t\tif timeout != config.NoTimeoutDuration {","\t\t\t\t\twaitTime := timeout - elapsed","\t\t\t\t\tif finallyWaitTime \u003c waitTime {","\t\t\t\t\t\treturn controller.NewRequeueAfter(finallyWaitTime)","\t\t\t\t\t}","\t\t\t\t\treturn controller.NewRequeueAfter(waitTime)","\t\t\t\t}","\t\t\t\treturn controller.NewRequeueAfter(finallyWaitTime)","\t\t\t}","\t\t\t// No finally timeout, use pipeline timeout if set","\t\t\tif timeout != config.NoTimeoutDuration {","\t\t\t\treturn controller.NewRequeueAfter(timeout - elapsed)","\t\t\t}","\t\t\treturn nil","\t\t}","","\t\t// We're in tasks phase - check for task-specific timeout","\t\tif taskTimeout != nil \u0026\u0026 taskTimeout.Duration != config.NoTimeoutDuration {","\t\t\treturn controller.NewRequeueAfter(taskTimeout.Duration - elapsed)","\t\t}","\t\t// No task timeout, use pipeline timeout if set","\t\tif timeout != config.NoTimeoutDuration {","\t\t\treturn controller.NewRequeueAfter(timeout - elapsed)","\t\t}","\t\treturn nil","","\t}","\treturn nil","}","","func (c *Reconciler) durationAndCountMetrics(ctx context.Context, pr *v1.PipelineRun, beforeCondition *apis.Condition) {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"durationAndCountMetrics\")","\tdefer span.End()","\tlogger := logging.FromContext(ctx)","\tif pr.IsDone() {","\t\terr := c.metrics.DurationAndCount(pr, beforeCondition)","\t\tif err != nil {","\t\t\tlogger.Warnf(\"Failed to log the metrics : %v\", err)","\t\t}","\t}","}","","func (c *Reconciler) finishReconcileUpdateEmitEvents(ctx context.Context, pr *v1.PipelineRun, beforeCondition *apis.Condition, previousError error) error {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"finishReconcileUpdateEmitEvents\")","\tdefer span.End()","\tlogger := logging.FromContext(ctx)","","\tafterCondition := pr.Status.GetCondition(apis.ConditionSucceeded)","\tevents.Emit(ctx, beforeCondition, afterCondition, pr)","\t_, err := c.updateLabelsAndAnnotations(ctx, pr)","\tif err != nil {","\t\tlogger.Warn(\"Failed to update PipelineRun labels/annotations\", zap.Error(err))","\t\tevents.EmitError(controller.GetEventRecorder(ctx), err, pr)","\t}","","\terrs := errors.Join(previousError, err)","\tif controller.IsPermanentError(previousError) {","\t\treturn controller.NewPermanentError(errs)","\t}","\treturn errs","}","","// resolvePipelineState will attempt to resolve each referenced pipeline task in the pipeline's spec and all of the resources","// specified by those tasks.","func (c *Reconciler) resolvePipelineState(","\tctx context.Context,","\tpipelineTasks []v1.PipelineTask,","\tpipelineMeta *metav1.ObjectMeta,","\tpr *v1.PipelineRun,","\tpst resources.PipelineRunState,",") (resources.PipelineRunState, error) {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"resolvePipelineState\")","\tdefer span.End()","\t// Resolve each pipeline task individually because they each could have a different reference context (remote or local).","\tfor _, pipelineTask := range pipelineTasks {","\t\t// We need the TaskRun name to ensure that we don't perform an additional remote resolution request for a PipelineTask","\t\t// in the TaskRun reconciler.","\t\ttrName := resources.GetTaskRunName(","\t\t\tpr.Status.ChildReferences,","\t\t\tpipelineTask.Name,","\t\t\tpr.Name,","\t\t)","","\t\t// list VerificationPolicies for trusted resources","\t\tvp, err := c.verificationPolicyLister.VerificationPolicies(pr.Namespace).List(labels.Everything())","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed to list VerificationPolicies from namespace %s with error %w\", pr.Namespace, err)","\t\t}","","\t\tgetChildPipelineRunFunc := func(name string) (*v1.PipelineRun, error) {","\t\t\treturn c.pipelineRunLister.PipelineRuns(pr.Namespace).Get(name)","\t\t}","","\t\tgetTaskFunc := tresources.GetTaskFunc(","\t\t\tctx,","\t\t\tc.KubeClientSet,","\t\t\tc.PipelineClientSet,","\t\t\tc.resolutionRequester,","\t\t\tpr,","\t\t\tpipelineTask.TaskRef,","\t\t\ttrName,","\t\t\tpr.Namespace,","\t\t\tpr.Spec.TaskRunTemplate.ServiceAccountName,","\t\t\tvp,","\t\t)","","\t\tgetTaskRunFunc := func(name string) (*v1.TaskRun, error) {","\t\t\treturn c.taskRunLister.TaskRuns(pr.Namespace).Get(name)","\t\t}","","\t\tgetCustomRunFunc := func(name string) (*v1beta1.CustomRun, error) {","\t\t\tr, err := c.customRunLister.CustomRuns(pr.Namespace).Get(name)","\t\t\tif err != nil {","\t\t\t\treturn nil, err","\t\t\t}","\t\t\treturn r, nil","\t\t}","","\t\tresolvedTask, err := resources.ResolvePipelineTask(ctx,","\t\t\t*pr,","\t\t\tgetChildPipelineRunFunc,","\t\t\tgetTaskFunc,","\t\t\tgetTaskRunFunc,","\t\t\tgetCustomRunFunc,","\t\t\tpipelineTask,","\t\t\tpst,","\t\t)","\t\tif err != nil {","\t\t\tif resolutioncommon.IsErrTransient(err) {","\t\t\t\treturn nil, err","\t\t\t}","\t\t\tif errors.Is(err, remote.ErrRequestInProgress) {","\t\t\t\treturn nil, err","\t\t\t}","\t\t\tvar nfErr *resources.TaskNotFoundError","\t\t\tif errors.As(err, \u0026nfErr) {","\t\t\t\tpr.Status.MarkFailed(v1.PipelineRunReasonCouldntGetTask.String(),","\t\t\t\t\t\"Pipeline %s/%s can't be Run; it contains Tasks that don't exist: %s\",","\t\t\t\t\tpipelineMeta.Namespace, pipelineMeta.Name, nfErr)","\t\t\t} else {","\t\t\t\tpr.Status.MarkFailed(v1.PipelineRunReasonFailedValidation.String(),","\t\t\t\t\t\"PipelineRun %s/%s can't be Run; couldn't resolve all references: %s\",","\t\t\t\t\tpipelineMeta.Namespace, pr.Name, pipelineErrors.WrapUserError(err))","\t\t\t}","\t\t\treturn nil, controller.NewPermanentError(err)","\t\t}","","\t\tif resolvedTask.ResolvedTask != nil \u0026\u0026 resolvedTask.ResolvedTask.VerificationResult != nil {","\t\t\tcond, err := conditionFromVerificationResult(resolvedTask.ResolvedTask.VerificationResult, pr, pipelineTask.Name)","\t\t\tpr.Status.SetCondition(cond)","\t\t\tif err != nil {","\t\t\t\tpr.Status.MarkFailed(v1.PipelineRunReasonResourceVerificationFailed.String(), err.Error())","\t\t\t\treturn nil, controller.NewPermanentError(err)","\t\t\t}","\t\t}","\t\tpst = append(pst, resolvedTask)","\t}","","\treturn pst, nil","}","","func (c *Reconciler) reconcile(ctx context.Context, pr *v1.PipelineRun, getPipelineFunc rprp.GetPipeline, beforeCondition *apis.Condition) error {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"reconcile\")","\tdefer span.End()","\tdefer c.durationAndCountMetrics(ctx, pr, beforeCondition)","\tlogger := logging.FromContext(ctx)","\tpr.SetDefaults(ctx)","","\t// When pipeline run is pending, return to avoid creating the task","\tif pr.IsPending() {","\t\tpr.Status.MarkRunning(v1.PipelineRunReasonPending.String(), fmt.Sprintf(\"PipelineRun %q is pending\", pr.Name))","\t\treturn nil","\t}","","\tpipelineMeta, pipelineSpec, err := rprp.GetPipelineData(ctx, pr, getPipelineFunc)","\tswitch {","\tcase errors.Is(err, remote.ErrRequestInProgress):","\t\tmessage := fmt.Sprintf(\"PipelineRun %s/%s awaiting remote resource\", pr.Namespace, pr.Name)","\t\tpr.Status.MarkRunning(v1.PipelineRunReasonResolvingPipelineRef.String(), message)","\t\treturn nil","\tcase errors.Is(err, apiserver.ErrReferencedObjectValidationFailed), errors.Is(err, apiserver.ErrCouldntValidateObjectPermanent):","\t\tlogger.Errorf(\"Failed dryRunValidation for PipelineRun %s: %v\", pr.Name, err)","\t\tpr.Status.MarkFailed(v1.PipelineRunReasonFailedValidation.String(),","\t\t\t\"Failed dryRunValidation for PipelineRun %s: %s\",","\t\t\tpr.Name, pipelineErrors.WrapUserError(err))","\t\treturn controller.NewPermanentError(err)","\tcase errors.Is(err, apiserver.ErrCouldntValidateObjectRetryable):","\t\treturn err","\tcase err != nil:","\t\tlogger.Errorf(\"Failed to determine Pipeline spec to use for pipelinerun %s: %v\", pr.Name, err)","\t\tpr.Status.MarkFailed(v1.PipelineRunReasonCouldntGetPipeline.String(),","\t\t\t\"Error retrieving pipeline for pipelinerun %s/%s: %s\",","\t\t\tpr.Namespace, pr.Name, err)","\t\treturn controller.NewPermanentError(err)","\tdefault:","\t\t// Store the fetched PipelineSpec on the PipelineRun for auditing","\t\tif err := storePipelineSpecAndMergeMeta(ctx, pr, pipelineSpec, pipelineMeta); err != nil {","\t\t\tlogger.Errorf(\"Failed to store PipelineSpec on PipelineRun.Status for pipelinerun %s: %v\", pr.Name, err)","\t\t}","\t}","","\tif pipelineMeta.VerificationResult != nil {","\t\tcond, err := conditionFromVerificationResult(pipelineMeta.VerificationResult, pr, pipelineMeta.Name)","\t\tpr.Status.SetCondition(cond)","\t\tif err != nil {","\t\t\tpr.Status.MarkFailed(v1.PipelineRunReasonResourceVerificationFailed.String(), err.Error())","\t\t\treturn controller.NewPermanentError(err)","\t\t}","\t}","","\td, err := dag.Build(v1.PipelineTaskList(pipelineSpec.Tasks), v1.PipelineTaskList(pipelineSpec.Tasks).Deps())","\tif err != nil {","\t\t// This Run has failed, so we need to mark it as failed and stop reconciling it","\t\tpr.Status.MarkFailed(v1.PipelineRunReasonInvalidGraph.String(),","\t\t\t\"PipelineRun %s/%s's Pipeline DAG is invalid: %s\",","\t\t\tpr.Namespace, pr.Name, pipelineErrors.WrapUserError(err))","\t\treturn controller.NewPermanentError(err)","\t}","","\t// build DAG with a list of final tasks, this DAG is used later to identify","\t// if a task in PipelineRunState is final task or not","\t// the finally section is optional and might not exist","\t// dfinally holds an empty Graph in the absence of finally clause","\tdfinally, err := dag.Build(v1.PipelineTaskList(pipelineSpec.Finally), map[string][]string{})","\tif err != nil {","\t\t// This Run has failed, so we need to mark it as failed and stop reconciling it","\t\tpr.Status.MarkFailed(v1.PipelineRunReasonInvalidGraph.String(),","\t\t\t\"PipelineRun %s/%s's Pipeline DAG is invalid for finally clause: %s\",","\t\t\tpr.Namespace, pr.Name, pipelineErrors.WrapUserError(err))","\t\treturn controller.NewPermanentError(err)","\t}","","\tif err := pipelineSpec.Validate(ctx); err != nil {","\t\t// This Run has failed, so we need to mark it as failed and stop reconciling it","\t\tpr.Status.MarkFailed(v1.PipelineRunReasonFailedValidation.String(),","\t\t\t\"Pipeline %s/%s can't be Run; it has an invalid spec: %s\",","\t\t\tpipelineMeta.Namespace, pipelineMeta.Name, pipelineErrors.WrapUserError(err))","\t\treturn controller.NewPermanentError(err)","\t}","","\t// Ensure that the PipelineRun provides all the parameters required by the Pipeline","\tif err := resources.ValidateRequiredParametersProvided(\u0026pipelineSpec.Params, \u0026pr.Spec.Params); err != nil {","\t\t// This Run has failed, so we need to mark it as failed and stop reconciling it","\t\tpr.Status.MarkFailed(v1.PipelineRunReasonParameterMissing.String(),","\t\t\t\"PipelineRun %s/%s is missing some parameters required by Pipeline %s/%s: %s\",","\t\t\tpr.Namespace, pr.Name, pr.Namespace, pipelineMeta.Name, err)","\t\treturn controller.NewPermanentError(err)","\t}","","\t// Ensure that the parameters from the PipelineRun are overriding Pipeline parameters with the same type.","\t// Weird substitution issues can occur if this is not validated (ApplyParameters() does not verify type).","\tif err = resources.ValidateParamTypesMatching(pipelineSpec, pr); err != nil {","\t\t// This Run has failed, so we need to mark it as failed and stop reconciling it","\t\tpr.Status.MarkFailed(v1.PipelineRunReasonParameterTypeMismatch.String(),","\t\t\t\"PipelineRun %s/%s parameters have mismatching types with Pipeline %s/%s's parameters: %s\",","\t\t\tpr.Namespace, pr.Name, pr.Namespace, pipelineMeta.Name, err)","\t\treturn controller.NewPermanentError(err)","\t}","","\tif config.FromContextOrDefaults(ctx).FeatureFlags.EnableParamEnum {","\t\tif err := taskrun.ValidateEnumParam(ctx, pr.Spec.Params, pipelineSpec.Params); err != nil {","\t\t\tlogger.Errorf(\"PipelineRun %q Param Enum validation failed: %v\", pr.Name, err)","\t\t\tpr.Status.MarkFailed(v1.PipelineRunReasonInvalidParamValue.String(),","\t\t\t\t\"PipelineRun %s/%s parameters have invalid value: %s\",","\t\t\t\tpr.Namespace, pr.Name, pipelineErrors.WrapUserError(err))","\t\t\treturn controller.NewPermanentError(err)","\t\t}","\t}","","\t// Ensure that the keys of an object param declared in PipelineSpec are not missed in the PipelineRunSpec","\tif err = resources.ValidateObjectParamRequiredKeys(pipelineSpec.Params, pr.Spec.Params); err != nil {","\t\t// This Run has failed, so we need to mark it as failed and stop reconciling it","\t\tpr.Status.MarkFailed(v1.PipelineRunReasonObjectParameterMissKeys.String(),","\t\t\t\"PipelineRun %s/%s parameters is missing object keys required by Pipeline %s/%s's parameters: %s\",","\t\t\tpr.Namespace, pr.Name, pr.Namespace, pipelineMeta.Name, err)","\t\treturn controller.NewPermanentError(err)","\t}","","\t// Ensure that the array reference is not out of bound","\tif err := resources.ValidateParamArrayIndex(pipelineSpec, pr.Spec.Params); err != nil {","\t\t// This Run has failed, so we need to mark it as failed and stop reconciling it","\t\tpr.Status.MarkFailed(v1.PipelineRunReasonParamArrayIndexingInvalid.String(),","\t\t\t\"PipelineRun %s/%s failed validation: failed to validate Pipeline %s/%s's parameter which has an invalid index while referring to an array: %s\",","\t\t\tpr.Namespace, pr.Name, pr.Namespace, pipelineMeta.Name, err)","\t\treturn controller.NewPermanentError(err)","\t}","","\t// Ensure that the workspaces expected by the Pipeline are provided by the PipelineRun.","\tif err := resources.ValidateWorkspaceBindings(pipelineSpec, pr); err != nil {","\t\tpr.Status.MarkFailed(v1.PipelineRunReasonInvalidWorkspaceBinding.String(),","\t\t\t\"PipelineRun %s/%s doesn't bind Pipeline %s/%s's Workspaces correctly: %s\",","\t\t\tpr.Namespace, pr.Name, pr.Namespace, pipelineMeta.Name, err)","\t\treturn controller.NewPermanentError(err)","\t}","","\t// Ensure that the TaskRunSpecs defined are correct.","\tif err := resources.ValidateTaskRunSpecs(pipelineSpec, pr); err != nil {","\t\tpr.Status.MarkFailed(v1.PipelineRunReasonInvalidTaskRunSpec.String(),","\t\t\t\"PipelineRun %s/%s doesn't define taskRunSpecs correctly: %s\",","\t\t\tpr.Namespace, pr.Name, err)","\t\treturn controller.NewPermanentError(err)","\t}","","\tresources.ApplyParametersToWorkspaceBindings(pr)","\t// Make a deep copy of the Pipeline and its Tasks before value substitution.","\t// This is used to find referenced pipeline-level params at each PipelineTask when validate param enum subset requirement","\toriginalPipeline := pipelineSpec.DeepCopy()","\toriginalTasks := originalPipeline.Tasks","\toriginalTasks = append(originalTasks, originalPipeline.Finally...)","","\t// Apply parameter substitution from the PipelineRun","\tpipelineSpec, err = resources.ApplyParameters(pipelineSpec, pr)","\tif err != nil {","\t\tlogger.Errorf(\"Failed to apply parameters to pipeline %q: %v\", pipelineMeta.Name, err)","\t\tpr.Status.MarkFailed(v1.PipelineRunReasonFailedValidation.String(),","\t\t\t\"Failed to apply parameters to Pipeline %s/%s: %s\",","\t\t\tpr.Namespace, pipelineMeta.Name, pipelineErrors.WrapUserError(err))","\t\treturn controller.NewPermanentError(err)","\t}","\tpipelineSpec = resources.ApplyContexts(pipelineSpec, pipelineMeta.Name, pr)","\tpipelineSpec = resources.ApplyWorkspaces(pipelineSpec, pr)","\t// Update pipelinespec of pipelinerun's status field","\tpr.Status.PipelineSpec = pipelineSpec","","\t// validate pipelineSpec after apply parameters","\tif err := validatePipelineSpecAfterApplyParameters(ctx, pipelineSpec); err != nil {","\t\t// This Run has failed, so we need to mark it as failed and stop reconciling it","\t\tpr.Status.MarkFailed(v1.PipelineRunReasonFailedValidation.String(),","\t\t\t\"Pipeline %s/%s can't be Run; it has an invalid spec: %s\",","\t\t\tpipelineMeta.Namespace, pipelineMeta.Name, pipelineErrors.WrapUserError(err))","\t\treturn controller.NewPermanentError(err)","\t}","","\t// pipelineRunState holds a list of pipeline tasks after fetching their resolved Task specs.","\t// pipelineRunState also holds a taskRun for each pipeline task after the taskRun is created","\t// pipelineRunState is instantiated and updated on every reconcile cycle","\t// Resolve the set of tasks (and possibly task runs).","\ttasks := pipelineSpec.Tasks","\tif len(pipelineSpec.Finally) \u003e 0 {","\t\ttasks = append(tasks, pipelineSpec.Finally...)","\t}","","\t// We split tasks in two lists:","\t// - those with a completed (Task|Custom)Run reference (i.e. those that finished running)","\t// - those without a (Task|Custom)Run reference","\t// We resolve the status for the former first, to collect all results available at this stage","\t// We know that tasks in progress or completed have had their fan-out already calculated so","\t// they can be safely processed in the first iteration. The underlying assumption is that if","\t// a PipelineTask has at least one TaskRun associated, then all its TaskRuns have been","\t// created already.","\t// The second group takes as input the partial state built in the first iteration and finally","\t// the two results are collated","\tranOrRunningTaskNames := sets.Set[string]{}","\tranOrRunningTasks := []v1.PipelineTask{}","\tnotStartedTasks := []v1.PipelineTask{}","","\tfor _, child := range pr.Status.ChildReferences {","\t\tranOrRunningTaskNames.Insert(child.PipelineTaskName)","\t}","\tfor _, task := range tasks {","\t\tif ranOrRunningTaskNames.Has(task.Name) {","\t\t\tranOrRunningTasks = append(ranOrRunningTasks, task)","\t\t} else {","\t\t\tnotStartedTasks = append(notStartedTasks, task)","\t\t}","\t}","","\t// First iteration","\tpipelineRunState, err := c.resolvePipelineState(ctx, ranOrRunningTasks, pipelineMeta.ObjectMeta, pr, resources.PipelineRunState{})","\tswitch {","\tcase errors.Is(err, remote.ErrRequestInProgress):","\t\tmessage := fmt.Sprintf(\"PipelineRun %s/%s awaiting remote resource\", pr.Namespace, pr.Name)","\t\tpr.Status.MarkRunning(v1.TaskRunReasonResolvingTaskRef, message)","\t\treturn nil","\tcase err != nil:","\t\treturn err","\tdefault:","\t}","","\t// Second iteration","\tpipelineRunState, err = c.resolvePipelineState(ctx, notStartedTasks, pipelineMeta.ObjectMeta, pr, pipelineRunState)","\tswitch {","\tcase errors.Is(err, remote.ErrRequestInProgress):","\t\tmessage := fmt.Sprintf(\"PipelineRun %s/%s awaiting remote resource\", pr.Namespace, pr.Name)","\t\tpr.Status.MarkRunning(v1.TaskRunReasonResolvingTaskRef, message)","\t\treturn nil","\tcase err != nil:","\t\treturn err","\tdefault:","\t}","","\t// Build PipelineRunFacts with a list of resolved pipeline tasks,","\t// dag tasks graph and final tasks graph","\tpipelineRunFacts := \u0026resources.PipelineRunFacts{","\t\tState:           pipelineRunState,","\t\tSpecStatus:      pr.Spec.Status,","\t\tTasksGraph:      d,","\t\tFinalTasksGraph: dfinally,","\t\tTimeoutsState: resources.PipelineRunTimeoutsState{","\t\t\tClock: c.Clock,","\t\t},","\t}","\tif pr.Status.StartTime != nil {","\t\tpipelineRunFacts.TimeoutsState.StartTime = \u0026pr.Status.StartTime.Time","\t}","\tif pr.Status.FinallyStartTime != nil {","\t\tpipelineRunFacts.TimeoutsState.FinallyStartTime = \u0026pr.Status.FinallyStartTime.Time","\t}","\ttasksTimeout := pr.TasksTimeout()","\tif tasksTimeout != nil {","\t\tpipelineRunFacts.TimeoutsState.TasksTimeout = \u0026tasksTimeout.Duration","\t}","\tfinallyTimeout := pr.FinallyTimeout()","\tif finallyTimeout != nil {","\t\tpipelineRunFacts.TimeoutsState.FinallyTimeout = \u0026finallyTimeout.Duration","\t}","\tif pipelineTimeout := pr.PipelineTimeout(ctx); pipelineTimeout != 0 {","\t\tpipelineRunFacts.TimeoutsState.PipelineTimeout = \u0026pipelineTimeout","\t}","","\tfor i, rpt := range pipelineRunFacts.State {","\t\t// Task?","\t\tif !rpt.IsCustomTask() \u0026\u0026 !rpt.IsChildPipeline() {","\t\t\terr := taskrun.ValidateResolvedTask(ctx, rpt.PipelineTask.Params, rpt.PipelineTask.Matrix, rpt.ResolvedTask)","\t\t\tif err != nil {","\t\t\t\tlogger.Errorf(\"Failed to validate pipelinerun %s with error %v\", pr.Name, err)","\t\t\t\tpr.Status.MarkFailed(v1.PipelineRunReasonFailedValidation.String(),","\t\t\t\t\t\"Validation failed for pipelinerun %s with error %s\",","\t\t\t\t\tpr.Name, pipelineErrors.WrapUserError(err))","\t\t\t\treturn controller.NewPermanentError(err)","\t\t\t}","","\t\t\tif config.FromContextOrDefaults(ctx).FeatureFlags.EnableParamEnum {","\t\t\t\tif err := resources.ValidateParamEnumSubset(originalTasks[i].Params, pipelineSpec.Params, rpt.ResolvedTask); err != nil {","\t\t\t\t\tlogger.Errorf(\"Failed to validate pipelinerun %q with error %v\", pr.Name, err)","\t\t\t\t\tpr.Status.MarkFailed(v1.PipelineRunReasonFailedValidation.String(),","\t\t\t\t\t\t\"Validation failed for pipelinerun with error %s\",","\t\t\t\t\t\tpipelineErrors.WrapUserError(err))","\t\t\t\t\treturn controller.NewPermanentError(err)","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\t// Evaluate the CEL of PipelineTask after the variable substitutions and validations.","\tfor _, rpt := range pipelineRunFacts.State {","\t\terr := rpt.EvaluateCEL()","\t\tif err != nil {","\t\t\tlogger.Errorf(\"Error evaluating CEL %s: %v\", pr.Name, err)","\t\t\tpr.Status.MarkFailed(string(v1.PipelineRunReasonCELEvaluationFailed),","\t\t\t\t\"Error evaluating CEL %s: %v\", pr.Name, pipelineErrors.WrapUserError(err))","\t\t\treturn controller.NewPermanentError(err)","\t\t}","\t}","","\t// check if pipeline run is gracefully cancelled and there are active pipeline task runs, which require cancelling","\tif pr.IsGracefullyCancelled() \u0026\u0026 pipelineRunFacts.IsRunning() {","\t\t// If the pipelinerun is cancelled, cancel tasks, but run finally","\t\terr := gracefullyCancelPipelineRun(ctx, logger, pr, c.PipelineClientSet)","\t\tif err != nil {","\t\t\t// failed to cancel tasks, maybe retry would help (don't return permanent error)","\t\t\treturn err","\t\t}","\t}","","\tif pipelineRunFacts.State.IsBeforeFirstTaskRun() {","\t\tif err := resources.ValidatePipelineTaskResults(pipelineRunFacts.State); err != nil {","\t\t\tlogger.Errorf(\"Failed to resolve task result reference for %q with error %v\", pr.Name, err)","\t\t\tpr.Status.MarkFailed(v1.PipelineRunReasonInvalidTaskResultReference.String(), err.Error())","\t\t\treturn controller.NewPermanentError(err)","\t\t}","","\t\tif err := resources.ValidatePipelineResults(pipelineSpec, pipelineRunFacts.State); err != nil {","\t\t\tlogger.Errorf(\"Failed to resolve pipeline result reference for %q with error %v\", pr.Name, err)","\t\t\tpr.Status.MarkFailed(v1.PipelineRunReasonInvalidPipelineResultReference.String(),","\t\t\t\t\"Failed to resolve pipeline result reference for %q with error %v\",","\t\t\t\tpr.Name, err)","\t\t\treturn controller.NewPermanentError(err)","\t\t}","","\t\tif err := resources.ValidateOptionalWorkspaces(pipelineSpec.Workspaces, pipelineRunFacts.State); err != nil {","\t\t\tlogger.Errorf(\"Optional workspace not supported by task: %v\", err)","\t\t\tpr.Status.MarkFailed(v1.PipelineRunReasonRequiredWorkspaceMarkedOptional.String(),","\t\t\t\t\"Optional workspace not supported by task: %v\", pipelineErrors.WrapUserError(err))","\t\t\treturn controller.NewPermanentError(err)","\t\t}","","\t\taaBehavior, err := affinityassistant.GetAffinityAssistantBehavior(ctx)","\t\tif err != nil {","\t\t\treturn controller.NewPermanentError(err)","\t\t}","\t\tif err := c.createOrUpdateAffinityAssistantsAndPVCs(ctx, pr, aaBehavior); err != nil {","\t\t\tswitch {","\t\t\tcase errors.Is(err, volumeclaim.ErrPvcCreationFailed):","\t\t\t\tlogger.Errorf(\"Failed to create PVC for PipelineRun %s: %v\", pr.Name, err)","\t\t\t\tpr.Status.MarkFailed(volumeclaim.ReasonCouldntCreateWorkspacePVC,","\t\t\t\t\t\"Failed to create PVC for PipelineRun %s/%s correctly: %s\",","\t\t\t\t\tpr.Namespace, pr.Name, err)","\t\t\tcase errors.Is(err, volumeclaim.ErrPvcCreationFailedRetryable):","\t\t\t\tlogger.Errorf(\"Failed to create PVC for PipelineRun %s: %v\", pr.Name, err)","\t\t\t\tpr.Status.MarkRunning(ReasonPending, \"Waiting for PVC creation to succeed: %v\", err)","\t\t\t\treturn err // not a permanent error, will requeue","\t\t\tcase errors.Is(err, ErrAffinityAssistantCreationFailed):","\t\t\t\tlogger.Errorf(\"Failed to create affinity assistant StatefulSet for PipelineRun %s: %v\", pr.Name, err)","\t\t\t\tpr.Status.MarkFailed(ReasonCouldntCreateOrUpdateAffinityAssistantStatefulSet,","\t\t\t\t\t\"Failed to create StatefulSet for PipelineRun %s/%s correctly: %s\",","\t\t\t\t\tpr.Namespace, pr.Name, err)","\t\t\tdefault:","\t\t\t\tlogger.Errorf(\"default error handling for PipelineRun %s: %v\", pr.Name, err)","\t\t\t}","\t\t\treturn controller.NewPermanentError(err)","\t\t}","\t}","","\tif pr.Status.FinallyStartTime == nil {","\t\tif pr.HaveTasksTimedOut(ctx, c.Clock) {","\t\t\ttasksToTimeOut := sets.NewString()","\t\t\tfor _, pt := range pipelineRunFacts.State {","\t\t\t\tif !pt.IsFinalTask(pipelineRunFacts) \u0026\u0026 pt.IsRunning() {","\t\t\t\t\ttasksToTimeOut.Insert(pt.PipelineTask.Name)","\t\t\t\t}","\t\t\t}","\t\t\tif tasksToTimeOut.Len() \u003e 0 {","\t\t\t\tlogger.Debugf(\"PipelineRun tasks timeout of %s reached, cancelling tasks\", tasksTimeout)","\t\t\t\terrs := timeoutPipelineTasksForTaskNames(ctx, logger, pr, c.PipelineClientSet, tasksToTimeOut)","\t\t\t\tif len(errs) \u003e 0 {","\t\t\t\t\terrString := strings.Join(errs, \"\\n\")","\t\t\t\t\tlogger.Errorf(\"Failed to timeout tasks for PipelineRun %s/%s: %s\", pr.Namespace, pr.Name, errString)","\t\t\t\t\treturn fmt.Errorf(\"error(s) from cancelling TaskRun(s) from PipelineRun %s: %s\", pr.Name, errString)","\t\t\t\t}","\t\t\t}","\t\t}","\t} else if pr.HasFinallyTimedOut(ctx, c.Clock) {","\t\ttasksToTimeOut := sets.NewString()","\t\tfor _, pt := range pipelineRunFacts.State {","\t\t\tif pt.IsFinalTask(pipelineRunFacts) \u0026\u0026 pt.IsRunning() {","\t\t\t\ttasksToTimeOut.Insert(pt.PipelineTask.Name)","\t\t\t}","\t\t}","\t\tif tasksToTimeOut.Len() \u003e 0 {","\t\t\tlogger.Debugf(\"PipelineRun finally timeout of %s reached, cancelling finally tasks\", finallyTimeout)","\t\t\terrs := timeoutPipelineTasksForTaskNames(ctx, logger, pr, c.PipelineClientSet, tasksToTimeOut)","\t\t\tif len(errs) \u003e 0 {","\t\t\t\terrString := strings.Join(errs, \"\\n\")","\t\t\t\tlogger.Errorf(\"Failed to timeout finally tasks for PipelineRun %s/%s: %s\", pr.Namespace, pr.Name, errString)","\t\t\t\treturn fmt.Errorf(\"error(s) from cancelling TaskRun(s) from PipelineRun %s: %s\", pr.Name, errString)","\t\t\t}","\t\t}","\t}","","\tif err := c.runNextSchedulableTask(ctx, pr, pipelineRunFacts); err != nil {","\t\treturn err","\t}","","\t// Reset the skipped status to trigger recalculation","\tpipelineRunFacts.ResetSkippedCache()","","\t// If the pipelinerun has timed out, mark tasks as timed out and update status","\tif pr.HasTimedOut(ctx, c.Clock) {","\t\tif err := timeoutPipelineRun(ctx, logger, pr, c.PipelineClientSet); err != nil {","\t\t\treturn err","\t\t}","\t}","","\tafter := pipelineRunFacts.GetPipelineConditionStatus(ctx, pr, logger, c.Clock)","\tswitch after.Status {","\tcase corev1.ConditionTrue:","\t\tpr.Status.MarkSucceeded(after.Reason, after.Message)","\tcase corev1.ConditionFalse:","\t\tpr.Status.MarkFailed(after.Reason, after.Message)","\tcase corev1.ConditionUnknown:","\t\tpr.Status.MarkRunning(after.Reason, after.Message)","\t}","\t// Read the condition the way it was set by the Mark* helpers","\tafter = pr.Status.GetCondition(apis.ConditionSucceeded)","\tpr.Status.StartTime = pipelineRunFacts.State.AdjustStartTime(pr.Status.StartTime)","","\tpr.Status.ChildReferences = pipelineRunFacts.GetChildReferences()","","\tpr.Status.SkippedTasks = pipelineRunFacts.GetSkippedTasks()","\tpipelineTaskStatus := pipelineRunFacts.GetPipelineTaskStatus()","\tfinalPipelineTaskStatus := pipelineRunFacts.GetPipelineFinalTaskStatus()","\tpipelineTaskStatus = kmap.Union(pipelineTaskStatus, finalPipelineTaskStatus)","","\tif after.Status == corev1.ConditionTrue || after.Status == corev1.ConditionFalse {","\t\tpr.Status.Results, err = resources.ApplyTaskResultsToPipelineResults(","\t\t\tpipelineSpec.Results,","\t\t\tpipelineRunFacts.State.GetTaskRunsResults(),","\t\t\tpipelineRunFacts.State.GetRunsResults(),","\t\t\tpipelineTaskStatus,","\t\t)","\t\tif err != nil {","\t\t\tpr.Status.MarkFailed(v1.PipelineRunReasonCouldntGetPipelineResult.String(),","\t\t\t\t\"Failed to get PipelineResult from TaskRun Results for PipelineRun %s: %s\",","\t\t\t\tpr.Name, err)","\t\t\treturn err","\t\t}","\t}","","\tlogger.Infof(\"PipelineRun %s status is being set to %s\", pr.Name, after)","\treturn nil","}","","// runNextSchedulableTask gets the next schedulable Tasks from the dag based on the current","// pipeline run state, and starts them","// after all DAG tasks are done, it's responsible for scheduling final tasks and start executing them","func (c *Reconciler) runNextSchedulableTask(ctx context.Context, pr *v1.PipelineRun, pipelineRunFacts *resources.PipelineRunFacts) error {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"runNextSchedulableTask\")","\tdefer span.End()","","\tlogger := logging.FromContext(ctx)","\trecorder := controller.GetEventRecorder(ctx)","","\t// nextRpts holds a list of pipeline tasks which should be executed next","\tnextRpts, err := pipelineRunFacts.DAGExecutionQueue()","\tif err != nil {","\t\tlogger.Errorf(\"Error getting potential next tasks for valid pipelinerun %s: %v\", pr.Name, err)","\t\treturn controller.NewPermanentError(err)","\t}","","\tfor _, rpt := range nextRpts {","\t\t// Check for Missing Result References","\t\t// if error found, present rpt will be","\t\t// added to the validationFailedTask list","\t\terr := resources.CheckMissingResultReferences(pipelineRunFacts.State, rpt)","\t\tif err != nil {","\t\t\tlogger.Infof(\"Failed to resolve task result reference for %q with error %v\", pr.Name, err)","\t\t\t// If there is an error encountered, no new task","\t\t\t// will be scheduled, hence nextRpts should be empty","\t\t\t// If finally tasks are found, then those tasks will","\t\t\t// be added to the nextRpts","\t\t\tnextRpts = nil","\t\t\tlogger.Infof(\"Adding the task %q to the validation failed list\", rpt.ResolvedTask)","\t\t\tpipelineRunFacts.ValidationFailedTask = append(pipelineRunFacts.ValidationFailedTask, rpt)","\t\t}","\t}","\t// GetFinalTasks only returns final tasks when a DAG is complete","\tfNextRpts := pipelineRunFacts.GetFinalTasks()","\tif len(fNextRpts) != 0 {","\t\t// apply the runtime context just before creating taskRuns for final tasks in queue","\t\tresources.ApplyPipelineTaskStateContext(fNextRpts, pipelineRunFacts.GetPipelineTaskStatus())","","\t\t// Before creating TaskRun for scheduled final task, check if it's consuming a task result","\t\t// Resolve and apply task result wherever applicable, report warning in case resolution fails","\t\tfor _, rpt := range fNextRpts {","\t\t\tresolvedResultRefs, _, err := resources.ResolveResultRef(pipelineRunFacts.State, rpt)","\t\t\tif err != nil {","\t\t\t\tlogger.Infof(\"Final task %q is not executed as it could not resolve task params for %q: %v\", rpt.PipelineTask.Name, pr.Name, err)","\t\t\t\tcontinue","\t\t\t}","\t\t\tresources.ApplyTaskResults(resources.PipelineRunState{rpt}, resolvedResultRefs)","","\t\t\tif err := rpt.EvaluateCEL(); err != nil {","\t\t\t\tlogger.Errorf(\"Final task %q is not executed, due to error evaluating CEL %s: %v\", rpt.PipelineTask.Name, pr.Name, err)","\t\t\t\tpr.Status.MarkFailed(string(v1.PipelineRunReasonCELEvaluationFailed),","\t\t\t\t\t\"Error evaluating CEL %s: %v\", pr.Name, pipelineErrors.WrapUserError(err))","\t\t\t\treturn controller.NewPermanentError(err)","\t\t\t}","","\t\t\tnextRpts = append(nextRpts, rpt)","\t\t}","\t}","","\t// If FinallyStartTime is not set, and one or more final tasks has been created","\t// Try to set the FinallyStartTime of this PipelineRun","\tif pr.Status.FinallyStartTime == nil \u0026\u0026 pipelineRunFacts.IsFinalTaskStarted() {","\t\tc.setFinallyStartedTimeIfNeeded(pr, pipelineRunFacts)","\t}","","\tresources.ApplyResultsToWorkspaceBindings(pipelineRunFacts.State.GetTaskRunsResults(), pr)","","\tfor _, rpt := range nextRpts {","\t\tif rpt.IsFinalTask(pipelineRunFacts) {","\t\t\tc.setFinallyStartedTimeIfNeeded(pr, pipelineRunFacts)","\t\t}","","\t\tif rpt == nil || rpt.Skip(pipelineRunFacts).IsSkipped || rpt.IsFinallySkipped(pipelineRunFacts).IsSkipped {","\t\t\tcontinue","\t\t}","","\t\t// propagate previous task results","\t\tresources.PropagateResults(rpt, pipelineRunFacts.State)","","\t\t// propagate previous task artifacts","\t\terr = resources.PropagateArtifacts(rpt, pipelineRunFacts.State)","\t\tif err != nil {","\t\t\tlogger.Errorf(\"Failed to propagate artifacts due to error: %v\", err)","\t\t\treturn controller.NewPermanentError(err)","\t\t}","","\t\t// Validate parameter types in matrix after apply substitutions from Task Results","\t\tif rpt.PipelineTask.IsMatrixed() {","\t\t\tif err := resources.ValidateParameterTypesInMatrix(pipelineRunFacts.State); err != nil {","\t\t\t\tlogger.Errorf(\"Failed to validate matrix %q with error %v\", pr.Name, err)","\t\t\t\tpr.Status.MarkFailed(v1.PipelineRunReasonInvalidMatrixParameterTypes.String(),","\t\t\t\t\t\"Failed to validate matrix %q with error %v\", pipelineErrors.WrapUserError(err))","\t\t\t\treturn controller.NewPermanentError(err)","\t\t\t}","\t\t}","","\t\tswitch {","\t\tcase rpt.IsChildPipeline():","\t\t\trpt.ChildPipelineRuns, err = c.createChildPipelineRuns(ctx, rpt, pr, pipelineRunFacts)","\t\t\tif err != nil {","\t\t\t\trecorder.Eventf(pr, corev1.EventTypeWarning, \"ChildPipelineRunsCreationFailed\", \"Failed to create child (PIP) PipelineRuns %q: %v\", rpt.ChildPipelineRunNames, err)","\t\t\t\terr = fmt.Errorf(\"error creating child PipelineRuns called %s for PipelineTask %s from PipelineRun %s: %w\", rpt.ChildPipelineRunNames, rpt.PipelineTask.Name, pr.Name, err)","\t\t\t\treturn err","\t\t\t}","\t\tcase rpt.IsCustomTask():","\t\t\trpt.CustomRuns, err = c.createCustomRuns(ctx, rpt, pr, pipelineRunFacts)","\t\t\tif err != nil {","\t\t\t\trecorder.Eventf(pr, corev1.EventTypeWarning, \"RunsCreationFailed\", \"Failed to create CustomRuns %q: %v\", rpt.CustomRunNames, err)","\t\t\t\terr = fmt.Errorf(\"error creating CustomRuns called %s for PipelineTask %s from PipelineRun %s: %w\", rpt.CustomRunNames, rpt.PipelineTask.Name, pr.Name, err)","\t\t\t\treturn err","\t\t\t}","\t\tdefault:","\t\t\trpt.TaskRuns, err = c.createTaskRuns(ctx, rpt, pr, pipelineRunFacts)","\t\t\tif err != nil {","\t\t\t\trecorder.Eventf(pr, corev1.EventTypeWarning, \"TaskRunsCreationFailed\", \"Failed to create TaskRuns %q: %v\", rpt.TaskRunNames, err)","\t\t\t\terr = fmt.Errorf(\"error creating TaskRuns called %s for PipelineTask %s from PipelineRun %s: %w\", rpt.TaskRunNames, rpt.PipelineTask.Name, pr.Name, err)","\t\t\t\treturn err","\t\t\t}","\t\t}","\t}","","\treturn nil","}","","// setFinallyStartedTimeIfNeeded sets the PipelineRun.Status.FinallyStartedTime to the current time if it's nil.","func (c *Reconciler) setFinallyStartedTimeIfNeeded(pr *v1.PipelineRun, facts *resources.PipelineRunFacts) {","\tif pr.Status.FinallyStartTime == nil {","\t\tpr.Status.FinallyStartTime = \u0026metav1.Time{Time: c.Clock.Now()}","\t}","\tif facts.TimeoutsState.FinallyStartTime == nil {","\t\tfacts.TimeoutsState.FinallyStartTime = \u0026pr.Status.FinallyStartTime.Time","\t}","}","","func (c *Reconciler) createChildPipelineRuns(","\tctx context.Context,","\trpt *resources.ResolvedPipelineTask,","\tpr *v1.PipelineRun,","\tfacts *resources.PipelineRunFacts,",") ([]*v1.PipelineRun, error) {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"createChildPipelineRuns\")","\tdefer span.End()","","\tvar childPipelineRuns []*v1.PipelineRun","\tfor _, childPipelineRunName := range rpt.ChildPipelineRunNames {","\t\tvar params v1.Params","\t\tchildPipelineRun, err := c.createChildPipelineRun(ctx, childPipelineRunName, params, rpt, pr, facts)","\t\tif err != nil {","\t\t\terr := c.handleRunCreationError(pr, err)","\t\t\treturn nil, err","\t\t}","\t\tchildPipelineRuns = append(childPipelineRuns, childPipelineRun)","\t}","","\treturn childPipelineRuns, nil","}","","func (c *Reconciler) createChildPipelineRun(","\tctx context.Context,","\tchildPipelineRunName string,","\tparams v1.Params,","\trpt *resources.ResolvedPipelineTask,","\tpr *v1.PipelineRun,","\tfacts *resources.PipelineRunFacts,",") (*v1.PipelineRun, error) {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"createChildPipelineRun\")","\tdefer span.End()","","\tlogger := logging.FromContext(ctx)","\trpt.PipelineTask = resources.ApplyPipelineTaskContexts(rpt.PipelineTask, pr.Status, facts)","","\tnewChildPipelineRun := \u0026v1.PipelineRun{","\t\tObjectMeta: metav1.ObjectMeta{","\t\t\tName:            childPipelineRunName,","\t\t\tNamespace:       pr.Namespace,","\t\t\tOwnerReferences: []metav1.OwnerReference{*kmeta.NewControllerRef(pr)},","\t\t\tLabels:          createChildResourceLabels(pr, rpt.PipelineTask.Name, true),","\t\t\tAnnotations:     createChildResourceAnnotations(pr),","\t\t},","\t\tSpec: v1.PipelineRunSpec{","\t\t\tPipelineSpec: rpt.PipelineTask.PipelineSpec,","\t\t},","\t}","","\tlogger.Infof(","\t\t\"Creating a new child (PIP) PipelineRun object %s for pipeline task %s\",","\t\tchildPipelineRunName,","\t\trpt.PipelineTask.Name,","\t)","","\treturn c.PipelineClientSet.TektonV1().","\t\tPipelineRuns(pr.Namespace).","\t\tCreate(ctx, newChildPipelineRun, metav1.CreateOptions{})","}","","func (c *Reconciler) createTaskRuns(ctx context.Context, rpt *resources.ResolvedPipelineTask, pr *v1.PipelineRun, facts *resources.PipelineRunFacts) ([]*v1.TaskRun, error) {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"createTaskRuns\")","\tdefer span.End()","","\tvar matrixCombinations []v1.Params","\tif rpt.PipelineTask.IsMatrixed() {","\t\tmatrixCombinations = rpt.PipelineTask.Matrix.FanOut()","\t}","","\t// validate the param values meet resolved Task Param Enum requirements before creating TaskRuns","\tif config.FromContextOrDefaults(ctx).FeatureFlags.EnableParamEnum {","\t\tfor i := range rpt.TaskRunNames {","\t\t\tvar params v1.Params","\t\t\tif len(matrixCombinations) \u003e i {","\t\t\t\tparams = matrixCombinations[i]","\t\t\t}","\t\t\tparams = append(params, rpt.PipelineTask.Params...)","\t\t\tif err := taskrun.ValidateEnumParam(ctx, params, rpt.ResolvedTask.TaskSpec.Params); err != nil {","\t\t\t\tpr.Status.MarkFailed(v1.PipelineRunReasonInvalidParamValue.String(),","\t\t\t\t\t\"Invalid param value from PipelineTask \\\"%s\\\": %v\",","\t\t\t\t\trpt.PipelineTask.Name, pipelineErrors.WrapUserError(err))","\t\t\t\treturn nil, controller.NewPermanentError(err)","\t\t\t}","\t\t}","\t}","","\tvar taskRuns []*v1.TaskRun","\tfor i, taskRunName := range rpt.TaskRunNames {","\t\tvar params v1.Params","\t\tif len(matrixCombinations) \u003e i {","\t\t\tparams = matrixCombinations[i]","\t\t}","\t\ttaskRun, err := c.createTaskRun(ctx, taskRunName, params, rpt, pr, facts)","\t\tif err != nil {","\t\t\terr := c.handleRunCreationError(pr, err)","\t\t\treturn nil, err","\t\t}","\t\ttaskRuns = append(taskRuns, taskRun)","\t}","","\treturn taskRuns, nil","}","","func (c *Reconciler) createTaskRun(ctx context.Context, taskRunName string, params v1.Params, rpt *resources.ResolvedPipelineTask, pr *v1.PipelineRun, facts *resources.PipelineRunFacts) (*v1.TaskRun, error) {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"createTaskRun\")","\tdefer span.End()","\tlogger := logging.FromContext(ctx)","\trpt.PipelineTask = resources.ApplyPipelineTaskContexts(rpt.PipelineTask, pr.Status, facts)","\ttaskRunSpec := pr.GetTaskRunSpec(rpt.PipelineTask.Name)","\tparams = append(params, rpt.PipelineTask.Params...)","\ttr := \u0026v1.TaskRun{","\t\tObjectMeta: metav1.ObjectMeta{","\t\t\tName:            taskRunName,","\t\t\tNamespace:       pr.Namespace,","\t\t\tOwnerReferences: []metav1.OwnerReference{*kmeta.NewControllerRef(pr)},","\t\t\tLabels:          combineTaskRunAndTaskSpecLabels(pr, rpt.PipelineTask),","\t\t\tAnnotations:     combineTaskRunAndTaskSpecAnnotations(pr, rpt.PipelineTask),","\t\t},","\t\tSpec: v1.TaskRunSpec{","\t\t\tRetries:            rpt.PipelineTask.Retries,","\t\t\tParams:             params,","\t\t\tServiceAccountName: taskRunSpec.ServiceAccountName,","\t\t\tPodTemplate:        taskRunSpec.PodTemplate,","\t\t\tStepSpecs:          taskRunSpec.StepSpecs,","\t\t\tSidecarSpecs:       taskRunSpec.SidecarSpecs,","\t\t\tComputeResources:   taskRunSpec.ComputeResources,","\t\t},","\t}","","\t// Add current spanContext as annotations to TaskRun","\t// so that tracing can be continued under the same traceId","\tif spanContext, err := getMarshalledSpanFromContext(ctx); err == nil {","\t\ttr.Annotations[TaskRunSpanContextAnnotation] = spanContext","\t}","\tif rpt.PipelineTask.OnError == v1.PipelineTaskContinue {","\t\ttr.Annotations[v1.PipelineTaskOnErrorAnnotation] = string(v1.PipelineTaskContinue)","\t}","","\tif rpt.PipelineTask.Timeout != nil {","\t\ttr.Spec.Timeout = rpt.PipelineTask.Timeout","\t}","","\t// taskRunSpec timeout overrides pipeline task timeout","\tif taskRunSpec.Timeout != nil {","\t\ttr.Spec.Timeout = taskRunSpec.Timeout","\t}","","\tif rpt.ResolvedTask.TaskName != \"\" {","\t\t// We pass the entire, original task ref because it may contain additional references like a Bundle url.","\t\ttr.Spec.TaskRef = rpt.PipelineTask.TaskRef","\t} else if rpt.ResolvedTask.TaskSpec != nil {","\t\ttr.Spec.TaskSpec = rpt.ResolvedTask.TaskSpec","\t}","","\tvar pipelinePVCWorkspaceName string","\tvar err error","\ttr.Spec.Workspaces, pipelinePVCWorkspaceName, err = c.getTaskrunWorkspaces(ctx, pr, rpt)","\tif err != nil {","\t\treturn nil, err","\t}","","\taaBehavior, err := affinityassistant.GetAffinityAssistantBehavior(ctx)","\tif err != nil {","\t\treturn nil, err","\t}","\tif aaAnnotationVal := getAffinityAssistantAnnotationVal(aaBehavior, pipelinePVCWorkspaceName, pr.Name); aaAnnotationVal != \"\" {","\t\ttr.Annotations[workspace.AnnotationAffinityAssistantName] = aaAnnotationVal","\t}","","\tlogger.Infof(\"Creating a new TaskRun object %s for pipeline task %s\", taskRunName, rpt.PipelineTask.Name)","","\tcfg := config.FromContextOrDefaults(ctx)","\tif !cfg.FeatureFlags.EnableWaitExponentialBackoff {","\t\treturn c.PipelineClientSet.TektonV1().TaskRuns(pr.Namespace).Create(ctx, tr, metav1.CreateOptions{})","\t}","","\tbackoff := wait.Backoff{","\t\tDuration: cfg.WaitExponentialBackoff.Duration, // Initial delay before retry","\t\tFactor:   cfg.WaitExponentialBackoff.Factor,   // Multiplier for exponential growth","\t\tSteps:    cfg.WaitExponentialBackoff.Steps,    // Maximum number of retry attempts","\t\tCap:      cfg.WaitExponentialBackoff.Cap,      // Maximum time spent before giving up","\t}","\tvar result *v1.TaskRun","\terr = wait.ExponentialBackoff(backoff, func() (bool, error) {","\t\tresult = nil","\t\tresult, err = c.PipelineClientSet.TektonV1().TaskRuns(pr.Namespace).Create(ctx, tr, metav1.CreateOptions{})","\t\tif err != nil {","\t\t\tif ctrl.IsWebhookTimeout(err) {","\t\t\t\treturn false, nil // retry","\t\t\t}","\t\t\treturn false, err // do not retry","\t\t}","\t\treturn true, nil","\t})","\tif err != nil {","\t\treturn nil, err","\t}","\treturn result, nil","}","","// handleRunCreationError marks the PipelineRun as failed and returns a permanent error if the run creation error is not retryable","func (c *Reconciler) handleRunCreationError(pr *v1.PipelineRun, err error) error {","\tif controller.IsPermanentError(err) {","\t\tpr.Status.MarkFailed(v1.PipelineRunReasonCreateRunFailed.String(), err.Error())","\t\treturn err","\t}","\t// This is not a complete list of permanent errors. Any permanent error with child (PinP)","\t// PipelinRun/TaskRun/CustomRun creation can be added here.","\tif apierrors.IsInvalid(err) || apierrors.IsBadRequest(err) {","\t\tpr.Status.MarkFailed(v1.PipelineRunReasonCreateRunFailed.String(), err.Error())","\t\treturn controller.NewPermanentError(err)","\t}","\treturn err","}","","func (c *Reconciler) createCustomRuns(ctx context.Context, rpt *resources.ResolvedPipelineTask, pr *v1.PipelineRun, facts *resources.PipelineRunFacts) ([]*v1beta1.CustomRun, error) {","\tvar customRuns []*v1beta1.CustomRun","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"createCustomRuns\")","\tdefer span.End()","\tvar matrixCombinations []v1.Params","","\tif rpt.PipelineTask.IsMatrixed() {","\t\tmatrixCombinations = rpt.PipelineTask.Matrix.FanOut()","\t}","\tfor i, customRunName := range rpt.CustomRunNames {","\t\tvar params v1.Params","\t\tif len(matrixCombinations) \u003e i {","\t\t\tparams = matrixCombinations[i]","\t\t}","\t\tcustomRun, err := c.createCustomRun(ctx, customRunName, params, rpt, pr, facts)","\t\tif err != nil {","\t\t\terr := c.handleRunCreationError(pr, err)","\t\t\treturn nil, err","\t\t}","\t\tcustomRuns = append(customRuns, customRun)","\t}","\treturn customRuns, nil","}","","func (c *Reconciler) createCustomRun(ctx context.Context, runName string, params v1.Params, rpt *resources.ResolvedPipelineTask, pr *v1.PipelineRun, facts *resources.PipelineRunFacts) (*v1beta1.CustomRun, error) {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"createCustomRun\")","\tdefer span.End()","\tlogger := logging.FromContext(ctx)","\trpt.PipelineTask = resources.ApplyPipelineTaskContexts(rpt.PipelineTask, pr.Status, facts)","\ttaskRunSpec := pr.GetTaskRunSpec(rpt.PipelineTask.Name)","\tparams = append(params, rpt.PipelineTask.Params...)","","\ttaskTimeout := rpt.PipelineTask.Timeout","\t// taskRunSpec timeout overrides pipeline task timeout","\tif taskRunSpec.Timeout != nil {","\t\ttaskTimeout = taskRunSpec.Timeout","\t}","","\tvar pipelinePVCWorkspaceName string","\tvar err error","\tvar workspaces []v1.WorkspaceBinding","\tworkspaces, pipelinePVCWorkspaceName, err = c.getTaskrunWorkspaces(ctx, pr, rpt)","\tif err != nil {","\t\treturn nil, err","\t}","","\tobjectMeta := metav1.ObjectMeta{","\t\tName:            runName,","\t\tNamespace:       pr.Namespace,","\t\tOwnerReferences: []metav1.OwnerReference{*kmeta.NewControllerRef(pr)},","\t\tLabels:          createChildResourceLabels(pr, rpt.PipelineTask.Name, true),","\t\tAnnotations:     createChildResourceAnnotations(pr),","\t}","","\t// TaskRef, Params and Workspaces are converted to v1beta1 since CustomRuns","\t// is still in v1beta1 apiVersion","\tvar customRef *v1beta1.TaskRef","\tif rpt.PipelineTask.TaskRef != nil {","\t\tcustomRef = \u0026v1beta1.TaskRef{}","\t\tcustomRef.ConvertFrom(ctx, *rpt.PipelineTask.TaskRef)","\t}","","\tcustomRunParams := v1beta1.Params{}","\tfor _, p := range params {","\t\tv1beta1Param := v1beta1.Param{}","\t\tv1beta1Param.ConvertFrom(ctx, p)","\t\tcustomRunParams = append(customRunParams, v1beta1Param)","\t}","","\tcustomRunWorkspaces := []v1beta1.WorkspaceBinding{}","\tfor _, w := range workspaces {","\t\tv1beta1WorkspaceBinding := v1beta1.WorkspaceBinding{}","\t\tv1beta1WorkspaceBinding.ConvertFrom(ctx, w)","\t\tcustomRunWorkspaces = append(customRunWorkspaces, v1beta1WorkspaceBinding)","\t}","","\tr := \u0026v1beta1.CustomRun{","\t\tObjectMeta: objectMeta,","\t\tSpec: v1beta1.CustomRunSpec{","\t\t\tRetries:            rpt.PipelineTask.Retries,","\t\t\tCustomRef:          customRef,","\t\t\tParams:             customRunParams,","\t\t\tServiceAccountName: taskRunSpec.ServiceAccountName,","\t\t\tTimeout:            taskTimeout,","\t\t\tWorkspaces:         customRunWorkspaces,","\t\t},","\t}","","\tif rpt.PipelineTask.TaskSpec != nil {","\t\tj, err := json.Marshal(rpt.PipelineTask.TaskSpec.Spec)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tr.Spec.CustomSpec = \u0026v1beta1.EmbeddedCustomRunSpec{","\t\t\tTypeMeta: runtime.TypeMeta{","\t\t\t\tAPIVersion: rpt.PipelineTask.TaskSpec.APIVersion,","\t\t\t\tKind:       rpt.PipelineTask.TaskSpec.Kind,","\t\t\t},","\t\t\tMetadata: v1beta1.PipelineTaskMetadata(rpt.PipelineTask.TaskSpec.Metadata),","\t\t\tSpec: runtime.RawExtension{","\t\t\t\tRaw: j,","\t\t\t},","\t\t}","\t}","","\t// Set the affinity assistant annotation in case the custom task creates TaskRuns or Pods","\t// that can take advantage of it.","\taaBehavior, err := affinityassistant.GetAffinityAssistantBehavior(ctx)","\tif err != nil {","\t\treturn nil, err","\t}","\tif aaAnnotationVal := getAffinityAssistantAnnotationVal(aaBehavior, pipelinePVCWorkspaceName, pr.Name); aaAnnotationVal != \"\" {","\t\tr.Annotations[workspace.AnnotationAffinityAssistantName] = aaAnnotationVal","\t}","","\tlogger.Infof(\"Creating a new CustomRun object %s\", runName)","","\tcfg := config.FromContextOrDefaults(ctx)","\tif !cfg.FeatureFlags.EnableWaitExponentialBackoff {","\t\treturn c.PipelineClientSet.TektonV1beta1().CustomRuns(pr.Namespace).Create(ctx, r, metav1.CreateOptions{})","\t}","","\tbackoff := wait.Backoff{","\t\tDuration: cfg.WaitExponentialBackoff.Duration, // Initial delay before retry","\t\tFactor:   cfg.WaitExponentialBackoff.Factor,   // Multiplier for exponential growth","\t\tSteps:    cfg.WaitExponentialBackoff.Steps,    // Maximum number of retry attempts","\t\tCap:      cfg.WaitExponentialBackoff.Cap,      // Maximum time spent before giving up","\t}","\tvar result *v1beta1.CustomRun","\terr = wait.ExponentialBackoff(backoff, func() (bool, error) {","\t\tresult = nil","\t\tresult, err = c.PipelineClientSet.TektonV1beta1().CustomRuns(pr.Namespace).Create(ctx, r, metav1.CreateOptions{})","\t\tif err != nil {","\t\t\tif ctrl.IsWebhookTimeout(err) {","\t\t\t\treturn false, nil // retry","\t\t\t}","\t\t\treturn false, err // do not retry","\t\t}","\t\treturn true, nil","\t})","\tif err != nil {","\t\treturn nil, err","\t}","\treturn result, nil","}","","// propagateWorkspaces identifies the workspaces that the pipeline task usess","// It adds the additional workspaces to the pipeline task's workspaces after","// creating workspace bindings. Finally, it returns the updated resolved pipeline task.","func propagateWorkspaces(rpt *resources.ResolvedPipelineTask) (*resources.ResolvedPipelineTask, error) {","\tts := rpt.PipelineTask.TaskSpec.TaskSpec","","\tworkspacesUsedInSteps, err := workspace.FindWorkspacesUsedByTask(ts)","\tif err != nil {","\t\treturn rpt, err","\t}","","\tptw := sets.NewString()","\tfor _, ws := range rpt.PipelineTask.Workspaces {","\t\tptw.Insert(ws.Name)","\t}","","\tfor wSpace := range workspacesUsedInSteps {","\t\tif !ptw.Has(wSpace) {","\t\t\trpt.PipelineTask.Workspaces = append(rpt.PipelineTask.Workspaces, v1.WorkspacePipelineTaskBinding{Name: wSpace})","\t\t}","\t}","\treturn rpt, nil","}","","func (c *Reconciler) getTaskrunWorkspaces(ctx context.Context, pr *v1.PipelineRun, rpt *resources.ResolvedPipelineTask) ([]v1.WorkspaceBinding, string, error) {","\tvar err error","\tvar workspaces []v1.WorkspaceBinding","\tvar pipelinePVCWorkspaceName string","\tpipelineRunWorkspaces := make(map[string]v1.WorkspaceBinding)","\tfor _, binding := range pr.Spec.Workspaces {","\t\tpipelineRunWorkspaces[binding.Name] = binding","\t}","","\t// Propagate required workspaces from pipelineRun to the pipelineTasks","\tif rpt.PipelineTask.TaskSpec != nil {","\t\trpt, err = propagateWorkspaces(rpt)","\t\tif err != nil {","\t\t\t// This error cannot be recovered without modifying the TaskSpec","\t\t\treturn nil, \"\", controller.NewPermanentError(err)","\t\t}","\t}","","\tfor _, ws := range rpt.PipelineTask.Workspaces {","\t\ttaskWorkspaceName, pipelineTaskSubPath, pipelineWorkspaceName := ws.Name, ws.SubPath, ws.Workspace","\t\tpipelineWorkspace := pipelineWorkspaceName","","\t\tif pipelineWorkspaceName == \"\" {","\t\t\tpipelineWorkspace = taskWorkspaceName","\t\t}","","\t\tif b, hasBinding := pipelineRunWorkspaces[pipelineWorkspace]; hasBinding {","\t\t\tif b.PersistentVolumeClaim != nil || b.VolumeClaimTemplate != nil {","\t\t\t\tpipelinePVCWorkspaceName = pipelineWorkspace","\t\t\t}","","\t\t\taaBehavior, err := affinityassistant.GetAffinityAssistantBehavior(ctx)","\t\t\tif err != nil {","\t\t\t\treturn nil, \"\", err","\t\t\t}","","\t\t\tworkspace := c.taskWorkspaceByWorkspaceVolumeSource(ctx, pipelinePVCWorkspaceName, pr.Name, b, taskWorkspaceName, pipelineTaskSubPath, *kmeta.NewControllerRef(pr), aaBehavior)","\t\t\tworkspaces = append(workspaces, workspace)","\t\t} else {","\t\t\tworkspaceIsOptional := false","\t\t\tif rpt.ResolvedTask != nil \u0026\u0026 rpt.ResolvedTask.TaskSpec != nil {","\t\t\t\tfor _, taskWorkspaceDeclaration := range rpt.ResolvedTask.TaskSpec.Workspaces {","\t\t\t\t\tif taskWorkspaceDeclaration.Name == taskWorkspaceName \u0026\u0026 taskWorkspaceDeclaration.Optional {","\t\t\t\t\t\tworkspaceIsOptional = true","\t\t\t\t\t\tbreak","\t\t\t\t\t}","\t\t\t\t}","\t\t\t}","\t\t\tif !workspaceIsOptional {","\t\t\t\terr = fmt.Errorf(\"expected workspace %q to be provided by pipelinerun for pipeline task %q\", pipelineWorkspace, rpt.PipelineTask.Name)","\t\t\t\t// This error cannot be recovered without modifying the PipelineRun","\t\t\t\treturn nil, \"\", controller.NewPermanentError(err)","\t\t\t}","\t\t}","\t}","","\t// replace pipelineRun context variables in workspace subPath in the workspace binding","\tvar p string","\tif pr.Spec.PipelineRef != nil {","\t\tp = pr.Spec.PipelineRef.Name","\t}","\tfor j := range workspaces {","\t\tworkspaces[j].SubPath = substitution.ApplyReplacements(workspaces[j].SubPath, resources.GetContextReplacements(p, pr))","\t}","","\treturn workspaces, pipelinePVCWorkspaceName, nil","}","","// taskWorkspaceByWorkspaceVolumeSource returns the WorkspaceBinding to be bound to each TaskRun in the Pipeline Task.","// If the PipelineRun WorkspaceBinding is a volumeClaimTemplate, the returned WorkspaceBinding references a PersistentVolumeClaim created for the PipelineRun WorkspaceBinding based on the PipelineRun as OwnerReference.","// Otherwise, the returned WorkspaceBinding references the same volume as the PipelineRun WorkspaceBinding, with the file path joined with pipelineTaskSubPath as the binding subpath.","func (c *Reconciler) taskWorkspaceByWorkspaceVolumeSource(ctx context.Context, pipelineWorkspaceName string, prName string, wb v1.WorkspaceBinding, taskWorkspaceName string, pipelineTaskSubPath string, owner metav1.OwnerReference, aaBehavior affinityassistant.AffinityAssistantBehavior) v1.WorkspaceBinding {","\tif wb.VolumeClaimTemplate == nil {","\t\tbinding := *wb.DeepCopy()","\t\tbinding.Name = taskWorkspaceName","\t\tbinding.SubPath = combinedSubPath(wb.SubPath, pipelineTaskSubPath)","\t\treturn binding","\t}","","\tbinding := v1.WorkspaceBinding{","\t\tSubPath:               combinedSubPath(wb.SubPath, pipelineTaskSubPath),","\t\tPersistentVolumeClaim: \u0026corev1.PersistentVolumeClaimVolumeSource{},","\t}","\tbinding.Name = taskWorkspaceName","","\tswitch aaBehavior {","\tcase affinityassistant.AffinityAssistantPerWorkspace, affinityassistant.AffinityAssistantDisabled:","\t\tbinding.PersistentVolumeClaim.ClaimName = volumeclaim.GeneratePVCNameFromWorkspaceBinding(wb.VolumeClaimTemplate.Name, wb, owner)","\tcase affinityassistant.AffinityAssistantPerPipelineRun, affinityassistant.AffinityAssistantPerPipelineRunWithIsolation:","\t\tbinding.PersistentVolumeClaim.ClaimName = getPersistentVolumeClaimNameWithAffinityAssistant(\"\", prName, wb, owner)","\t}","","\treturn binding","}","","// combinedSubPath returns the combined value of the optional subPath from workspaceBinding and the optional","// subPath from pipelineTask. If both is set, they are joined with a slash.","func combinedSubPath(workspaceSubPath string, pipelineTaskSubPath string) string {","\tif workspaceSubPath == \"\" {","\t\treturn pipelineTaskSubPath","\t} else if pipelineTaskSubPath == \"\" {","\t\treturn workspaceSubPath","\t}","\treturn filepath.Join(workspaceSubPath, pipelineTaskSubPath)","}","","func createChildResourceAnnotations(pr *v1.PipelineRun) map[string]string {","\t// propagate annotations from PipelineRun to child (PinP) PipelineRun/TaskRun/CustomRun","\tannotations := make(map[string]string, len(pr.ObjectMeta.Annotations)+1)","\tfor key, val := range pr.ObjectMeta.Annotations {","\t\tannotations[key] = val","\t}","\treturn kmap.Filter(annotations, func(s string) bool {","\t\treturn filterReservedAnnotationRegexp.MatchString(s)","\t})","}","","func propagatePipelineNameLabelToPipelineRun(pr *v1.PipelineRun) error {","\tif pr.ObjectMeta.Labels == nil {","\t\tpr.ObjectMeta.Labels = make(map[string]string)","\t}","","\tif _, ok := pr.ObjectMeta.Labels[pipeline.PipelineLabelKey]; ok {","\t\treturn nil","\t}","","\tswitch {","\tcase pr.Spec.PipelineRef != nil \u0026\u0026 pr.Spec.PipelineRef.Name != \"\":","\t\tpr.ObjectMeta.Labels[pipeline.PipelineLabelKey] = pr.Spec.PipelineRef.Name","\tcase pr.Spec.PipelineSpec != nil:","\t\tpr.ObjectMeta.Labels[pipeline.PipelineLabelKey] = pr.Name","\tcase pr.Spec.PipelineRef != nil \u0026\u0026 pr.Spec.PipelineRef.Resolver != \"\":","\t\tpr.ObjectMeta.Labels[pipeline.PipelineLabelKey] = pr.Name","","\t\t// https://tekton.dev/docs/pipelines/cluster-resolver/#pipeline-resolution","\t\tvar kind, name string","\t\tfor _, param := range pr.Spec.PipelineRef.Params {","\t\t\tif param.Name == \"kind\" {","\t\t\t\tkind = param.Value.StringVal","\t\t\t}","\t\t\tif param.Name == \"name\" {","\t\t\t\tname = param.Value.StringVal","\t\t\t}","\t\t}","\t\tif kind == \"pipeline\" {","\t\t\tpr.ObjectMeta.Labels[pipeline.PipelineLabelKey] = name","\t\t}","\tdefault:","\t\treturn fmt.Errorf(\"pipelineRun %s not providing PipelineRef or PipelineSpec\", pr.Name)","\t}","\treturn nil","}","","func createChildResourceLabels(pr *v1.PipelineRun, pipelineTaskName string, includePipelineRunLabels bool) map[string]string {","\t// propagate labels from PipelineRun to child (PinP) PipelineRun/TaskRun/CustomRun","\tlabels := make(map[string]string, len(pr.ObjectMeta.Labels)+1)","\tif includePipelineRunLabels {","\t\tfor key, val := range pr.ObjectMeta.Labels {","\t\t\tlabels[key] = val","\t\t}","\t}","\tlabels[pipeline.PipelineRunLabelKey] = pr.Name","\tlabels[pipeline.PipelineRunUIDLabelKey] = string(pr.UID)","\tif pipelineTaskName != \"\" {","\t\tlabels[pipeline.PipelineTaskLabelKey] = pipelineTaskName","\t}","\tif pr.Status.PipelineSpec != nil {","\t\t// check if a task is part of the \"tasks\" section, add a label to identify it during the runtime","\t\tfor _, f := range pr.Status.PipelineSpec.Tasks {","\t\t\tif pipelineTaskName == f.Name {","\t\t\t\tlabels[pipeline.MemberOfLabelKey] = v1.PipelineTasks","\t\t\t\tbreak","\t\t\t}","\t\t}","\t\t// check if a task is part of the \"finally\" section, add a label to identify it during the runtime","\t\tfor _, f := range pr.Status.PipelineSpec.Finally {","\t\t\tif pipelineTaskName == f.Name {","\t\t\t\tlabels[pipeline.MemberOfLabelKey] = v1.PipelineFinallyTasks","\t\t\t\tbreak","\t\t\t}","\t\t}","\t}","\treturn labels","}","","func combineTaskRunAndTaskSpecLabels(pr *v1.PipelineRun, pipelineTask *v1.PipelineTask) map[string]string {","\tlabels := make(map[string]string)","","\ttaskRunSpec := pr.GetTaskRunSpec(pipelineTask.Name)","\tif taskRunSpec.Metadata != nil {","\t\taddMetadataByPrecedence(labels, taskRunSpec.Metadata.Labels)","\t}","","\taddMetadataByPrecedence(labels, createChildResourceLabels(pr, pipelineTask.Name, true))","","\tif pipelineTask.TaskSpec != nil {","\t\taddMetadataByPrecedence(labels, pipelineTask.TaskSpecMetadata().Labels)","\t}","","\treturn labels","}","","func combineTaskRunAndTaskSpecAnnotations(pr *v1.PipelineRun, pipelineTask *v1.PipelineTask) map[string]string {","\tannotations := make(map[string]string)","","\ttaskRunSpec := pr.GetTaskRunSpec(pipelineTask.Name)","\tif taskRunSpec.Metadata != nil {","\t\taddMetadataByPrecedence(annotations, taskRunSpec.Metadata.Annotations)","\t}","","\taddMetadataByPrecedence(annotations, createChildResourceAnnotations(pr))","","\tif pipelineTask.TaskSpec != nil {","\t\taddMetadataByPrecedence(annotations, pipelineTask.TaskSpecMetadata().Annotations)","\t}","","\treturn annotations","}","","// addMetadataByPrecedence() adds the elements in addedMetadata to metadata. If the same key is present in both maps, the value from metadata will be used.","func addMetadataByPrecedence(metadata map[string]string, addedMetadata map[string]string) {","\tfor key, value := range addedMetadata {","\t\t// add new annotations/labels  if the key not exists in current ones","\t\tif _, ok := metadata[key]; !ok {","\t\t\tmetadata[key] = value","\t\t}","\t}","}","","func (c *Reconciler) updateLabelsAndAnnotations(ctx context.Context, pr *v1.PipelineRun) (*v1.PipelineRun, error) {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"updateLabelsAndAnnotations\")","\tdefer span.End()","\tnewPr, err := c.pipelineRunLister.PipelineRuns(pr.Namespace).Get(pr.Name)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"error getting PipelineRun %s when updating labels/annotations: %w\", pr.Name, err)","\t}","\tif !reflect.DeepEqual(pr.ObjectMeta.Labels, newPr.ObjectMeta.Labels) || !reflect.DeepEqual(pr.ObjectMeta.Annotations, newPr.ObjectMeta.Annotations) {","\t\t// Note that this uses Update vs. Patch because the former is significantly easier to test.","\t\t// If we want to switch this to Patch, then we will need to teach the utilities in test/controller.go","\t\t// to deal with Patch (setting resourceVersion, and optimistic concurrency checks).","\t\tnewPr = newPr.DeepCopy()","\t\t// Properly merge labels and annotations, as the labels *might* have changed during the reconciliation","\t\tnewPr.Labels = kmap.Union(newPr.Labels, pr.Labels)","\t\tnewPr.Annotations = kmap.Union(newPr.Annotations, pr.Annotations)","\t\treturn c.PipelineClientSet.TektonV1().PipelineRuns(pr.Namespace).Update(ctx, newPr, metav1.UpdateOptions{})","\t}","\treturn newPr, nil","}","","func storePipelineSpecAndMergeMeta(ctx context.Context, pr *v1.PipelineRun, ps *v1.PipelineSpec, meta *resolutionutil.ResolvedObjectMeta) error {","\t// Only store the PipelineSpec once, if it has never been set before.","\tif pr.Status.PipelineSpec == nil {","\t\tpr.Status.PipelineSpec = ps","\t\tif meta == nil {","\t\t\treturn nil","\t\t}","","\t\t// Propagate labels from Pipeline to PipelineRun. PipelineRun labels take precedences over Pipeline.","\t\tpr.ObjectMeta.Labels = kmap.Union(meta.Labels, pr.ObjectMeta.Labels)","\t\tif len(meta.Name) \u003e 0 {","\t\t\tpr.ObjectMeta.Labels[pipeline.PipelineLabelKey] = meta.Name","\t\t}","","\t\t// Propagate annotations from Pipeline to PipelineRun. PipelineRun annotations take precedences over Pipeline.","\t\tpr.ObjectMeta.Annotations = kmap.Union(kmap.ExcludeKeys(meta.Annotations, tknreconciler.KubectlLastAppliedAnnotationKey), pr.ObjectMeta.Annotations)","\t}","","\t// Propagate refSource from remote resolution to PipelineRun Status","\t// This lives outside of the status.spec check to avoid the case where only the spec is available in the first reconcile and source comes in next reconcile.","\tcfg := config.FromContextOrDefaults(ctx)","\tif cfg.FeatureFlags.EnableProvenanceInStatus {","\t\tif pr.Status.Provenance == nil {","\t\t\tpr.Status.Provenance = \u0026v1.Provenance{}","\t\t}","\t\t// Store FeatureFlags in the Provenance.","\t\tpr.Status.Provenance.FeatureFlags = cfg.FeatureFlags","","\t\tif meta != nil \u0026\u0026 meta.RefSource != nil \u0026\u0026 pr.Status.Provenance.RefSource == nil {","\t\t\tpr.Status.Provenance.RefSource = meta.RefSource","\t\t}","\t}","","\treturn nil","}","","func (c *Reconciler) updatePipelineRunStatusFromInformer(ctx context.Context, pr *v1.PipelineRun) error {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"updatePipelineRunStatusFromInformer\")","\tdefer span.End()","\tlogger := logging.FromContext(ctx)","","\t// Get the parent PipelineRun label that is set on each child (PinP) PipelineRun/TaskRun/CustomRun. Do not include the propagated labels from the","\t// Pipeline and PipelineRun. The user could change them during the lifetime of the PipelineRun so the","\t// current labels may not be set on the previously created TaskRuns.","\tpipelineRunLabels := createChildResourceLabels(pr, \"\", false)","\tchildPipelineRuns, err := c.pipelineRunLister.PipelineRuns(pr.Namespace).List(k8slabels.SelectorFromSet(pipelineRunLabels))","\tif err != nil {","\t\tlogger.Errorf(\"Could not list PipelineRuns %#v\", err)","\t\treturn err","\t}","","\ttaskRuns, err := c.taskRunLister.TaskRuns(pr.Namespace).List(k8slabels.SelectorFromSet(pipelineRunLabels))","\tif err != nil {","\t\tlogger.Errorf(\"Could not list TaskRuns %#v\", err)","\t\treturn err","\t}","","\tcustomRuns, err := c.customRunLister.CustomRuns(pr.Namespace).List(k8slabels.SelectorFromSet(pipelineRunLabels))","\tif err != nil {","\t\tlogger.Errorf(\"Could not list CustomRuns %#v\", err)","\t\treturn err","\t}","","\treturn updatePipelineRunStatusFromChildObjects(ctx, logger, pr, childPipelineRuns, taskRuns, customRuns)","}","","func updatePipelineRunStatusFromChildObjects(ctx context.Context, logger *zap.SugaredLogger, pr *v1.PipelineRun, childPipelineRuns []*v1.PipelineRun, taskRuns []*v1.TaskRun, customRuns []*v1beta1.CustomRun) error {","\tupdatePipelineRunStatusFromChildRefs(logger, pr, childPipelineRuns, taskRuns, customRuns)","","\treturn validateChildObjectsInPipelineRunStatus(ctx, pr.Status)","}","","func validateChildObjectsInPipelineRunStatus(ctx context.Context, prs v1.PipelineRunStatus) error {","\tvar err error","","\tfor _, cr := range prs.ChildReferences {","\t\tswitch cr.Kind {","\t\tcase taskRun, customRun, pipelineRun:","\t\t\tcontinue","\t\tdefault:","\t\t\terr = errors.Join(err, fmt.Errorf(\"child with name %s has unknown kind %s\", cr.Name, cr.Kind))","\t\t}","\t}","","\treturn err","}","","// filterChildPipelineRunsForParentPipelineRunStatus returns child (PinP) PipelineRuns owned by the parent PipelineRun.","func filterChildPipelineRunsForParentPipelineRunStatus(logger *zap.SugaredLogger, pr *v1.PipelineRun, childPipelineRuns []*v1.PipelineRun) []*v1.PipelineRun {","\tvar owned []*v1.PipelineRun","","\tfor _, child := range childPipelineRuns {","\t\t// Only process child (PinP) PipelineRuns that are owned by this parent PipelineRun.","\t\t// This skips PipelineRuns that are indirectly created by the PipelineRun (e.g. by custom tasks).","\t\tif len(child.OwnerReferences) == 0 || child.OwnerReferences[0].UID != pr.ObjectMeta.UID {","\t\t\tlogger.Debugf(\"Found a child (PIP) PipelineRun %s that is not owned by this parent PipelineRun\", child.Name)","\t\t\tcontinue","\t\t}","\t\towned = append(owned, child)","\t}","","\treturn owned","}","","func filterTaskRunsForPipelineRunStatus(logger *zap.SugaredLogger, pr *v1.PipelineRun, trs []*v1.TaskRun) []*v1.TaskRun {","\tvar ownedTaskRuns []*v1.TaskRun","","\tfor _, tr := range trs {","\t\t// Only process TaskRuns that are owned by this PipelineRun.","\t\t// This skips TaskRuns that are indirectly created by the PipelineRun (e.g. by custom tasks).","\t\tif len(tr.OwnerReferences) \u003c 1 || tr.OwnerReferences[0].UID != pr.ObjectMeta.UID {","\t\t\tlogger.Debugf(\"Found a TaskRun %s that is not owned by this PipelineRun\", tr.Name)","\t\t\tcontinue","\t\t}","\t\townedTaskRuns = append(ownedTaskRuns, tr)","\t}","","\treturn ownedTaskRuns","}","","// filterCustomRunsForPipelineRunStatus filters the given slice of customRuns, returning information only those owned by the given PipelineRun.","func filterCustomRunsForPipelineRunStatus(logger *zap.SugaredLogger, pr *v1.PipelineRun, customRuns []*v1beta1.CustomRun) ([]string, []string, []schema.GroupVersionKind, []*v1beta1.CustomRunStatus) {","\tvar names []string","\tvar taskLabels []string","\tvar gvks []schema.GroupVersionKind","\tvar statuses []*v1beta1.CustomRunStatus","","\t// Loop over all the customRuns associated to Tasks","\tfor _, cr := range customRuns {","\t\t// Only process customRuns that are owned by this PipelineRun.","\t\t// This skips customRuns that are indirectly created by the PipelineRun (e.g. by custom tasks).","\t\tif len(cr.GetObjectMeta().GetOwnerReferences()) \u003c 1 || cr.GetObjectMeta().GetOwnerReferences()[0].UID != pr.ObjectMeta.UID {","\t\t\tlogger.Debugf(\"Found a %s %s that is not owned by this PipelineRun\", cr.GetObjectKind().GroupVersionKind().Kind, cr.GetObjectMeta().GetName())","\t\t\tcontinue","\t\t}","","\t\tnames = append(names, cr.GetObjectMeta().GetName())","\t\ttaskLabels = append(taskLabels, cr.GetObjectMeta().GetLabels()[pipeline.PipelineTaskLabelKey])","","\t\tstatuses = append(statuses, \u0026cr.Status)","\t\t// We can't just get the gvk from the customRun's TypeMeta because that isn't populated for resources created through the fake client.","\t\tgvks = append(gvks, v1beta1.SchemeGroupVersion.WithKind(customRun))","\t}","","\t// NAMES are names","","\treturn names, taskLabels, gvks, statuses","}","","func updatePipelineRunStatusFromChildRefs(logger *zap.SugaredLogger, pr *v1.PipelineRun, childPipelineRuns []*v1.PipelineRun, trs []*v1.TaskRun, customRuns []*v1beta1.CustomRun) {","\t// If no child (PinP) PipelineRun, TaskRun or CustomRun was found, nothing to be done. We never remove child references from the status.","\t// We do still return an empty map of TaskRun/Run names keyed by PipelineTask name for later functions.","\tif len(childPipelineRuns) == 0 \u0026\u0026 len(trs) == 0 \u0026\u0026 len(customRuns) == 0 {","\t\treturn","\t}","","\t// Map PipelineTask names to child (PinP) PipelineRun, TaskRun or CustomRun child references that were already in the status","\tchildRefByName := make(map[string]*v1.ChildStatusReference)","","\tfor i := range pr.Status.ChildReferences {","\t\tchildRefByName[pr.Status.ChildReferences[i].Name] = \u0026pr.Status.ChildReferences[i]","\t}","","\tfilteredChildPipelineRuns := filterChildPipelineRunsForParentPipelineRunStatus(logger, pr, childPipelineRuns)","","\t// Loop over all the child (PinP) PipelineRuns associated to the parent PipelineRun","\tfor _, fcpr := range filteredChildPipelineRuns {","\t\tlabels := fcpr.GetLabels()","\t\tpipelineTaskName := labels[pipeline.PipelineTaskLabelKey]","","\t\t// this child pipeline run is already in the status","\t\tif _, ok := childRefByName[fcpr.Name]; ok {","\t\t\tcontinue","\t\t}","","\t\tlogger.Infof(\"Found a child (PinP) PipelineRun %s that was missing from the parent PipelineRun status\", fcpr.Name)","","\t\t// Since this was recovered now, add it to the map, or it might be overwritten","\t\tchildRefByName[fcpr.Name] = \u0026v1.ChildStatusReference{","\t\t\tTypeMeta: runtime.TypeMeta{","\t\t\t\tAPIVersion: v1.SchemeGroupVersion.String(),","\t\t\t\tKind:       pipelineRun,","\t\t\t},","\t\t\tName:             fcpr.Name,","\t\t\tPipelineTaskName: pipelineTaskName,","\t\t}","\t}","","\ttaskRuns := filterTaskRunsForPipelineRunStatus(logger, pr, trs)","\t// Loop over all the TaskRuns associated to Tasks","\tfor _, tr := range taskRuns {","\t\tlbls := tr.GetLabels()","\t\tpipelineTaskName := lbls[pipeline.PipelineTaskLabelKey]","","\t\tif _, ok := childRefByName[tr.Name]; !ok {","\t\t\t// This tr was missing from the status.","\t\t\t// Add it without conditions, which are handled in the next loop","\t\t\tlogger.Infof(\"Found a TaskRun %s that was missing from the PipelineRun status\", tr.Name)","","\t\t\t// Since this was recovered now, add it to the map, or it might be overwritten","\t\t\tchildRefByName[tr.Name] = \u0026v1.ChildStatusReference{","\t\t\t\tTypeMeta: runtime.TypeMeta{","\t\t\t\t\tAPIVersion: v1.SchemeGroupVersion.String(),","\t\t\t\t\tKind:       taskRun,","\t\t\t\t},","\t\t\t\tName:             tr.Name,","\t\t\t\tPipelineTaskName: pipelineTaskName,","\t\t\t}","\t\t}","\t}","","\t// Get the names, their task label values, and their group/version/kind info for all CustomRuns or Runs associated with the PipelineRun","\tnames, taskLabels, gvks, _ := filterCustomRunsForPipelineRunStatus(logger, pr, customRuns)","\t// Loop over that data and populate the child references","\tfor idx := range names {","\t\tname := names[idx]","\t\ttaskLabel := taskLabels[idx]","\t\tgvk := gvks[idx]","","\t\tif _, ok := childRefByName[name]; !ok {","\t\t\t// This run was missing from the status.","\t\t\t// Add it without conditions, which are handled in the next loop","\t\t\tlogger.Infof(\"Found a %s %s that was missing from the PipelineRun status\", gvk.Kind, name)","","\t\t\t// Since this was recovered now, add it to the map, or it might be overwritten","\t\t\tchildRefByName[name] = \u0026v1.ChildStatusReference{","\t\t\t\tTypeMeta: runtime.TypeMeta{","\t\t\t\t\tAPIVersion: gvk.GroupVersion().String(),","\t\t\t\t\tKind:       gvk.Kind,","\t\t\t\t},","\t\t\t\tName:             name,","\t\t\t\tPipelineTaskName: taskLabel,","\t\t\t}","\t\t}","\t}","","\tvar newChildRefs []v1.ChildStatusReference","\tfor k := range childRefByName {","\t\tnewChildRefs = append(newChildRefs, *childRefByName[k])","\t}","","\t// sorting childRef in a specific order can greatly avoid","\t// meaningless updates of status caused by unordered arrays.","\tsort.Slice(newChildRefs, func(i, j int) bool {","\t\tif newChildRefs[i].PipelineTaskName == newChildRefs[j].PipelineTaskName {","\t\t\tif newChildRefs[i].Name == newChildRefs[j].Name {","\t\t\t\treturn newChildRefs[i].Kind \u003c newChildRefs[j].Kind","\t\t\t}","\t\t\treturn newChildRefs[i].Name \u003c newChildRefs[j].Name","\t\t}","\t\treturn newChildRefs[i].PipelineTaskName \u003c newChildRefs[j].PipelineTaskName","\t})","\tpr.Status.ChildReferences = newChildRefs","}","","// conditionFromVerificationResult returns the ConditionTrustedResourcesVerified condition based on the VerificationResult, err is returned when the VerificationResult type is VerificationError","func conditionFromVerificationResult(verificationResult *trustedresources.VerificationResult, pr *v1.PipelineRun, resourceName string) (*apis.Condition, error) {","\tvar condition *apis.Condition","\tvar err error","\tswitch verificationResult.VerificationResultType {","\tcase trustedresources.VerificationError:","\t\terr = fmt.Errorf(\"pipelineRun %s/%s referred resource %s failed signature verification: %w\", pr.Namespace, pr.Name, resourceName, verificationResult.Err)","\t\tcondition = \u0026apis.Condition{","\t\t\tType:    trustedresources.ConditionTrustedResourcesVerified,","\t\t\tStatus:  corev1.ConditionFalse,","\t\t\tMessage: err.Error(),","\t\t}","\tcase trustedresources.VerificationWarn:","\t\tcondition = \u0026apis.Condition{","\t\t\tType:    trustedresources.ConditionTrustedResourcesVerified,","\t\t\tStatus:  corev1.ConditionFalse,","\t\t\tMessage: verificationResult.Err.Error(),","\t\t}","\tcase trustedresources.VerificationPass:","\t\tcondition = \u0026apis.Condition{","\t\t\tType:   trustedresources.ConditionTrustedResourcesVerified,","\t\t\tStatus: corev1.ConditionTrue,","\t\t}","\tcase trustedresources.VerificationSkip:","\t\t// do nothing","\t}","\treturn condition, err","}","","// validatePipelineSpecAfterApplyParameters validates the PipelineSpec after apply parameters","// Maybe some fields are modified during apply parameters, need to validate again. For example, tasks[].OnError.","func validatePipelineSpecAfterApplyParameters(ctx context.Context, pipelineSpec *v1.PipelineSpec) (errs *apis.FieldError) {","\tif pipelineSpec == nil {","\t\terrs = errs.Also(apis.ErrMissingField(\"PipelineSpec\"))","\t\treturn","\t}","\ttasks := make([]v1.PipelineTask, 0, len(pipelineSpec.Tasks)+len(pipelineSpec.Finally))","\ttasks = append(tasks, pipelineSpec.Tasks...)","\ttasks = append(tasks, pipelineSpec.Finally...)","\tfor _, t := range tasks {","\t\terrs = errs.Also(t.ValidateOnError(ctx))","\t}","\treturn errs","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,1,1,2,0,0,2,2,2,2,1,1,1,0,0,0,0,0,0,2,2,2,2,2,0,0,0,2,2,1,1,2,2,2,2,2,2,1,1,2,0,0,2,1,1,1,0,0,2,2,2,2,0,0,2,2,1,1,1,1,0,0,0,2,2,2,0,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,0,1,0,0,2,2,2,1,0,0,0,2,2,2,0,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,1,1,0,0,0,2,2,2,2,2,2,2,2,2,1,1,1,0,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,2,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,2,2,1,1,1,1,1,1,0,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,2,1,1,1,1,1,0,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,1,1,1,1,2,2,0,0,0,0,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,1,1,2,2,2,2,2,2,2,1,1,1,1,2,2,2,2,2,1,1,0,2,0,0,0,2,2,2,2,2,2,2,0,2,2,2,2,1,1,1,1,0,0,2,2,2,2,2,2,0,2,2,2,2,1,1,1,1,0,0,0,2,2,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,0,0,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,1,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,1,1,1,1,1,0,2,0,0,0,0,0,2,2,2,0,2,2,2,2,2,2,0,2,2,0,0,0,2,2,2,2,2,1,1,1,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,2,2,2,2,2,2,2,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,1,1,0,2,2,2,0,0,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,1,1,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,2,2,2,2,0,0,0,2,2,2,2,2,0,0,2,2,2,2,1,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,1,1,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,2,2,2,2,0,0,0,0,0,2,2,2,2,2,1,1,0,2,2,2,2,0,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,1,1,1,0,0,2,2,2,2,2,2,2,0,2,2,2,2,0,2,2,1,1,0,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,0,2,0,0,0,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,1,1,0,0,2,0,0,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,1,1,0,2,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,0,0,0,2,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,1,1,0,0,2,2,2,2,0,0,2,0,0,0,0,2,2,2,2,2,0,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,1,1,1,0,2,2,1,1,1,0,2,2,1,1,1,0,2,0,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,2,2,2,2,1,1,1,1,1,0,1,0,0,2,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,0,0,2,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,0,2,2,2,2,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,0,0,2,2,2,1,1,2,0,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,0,2,2,1,1,1,2,2,2,2,2,2,2,0]},{"id":190,"path":"pkg/reconciler/pipelinerun/pipelinespec/pipelinespec.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pipelinespec","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tresolutionutil \"github.com/tektoncd/pipeline/pkg/internal/resolution\"","\t\"github.com/tektoncd/pipeline/pkg/trustedresources\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"",")","","// GetPipeline is a function used to retrieve Pipelines.","// VerificationResult is the result from trusted resources if the feature is enabled.","type GetPipeline func(context.Context, string) (*v1.Pipeline, *v1.RefSource, *trustedresources.VerificationResult, error)","","// GetPipelineData will retrieve the Pipeline metadata and Spec associated with the","// provided PipelineRun. This can come from a reference Pipeline or from the PipelineRun's","// metadata and embedded PipelineSpec.","func GetPipelineData(ctx context.Context, pipelineRun *v1.PipelineRun, getPipeline GetPipeline) (*resolutionutil.ResolvedObjectMeta, *v1.PipelineSpec, error) {","\tpipelineMeta := metav1.ObjectMeta{}","\tvar refSource *v1.RefSource","\tvar verificationResult *trustedresources.VerificationResult","\tpipelineSpec := v1.PipelineSpec{}","\tswitch {","\tcase pipelineRun.Spec.PipelineRef != nil \u0026\u0026 pipelineRun.Spec.PipelineRef.Name != \"\":","\t\t// Get related pipeline for pipelinerun","\t\tp, source, vr, err := getPipeline(ctx, pipelineRun.Spec.PipelineRef.Name)","\t\tif err != nil {","\t\t\treturn nil, nil, fmt.Errorf(\"error when getting Pipeline for PipelineRun %s: %w\", pipelineRun.Name, err)","\t\t}","\t\tpipelineMeta = p.PipelineMetadata()","\t\tpipelineSpec = p.PipelineSpec()","\t\trefSource = source","\t\tverificationResult = vr","\tcase pipelineRun.Spec.PipelineSpec != nil:","\t\tpipelineMeta = pipelineRun.ObjectMeta","\t\tpipelineSpec = *pipelineRun.Spec.PipelineSpec","\t\t// TODO: if we want to set RefSource for embedded pipeline, set it here.","\t\t// https://github.com/tektoncd/pipeline/issues/5522","\tcase pipelineRun.Spec.PipelineRef != nil \u0026\u0026 pipelineRun.Spec.PipelineRef.Resolver != \"\":","\t\tpipeline, source, vr, err := getPipeline(ctx, \"\")","\t\tswitch {","\t\tcase err != nil:","\t\t\treturn nil, nil, err","\t\tcase pipeline == nil:","\t\t\treturn nil, nil, errors.New(\"resolution of remote resource completed successfully but no pipeline was returned\")","\t\tdefault:","\t\t\tpipelineMeta = pipeline.PipelineMetadata()","\t\t\tpipelineSpec = pipeline.PipelineSpec()","\t\t}","\t\trefSource = source","\t\tverificationResult = vr","\tdefault:","\t\treturn nil, nil, fmt.Errorf(\"pipelineRun %s not providing PipelineRef or PipelineSpec\", pipelineRun.Name)","\t}","","\tpipelineSpec.SetDefaults(ctx)","\treturn \u0026resolutionutil.ResolvedObjectMeta{","\t\tObjectMeta:         \u0026pipelineMeta,","\t\tRefSource:          refSource,","\t\tVerificationResult: verificationResult,","\t}, \u0026pipelineSpec, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,0,2,2,2,2,2,2,0]},{"id":191,"path":"pkg/reconciler/pipelinerun/resources/apply.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resources","","import (","\t\"encoding/json\"","\t\"fmt\"","\t\"strconv\"","\t\"strings\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/taskrun/resources\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\t\"github.com/tektoncd/pipeline/pkg/workspace\"",")","","const (","\t// resultsParseNumber is the value of how many parts we split from result reference. e.g.  tasks.\u003ctaskName\u003e.results.\u003cobjectResultName\u003e","\tresultsParseNumber = 4","\t// objectElementResultsParseNumber is the value of how many parts we split from","\t// object attribute result reference. e.g.  tasks.\u003ctaskName\u003e.results.\u003cobjectResultName\u003e.\u003cindividualAttribute\u003e","\tobjectElementResultsParseNumber = 5","\t// objectIndividualVariablePattern is the reference pattern for object individual keys params.\u003cobject_param_name\u003e.\u003ckey_name\u003e","\tobjectIndividualVariablePattern = \"params.%s.%s\"","\t// maxParamReferenceDepth limits recursive parameter resolution to prevent stack overflow attacks","\tmaxParamReferenceDepth = 10",")","","var paramPatterns = []string{","\t\"params.%s\",","\t\"params[%q]\",","\t\"params['%s']\",","}","","// ApplyParameters applies the params from a PipelineRun.Params to a PipelineSpec.","//","// It resolves parameter defaults that reference other parameters using recursive resolution","// with caching. The algorithm supports dependency chains up to 10 levels deep, handles","// parameters in any declaration order, and detects circular dependencies.","//","// Example - Container image build pipeline:","//","//\t# PipelineRun provides:","//\tparams:","//\t  - name: repo","//\t    value: \"my-app\"","//","//\t# PipelineSpec defaults (unresolved references):","//\tparams:","//\t  - name: registry","//\t    default: \"gcr.io/my-project\"","//\t  - name: tag","//\t    default: \"v1.0\"","//\t  - name: image-name","//\t    default: \"$(params.registry)/$(params.repo):$(params.tag)\"","//\t  - name: build-args","//\t    type: array","//\t    default: [\"IMAGE=$(params.image-name)\", \"VERSION=$(params.tag)\"]","//","//\t# After ApplyParameters resolves to:","//\t  repo: \"my-app\"                                    # from PipelineRun","//\t  registry: \"gcr.io/my-project\"                     # from default","//\t  tag: \"v1.0\"                                       # from default","//\t  image-name: \"gcr.io/my-project/my-app:v1.0\"       # resolved recursively","//\t  build-args: [\"IMAGE=gcr.io/my-project/my-app:v1.0\", \"VERSION=v1.0\"]  # resolved from strings","//","// The function uses a 6-phase approach:","//  1. Extract params from PipelineRun (already resolved values)","//  2. Build unresolved maps for defaults (by type: string, array, object)","//  3. Recursively resolve string params with dependency tracking (max depth: 10)","//  4. Resolve array params with substitution","//  5. Resolve object params with substitution","//  6. Apply all replacements to PipelineSpec","func ApplyParameters(p *v1.PipelineSpec, pr *v1.PipelineRun) (*v1.PipelineSpec, error) {","\t// ===== Phase 1: Get params from PipelineRun =====","\tresolvedStringParams, resolvedArrayParams, resolvedObjectParams := paramsFromPipelineRun(pr)","","\t// ===== Phase 2: Build unresolved maps for defaults =====","\tunresolvedStringParams := buildUnresolvedStringParamDefaults(p.Params, resolvedStringParams)","\tunresolvedArrayParams := buildUnresolvedArrayParamDefaults(p.Params, resolvedArrayParams)","\tunresolvedObjectParams := buildUnresolvedObjectParamDefaults(p.Params, resolvedObjectParams)","","\t// ===== Phase 3: Recursively resolve string params =====","\tvisiting := map[string]bool{}","\tfor paramKey, paramValue := range unresolvedStringParams {","\t\tif _, exist := resolvedStringParams[paramKey]; exist {","\t\t\tcontinue","\t\t}","","\t\tif err := resolveStringParamRecursively(","\t\t\tparamKey,","\t\t\tparamValue,","\t\t\tresolvedStringParams,","\t\t\tunresolvedStringParams,","\t\t\tvisiting,","\t\t\t0,","\t\t); err != nil {","\t\t\treturn nil, err","\t\t}","\t}","","\t// ===== Phase 4: Resolve array params =====","\tfor paramKey, paramValue := range unresolvedArrayParams {","\t\tresolveArrayParam(paramKey, paramValue, resolvedStringParams, resolvedArrayParams)","\t}","","\t// ===== Phase 5: Resolve object params =====","\tfor paramKey, paramValue := range unresolvedObjectParams {","\t\tresolveObjectParam(paramKey, paramValue, resolvedStringParams, resolvedObjectParams)","\t}","","\t// ===== Phase 6: Apply all replacements to PipelineSpec =====","\treturn ApplyReplacements(p, resolvedStringParams, resolvedArrayParams, resolvedObjectParams), nil","}","","func paramsFromPipelineRun(pr *v1.PipelineRun) (map[string]string, map[string][]string, map[string]map[string]string) {","\t// stringReplacements is used for standard single-string stringReplacements,","\t// while arrayReplacements/objectReplacements contains arrays/objects that need to be further processed.","\tstringReplacements := map[string]string{}","\tarrayReplacements := map[string][]string{}","\tobjectReplacements := map[string]map[string]string{}","","\tfor _, p := range pr.Spec.Params {","\t\tswitch p.Value.Type {","\t\tcase v1.ParamTypeArray:","\t\t\tfor _, pattern := range paramPatterns {","\t\t\t\tfor i := range len(p.Value.ArrayVal) {","\t\t\t\t\tstringReplacements[fmt.Sprintf(pattern+\"[%d]\", p.Name, i)] = p.Value.ArrayVal[i]","\t\t\t\t}","\t\t\t\tarrayReplacements[fmt.Sprintf(pattern, p.Name)] = p.Value.ArrayVal","\t\t\t}","\t\tcase v1.ParamTypeObject:","\t\t\tfor _, pattern := range paramPatterns {","\t\t\t\tobjectReplacements[fmt.Sprintf(pattern, p.Name)] = p.Value.ObjectVal","\t\t\t}","\t\t\tfor k, v := range p.Value.ObjectVal {","\t\t\t\tstringReplacements[fmt.Sprintf(objectIndividualVariablePattern, p.Name, k)] = v","\t\t\t}","\t\tcase v1.ParamTypeString:","\t\t\tfallthrough","\t\tdefault:","\t\t\tfor _, pattern := range paramPatterns {","\t\t\t\tstringReplacements[fmt.Sprintf(pattern, p.Name)] = p.Value.StringVal","\t\t\t}","\t\t}","\t}","","\treturn stringReplacements, arrayReplacements, objectReplacements","}","","// buildUnresolvedStringParamDefaults builds a map of parameter defaults that haven't been provided by the PipelineRun.","// It filters for string-type parameters only and excludes those already present in resolvedStringParams.","func buildUnresolvedStringParamDefaults(params []v1.ParamSpec, resolvedStringParams map[string]string) map[string]string {","\tresult := map[string]string{}","","\tfor _, param := range params {","\t\tif param.Type != v1.ParamTypeString \u0026\u0026 param.Type != \"\" {","\t\t\tcontinue","\t\t}","","\t\tif param.Default == nil {","\t\t\tcontinue","\t\t}","","\t\tif paramExists(param.Name, resolvedStringParams) {","\t\t\tcontinue","\t\t}","","\t\taddPatternEntry(param.Name, param.Default.StringVal, result)","\t}","","\treturn result","}","","type paramValue interface {","\tstring | []string | map[string]string","}","","func paramExists[T paramValue](paramName string, bucket map[string]T) bool {","\tfor _, pattern := range paramPatterns {","\t\tkey := fmt.Sprintf(pattern, paramName)","\t\tif _, exists := bucket[key]; exists {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","func addPatternEntry[T paramValue](key string, value T, bucket map[string]T) {","\tfor _, pattern := range paramPatterns {","\t\tpatternKey := fmt.Sprintf(pattern, key)","\t\tbucket[patternKey] = value","\t}","}","","// buildUnresolvedArrayParamDefaults builds a map of parameter defaults that haven't been provided by the PipelineRun.","// It filters for array-type parameters only and excludes those already present in resolvedArrayParams.","func buildUnresolvedArrayParamDefaults(params []v1.ParamSpec, resolvedArrayParams map[string][]string) map[string][]string {","\tresult := map[string][]string{}","","\tfor _, param := range params {","\t\tif param.Type != v1.ParamTypeArray {","\t\t\tcontinue","\t\t}","","\t\tif param.Default == nil {","\t\t\tcontinue","\t\t}","","\t\tif paramExists(param.Name, resolvedArrayParams) {","\t\t\tcontinue","\t\t}","","\t\taddPatternEntry(param.Name, param.Default.ArrayVal, result)","\t}","","\treturn result","}","","// buildUnresolvedObjectParamDefaults builds a map of parameter defaults that haven't been provided by the PipelineRun.","// It filters for object-type parameters only and excludes those already present in resolvedObjectParams.","func buildUnresolvedObjectParamDefaults(params []v1.ParamSpec, resolvedObjectParams map[string]map[string]string) map[string]map[string]string {","\tresult := map[string]map[string]string{}","","\tfor _, param := range params {","\t\tif param.Type != v1.ParamTypeObject {","\t\t\tcontinue","\t\t}","","\t\tif param.Default == nil {","\t\t\tcontinue","\t\t}","","\t\tif paramExists(param.Name, resolvedObjectParams) {","\t\t\tcontinue","\t\t}","","\t\taddPatternEntry(param.Name, param.Default.ObjectVal, result)","\t}","","\treturn result","}","","// resolveStringParamRecursively resolves a string parameter by recursively resolving any $(params.*) references.","// It handles dependency chains of any depth and detects circular dependencies.","//","// Example: If registry=\"docker.io\", image-url=\"$(params.registry)/app\" resolves to \"docker.io/app\".","// For chains like base=\"docker.io\" â†’ registry=\"$(params.base)/org\" â†’ url=\"$(params.registry)/app\",","// it recursively resolves base first, then registry, then url, resulting in \"docker.io/org/app\".","//","// Returns error if circular dependency or undefined parameter reference is detected.","func resolveStringParamRecursively(","\tparamKey string,","\tparamValue string,","\tresolvedStringParams,","\tunresolvedStringParams map[string]string,","\tvisiting map[string]bool,","\tdepth uint,",") error {","\t// Circular dependency check","\tif visiting[paramKey] {","\t\treturn fmt.Errorf(\"parameter resolution failed: circular dependency detected in param %q\", paramKey)","\t}","\tvisiting[paramKey] = true","\tdefer delete(visiting, paramKey)","","\t// Protection against stack overflow attack","\tif depth \u003e maxParamReferenceDepth {","\t\treturn fmt.Errorf(\"parameter resolution failed: maximum recursion depth (%d) exceeded for param %q\", maxParamReferenceDepth, paramKey)","\t}","","\tparamRefsFromParamValue := extractParamReferences(paramValue)","","\t// If value has no references it is already resolved and needs no","\t// substitution, store it as resolved","\tif len(paramRefsFromParamValue) == 0 {","\t\tresolvedStringParams[paramKey] = paramValue","\t\treturn nil","\t}","","\t// Resolve each reference","\tfor _, paramRef := range paramRefsFromParamValue {","\t\tif _, exist := resolvedStringParams[paramRef]; exist {","\t\t\tcontinue","\t\t}","","\t\t// Non-existing parameter reference check","\t\tunresolvedValue, exist := unresolvedStringParams[paramRef]","\t\tif !exist {","\t\t\treturn fmt.Errorf(\"parameter resolution failed: param %q references undefined param %q\", paramKey, paramRef)","\t\t}","","\t\tif err := resolveStringParamRecursively(","\t\t\tparamRef,","\t\t\tunresolvedValue,","\t\t\tresolvedStringParams,","\t\t\tunresolvedStringParams,","\t\t\tvisiting,","\t\t\tdepth+1,","\t\t); err != nil {","\t\t\treturn err","\t\t}","\t}","","\t// Substitute references (executes after recursion resolves all dependencies)","\t// e.g., resolvedStringParams[\"params.image-url\"] = \"$(params.registry)/app\" becomes \"docker.io/app\"","\tresolvedStringParams[paramKey] = substitution.ApplyReplacements(paramValue, resolvedStringParams)","","\treturn nil","}","","// extractParamReferences extracts all $(params.*) variable references from a parameter value string.","// Example: \"$(params.registry)/app:$(params.tag)\" â†’ [\"params.registry\", \"params.tag\"]","func extractParamReferences(paramValue string) []string {","\tparam := v1.Param{Value: *v1.NewStructuredValues(paramValue)}","\tvariableRefs, ok := param.GetVarSubstitutionExpressions()","\tif !ok {","\t\treturn []string{}","\t}","","\t// Filter references to non-parameter variables","\tparamRefs := make([]string, 0, len(variableRefs))","\tfor _, variable := range variableRefs {","\t\tif strings.HasPrefix(variable, \"params.\") {","\t\t\tparamRefs = append(paramRefs, variable)","\t\t}","\t}","\treturn paramRefs","}","","// resolveArrayParam resolves an array parameter by applying string parameter substitutions to each element and adds","// indexed access to enable references like $(params.tags[0]) in other parameters.","//","// Example: If registry=\"docker.io\", tags=[\"$(params.registry)/app:v1\", \"alpine\"] resolves to:","//   - resolvedArrayParam[\"params.tags\"] = [\"docker.io/app:v1\", \"alpine\"]","//   - resolvedStringParams[\"params.tags[0]\"] = \"docker.io/app:v1\"","//   - resolvedStringParams[\"params.tags[1]\"] = \"alpine\"","func resolveArrayParam(paramKey string, paramValue []string, resolvedStringParams map[string]string, resolvedArrayParam map[string][]string) {","\tresolvedValues := make([]string, len(paramValue))","\tfor key, value := range paramValue {","\t\tresolvedValues[key] = substitution.ApplyReplacements(value, resolvedStringParams)","\t}","\tresolvedArrayParam[paramKey] = resolvedValues","","\t// Add indexed access to enable references like $(params.tags[0]) in other params","\tfor i, value := range resolvedValues {","\t\tkey := fmt.Sprintf(\"%s[%d]\", paramKey, i)","\t\tresolvedStringParams[key] = value","\t}","}","","// resolveObjectParam resolves an object parameter by applying string parameter substitutions to each value and adds","// keyed access to enable references like $(params.config.host) in other parameters.","//","// Example: If registry=\"docker.io\", config={\"host\": \"$(params.registry)\", \"port\": \"5000\"} resolves to:","//   - resolvedObjectParams[\"params.config\"] = {\"host\": \"docker.io\", \"port\": \"5000\"}","//   - resolvedStringParams[\"params.config.host\"] = \"docker.io\"","//   - resolvedStringParams[\"params.config.port\"] = \"5000\"","func resolveObjectParam(paramKey string, paramValue map[string]string, resolvedStringParams map[string]string, resolvedObjectParams map[string]map[string]string) {","\tresolvedValues := make(map[string]string, len(paramValue))","\tfor key, value := range paramValue {","\t\tresolvedValues[key] = substitution.ApplyReplacements(value, resolvedStringParams)","\t}","\tresolvedObjectParams[paramKey] = resolvedValues","","\t// Add keyed access to enable references like $(params.config.host) in other params","\tfor key, value := range resolvedValues {","\t\tstringsKey := fmt.Sprintf(\"%s.%s\", paramKey, key)","\t\tresolvedStringParams[stringsKey] = value","\t}","}","","// GetContextReplacements returns the pipelineRun context which can be used to replace context variables in the specifications","func GetContextReplacements(pipelineName string, pr *v1.PipelineRun) map[string]string {","\treturn map[string]string{","\t\t\"context.pipelineRun.name\":      pr.Name,","\t\t\"context.pipeline.name\":         pipelineName,","\t\t\"context.pipelineRun.namespace\": pr.Namespace,","\t\t\"context.pipelineRun.uid\":       string(pr.ObjectMeta.UID),","\t}","}","","// ApplyContexts applies the substitution from $(context.(pipelineRun|pipeline).*) with the specified values.","// Currently supports only name substitution. Uses \"\" as a default if name is not specified.","func ApplyContexts(spec *v1.PipelineSpec, pipelineName string, pr *v1.PipelineRun) *v1.PipelineSpec {","\tfor i := range spec.Tasks {","\t\tspec.Tasks[i].DisplayName = substitution.ApplyReplacements(spec.Tasks[i].DisplayName, GetContextReplacements(pipelineName, pr))","\t}","\tfor i := range spec.Finally {","\t\tspec.Finally[i].DisplayName = substitution.ApplyReplacements(spec.Finally[i].DisplayName, GetContextReplacements(pipelineName, pr))","\t}","\treturn ApplyReplacements(spec, GetContextReplacements(pipelineName, pr), map[string][]string{}, map[string]map[string]string{})","}","","// filterMatrixContextVar returns a list of params which contain any matrix context variables such as","// $(tasks.\u003cpipelineTaskName\u003e.matrix.length) and $(tasks.\u003cpipelineTaskName\u003e.matrix.\u003cresultName\u003e.length)","func filterMatrixContextVar(params v1.Params) v1.Params {","\tvar filteredParams v1.Params","\tfor _, param := range params {","\t\tif expressions, ok := param.GetVarSubstitutionExpressions(); ok {","\t\t\tfor _, expression := range expressions {","\t\t\t\t// tasks.\u003cpipelineTaskName\u003e.matrix.length","\t\t\t\t// tasks.\u003cpipelineTaskName\u003e.matrix.\u003cresultName\u003e.length","\t\t\t\tsubExpressions := strings.Split(expression, \".\")","\t\t\t\tif len(subExpressions) \u003e= 4 \u0026\u0026 subExpressions[2] == \"matrix\" \u0026\u0026 subExpressions[len(subExpressions)-1] == \"length\" {","\t\t\t\t\tfilteredParams = append(filteredParams, param)","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn filteredParams","}","","// ApplyPipelineTaskContexts applies the substitution from $(context.pipelineTask.*) with the specified values.","// Uses \"0\" as a default if a value is not available as well as matrix context variables","// $(tasks.\u003cpipelineTaskName\u003e.matrix.length) and $(tasks.\u003cpipelineTaskName\u003e.matrix.\u003cresultName\u003e.length)","func ApplyPipelineTaskContexts(pt *v1.PipelineTask, pipelineRunStatus v1.PipelineRunStatus, facts *PipelineRunFacts) *v1.PipelineTask {","\tpt = pt.DeepCopy()","\tvar pipelineTaskName string","\tvar resultName string","\tvar matrixLength int","","\treplacements := map[string]string{","\t\t\"context.pipelineTask.retries\": strconv.Itoa(pt.Retries),","\t}","","\tfilteredParams := filterMatrixContextVar(pt.Params)","","\tfor _, p := range filteredParams {","\t\tpipelineTaskName, resultName = p.ParseTaskandResultName()","\t\t// find the referenced pipelineTask to count the matrix combinations","\t\tif pipelineTaskName != \"\" \u0026\u0026 pipelineRunStatus.PipelineSpec != nil {","\t\t\tfor _, task := range pipelineRunStatus.PipelineSpec.Tasks {","\t\t\t\tif task.Name == pipelineTaskName {","\t\t\t\t\tmatrixLength = task.Matrix.CountCombinations()","\t\t\t\t\treplacements[\"tasks.\"+pipelineTaskName+\".matrix.length\"] = strconv.Itoa(matrixLength)","\t\t\t\t\tcontinue","\t\t\t\t}","\t\t\t}","\t\t}","\t\t// find the resultName from the ResultsCache","\t\tif pipelineTaskName != \"\" \u0026\u0026 resultName != \"\" {","\t\t\tfor _, pt := range facts.State {","\t\t\t\tif pt.PipelineTask.Name == pipelineTaskName {","\t\t\t\t\tif len(pt.ResultsCache) == 0 {","\t\t\t\t\t\tpt.ResultsCache = createResultsCacheMatrixedTaskRuns(pt)","\t\t\t\t\t}","\t\t\t\t\tresultLength := len(pt.ResultsCache[resultName])","\t\t\t\t\treplacements[\"tasks.\"+pipelineTaskName+\".matrix.\"+resultName+\".length\"] = strconv.Itoa(resultLength)","\t\t\t\t\tcontinue","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\tpt.Params = pt.Params.ReplaceVariables(replacements, map[string][]string{}, map[string]map[string]string{})","\tif pt.IsMatrixed() {","\t\tpt.Matrix.Params = pt.Matrix.Params.ReplaceVariables(replacements, map[string][]string{}, map[string]map[string]string{})","\t\tfor i := range pt.Matrix.Include {","\t\t\tpt.Matrix.Include[i].Params = pt.Matrix.Include[i].Params.ReplaceVariables(replacements, map[string][]string{}, map[string]map[string]string{})","\t\t}","\t}","\tpt.DisplayName = substitution.ApplyReplacements(pt.DisplayName, replacements)","\treturn pt","}","","// ApplyTaskResults applies the ResolvedResultRef to each PipelineTask.Params and Pipeline.When in targets","func ApplyTaskResults(targets PipelineRunState, resolvedResultRefs ResolvedResultRefs) {","\tstringReplacements := resolvedResultRefs.getStringReplacements()","\tarrayReplacements := resolvedResultRefs.getArrayReplacements()","\tobjectReplacements := resolvedResultRefs.getObjectReplacements()","\tfor _, resolvedPipelineRunTask := range targets {","\t\tif resolvedPipelineRunTask.PipelineTask != nil {","\t\t\tpipelineTask := resolvedPipelineRunTask.PipelineTask.DeepCopy()","\t\t\tpipelineTask.Params = pipelineTask.Params.ReplaceVariables(stringReplacements, arrayReplacements, objectReplacements)","\t\t\tif pipelineTask.IsMatrixed() {","\t\t\t\t// Matrixed pipeline results replacements support:","\t\t\t\t// 1. String replacements from string, array or object results","\t\t\t\t// 2. array replacements from array results are supported","\t\t\t\tpipelineTask.Matrix.Params = pipelineTask.Matrix.Params.ReplaceVariables(stringReplacements, arrayReplacements, nil)","\t\t\t\tfor i := range pipelineTask.Matrix.Include {","\t\t\t\t\t// matrix include parameters can only be type string","\t\t\t\t\tpipelineTask.Matrix.Include[i].Params = pipelineTask.Matrix.Include[i].Params.ReplaceVariables(stringReplacements, nil, nil)","\t\t\t\t}","\t\t\t}","\t\t\tpipelineTask.When = pipelineTask.When.ReplaceVariables(stringReplacements, arrayReplacements)","\t\t\tif pipelineTask.TaskRef != nil {","\t\t\t\tif pipelineTask.TaskRef.Params != nil {","\t\t\t\t\tpipelineTask.TaskRef.Params = pipelineTask.TaskRef.Params.ReplaceVariables(stringReplacements, arrayReplacements, objectReplacements)","\t\t\t\t}","\t\t\t\tpipelineTask.TaskRef.Name = substitution.ApplyReplacements(pipelineTask.TaskRef.Name, stringReplacements)","\t\t\t}","\t\t\tpipelineTask.DisplayName = substitution.ApplyReplacements(pipelineTask.DisplayName, stringReplacements)","\t\t\tfor i, workspace := range pipelineTask.Workspaces {","\t\t\t\tpipelineTask.Workspaces[i].SubPath = substitution.ApplyReplacements(workspace.SubPath, stringReplacements)","\t\t\t}","\t\t\tresolvedPipelineRunTask.PipelineTask = pipelineTask","\t\t}","\t}","}","","// ApplyPipelineTaskStateContext replaces context variables referring to execution status with the specified status","func ApplyPipelineTaskStateContext(state PipelineRunState, replacements map[string]string) {","\tfor _, resolvedPipelineRunTask := range state {","\t\tif resolvedPipelineRunTask.PipelineTask != nil {","\t\t\tpipelineTask := resolvedPipelineRunTask.PipelineTask.DeepCopy()","\t\t\tpipelineTask.Params = pipelineTask.Params.ReplaceVariables(replacements, nil, nil)","\t\t\tpipelineTask.When = pipelineTask.When.ReplaceVariables(replacements, nil)","\t\t\tif pipelineTask.TaskRef != nil {","\t\t\t\tif pipelineTask.TaskRef.Params != nil {","\t\t\t\t\tpipelineTask.TaskRef.Params = pipelineTask.TaskRef.Params.ReplaceVariables(replacements, nil, nil)","\t\t\t\t}","\t\t\t\tpipelineTask.TaskRef.Name = substitution.ApplyReplacements(pipelineTask.TaskRef.Name, replacements)","\t\t\t}","\t\t\tpipelineTask.DisplayName = substitution.ApplyReplacements(pipelineTask.DisplayName, replacements)","\t\t\tresolvedPipelineRunTask.PipelineTask = pipelineTask","\t\t}","\t}","}","","// ApplyWorkspaces replaces workspace variables in the given pipeline spec with their","// concrete values.","func ApplyWorkspaces(p *v1.PipelineSpec, pr *v1.PipelineRun) *v1.PipelineSpec {","\tp = p.DeepCopy()","\treplacements := map[string]string{}","\tfor _, declaredWorkspace := range p.Workspaces {","\t\tkey := fmt.Sprintf(\"workspaces.%s.bound\", declaredWorkspace.Name)","\t\treplacements[key] = \"false\"","\t}","\tfor _, boundWorkspace := range pr.Spec.Workspaces {","\t\tkey := fmt.Sprintf(\"workspaces.%s.bound\", boundWorkspace.Name)","\t\treplacements[key] = \"true\"","\t}","\treturn ApplyReplacements(p, replacements, map[string][]string{}, map[string]map[string]string{})","}","","// replaceVariablesInPipelineTasks handles variable replacement for a slice of PipelineTasks in-place","func replaceVariablesInPipelineTasks(tasks []v1.PipelineTask, replacements map[string]string,","\tarrayReplacements map[string][]string, objectReplacements map[string]map[string]string) {","\tfor i := range tasks {","\t\ttasks[i].Params = tasks[i].Params.ReplaceVariables(replacements, arrayReplacements, objectReplacements)","\t\tif tasks[i].IsMatrixed() {","\t\t\ttasks[i].Matrix.Params = tasks[i].Matrix.Params.ReplaceVariables(replacements, arrayReplacements, nil)","\t\t\tfor j := range tasks[i].Matrix.Include {","\t\t\t\ttasks[i].Matrix.Include[j].Params = tasks[i].Matrix.Include[j].Params.ReplaceVariables(replacements, nil, nil)","\t\t\t}","\t\t} else {","\t\t\ttasks[i].DisplayName = substitution.ApplyReplacements(tasks[i].DisplayName, replacements)","\t\t}","\t\tfor j := range tasks[i].Workspaces {","\t\t\ttasks[i].Workspaces[j].SubPath = substitution.ApplyReplacements(tasks[i].Workspaces[j].SubPath, replacements)","\t\t}","\t\ttasks[i].When = tasks[i].When.ReplaceVariables(replacements, arrayReplacements)","\t\tif tasks[i].TaskRef != nil {","\t\t\tif tasks[i].TaskRef.Params != nil {","\t\t\t\ttasks[i].TaskRef.Params = tasks[i].TaskRef.Params.ReplaceVariables(replacements, arrayReplacements, objectReplacements)","\t\t\t}","\t\t\ttasks[i].TaskRef.Name = substitution.ApplyReplacements(tasks[i].TaskRef.Name, replacements)","\t\t}","\t\ttasks[i].OnError = v1.PipelineTaskOnErrorType(substitution.ApplyReplacements(string(tasks[i].OnError), replacements))","\t\ttasks[i] = propagateParams(tasks[i], replacements, arrayReplacements, objectReplacements)","\t}","}","","// ApplyReplacements replaces placeholders for declared parameters with the specified replacements.","func ApplyReplacements(p *v1.PipelineSpec, replacements map[string]string, arrayReplacements map[string][]string, objectReplacements map[string]map[string]string) *v1.PipelineSpec {","\tp = p.DeepCopy()","","\t// Replace variables in Tasks and Finally tasks","\treplaceVariablesInPipelineTasks(p.Tasks, replacements, arrayReplacements, objectReplacements)","\treplaceVariablesInPipelineTasks(p.Finally, replacements, arrayReplacements, objectReplacements)","","\treturn p","}","","// propagateParams returns a Pipeline Task spec that is the same as the input Pipeline Task spec, but with","// all parameter replacements from `stringReplacements`, `arrayReplacements`, and `objectReplacements` substituted.","// It does not modify `stringReplacements`, `arrayReplacements`, or `objectReplacements`.","func propagateParams(t v1.PipelineTask, stringReplacements map[string]string, arrayReplacements map[string][]string, objectReplacements map[string]map[string]string) v1.PipelineTask {","\tif t.TaskSpec == nil {","\t\treturn t","\t}","\t// check if there are task parameters defined that match the params at pipeline level","\tif len(t.Params) \u003e 0 {","\t\tstringReplacementsDup := make(map[string]string)","\t\tarrayReplacementsDup := make(map[string][]string)","\t\tobjectReplacementsDup := make(map[string]map[string]string)","\t\tfor k, v := range stringReplacements {","\t\t\tstringReplacementsDup[k] = v","\t\t}","\t\tfor k, v := range arrayReplacements {","\t\t\tarrayReplacementsDup[k] = v","\t\t}","\t\tfor k, v := range objectReplacements {","\t\t\tobjectReplacementsDup[k] = v","\t\t}","\t\tfor _, par := range t.Params {","\t\t\tfor _, pattern := range paramPatterns {","\t\t\t\tcheckName := fmt.Sprintf(pattern, par.Name)","\t\t\t\t// Scoping. Task Params will replace Pipeline Params","\t\t\t\tif _, ok := stringReplacementsDup[checkName]; ok {","\t\t\t\t\tstringReplacementsDup[checkName] = par.Value.StringVal","\t\t\t\t}","\t\t\t\tif _, ok := arrayReplacementsDup[checkName]; ok {","\t\t\t\t\tarrayReplacementsDup[checkName] = par.Value.ArrayVal","\t\t\t\t}","\t\t\t\tif _, ok := objectReplacementsDup[checkName]; ok {","\t\t\t\t\tobjectReplacementsDup[checkName] = par.Value.ObjectVal","\t\t\t\t\tfor k, v := range par.Value.ObjectVal {","\t\t\t\t\t\tstringReplacementsDup[fmt.Sprintf(objectIndividualVariablePattern, par.Name, k)] = v","\t\t\t\t\t}","\t\t\t\t}","\t\t\t}","\t\t}","\t\tt.TaskSpec.TaskSpec = *resources.ApplyReplacements(\u0026t.TaskSpec.TaskSpec, stringReplacementsDup, arrayReplacementsDup, objectReplacementsDup)","\t} else {","\t\tt.TaskSpec.TaskSpec = *resources.ApplyReplacements(\u0026t.TaskSpec.TaskSpec, stringReplacements, arrayReplacements, objectReplacements)","\t}","\treturn t","}","","// ApplyResultsToWorkspaceBindings applies results from TaskRuns to  WorkspaceBindings in a PipelineRun. It replaces placeholders in","// various binding types with values from TaskRun results.","func ApplyResultsToWorkspaceBindings(trResults map[string][]v1.TaskRunResult, pr *v1.PipelineRun) {","\tstringReplacements := map[string]string{}","\tfor taskName, taskResults := range trResults {","\t\tfor _, res := range taskResults {","\t\t\tswitch res.Type {","\t\t\tcase v1.ResultsTypeString:","\t\t\t\tstringReplacements[fmt.Sprintf(\"tasks.%s.results.%s\", taskName, res.Name)] = res.Value.StringVal","\t\t\tcase v1.ResultsTypeArray:","\t\t\t\tcontinue","\t\t\tcase v1.ResultsTypeObject:","\t\t\t\tfor k, v := range res.Value.ObjectVal {","\t\t\t\t\tstringReplacements[fmt.Sprintf(\"tasks.%s.results.%s.%s\", taskName, res.Name, k)] = v","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\tpr.Spec.Workspaces = workspace.ReplaceWorkspaceBindingsVars(pr.Spec.Workspaces, stringReplacements)","}","","// PropagateResults propagate the result of the completed task to the unfinished task that is not explicitly specify in the params","func PropagateResults(rpt *ResolvedPipelineTask, runStates PipelineRunState) {","\tif rpt.ResolvedTask == nil || rpt.ResolvedTask.TaskSpec == nil {","\t\treturn","\t}","\tstringReplacements := map[string]string{}","\tarrayReplacements := map[string][]string{}","\tfor taskName, taskResults := range runStates.GetTaskRunsResults() {","\t\tfor _, res := range taskResults {","\t\t\tswitch res.Type {","\t\t\tcase v1.ResultsTypeString:","\t\t\t\tstringReplacements[fmt.Sprintf(\"tasks.%s.results.%s\", taskName, res.Name)] = res.Value.StringVal","\t\t\tcase v1.ResultsTypeArray:","\t\t\t\tarrayReplacements[fmt.Sprintf(\"tasks.%s.results.%s\", taskName, res.Name)] = res.Value.ArrayVal","\t\t\tcase v1.ResultsTypeObject:","\t\t\t\tfor k, v := range res.Value.ObjectVal {","\t\t\t\t\tstringReplacements[fmt.Sprintf(\"tasks.%s.results.%s.%s\", taskName, res.Name, k)] = v","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\trpt.ResolvedTask.TaskSpec = resources.ApplyReplacements(rpt.ResolvedTask.TaskSpec, stringReplacements, arrayReplacements, map[string]map[string]string{})","}","","// PropagateArtifacts propagates artifact values from previous task runs into the TaskSpec of the current task.","func PropagateArtifacts(rpt *ResolvedPipelineTask, runStates PipelineRunState) error {","\tif rpt.ResolvedTask == nil || rpt.ResolvedTask.TaskSpec == nil {","\t\treturn nil","\t}","\tstringReplacements := map[string]string{}","\tfor taskName, artifacts := range runStates.GetTaskRunsArtifacts() {","\t\tif artifacts != nil {","\t\t\tfor i, input := range artifacts.Inputs {","\t\t\t\tib, err := json.Marshal(input.Values)","\t\t\t\tif err != nil {","\t\t\t\t\treturn err","\t\t\t\t}","\t\t\t\tstringReplacements[fmt.Sprintf(\"tasks.%s.inputs.%s\", taskName, input.Name)] = string(ib)","\t\t\t\tif i == 0 {","\t\t\t\t\tstringReplacements[fmt.Sprintf(\"tasks.%s.inputs\", taskName)] = string(ib)","\t\t\t\t}","\t\t\t}","\t\t\tfor i, output := range artifacts.Outputs {","\t\t\t\tob, err := json.Marshal(output.Values)","\t\t\t\tif err != nil {","\t\t\t\t\treturn err","\t\t\t\t}","\t\t\t\tstringReplacements[fmt.Sprintf(\"tasks.%s.outputs.%s\", taskName, output.Name)] = string(ob)","\t\t\t\tif i == 0 {","\t\t\t\t\tstringReplacements[fmt.Sprintf(\"tasks.%s.outputs\", taskName)] = string(ob)","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\trpt.ResolvedTask.TaskSpec = resources.ApplyReplacements(rpt.ResolvedTask.TaskSpec, stringReplacements, map[string][]string{}, map[string]map[string]string{})","\treturn nil","}","","// ApplyTaskResultsToPipelineResults applies the results of completed TasksRuns and Runs to a Pipeline's","// list of PipelineResults, returning the computed set of PipelineRunResults. References to","// non-existent TaskResults or failed TaskRuns or Runs result in a PipelineResult being considered invalid","// and omitted from the returned slice. A nil slice is returned if no results are passed in or all","// results are invalid.","func ApplyTaskResultsToPipelineResults(","\tresults []v1.PipelineResult,","\ttaskRunResults map[string][]v1.TaskRunResult,","\tcustomTaskResults map[string][]v1beta1.CustomRunResult,","\ttaskstatus map[string]string,",") ([]v1.PipelineRunResult, error) {","\tvar runResults []v1.PipelineRunResult","\tvar invalidPipelineResults []string","","\tstringReplacements := map[string]string{}","\tarrayReplacements := map[string][]string{}","\tobjectReplacements := map[string]map[string]string{}","\tfor _, pipelineResult := range results {","\t\tvariablesInPipelineResult, _ := pipelineResult.GetVarSubstitutionExpressions()","\t\tif len(variablesInPipelineResult) == 0 {","\t\t\tcontinue","\t\t}","\t\tvalidPipelineResult := true","\t\tfor _, variable := range variablesInPipelineResult {","\t\t\tif _, isMemoized := stringReplacements[variable]; isMemoized {","\t\t\t\tcontinue","\t\t\t}","\t\t\tif _, isMemoized := arrayReplacements[variable]; isMemoized {","\t\t\t\tcontinue","\t\t\t}","\t\t\tif _, isMemoized := objectReplacements[variable]; isMemoized {","\t\t\t\tcontinue","\t\t\t}","\t\t\tvariableParts := strings.Split(variable, \".\")","","\t\t\tif (variableParts[0] != v1.ResultTaskPart \u0026\u0026 variableParts[0] != v1.ResultFinallyPart) || variableParts[2] != v1beta1.ResultResultPart {","\t\t\t\tvalidPipelineResult = false","\t\t\t\tinvalidPipelineResults = append(invalidPipelineResults, pipelineResult.Name)","\t\t\t\tcontinue","\t\t\t}","\t\t\tswitch len(variableParts) {","\t\t\t// For string result: tasks.\u003ctaskName\u003e.results.\u003cstringResultName\u003e","\t\t\t// For array result: tasks.\u003ctaskName\u003e.results.\u003carrayResultName\u003e[*], tasks.\u003ctaskName\u003e.results.\u003carrayResultName\u003e[i]","\t\t\t// For object result: tasks.\u003ctaskName\u003e.results.\u003cobjectResultName\u003e[*],","\t\t\tcase resultsParseNumber:","\t\t\t\ttaskName, resultName := variableParts[1], variableParts[3]","\t\t\t\tresultName, stringIdx := v1.ParseResultName(resultName)","\t\t\t\tif resultValue := taskResultValue(taskName, resultName, taskRunResults); resultValue != nil {","\t\t\t\t\tswitch resultValue.Type {","\t\t\t\t\tcase v1.ParamTypeString:","\t\t\t\t\t\tstringReplacements[variable] = resultValue.StringVal","\t\t\t\t\tcase v1.ParamTypeArray:","\t\t\t\t\t\tif stringIdx != \"*\" {","\t\t\t\t\t\t\tintIdx, _ := strconv.Atoi(stringIdx)","\t\t\t\t\t\t\tif intIdx \u003c len(resultValue.ArrayVal) {","\t\t\t\t\t\t\t\tstringReplacements[variable] = resultValue.ArrayVal[intIdx]","\t\t\t\t\t\t\t} else {","\t\t\t\t\t\t\t\t// referred array index out of bound","\t\t\t\t\t\t\t\tinvalidPipelineResults = append(invalidPipelineResults, pipelineResult.Name)","\t\t\t\t\t\t\t\tvalidPipelineResult = false","\t\t\t\t\t\t\t}","\t\t\t\t\t\t} else {","\t\t\t\t\t\t\tarrayReplacements[substitution.StripStarVarSubExpression(variable)] = resultValue.ArrayVal","\t\t\t\t\t\t}","\t\t\t\t\tcase v1.ParamTypeObject:","\t\t\t\t\t\tobjectReplacements[substitution.StripStarVarSubExpression(variable)] = resultValue.ObjectVal","\t\t\t\t\t}","\t\t\t\t} else if resultValue := runResultValue(taskName, resultName, customTaskResults); resultValue != nil {","\t\t\t\t\tstringReplacements[variable] = *resultValue","\t\t\t\t} else {","\t\t\t\t\t// if the task is not successful (e.g. skipped or failed) and the results is missing, don't return error","\t\t\t\t\tif status, ok := taskstatus[PipelineTaskStatusPrefix+taskName+PipelineTaskStatusSuffix]; ok {","\t\t\t\t\t\tif status != v1.TaskRunReasonSuccessful.String() {","\t\t\t\t\t\t\tvalidPipelineResult = false","\t\t\t\t\t\t\tcontinue","\t\t\t\t\t\t}","\t\t\t\t\t}","\t\t\t\t\t// referred result name is not existent","\t\t\t\t\tinvalidPipelineResults = append(invalidPipelineResults, pipelineResult.Name)","\t\t\t\t\tvalidPipelineResult = false","\t\t\t\t}","\t\t\t// For object type result: tasks.\u003ctaskName\u003e.results.\u003cobjectResultName\u003e.\u003cindividualAttribute\u003e","\t\t\tcase objectElementResultsParseNumber:","\t\t\t\ttaskName, resultName, objectKey := variableParts[1], variableParts[3], variableParts[4]","\t\t\t\tresultName, _ = v1.ParseResultName(resultName)","\t\t\t\tif resultValue := taskResultValue(taskName, resultName, taskRunResults); resultValue != nil {","\t\t\t\t\tif _, ok := resultValue.ObjectVal[objectKey]; ok {","\t\t\t\t\t\tstringReplacements[variable] = resultValue.ObjectVal[objectKey]","\t\t\t\t\t} else {","\t\t\t\t\t\t// referred object key is not existent","\t\t\t\t\t\tinvalidPipelineResults = append(invalidPipelineResults, pipelineResult.Name)","\t\t\t\t\t\tvalidPipelineResult = false","\t\t\t\t\t}","\t\t\t\t} else {","\t\t\t\t\t// if the task is not successful (e.g. skipped or failed) and the results is missing, don't return error","\t\t\t\t\tif status, ok := taskstatus[PipelineTaskStatusPrefix+taskName+PipelineTaskStatusSuffix]; ok {","\t\t\t\t\t\tif status != v1.TaskRunReasonSuccessful.String() {","\t\t\t\t\t\t\tvalidPipelineResult = false","\t\t\t\t\t\t\tcontinue","\t\t\t\t\t\t}","\t\t\t\t\t}","\t\t\t\t\t// referred result name is not existent","\t\t\t\t\tinvalidPipelineResults = append(invalidPipelineResults, pipelineResult.Name)","\t\t\t\t\tvalidPipelineResult = false","\t\t\t\t}","\t\t\tdefault:","\t\t\t\tinvalidPipelineResults = append(invalidPipelineResults, pipelineResult.Name)","\t\t\t\tvalidPipelineResult = false","\t\t\t}","\t\t}","\t\tif validPipelineResult {","\t\t\tfinalValue := pipelineResult.Value","\t\t\tfinalValue.ApplyReplacements(stringReplacements, arrayReplacements, objectReplacements)","\t\t\trunResults = append(runResults, v1.PipelineRunResult{","\t\t\t\tName:  pipelineResult.Name,","\t\t\t\tValue: finalValue,","\t\t\t})","\t\t}","\t}","","\tif len(invalidPipelineResults) \u003e 0 {","\t\treturn runResults, fmt.Errorf(\"invalid pipelineresults %v, the referenced results don't exist\", invalidPipelineResults)","\t}","","\treturn runResults, nil","}","","// taskResultValue returns the result value for a given pipeline task name and result name in a map of TaskRunResults for","// pipeline task names. It returns nil if either the pipeline task name isn't present in the map, or if there is no","// result with the result name in the pipeline task name's slice of results.","func taskResultValue(taskName string, resultName string, taskResults map[string][]v1.TaskRunResult) *v1.ResultValue {","\tfor _, trResult := range taskResults[taskName] {","\t\tif trResult.Name == resultName {","\t\t\treturn \u0026trResult.Value","\t\t}","\t}","\treturn nil","}","","// runResultValue returns the result value for a given pipeline task name and result name in a map of RunResults for","// pipeline task names. It returns nil if either the pipeline task name isn't present in the map, or if there is no","// result with the result name in the pipeline task name's slice of results.","func runResultValue(taskName string, resultName string, runResults map[string][]v1beta1.CustomRunResult) *string {","\tfor _, runResult := range runResults[taskName] {","\t\tif runResult.Name == resultName {","\t\t\treturn \u0026runResult.Value","\t\t}","\t}","\treturn nil","}","","// ApplyParametersToWorkspaceBindings applies parameters from PipelineSpec and  PipelineRun to the WorkspaceBindings in a PipelineRun. It replaces","// placeholders in various binding types with values from provided parameters.","func ApplyParametersToWorkspaceBindings(pr *v1.PipelineRun) {","\tparameters, _, _ := paramsFromPipelineRun(pr)","\tpr.Spec.Workspaces = workspace.ReplaceWorkspaceBindingsVars(pr.Spec.Workspaces, parameters)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,0,0,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,0,2,2,2,2,2,2,0,0,2,2,0,0,2,2,0,0,2,0,0,2,0,0,0,0,0,0,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,0,0,2,2,0,0,2,1,0,0,2,0,0,2,0,0,0,0,2,2,2,2,2,2,0,0,2,2,0,0,2,2,0,0,2,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,0,0,2,2,2,0,0,0,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,0,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,0,2,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,0,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,1,1,2,0,2,2,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,0,2,2,2,1,1,2,2,2,2,0,0,0,2,2,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,2,1,0,2,1,0,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,0,0,0,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,0,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,0,2,0,0,0,0,0,2,2,2,2,2,0,2,0,0,0,0,0,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2]},{"id":192,"path":"pkg/reconciler/pipelinerun/resources/pipelineref.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resources","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1alpha1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\tresolutionV1beta1 \"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\tclientset \"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/apiserver\"","\trprp \"github.com/tektoncd/pipeline/pkg/reconciler/pipelinerun/pipelinespec\"","\t\"github.com/tektoncd/pipeline/pkg/remote\"","\t\"github.com/tektoncd/pipeline/pkg/remoteresolution/remote/resolution\"","\tremoteresource \"github.com/tektoncd/pipeline/pkg/remoteresolution/resource\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\t\"github.com/tektoncd/pipeline/pkg/trustedresources\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/client-go/kubernetes\"",")","","// GetPipelineFunc is a factory function that will use the given PipelineRef to return a valid GetPipeline function that","// looks up the pipeline. It uses as context a k8s client, tekton client, namespace, and service account name to return","// the pipeline. It knows whether it needs to look in the cluster or in a remote location to fetch the reference.","// OCI bundle and remote resolution pipelines will be verified by trusted resources if the feature is enabled","func GetPipelineFunc(ctx context.Context, k8s kubernetes.Interface, tekton clientset.Interface, requester remoteresource.Requester, pipelineRun *v1.PipelineRun, verificationPolicies []*v1alpha1.VerificationPolicy) rprp.GetPipeline {","\tpr := pipelineRun.Spec.PipelineRef","\tnamespace := pipelineRun.Namespace","\t// if the spec is already in the status, do not try to fetch it again, just use it as source of truth.","\t// Same for the RefSource field in the Status.Provenance.","\tif pipelineRun.Status.PipelineSpec != nil {","\t\treturn func(_ context.Context, name string) (*v1.Pipeline, *v1.RefSource, *trustedresources.VerificationResult, error) {","\t\t\tvar refSource *v1.RefSource","\t\t\tif pipelineRun.Status.Provenance != nil {","\t\t\t\trefSource = pipelineRun.Status.Provenance.RefSource","\t\t\t}","\t\t\treturn \u0026v1.Pipeline{","\t\t\t\tObjectMeta: metav1.ObjectMeta{","\t\t\t\t\tName:      name,","\t\t\t\t\tNamespace: namespace,","\t\t\t\t},","\t\t\t\tSpec: *pipelineRun.Status.PipelineSpec,","\t\t\t}, refSource, nil, nil","\t\t}","\t}","","\tswitch {","\tcase pr != nil \u0026\u0026 pr.Resolver != \"\" \u0026\u0026 requester != nil:","\t\treturn func(ctx context.Context, name string) (*v1.Pipeline, *v1.RefSource, *trustedresources.VerificationResult, error) {","\t\t\tstringReplacements, arrayReplacements, objectReplacements := paramsFromPipelineRun(pipelineRun)","\t\t\tfor k, v := range GetContextReplacements(\"\", pipelineRun) {","\t\t\t\tstringReplacements[k] = v","\t\t\t}","\t\t\treplacedParams := pr.Params.ReplaceVariables(stringReplacements, arrayReplacements, objectReplacements)","\t\t\tvar url string","\t\t\t// The name is url-like so its not a local reference.","\t\t\tif err := v1.RefNameLikeUrl(pr.Name); err == nil {","\t\t\t\t// apply variable replacements in the name.","\t\t\t\tpr.Name = substitution.ApplyReplacements(pr.Name, stringReplacements)","\t\t\t\turl = pr.Name","\t\t\t}","\t\t\tresolverPayload := remoteresource.ResolverPayload{","\t\t\t\tResolutionSpec: \u0026resolutionV1beta1.ResolutionRequestSpec{","\t\t\t\t\tParams: replacedParams,","\t\t\t\t\tURL:    url,","\t\t\t\t},","\t\t\t}","\t\t\tresolver := resolution.NewResolver(requester, pipelineRun, string(pr.Resolver), resolverPayload)","\t\t\treturn resolvePipeline(ctx, resolver, name, namespace, k8s, tekton, verificationPolicies)","\t\t}","\tdefault:","\t\t// Even if there is no pipeline ref, we should try to return a local resolver.","\t\tlocal := \u0026LocalPipelineRefResolver{","\t\t\tNamespace:    namespace,","\t\t\tTektonclient: tekton,","\t\t}","\t\treturn local.GetPipeline","\t}","}","","// LocalPipelineRefResolver uses the current cluster to resolve a pipeline reference.","type LocalPipelineRefResolver struct {","\tNamespace    string","\tTektonclient clientset.Interface","}","","// GetPipeline will resolve a Pipeline from the local cluster using a versioned Tekton client. It will","// return an error if it can't find an appropriate Pipeline for any reason.","// TODO: if we want to set RefSource for in-cluster pipeline, set it here.","// https://github.com/tektoncd/pipeline/issues/5522","// TODO(#6666): Support local resources verification","func (l *LocalPipelineRefResolver) GetPipeline(ctx context.Context, name string) (*v1.Pipeline, *v1.RefSource, *trustedresources.VerificationResult, error) {","\t// If we are going to resolve this reference locally, we need a namespace scope.","\tif l.Namespace == \"\" {","\t\treturn nil, nil, nil, fmt.Errorf(\"must specify namespace to resolve reference to pipeline %s\", name)","\t}","","\tpipeline, err := l.Tektonclient.TektonV1().Pipelines(l.Namespace).Get(ctx, name, metav1.GetOptions{})","\tif err != nil {","\t\treturn nil, nil, nil, fmt.Errorf(\"tekton client cannot get pipeline %s from local cluster: %w\", name, err)","\t}","\treturn pipeline, nil, nil, nil","}","","// resolvePipeline accepts an impl of remote.Resolver and attempts to","// fetch a pipeline with given name and verify the v1beta1 pipeline if trusted resources is enabled.","// An error is returned if the remoteresource doesn't work","// A VerificationResult is returned if trusted resources is enabled, VerificationResult contains the result type and err.","// or the returned data isn't a valid *v1.Pipeline.","func resolvePipeline(ctx context.Context, resolver remote.Resolver, name string, namespace string, k8s kubernetes.Interface, tekton clientset.Interface, verificationPolicies []*v1alpha1.VerificationPolicy) (*v1.Pipeline, *v1.RefSource, *trustedresources.VerificationResult, error) {","\tobj, refSource, err := resolver.Get(ctx, \"pipeline\", name)","\tif err != nil {","\t\treturn nil, nil, nil, fmt.Errorf(\"resolver failed to get Pipeline %s: %w\", name, err)","\t}","\tpipelineObj, vr, err := readRuntimeObjectAsPipeline(ctx, namespace, obj, k8s, tekton, refSource, verificationPolicies)","\tif err != nil {","\t\treturn nil, nil, nil, fmt.Errorf(\"failed to read runtime object as Pipeline: %w\", err)","\t}","\treturn pipelineObj, refSource, vr, nil","}","","// readRuntimeObjectAsPipeline tries to convert a generic runtime.Object","// into a *v1.Pipeline type so that its meta and spec fields","// can be read. v1 object will be converted to v1beta1 and returned.","// v1beta1 Pipeline will be verified if trusted resources is enabled","// A VerificationResult is returned if trusted resources is enabled, VerificationResult contains the result type and err.","// An error is returned if the given object is not a","// PipelineObject or if there is an error validating or upgrading an","// older PipelineObject into its v1beta1 equivalent.","// TODO(#5541): convert v1beta1 obj to v1 once we use v1 as the stored version","func readRuntimeObjectAsPipeline(ctx context.Context, namespace string, obj runtime.Object, k8s kubernetes.Interface, tekton clientset.Interface, refSource *v1.RefSource, verificationPolicies []*v1alpha1.VerificationPolicy) (*v1.Pipeline, *trustedresources.VerificationResult, error) {","\tswitch obj := obj.(type) {","\tcase *v1beta1.Pipeline:","\t\tobj.SetDefaults(ctx)","\t\t// Cleanup object from things we don't care about","\t\t// FIXME: extract this in a function","\t\tobj.ObjectMeta.OwnerReferences = nil","\t\t// Verify the Pipeline once we fetch from the remote resolution, mutating, validation and conversion of the pipeline should happen after the verification, since signatures are based on the remote pipeline contents","\t\tvr := trustedresources.VerifyResource(ctx, obj, k8s, refSource, verificationPolicies)","\t\t// Issue a dry-run request to create the remote Pipeline, so that it can undergo validation from validating admission webhooks","\t\t// and mutation from mutating admission webhooks without actually creating the Pipeline on the cluster","\t\to, err := apiserver.DryRunValidate(ctx, namespace, obj, tekton)","\t\tif err != nil {","\t\t\treturn nil, nil, err","\t\t}","\t\tif mutatedPipeline, ok := o.(*v1beta1.Pipeline); ok {","\t\t\tmutatedPipeline.ObjectMeta = obj.ObjectMeta","\t\t\tp := \u0026v1.Pipeline{","\t\t\t\tTypeMeta: metav1.TypeMeta{","\t\t\t\t\tKind:       \"Pipeline\",","\t\t\t\t\tAPIVersion: \"tekton.dev/v1\",","\t\t\t\t},","\t\t\t}","\t\t\tif err := mutatedPipeline.ConvertTo(ctx, p); err != nil {","\t\t\t\treturn nil, nil, fmt.Errorf(\"failed to convert v1beta1 obj %s into v1 Pipeline\", mutatedPipeline.GetObjectKind().GroupVersionKind().String())","\t\t\t}","\t\t\treturn p, \u0026vr, nil","\t\t}","\tcase *v1.Pipeline:","\t\t// Cleanup object from things we don't care about","\t\t// FIXME: extract this in a function","\t\tobj.ObjectMeta.OwnerReferences = nil","\t\t// This SetDefaults is currently not necessary, but for consistency, it is recommended to add it.","\t\t// Avoid forgetting to add it in the future when there is a v2 version, causing similar problems.","\t\tobj.SetDefaults(ctx)","\t\tvr := trustedresources.VerifyResource(ctx, obj, k8s, refSource, verificationPolicies)","\t\to, err := apiserver.DryRunValidate(ctx, namespace, obj, tekton)","\t\tif err != nil {","\t\t\treturn nil, nil, err","\t\t}","\t\tif mutatedPipeline, ok := o.(*v1.Pipeline); ok {","\t\t\tmutatedPipeline.ObjectMeta = obj.ObjectMeta","\t\t\treturn mutatedPipeline, \u0026vr, nil","\t\t}","\t}","\treturn nil, nil, errors.New(\"resource is not a pipeline\")","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,1,1,0,2,2,2,2,2,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,1,0]},{"id":193,"path":"pkg/reconciler/pipelinerun/resources/pipelinerunresolution.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resources","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","\t\"sort\"","\t\"strings\"","","\t\"github.com/google/cel-go/cel\"","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tpipelineErrors \"github.com/tektoncd/pipeline/pkg/apis/pipeline/errors\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/taskrun/resources\"","\t\"github.com/tektoncd/pipeline/pkg/remote\"","\tresolutioncommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/resource\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\tkerrors \"k8s.io/apimachinery/pkg/api/errors\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/kmeta\"",")","","const (","\t// ReasonConditionCheckFailed indicates that the reason for the failure status is that the","\t// condition check associated to the pipeline task evaluated to false","\tReasonConditionCheckFailed = \"ConditionCheckFailed\"",")","","// TaskSkipStatus stores whether a task was skipped and why","type TaskSkipStatus struct {","\tIsSkipped      bool","\tSkippingReason v1.SkippingReason","}","","// TaskNotFoundError indicates that the resolution failed because a referenced Task couldn't be retrieved","type TaskNotFoundError struct {","\tName string","\tErr  error","}","","func (e *TaskNotFoundError) Error() string {","\treturn fmt.Sprintf(\"Couldn't retrieve Task %q: %s\", e.Name, e.Err.Error())","}","","func (e *TaskNotFoundError) Unwrap() error {","\treturn e.Err","}","","// ResolvedPipelineTask contains a PipelineTask and its associated child PipelineRun(s) (Pipelines-in-Pipelines), TaskRun(s) or CustomRuns, if they exist.","type ResolvedPipelineTask struct {","\tChildPipelineRunNames []string","\tChildPipelineRuns     []*v1.PipelineRun","\tResolvedPipeline      ResolvedPipeline","","\tTaskRunNames []string","\tTaskRuns     []*v1.TaskRun","\tResolvedTask *resources.ResolvedTask","","\t// If the PipelineTask is a Custom Task, CustomRunName and CustomRun will be set.","\tCustomTask     bool","\tCustomRunNames []string","\tCustomRuns     []*v1beta1.CustomRun","","\tPipelineTask *v1.PipelineTask","\tResultsCache map[string][]string","","\t// EvaluatedCEL is used to store the results of evaluated CEL expression","\tEvaluatedCEL map[string]bool","}","","// EvaluateCEL evaluate the CEL expressions, and store the evaluated results in EvaluatedCEL","func (t *ResolvedPipelineTask) EvaluateCEL() error {","\tif t.PipelineTask != nil {","\t\t// Each call to this function will reset this field to prevent additional CELs.","\t\tt.EvaluatedCEL = make(map[string]bool)","\t\tfor _, we := range t.PipelineTask.When {","\t\t\tif we.CEL == \"\" {","\t\t\t\tcontinue","\t\t\t}","\t\t\t_, ok := t.EvaluatedCEL[we.CEL]","\t\t\tif !ok {","\t\t\t\t// Create a program environment configured with the standard library of CEL functions and macros","\t\t\t\t// The error is omitted because not environment declarations are passed in.","\t\t\t\tenv, _ := cel.NewEnv()","\t\t\t\t// Parse and Check the CEL to get the Abstract Syntax Tree","\t\t\t\tast, iss := env.Compile(we.CEL)","\t\t\t\tif iss.Err() != nil {","\t\t\t\t\treturn iss.Err()","\t\t\t\t}","\t\t\t\t// Generate an evaluatable instance of the Ast within the environment","\t\t\t\tprg, err := env.Program(ast)","\t\t\t\tif err != nil {","\t\t\t\t\treturn err","\t\t\t\t}","\t\t\t\t// Evaluate the CEL expression","\t\t\t\tout, _, err := prg.Eval(map[string]interface{}{})","\t\t\t\tif err != nil {","\t\t\t\t\treturn err","\t\t\t\t}","","\t\t\t\tb, ok := out.Value().(bool)","\t\t\t\tif ok {","\t\t\t\t\tt.EvaluatedCEL[we.CEL] = b","\t\t\t\t} else {","\t\t\t\t\treturn fmt.Errorf(\"The CEL expression %s is not evaluated to a boolean\", we.CEL)","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn nil","}","","// isDone returns true only if the task is skipped, succeeded or failed","func (t ResolvedPipelineTask) isDone(facts *PipelineRunFacts) bool {","\treturn t.Skip(facts).IsSkipped || t.isSuccessful() || t.isFailure() || t.isValidationFailed(facts.ValidationFailedTask)","}","","// IsRunning returns true only if the task is neither succeeded, cancelled nor failed","func (t ResolvedPipelineTask) IsRunning() bool {","\tif t.IsCustomTask() \u0026\u0026 len(t.CustomRuns) == 0 {","\t\treturn false","\t}","\tif !t.IsCustomTask() \u0026\u0026 len(t.TaskRuns) == 0 {","\t\treturn false","\t}","\treturn !t.isSuccessful() \u0026\u0026 !t.isFailure()","}","","// IsCustomTask returns true if the PipelineTask references a Custom Task.","func (t ResolvedPipelineTask) IsCustomTask() bool {","\treturn t.CustomTask","}","","// IsChildPipeline returns true if the PipelineTask references a child Pipeline.","func (t ResolvedPipelineTask) IsChildPipeline() bool {","\treturn t.PipelineTask.PipelineSpec != nil","}","","// getReason returns the latest reason if the run has completed successfully","// If the PipelineTask has a Matrix, getReason returns the failure reason for any failure","// otherwise, it returns an empty string","func (t ResolvedPipelineTask) getReason() string {","\tif t.IsChildPipeline() {","\t\tif len(t.ChildPipelineRuns) == 0 {","\t\t\treturn \"\"","\t\t}","\t\tfor _, childPipelineRun := range t.ChildPipelineRuns {","\t\t\tif !childPipelineRun.IsSuccessful() \u0026\u0026 len(childPipelineRun.Status.Conditions) \u003e= 1 {","\t\t\t\treturn childPipelineRun.Status.Conditions[0].Reason","\t\t\t}","\t\t}","\t\tif len(t.ChildPipelineRuns) \u003e= 1 \u0026\u0026 len(t.ChildPipelineRuns[0].Status.Conditions) \u003e= 1 {","\t\t\treturn t.ChildPipelineRuns[0].Status.Conditions[0].Reason","\t\t}","\t}","","\tif t.IsCustomTask() {","\t\tif len(t.CustomRuns) == 0 {","\t\t\treturn \"\"","\t\t}","\t\tfor _, run := range t.CustomRuns {","\t\t\tif !run.IsSuccessful() \u0026\u0026 len(run.Status.Conditions) \u003e= 1 {","\t\t\t\treturn run.Status.Conditions[0].Reason","\t\t\t}","\t\t}","\t\tif len(t.CustomRuns) \u003e= 1 \u0026\u0026 len(t.CustomRuns[0].Status.Conditions) \u003e= 1 {","\t\t\treturn t.CustomRuns[0].Status.Conditions[0].Reason","\t\t}","\t}","","\tif len(t.TaskRuns) == 0 {","\t\treturn \"\"","\t}","\tfor _, taskRun := range t.TaskRuns {","\t\tif !taskRun.IsSuccessful() \u0026\u0026 len(taskRun.Status.Conditions) \u003e= 1 {","\t\t\treturn taskRun.Status.Conditions[0].Reason","\t\t}","\t}","\tif len(t.TaskRuns) \u003e= 1 \u0026\u0026 len(t.TaskRuns[0].Status.Conditions) \u003e= 1 {","\t\treturn t.TaskRuns[0].Status.Conditions[0].Reason","\t}","","\treturn \"\"","}","","// isSuccessful returns true only if the run has completed successfully","// If the PipelineTask has a Matrix, isSuccessful returns true if all runs have completed successfully","func (t ResolvedPipelineTask) isSuccessful() bool {","\tif t.IsChildPipeline() {","\t\tif len(t.ChildPipelineRuns) == 0 {","\t\t\treturn false","\t\t}","","\t\tfor _, childPipelineRun := range t.ChildPipelineRuns {","\t\t\tif !childPipelineRun.IsSuccessful() {","\t\t\t\treturn false","\t\t\t}","\t\t}","","\t\treturn true","\t}","","\tif t.IsCustomTask() {","\t\tif len(t.CustomRuns) == 0 {","\t\t\treturn false","\t\t}","\t\tfor _, run := range t.CustomRuns {","\t\t\tif !run.IsSuccessful() {","\t\t\t\treturn false","\t\t\t}","\t\t}","\t\treturn true","\t}","","\tif len(t.TaskRuns) == 0 {","\t\treturn false","\t}","\tfor _, taskRun := range t.TaskRuns {","\t\tif !taskRun.IsSuccessful() {","\t\t\treturn false","\t\t}","\t}","\treturn true","}","","// isFailure returns true only if the run has failed (if it has ConditionSucceeded = False).","// If the PipelineTask has a Matrix, isFailure returns true if any run has failed and all other runs are done.","func (t ResolvedPipelineTask) isFailure() bool {","\tvar isDone bool","\tif t.IsChildPipeline() {","\t\tif len(t.ChildPipelineRuns) == 0 {","\t\t\treturn false","\t\t}","\t\tisDone = true","\t\tfor _, childPipelineRun := range t.ChildPipelineRuns {","\t\t\tisDone = isDone \u0026\u0026 childPipelineRun.IsDone()","\t\t}","\t\treturn t.haveAnyChildPipelineRunsFailed() \u0026\u0026 isDone","\t}","","\tif t.IsCustomTask() {","\t\tif len(t.CustomRuns) == 0 {","\t\t\treturn false","\t\t}","\t\tisDone = true","\t\tfor _, run := range t.CustomRuns {","\t\t\tisDone = isDone \u0026\u0026 run.IsDone()","\t\t}","\t\treturn t.haveAnyRunsFailed() \u0026\u0026 isDone","\t}","","\tif len(t.TaskRuns) == 0 {","\t\treturn false","\t}","\tisDone = true","\tfor _, taskRun := range t.TaskRuns {","\t\tisDone = isDone \u0026\u0026 taskRun.IsDone()","\t}","\treturn t.haveAnyTaskRunsFailed() \u0026\u0026 isDone","}","","// isValidationFailed return true if the task is failed at the validation step","func (t ResolvedPipelineTask) isValidationFailed(ftasks []*ResolvedPipelineTask) bool {","\tfor _, ftask := range ftasks {","\t\tif ftask.ResolvedTask == t.ResolvedTask {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// isCancelledForTimeOut returns true only if the run is cancelled due to PipelineRun-controlled timeout","// If the PipelineTask has a Matrix, isCancelled returns true if any run is cancelled due to PipelineRun-controlled timeout and all other runs are done.","func (t ResolvedPipelineTask) isCancelledForTimeOut() bool {","\tif t.IsCustomTask() {","\t\tif len(t.CustomRuns) == 0 {","\t\t\treturn false","\t\t}","\t\tisDone := true","\t\tatLeastOneCancelled := false","\t\tfor _, run := range t.CustomRuns {","\t\t\tisDone = isDone \u0026\u0026 run.IsDone()","\t\t\tc := run.GetStatusCondition().GetCondition(apis.ConditionSucceeded)","\t\t\trunCancelled := c.IsFalse() \u0026\u0026","\t\t\t\tc.Reason == v1beta1.CustomRunReasonCancelled.String() \u0026\u0026","\t\t\t\tisCustomRunCancelledByPipelineRunTimeout(run)","\t\t\tatLeastOneCancelled = atLeastOneCancelled || runCancelled","\t\t}","\t\treturn atLeastOneCancelled \u0026\u0026 isDone","\t}","\tif len(t.TaskRuns) == 0 {","\t\treturn false","\t}","\tisDone := true","\tatLeastOneCancelled := false","\tfor _, taskRun := range t.TaskRuns {","\t\tisDone = isDone \u0026\u0026 taskRun.IsDone()","\t\tc := taskRun.Status.GetCondition(apis.ConditionSucceeded)","\t\ttaskRunCancelled := c.IsFalse() \u0026\u0026","\t\t\tc.Reason == v1beta1.TaskRunReasonCancelled.String() \u0026\u0026","\t\t\ttaskRun.Spec.StatusMessage == v1.TaskRunCancelledByPipelineTimeoutMsg","\t\tatLeastOneCancelled = atLeastOneCancelled || taskRunCancelled","\t}","\treturn atLeastOneCancelled \u0026\u0026 isDone","}","","// isCancelled returns true only if the run is cancelled","// If the PipelineTask has a Matrix, isCancelled returns true if any run is cancelled and all other runs are done.","func (t ResolvedPipelineTask) isCancelled() bool {","\tif t.IsCustomTask() {","\t\tif len(t.CustomRuns) == 0 {","\t\t\treturn false","\t\t}","\t\tisDone := true","\t\tatLeastOneCancelled := false","\t\tfor _, run := range t.CustomRuns {","\t\t\tisDone = isDone \u0026\u0026 run.IsDone()","\t\t\tc := run.GetStatusCondition().GetCondition(apis.ConditionSucceeded)","\t\t\trunCancelled := c.IsFalse() \u0026\u0026 c.Reason == v1beta1.CustomRunReasonCancelled.String()","\t\t\tatLeastOneCancelled = atLeastOneCancelled || runCancelled","\t\t}","\t\treturn atLeastOneCancelled \u0026\u0026 isDone","\t}","\tif len(t.TaskRuns) == 0 {","\t\treturn false","\t}","\tisDone := true","\tatLeastOneCancelled := false","\tfor _, taskRun := range t.TaskRuns {","\t\tisDone = isDone \u0026\u0026 taskRun.IsDone()","\t\tc := taskRun.Status.GetCondition(apis.ConditionSucceeded)","\t\ttaskRunCancelled := c.IsFalse() \u0026\u0026 c.Reason == v1beta1.TaskRunReasonCancelled.String()","\t\tatLeastOneCancelled = atLeastOneCancelled || taskRunCancelled","\t}","\treturn atLeastOneCancelled \u0026\u0026 isDone","}","","// isScheduled returns true when the PipelineRunTask itself has any TaskRuns/CustomRuns","// or a singular TaskRun/CustomRun associated.","func (t ResolvedPipelineTask) isScheduled() bool {","\tif t.IsCustomTask() {","\t\treturn len(t.CustomRuns) \u003e 0","\t}","\treturn len(t.TaskRuns) \u003e 0","}","","// haveAnyRunsFailed returns true when any of the child PipelineRuns/TaskRuns/CustomRuns have succeeded condition with status set to false","func (t ResolvedPipelineTask) haveAnyRunsFailed() bool {","\tif t.IsChildPipeline() {","\t\treturn t.haveAnyChildPipelineRunsFailed()","\t}","","\tif t.IsCustomTask() {","\t\treturn t.haveAnyCustomRunsFailed()","\t}","","\treturn t.haveAnyTaskRunsFailed()","}","","// haveAnyChildPipelineRunsFailed returns true when any of the child PipelineRuns have succeeded condition with status set to false","func (t ResolvedPipelineTask) haveAnyChildPipelineRunsFailed() bool {","\tfor _, childPipelineRun := range t.ChildPipelineRuns {","\t\tif childPipelineRun.IsFailure() {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// haveAnyTaskRunsFailed returns true when any of the TaskRuns have succeeded condition with status set to false","func (t ResolvedPipelineTask) haveAnyTaskRunsFailed() bool {","\tfor _, taskRun := range t.TaskRuns {","\t\tif taskRun.IsFailure() {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// haveAnyCustomRunsFailed returns true when any of the CustomRuns have succeeded condition with status set to false","func (t ResolvedPipelineTask) haveAnyCustomRunsFailed() bool {","\tfor _, customRun := range t.CustomRuns {","\t\tif customRun.IsFailure() {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","func (t *ResolvedPipelineTask) checkParentsDone(facts *PipelineRunFacts) bool {","\tif facts.isFinalTask(t.PipelineTask.Name) {","\t\treturn true","\t}","\tstateMap := facts.State.ToMap()","\tnode := facts.TasksGraph.Nodes[t.PipelineTask.Name]","\tfor _, p := range node.Prev {","\t\tif !stateMap[p.Key].isDone(facts) {","\t\t\treturn false","\t\t}","\t}","\treturn true","}","","func (t *ResolvedPipelineTask) skip(facts *PipelineRunFacts) TaskSkipStatus {","\tvar skippingReason v1.SkippingReason","","\tswitch {","\tcase facts.isFinalTask(t.PipelineTask.Name) || t.isScheduled() || t.isValidationFailed(facts.ValidationFailedTask):","\t\tskippingReason = v1.None","\tcase facts.IsStopping():","\t\tskippingReason = v1.StoppingSkip","\tcase facts.IsGracefullyCancelled():","\t\tskippingReason = v1.GracefullyCancelledSkip","\tcase facts.IsGracefullyStopped():","\t\tskippingReason = v1.GracefullyStoppedSkip","\tcase t.skipBecauseWhenExpressionsEvaluatedToFalse(facts):","\t\tskippingReason = v1.WhenExpressionsSkip","\tcase t.skipBecauseParentTaskWasSkipped(facts):","\t\tskippingReason = v1.ParentTasksSkip","\tcase t.skipBecauseResultReferencesAreMissing(facts):","\t\tskippingReason = v1.MissingResultsSkip","\tcase t.skipBecausePipelineRunPipelineTimeoutReached(facts):","\t\tskippingReason = v1.PipelineTimedOutSkip","\tcase t.skipBecausePipelineRunTasksTimeoutReached(facts):","\t\tskippingReason = v1.TasksTimedOutSkip","\tcase t.skipBecauseEmptyArrayInMatrixParams():","\t\tskippingReason = v1.EmptyArrayInMatrixParams","\tdefault:","\t\tskippingReason = v1.None","\t}","","\treturn TaskSkipStatus{","\t\tIsSkipped:      skippingReason != v1.None,","\t\tSkippingReason: skippingReason,","\t}","}","","// Skip returns true if a PipelineTask will not be run because","// (1) its When Expressions evaluated to false","// (2) its Condition Checks failed","// (3) its parent task was skipped","// (4) Pipeline is in stopping state (one of the PipelineTasks failed)","// (5) Pipeline is gracefully cancelled or stopped","func (t *ResolvedPipelineTask) Skip(facts *PipelineRunFacts) TaskSkipStatus {","\tif facts.SkipCache == nil {","\t\tfacts.SkipCache = make(map[string]TaskSkipStatus)","\t}","\tif _, cached := facts.SkipCache[t.PipelineTask.Name]; !cached {","\t\tfacts.SkipCache[t.PipelineTask.Name] = t.skip(facts)","\t}","\treturn facts.SkipCache[t.PipelineTask.Name]","}","","// skipBecauseWhenExpressionsEvaluatedToFalse confirms that the when expressions have completed evaluating, and","// it returns true if any of the when expressions evaluate to false","func (t *ResolvedPipelineTask) skipBecauseWhenExpressionsEvaluatedToFalse(facts *PipelineRunFacts) bool {","\tif t.checkParentsDone(facts) {","\t\tif !t.PipelineTask.When.AllowsExecution(t.EvaluatedCEL) {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// skipBecauseParentTaskWasSkipped loops through the parent tasks and checks if the parent task skipped:","//","//\tif yes, is it because of when expressions?","//\t    if yes, it ignores this parent skip and continue evaluating other parent tasks","//\t    if no, it returns true to skip the current task because this parent task was skipped","//\tif no, it continues checking the other parent tasks","func (t *ResolvedPipelineTask) skipBecauseParentTaskWasSkipped(facts *PipelineRunFacts) bool {","\tstateMap := facts.State.ToMap()","\tnode := facts.TasksGraph.Nodes[t.PipelineTask.Name]","\tfor _, p := range node.Prev {","\t\tparentTask := stateMap[p.Key]","\t\tif parentSkipStatus := parentTask.Skip(facts); parentSkipStatus.IsSkipped {","\t\t\t// if the parent task was skipped due to its `when` expressions,","\t\t\t// then we should ignore that and continue evaluating if we should skip because of other parent tasks","\t\t\tif parentSkipStatus.SkippingReason == v1.WhenExpressionsSkip {","\t\t\t\tcontinue","\t\t\t}","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// skipBecauseResultReferencesAreMissing checks if the task references results that cannot be resolved, which is a","// reason for skipping the task, and applies result references if found","func (t *ResolvedPipelineTask) skipBecauseResultReferencesAreMissing(facts *PipelineRunFacts) bool {","\tif t.checkParentsDone(facts) \u0026\u0026 t.hasResultReferences() {","\t\tresolvedResultRefs, pt, err := ResolveResultRefs(facts.State, PipelineRunState{t})","\t\trpt := facts.State.ToMap()[pt]","\t\tif rpt != nil {","\t\t\tif err != nil \u0026\u0026","\t\t\t\t(t.PipelineTask.OnError == v1.PipelineTaskContinue ||","\t\t\t\t\t(t.IsFinalTask(facts) || rpt.Skip(facts).SkippingReason == v1.WhenExpressionsSkip)) {","\t\t\t\treturn true","\t\t\t}","\t\t}","\t\tApplyTaskResults(PipelineRunState{t}, resolvedResultRefs)","\t\tfacts.ResetSkippedCache()","\t}","\treturn false","}","","// skipBecausePipelineRunPipelineTimeoutReached returns true if the task shouldn't be launched because the elapsed time since","// the PipelineRun started is greater than the PipelineRun's pipeline timeout","func (t *ResolvedPipelineTask) skipBecausePipelineRunPipelineTimeoutReached(facts *PipelineRunFacts) bool {","\tif t.checkParentsDone(facts) {","\t\tif facts.TimeoutsState.PipelineTimeout != nil \u0026\u0026 *facts.TimeoutsState.PipelineTimeout != config.NoTimeoutDuration \u0026\u0026 facts.TimeoutsState.StartTime != nil {","\t\t\t// If the elapsed time since the PipelineRun's start time is greater than the PipelineRun's Pipeline timeout, skip.","\t\t\treturn facts.TimeoutsState.Clock.Since(*facts.TimeoutsState.StartTime) \u003e *facts.TimeoutsState.PipelineTimeout","\t\t}","\t}","","\treturn false","}","","// skipBecausePipelineRunTasksTimeoutReached returns true if the task shouldn't be launched because the elapsed time since","// the PipelineRun started is greater than the PipelineRun's tasks timeout","func (t *ResolvedPipelineTask) skipBecausePipelineRunTasksTimeoutReached(facts *PipelineRunFacts) bool {","\tif t.checkParentsDone(facts) \u0026\u0026 !t.IsFinalTask(facts) {","\t\tif facts.TimeoutsState.TasksTimeout != nil \u0026\u0026 *facts.TimeoutsState.TasksTimeout != config.NoTimeoutDuration \u0026\u0026 facts.TimeoutsState.StartTime != nil {","\t\t\t// If the elapsed time since the PipelineRun's start time is greater than the PipelineRun's Tasks timeout, skip.","\t\t\treturn facts.TimeoutsState.Clock.Since(*facts.TimeoutsState.StartTime) \u003e *facts.TimeoutsState.TasksTimeout","\t\t}","\t}","","\treturn false","}","","// skipBecausePipelineRunFinallyTimeoutReached returns true if the task shouldn't be launched because the elapsed time since","// finally tasks started being executed is greater than the PipelineRun's finally timeout","func (t *ResolvedPipelineTask) skipBecausePipelineRunFinallyTimeoutReached(facts *PipelineRunFacts) bool {","\tif t.checkParentsDone(facts) \u0026\u0026 t.IsFinalTask(facts) {","\t\tif facts.TimeoutsState.FinallyTimeout != nil \u0026\u0026 *facts.TimeoutsState.FinallyTimeout != config.NoTimeoutDuration \u0026\u0026 facts.TimeoutsState.FinallyStartTime != nil {","\t\t\t// If the elapsed time since the PipelineRun's finally start time is greater than the PipelineRun's finally timeout, skip.","\t\t\treturn facts.TimeoutsState.Clock.Since(*facts.TimeoutsState.FinallyStartTime) \u003e *facts.TimeoutsState.FinallyTimeout","\t\t}","\t}","","\treturn false","}","","// skipBecauseEmptyArrayInMatrixParams returns true if the matrix parameters contain an empty array","func (t *ResolvedPipelineTask) skipBecauseEmptyArrayInMatrixParams() bool {","\tif t.PipelineTask.IsMatrixed() {","\t\tfor _, ps := range t.PipelineTask.Matrix.Params {","\t\t\tif ps.Value.Type == v1.ParamTypeArray \u0026\u0026 len(ps.Value.ArrayVal) == 0 {","\t\t\t\treturn true","\t\t\t}","\t\t}","\t}","","\treturn false","}","","// IsFinalTask returns true if a task is a finally task","func (t *ResolvedPipelineTask) IsFinalTask(facts *PipelineRunFacts) bool {","\treturn facts.isFinalTask(t.PipelineTask.Name)","}","","// IsFinallySkipped returns true if a finally task is not executed and skipped due to task result validation failure","func (t *ResolvedPipelineTask) IsFinallySkipped(facts *PipelineRunFacts) TaskSkipStatus {","\tvar skippingReason v1.SkippingReason","","\tswitch {","\tcase t.isScheduled():","\t\tskippingReason = v1.None","\tcase facts.checkDAGTasksDone() \u0026\u0026 facts.isFinalTask(t.PipelineTask.Name):","\t\tswitch {","\t\tcase t.skipBecauseResultReferencesAreMissing(facts):","\t\t\tskippingReason = v1.MissingResultsSkip","\t\tcase t.skipBecauseWhenExpressionsEvaluatedToFalse(facts):","\t\t\tskippingReason = v1.WhenExpressionsSkip","\t\tcase t.skipBecausePipelineRunPipelineTimeoutReached(facts):","\t\t\tskippingReason = v1.PipelineTimedOutSkip","\t\tcase t.skipBecausePipelineRunFinallyTimeoutReached(facts):","\t\t\tskippingReason = v1.FinallyTimedOutSkip","\t\tcase t.skipBecauseEmptyArrayInMatrixParams():","\t\t\tskippingReason = v1.EmptyArrayInMatrixParams","\t\tdefault:","\t\t\tskippingReason = v1.None","\t\t}","\tdefault:","\t\tskippingReason = v1.None","\t}","","\treturn TaskSkipStatus{","\t\tIsSkipped:      skippingReason != v1.None,","\t\tSkippingReason: skippingReason,","\t}","}","","// GetRun is a function that will retrieve a CustomRun by name.","type GetRun func(name string) (*v1beta1.CustomRun, error)","","// ValidateWorkspaceBindings validates that the Workspaces expected by a Pipeline are provided by a PipelineRun.","func ValidateWorkspaceBindings(p *v1.PipelineSpec, pr *v1.PipelineRun) error {","\tpipelineRunWorkspaces := make(map[string]v1.WorkspaceBinding)","\tfor _, binding := range pr.Spec.Workspaces {","\t\tpipelineRunWorkspaces[binding.Name] = binding","\t}","","\tfor _, ws := range p.Workspaces {","\t\tif ws.Optional {","\t\t\tcontinue","\t\t}","\t\tif _, ok := pipelineRunWorkspaces[ws.Name]; !ok {","\t\t\treturn pipelineErrors.WrapUserError(fmt.Errorf(\"pipeline requires workspace with name %q be provided by pipelinerun\", ws.Name))","\t\t}","\t}","\treturn nil","}","","// ValidateTaskRunSpecs that the TaskRunSpecs defined by a PipelineRun are correct.","func ValidateTaskRunSpecs(p *v1.PipelineSpec, pr *v1.PipelineRun) error {","\tpipelineTasks := make(map[string]string)","\tfor _, task := range p.Tasks {","\t\tpipelineTasks[task.Name] = task.Name","\t}","","\tfor _, task := range p.Finally {","\t\tpipelineTasks[task.Name] = task.Name","\t}","","\tfor _, taskrunSpec := range pr.Spec.TaskRunSpecs {","\t\tif _, ok := pipelineTasks[taskrunSpec.PipelineTaskName]; !ok {","\t\t\treturn pipelineErrors.WrapUserError(fmt.Errorf(\"pipelineRun's taskrunSpecs defined wrong taskName: %q, does not exist in Pipeline\", taskrunSpec.PipelineTaskName))","\t\t}","\t}","\treturn nil","}","","// ResolvePipelineTask returns a new ResolvedPipelineTask representing any TaskRuns or CustomRuns","// associated with this Pipeline Task, if they exist.","//","// If the Pipeline Task is a Task, it retrieves any TaskRuns, plus the Task spec, and updates the ResolvedPipelineTask","// with this information. It also sets the ResolvedPipelineTask's TaskRunName(s) with the names of TaskRuns","// that should be or already have been created.","//","// If the Pipeline Task is a Custom Task, it retrieves any CustomRuns and updates the ResolvedPipelineTask with this information.","// It also sets the ResolvedPipelineTask's RunName(s) with the names of CustomRuns that should be or already have been created.","//","// If the Pipeline Task is a Pipeline, it retrieves any child PipelineRuns, plus the Pipeline spec and updates the","// ResolvedPipelineTask with this information. It also sets the ResolvedPipelineTask's ChildPipelineRunName(s) with the names","// of child PipelineRuns that should be or already have been created.","func ResolvePipelineTask(","\tctx context.Context,","\tpipelineRun v1.PipelineRun,","\tgetChildPipelineRun GetPipelineRun,","\tgetTask resources.GetTask,","\tgetTaskRun resources.GetTaskRun,","\tgetRun GetRun,","\tpipelineTask v1.PipelineTask,","\tpst PipelineRunState,",") (*ResolvedPipelineTask, error) {","\trpt := ResolvedPipelineTask{","\t\tPipelineTask: \u0026pipelineTask,","\t}","\trpt.CustomTask = rpt.PipelineTask.TaskRef.IsCustomTask() || rpt.PipelineTask.TaskSpec.IsCustomTask()","\tnumCombinations := 1","\t// We want to resolve all of the result references and ignore any errors at this point since there could be","\t// instances where result references are missing here, but will be later skipped and resolved in","\t// skipBecauseResultReferencesAreMissing. The final validation is handled in CheckMissingResultReferences.","\tresolvedResultRefs, _, _ := ResolveResultRefs(pst, PipelineRunState{\u0026rpt})","\tif err := validateArrayResultsIndex(resolvedResultRefs); err != nil {","\t\treturn nil, err","\t}","","\tApplyTaskResults(PipelineRunState{\u0026rpt}, resolvedResultRefs)","","\tif rpt.PipelineTask.IsMatrixed() {","\t\tnumCombinations = rpt.PipelineTask.Matrix.CountCombinations()","\t}","","\tswitch {","\tcase rpt.IsChildPipeline():","\t\trpt.ChildPipelineRunNames = GetNamesOfChildPipelineRuns(","\t\t\tpipelineRun.Status.ChildReferences,","\t\t\tpipelineTask.Name,","\t\t\tpipelineRun.Name,","\t\t\tnumCombinations,","\t\t)","","\t\t// happy path: no pipelineRef, no local/remote resolution, no getPipeline","\t\tfor _, childPipelineRunName := range rpt.ChildPipelineRunNames {","\t\t\tif err := rpt.setChildPipelineRunsAndResolvedPipeline(ctx, childPipelineRunName, getChildPipelineRun, pipelineTask); err != nil {","\t\t\t\treturn nil, err","\t\t\t}","\t\t}","","\tcase rpt.IsCustomTask():","\t\trpt.CustomRunNames = getNamesOfCustomRuns(pipelineRun.Status.ChildReferences, pipelineTask.Name, pipelineRun.Name, numCombinations)","\t\tfor _, runName := range rpt.CustomRunNames {","\t\t\trun, err := getRun(runName)","\t\t\tif err != nil \u0026\u0026 !kerrors.IsNotFound(err) {","\t\t\t\treturn nil, fmt.Errorf(\"error retrieving CustomRun %s: %w\", runName, err)","\t\t\t}","\t\t\tif run != nil {","\t\t\t\trpt.CustomRuns = append(rpt.CustomRuns, run)","\t\t\t}","\t\t}","","\tdefault:","\t\trpt.TaskRunNames = GetNamesOfTaskRuns(pipelineRun.Status.ChildReferences, pipelineTask.Name, pipelineRun.Name, numCombinations)","\t\tfor _, taskRunName := range rpt.TaskRunNames {","\t\t\tif err := rpt.setTaskRunsAndResolvedTask(ctx, taskRunName, getTask, getTaskRun, pipelineTask); err != nil {","\t\t\t\treturn nil, err","\t\t\t}","\t\t}","\t}","","\treturn \u0026rpt, nil","}","","func (t *ResolvedPipelineTask) setChildPipelineRunsAndResolvedPipeline(","\tctx context.Context,","\tchildPipelineRunName string,","\tgetChildPipelineRun GetPipelineRun,","\tpipelineTask v1.PipelineTask,",") error {","\tchildPipelineRun, err := getChildPipelineRun(childPipelineRunName)","\tif err != nil {","\t\tif !kerrors.IsNotFound(err) {","\t\t\treturn fmt.Errorf(\"error retrieving child PipelineRun %s: %w\", childPipelineRunName, err)","\t\t}","\t}","\tif childPipelineRun != nil {","\t\tt.ChildPipelineRuns = append(t.ChildPipelineRuns, childPipelineRun)","\t}","","\trp := ResolvedPipeline{}","\tswitch {","\tcase pipelineTask.PipelineSpec != nil:","\t\trp.PipelineSpec = pipelineTask.PipelineSpec","\tcase pipelineTask.PipelineRef != nil:","\t\treturn fmt.Errorf(\"PipelineRef for PipelineTask %q is not yet implemented\", pipelineTask.Name)","\tdefault:","\t\treturn fmt.Errorf(\"PipelineSpec in PipelineTask %q missing\", pipelineTask.Name)","\t}","","\tt.ResolvedPipeline = rp","\treturn nil","}","","// setTaskRunsAndResolvedTask fetches the named TaskRun using the input function getTaskRun,","// and the resolved Task spec of the Pipeline Task using the input function getTask.","// It updates the ResolvedPipelineTask with the ResolvedTask and a pointer to the fetched TaskRun.","func (t *ResolvedPipelineTask) setTaskRunsAndResolvedTask(","\tctx context.Context,","\ttaskRunName string,","\tgetTask resources.GetTask,","\tgetTaskRun resources.GetTaskRun,","\tpipelineTask v1.PipelineTask,",") error {","\ttaskRun, err := getTaskRun(taskRunName)","\tif err != nil {","\t\tif !kerrors.IsNotFound(err) {","\t\t\treturn fmt.Errorf(\"error retrieving TaskRun %s: %w\", taskRunName, err)","\t\t}","\t}","\tif taskRun != nil {","\t\tt.TaskRuns = append(t.TaskRuns, taskRun)","\t}","","\trt, err := resolveTask(ctx, taskRun, getTask, pipelineTask)","\tif err != nil {","\t\treturn err","\t}","\tt.ResolvedTask = rt","\treturn nil","}","","// resolveTask fetches the Task spec for the PipelineTask and sets its default values.","// It returns a ResolvedTask with the defaulted spec, name, and kind (namespaced Task or Cluster Task) of the Task.","// Returns an error if the Task could not be found because resolution was in progress or any other reason.","func resolveTask(","\tctx context.Context,","\ttaskRun *v1.TaskRun,","\tgetTask resources.GetTask,","\tpipelineTask v1.PipelineTask,",") (*resources.ResolvedTask, error) {","\trt := \u0026resources.ResolvedTask{}","\tswitch {","\tcase pipelineTask.TaskRef != nil:","\t\t// If the TaskRun has already a stored TaskSpec in its status, use it as source of truth","\t\tif taskRun != nil \u0026\u0026 taskRun.Status.TaskSpec != nil {","\t\t\trt.TaskSpec = taskRun.Status.TaskSpec","\t\t\trt.TaskName = pipelineTask.TaskRef.Name","\t\t} else {","\t\t\t// Following minimum status principle (TEP-0100), no need to propagate the RefSource about PipelineTask up to PipelineRun status.","\t\t\t// Instead, the child TaskRun's status will be the place recording the RefSource of individual task.","\t\t\tt, _, vr, err := getTask(ctx, pipelineTask.TaskRef.Name)","\t\t\tswitch {","\t\t\tcase errors.Is(err, remote.ErrRequestInProgress) || (err != nil \u0026\u0026 resolutioncommon.IsErrTransient(err)):","\t\t\t\treturn rt, err","\t\t\tcase err != nil:","\t\t\t\t// some of the resolvers obtain the name from the parameters instead of from the TaskRef.Name field,","\t\t\t\t// so we account for both locations when constructing the error","\t\t\t\tname := pipelineTask.TaskRef.Name","\t\t\t\tif len(strings.TrimSpace(name)) == 0 {","\t\t\t\t\tname = resource.GenerateErrorLogString(string(pipelineTask.TaskRef.Resolver), pipelineTask.TaskRef.Params)","\t\t\t\t}","\t\t\t\treturn rt, \u0026TaskNotFoundError{","\t\t\t\t\tName: name,","\t\t\t\t\tErr:  err,","\t\t\t\t}","\t\t\tdefault:","\t\t\t\tspec := t.Spec","\t\t\t\trt.TaskSpec = \u0026spec","\t\t\t\trt.TaskName = t.Name","\t\t\t\trt.VerificationResult = vr","\t\t\t}","\t\t}","\t\trt.Kind = pipelineTask.TaskRef.Kind","\tcase pipelineTask.TaskSpec != nil:","\t\trt.TaskSpec = \u0026pipelineTask.TaskSpec.TaskSpec","\tdefault:","\t\t// If the alpha feature is enabled, and the user has configured pipelineSpec or pipelineRef, it will enter here.","\t\t// Currently, the controller is not yet adapted, and to avoid a panic, an error message is provided here.","\t\t// TODO: Adjust the logic here once the feature is supported in the future.","\t\treturn nil, fmt.Errorf(\"currently, Task %q does not support PipelineRef, please use PipelineSpec, TaskRef or TaskSpec instead\", pipelineTask.Name)","\t}","\trt.TaskSpec.SetDefaults(ctx)","\treturn rt, nil","}","","// GetTaskRunName should return a unique name for a `TaskRun` if one has not already been defined, and the existing one otherwise.","func GetTaskRunName(childRefs []v1.ChildStatusReference, ptName, prName string) string {","\tfor _, cr := range childRefs {","\t\tif cr.Kind == pipeline.TaskRunControllerName \u0026\u0026 cr.PipelineTaskName == ptName {","\t\t\treturn cr.Name","\t\t}","\t}","\treturn kmeta.ChildName(prName, \"-\"+ptName)","}","","// GetNamesOfTaskRuns should return unique names for `TaskRuns` if one has not already been defined, and the existing one otherwise.","func GetNamesOfTaskRuns(childRefs []v1.ChildStatusReference, ptName, prName string, numberOfTaskRuns int) []string {","\tif taskRunNames := getTaskRunNamesFromChildRefs(childRefs, ptName); taskRunNames != nil {","\t\treturn taskRunNames","\t}","\treturn getNewRunNames(ptName, prName, numberOfTaskRuns)","}","","// GetNamesOfChildPipelineRuns should return unique names for child PipelineRuns if one has not already been","// defined, and the existing one otherwise.","func GetNamesOfChildPipelineRuns(childRefs []v1.ChildStatusReference, ptName, prName string, numberOfPipelineRuns int) []string {","\tif pipelineRunNames := getChildPipelineRunNamesFromChildRefs(childRefs, ptName); pipelineRunNames != nil {","\t\treturn pipelineRunNames","\t}","\treturn getNewRunNames(ptName, prName, numberOfPipelineRuns)","}","","// getTaskRunNamesFromChildRefs returns the names of TaskRuns defined in childRefs that are associated with the named Pipeline Task.","func getTaskRunNamesFromChildRefs(childRefs []v1.ChildStatusReference, ptName string) []string {","\tvar taskRunNames []string","\tfor _, cr := range childRefs {","\t\tif cr.Kind == pipeline.TaskRunControllerName \u0026\u0026 cr.PipelineTaskName == ptName {","\t\t\ttaskRunNames = append(taskRunNames, cr.Name)","\t\t}","\t}","\treturn taskRunNames","}","","func getNewRunNames(ptName, prName string, numberOfRuns int) []string {","\tvar runNames []string","\t// If it is a singular PipelineRun/TaskRun/CustomRun, we only append the ptName","\tif numberOfRuns == 1 {","\t\trunName := kmeta.ChildName(prName, \"-\"+ptName)","\t\treturn append(runNames, runName)","\t}","","\t// For a matrix we append i to the end of the fanned out PipelineRun/TaskRun/CustomRun \"matrixed-pr-taskrun-0\"","\tfor i := range numberOfRuns {","\t\trunName := kmeta.ChildName(prName, fmt.Sprintf(\"-%s-%d\", ptName, i))","\t\t// check if the PipelineRun/TaskRun/CustomRun name ends with a matrix instance count","\t\tif !strings.HasSuffix(runName, fmt.Sprintf(\"-%d\", i)) {","\t\t\trunName = kmeta.ChildName(prName, \"-\"+ptName)","\t\t\t// kmeta.ChildName limits the size of a name to max of 63 characters based on k8s guidelines","\t\t\t// truncate the name such that \"-\u003cmatrix-id\u003e\" can be appended to the PipelineRun/TaskRun/CustomRun name","\t\t\tlongest := 63 - len(fmt.Sprintf(\"-%d\", numberOfRuns))","\t\t\trunName = runName[0:longest]","\t\t\trunName = fmt.Sprintf(\"%s-%d\", runName, i)","\t\t}","\t\trunNames = append(runNames, runName)","\t}","","\treturn runNames","}","","// getCustomRunName should return a unique name for a `Run` if one has not already","// been defined, and the existing one otherwise.","func getCustomRunName(childRefs []v1.ChildStatusReference, ptName, prName string) string {","\tfor _, cr := range childRefs {","\t\tif cr.PipelineTaskName == ptName {","\t\t\tif cr.Kind == pipeline.CustomRunControllerName {","\t\t\t\treturn cr.Name","\t\t\t}","\t\t}","\t}","","\treturn kmeta.ChildName(prName, \"-\"+ptName)","}","","// getNamesOfCustomRuns should return a unique names for `CustomRuns` if they have not already been defined,","// and the existing ones otherwise.","func getNamesOfCustomRuns(childRefs []v1.ChildStatusReference, ptName, prName string, numberOfRuns int) []string {","\tif customRunNames := getRunNamesFromChildRefs(childRefs, ptName); customRunNames != nil {","\t\treturn customRunNames","\t}","\treturn getNewRunNames(ptName, prName, numberOfRuns)","}","","// getRunNamesFromChildRefs returns the names of CustomRuns defined in childRefs that are associated with the named Pipeline Task.","func getRunNamesFromChildRefs(childRefs []v1.ChildStatusReference, ptName string) []string {","\tvar runNames []string","\tfor _, cr := range childRefs {","\t\tif cr.PipelineTaskName == ptName {","\t\t\tif cr.Kind == pipeline.CustomRunControllerName {","\t\t\t\trunNames = append(runNames, cr.Name)","\t\t\t}","\t\t}","\t}","\treturn runNames","}","","// getChildPipelineRunNamesFromChildRefs returns the names of child PipelineRuns defined in childRefs that are","// associated with the named Pipeline Task.","func getChildPipelineRunNamesFromChildRefs(childRefs []v1.ChildStatusReference, ptName string) []string {","\tvar childPipelineRunNames []string","\tfor _, cr := range childRefs {","\t\tif cr.PipelineTaskName == ptName {","\t\t\tif cr.Kind == pipeline.PipelineRunControllerName {","\t\t\t\tchildPipelineRunNames = append(childPipelineRunNames, cr.Name)","\t\t\t}","\t\t}","\t}","\treturn childPipelineRunNames","}","","func (t *ResolvedPipelineTask) hasResultReferences() bool {","\tvar matrixParams v1.Params","\tif t.PipelineTask.IsMatrixed() {","\t\tmatrixParams = t.PipelineTask.Params","\t}","\tfor _, param := range append(t.PipelineTask.Params, matrixParams...) {","\t\tif ps, ok := param.GetVarSubstitutionExpressions(); ok {","\t\t\tif v1.LooksLikeContainsResultRefs(ps) {","\t\t\t\treturn true","\t\t\t}","\t\t}","\t}","\tfor _, we := range t.PipelineTask.When {","\t\tif ps, ok := we.GetVarSubstitutionExpressions(); ok {","\t\t\tif v1.LooksLikeContainsResultRefs(ps) {","\t\t\t\treturn true","\t\t\t}","\t\t}","\t}","\treturn false","}","","func isCustomRunCancelledByPipelineRunTimeout(cr *v1beta1.CustomRun) bool {","\treturn cr.Spec.StatusMessage == v1beta1.CustomRunCancelledByPipelineTimeoutMsg","}","","// CheckMissingResultReferences returns an error if it is missing any result references.","// Missing result references can occur if task fails to produce a result but has","// OnError: continue (ie TestMissingResultWhenStepErrorIsIgnored)","func CheckMissingResultReferences(pipelineRunState PipelineRunState, target *ResolvedPipelineTask) error {","\tfor _, resultRef := range v1.PipelineTaskResultRefs(target.PipelineTask) {","\t\treferencedPipelineTask, ok := pipelineRunState.ToMap()[resultRef.PipelineTask]","\t\tif !ok {","\t\t\treturn fmt.Errorf(\"Result reference error: Could not find ref \\\"%s\\\" in internal pipelineRunState\", resultRef.PipelineTask)","\t\t}","\t\tif referencedPipelineTask.IsCustomTask() {","\t\t\tif len(referencedPipelineTask.CustomRuns) == 0 {","\t\t\t\treturn fmt.Errorf(\"Result reference error: Internal result ref \\\"%s\\\" has zero-length CustomRuns\", resultRef.PipelineTask)","\t\t\t}","\t\t\tcustomRun := referencedPipelineTask.CustomRuns[0]","\t\t\t_, err := findRunResultForParam(customRun, resultRef)","\t\t\tif err != nil {","\t\t\t\treturn err","\t\t\t}","\t\t} else {","\t\t\tif len(referencedPipelineTask.TaskRuns) == 0 {","\t\t\t\treturn fmt.Errorf(\"Result reference error: Internal result ref \\\"%s\\\" has zero-length TaskRuns\", resultRef.PipelineTask)","\t\t\t}","\t\t\ttaskRun := referencedPipelineTask.TaskRuns[0]","\t\t\t_, err := findTaskResultForParam(taskRun, resultRef)","\t\t\tif err != nil {","\t\t\t\treturn err","\t\t\t}","\t\t}","\t}","\treturn nil","}","","// createResultsCacheMatrixedTaskRuns creates a cache of results that have been fanned out from a","// referenced matrixed PipelineTask so that you can easily access these results in subsequent Pipeline Tasks","func createResultsCacheMatrixedTaskRuns(rpt *ResolvedPipelineTask) (resultsCache map[string][]string) {","\tif len(rpt.ResultsCache) == 0 {","\t\tresultsCache = make(map[string][]string)","\t}","\t// Sort the taskRuns by name to ensure the order is deterministic","\tsort.Slice(rpt.TaskRuns, func(i, j int) bool {","\t\treturn rpt.TaskRuns[i].Name \u003c rpt.TaskRuns[j].Name","\t})","\tfor _, taskRun := range rpt.TaskRuns {","\t\tresults := taskRun.Status.Results","\t\tfor _, result := range results {","\t\t\tresultsCache[result.Name] = append(resultsCache[result.Name], result.Value.StringVal)","\t\t}","\t}","\treturn resultsCache","}","","// ValidateParamEnumSubset finds the referenced pipeline-level params in the resolved pipelineTask.","// It then validates if the referenced pipeline-level param enums are subsets of the resolved pipelineTask-level param enums","func ValidateParamEnumSubset(pipelineTaskParams []v1.Param, pipelineParamSpecs []v1.ParamSpec, rt *resources.ResolvedTask) error {","\t// When the matrix Task has no TaskRun, the rt will be nil, we should skip the validation.","\tif rt == nil {","\t\treturn nil","\t}","\tfor _, p := range pipelineTaskParams {","\t\t// calculate referenced param enums","\t\tres, present, errString := substitution.ExtractVariablesFromString(p.Value.StringVal, \"params\")","\t\tif errString != \"\" {","\t\t\treturn fmt.Errorf(\"unexpected error in ExtractVariablesFromString: %s\", errString)","\t\t}","","\t\t// if multiple params are extracted, that means the task-level param is a compounded value, skip subset validation","\t\tif !present || len(res) \u003e 1 {","\t\t\tcontinue","\t\t}","","\t\t// resolve pipeline-level and pipelineTask-level enums","\t\tparamName := substitution.TrimArrayIndex(res[0])","\t\tpipelineParam := getParamFromName(paramName, pipelineParamSpecs)","\t\tresolvedTaskParam := getParamFromName(p.Name, rt.TaskSpec.Params)","","\t\t// param enum is only supported for string param type,","\t\t// we only validate the enum subset requirement for string typed param.","\t\t// If there is no task-level enum (allowing any value), any pipeline-level enum is allowed","\t\tif pipelineParam.Type != v1.ParamTypeString || len(resolvedTaskParam.Enum) == 0 {","\t\t\treturn nil","\t\t}","","\t\t// if pipelin-level enum is empty (allowing any value) but task-level enum is not, it is not a \"subset\"","\t\tif len(pipelineParam.Enum) == 0 \u0026\u0026 len(resolvedTaskParam.Enum) \u003e 0 {","\t\t\treturn fmt.Errorf(\"pipeline param \\\"%s\\\" has no enum, but referenced in \\\"%s\\\" task has enums: %v\", pipelineParam.Name, rt.TaskName, resolvedTaskParam.Enum)","\t\t}","","\t\t// validate if pipeline-level enum is a subset of pipelineTask-level enum","\t\tif isValid := isSubset(pipelineParam.Enum, resolvedTaskParam.Enum); !isValid {","\t\t\treturn fmt.Errorf(\"pipeline param \\\"%s\\\" enum: %v is not a subset of the referenced in \\\"%s\\\" task param enum: %v\", pipelineParam.Name, pipelineParam.Enum, rt.TaskName, resolvedTaskParam.Enum)","\t\t}","\t}","","\treturn nil","}","","func isSubset(pipelineEnum, taskEnum []string) bool {","\tpipelineEnumMap := make(map[string]bool)","\tTaskEnumMap := make(map[string]bool)","\tfor _, e := range pipelineEnum {","\t\tpipelineEnumMap[e] = true","\t}","\tfor _, e := range taskEnum {","\t\tTaskEnumMap[e] = true","\t}","","\tfor e := range pipelineEnumMap {","\t\tif !TaskEnumMap[e] {","\t\t\treturn false","\t\t}","\t}","","\treturn true","}","","func getParamFromName(name string, pss v1.ParamSpecs) v1.ParamSpec {","\tfor _, ps := range pss {","\t\tif ps.Name == name {","\t\t\treturn ps","\t\t}","\t}","\treturn v1.ParamSpec{}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,0,2,2,1,1,0,2,2,1,1,0,2,2,2,2,2,2,0,0,0,2,0,0,0,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,0,0,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,0,0,2,2,2,2,2,2,2,2,0,2,2,2,0,0,2,2,2,2,2,2,2,0,2,2,2,0,2,0,0,0,0,2,2,2,2,2,0,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,1,1,1,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,0,2,2,2,0,2,0,0,0,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,0,2,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,0,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,2,0,2,0,0,0,0,2,2,2,2,2,2,0,0,2,0,0,0,0,2,2,2,2,2,2,0,0,2,0,0,0,0,2,2,2,2,2,2,0,0,2,0,0,0,2,2,2,2,2,2,0,0,0,2,0,0,0,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,0,0,2,2,2,2,0,0,0,0,0,0,2,2,2,2,2,0,2,2,2,0,2,2,2,0,2,0,0,0,2,2,2,2,2,0,2,2,2,0,2,2,2,2,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,0,2,2,2,2,2,1,1,2,2,2,0,0,2,2,2,2,2,2,0,0,0,2,0,0,0,0,0,0,0,2,2,2,2,1,1,0,2,2,2,0,2,2,2,2,1,1,1,1,0,0,2,2,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,1,1,0,2,2,2,0,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,2,2,0,0,0,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,2,2,2,2,2,2,0,0,0,2,0,0,0,0,2,2,1,1,2,0,0,0,2,2,2,2,2,1,1,0,0,2,0,0,0,0,2,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,0,2,0,0,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,2,2,2,2,0,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,0,2,0,0,2,2,2,2,2,0,1,0]},{"id":194,"path":"pkg/reconciler/pipelinerun/resources/pipelinerunstate.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resources","","import (","\t\"context\"","\t\"fmt\"","\t\"strings\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/pipeline/dag\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\t\"go.uber.org/zap\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"k8s.io/utils/clock\"","\t\"knative.dev/pkg/apis\"",")","","const (","\t// PipelineTaskStateNone indicates that the execution status of a pipelineTask is unknown","\tPipelineTaskStateNone = \"None\"","\t// PipelineTaskStatusPrefix is a prefix of the param representing execution state of pipelineTask","\tPipelineTaskStatusPrefix = \"tasks.\"","\t// PipelineTaskStatusSuffix is a suffix of the param representing execution state of pipelineTask","\tPipelineTaskStatusSuffix = \".status\"","\tPipelineTaskReasonSuffix = \".reason\"",")","","// PipelineRunState is a slice of ResolvedPipelineRunTasks the represents the current execution","// state of the PipelineRun.","type PipelineRunState []*ResolvedPipelineTask","","// PipelineRunFacts holds the state of all the components that make up the Pipeline graph that are used to track the","// PipelineRun state without passing all these components separately. It helps simplify our implementation for getting","// and scheduling the next tasks. It is a collection of list of ResolvedPipelineTask, graph of DAG tasks, graph of","// finally tasks, cache of skipped tasks.","type PipelineRunFacts struct {","\tState           PipelineRunState","\tSpecStatus      v1.PipelineRunSpecStatus","\tTasksGraph      *dag.Graph","\tFinalTasksGraph *dag.Graph","\tTimeoutsState   PipelineRunTimeoutsState","","\t// SkipCache is a hash of PipelineTask names that stores whether a task will be","\t// executed or not, because it's either not reachable via the DAG due to the pipeline","\t// state, or because it was skipped due to when expressions.","\t// We cache this data along the state, because it's expensive to compute, it requires","\t// traversing potentially the whole graph; this way it can built incrementally, when","\t// needed, via the `Skip` method in pipelinerunresolution.go","\t// The skip data is sensitive to changes in the state. The ResetSkippedCache method","\t// can be used to clean the cache and force re-computation when needed.","\tSkipCache map[string]TaskSkipStatus","","\t// ValidationFailedTask are the tasks for which taskrun is not created as they","\t// never got added to the execution i.e. they failed in the validation step. One of","\t// the case of failing at the validation is during CheckMissingResultReferences method","\t// Tasks in ValidationFailedTask is added in method runNextSchedulableTask","\tValidationFailedTask []*ResolvedPipelineTask","}","","// PipelineRunTimeoutsState records information about start times and timeouts for the PipelineRun, so that the PipelineRunFacts","// can reference those values in its functions.","type PipelineRunTimeoutsState struct {","\tStartTime        *time.Time","\tFinallyStartTime *time.Time","\tPipelineTimeout  *time.Duration","\tTasksTimeout     *time.Duration","\tFinallyTimeout   *time.Duration","\tClock            clock.PassiveClock","}","","// pipelineRunStatusCount holds the count of successful, failed, cancelled, skipped, and incomplete tasks","type pipelineRunStatusCount struct {","\t// skipped tasks count","\tSkipped int","\t// successful tasks count","\tSucceeded int","\t// failed tasks count","\tFailed int","\t// failed but ignored tasks count","\tIgnoredFailed int","\t// cancelled tasks count","\tCancelled int","\t// number of tasks which are still pending, have not executed","\tIncomplete int","\t// count of tasks skipped due to the relevant timeout having elapsed before the task is launched","\tSkippedDueToTimeout int","\t// count of validation failed task and taskrun not created","\tValidationFailed int","}","","// ResetSkippedCache resets the skipped cache in the facts map","func (facts *PipelineRunFacts) ResetSkippedCache() {","\tfacts.SkipCache = make(map[string]TaskSkipStatus)","}","","// ToMap returns a map that maps pipeline task name to the resolved pipeline run task","func (state PipelineRunState) ToMap() map[string]*ResolvedPipelineTask {","\tm := make(map[string]*ResolvedPipelineTask)","\tfor _, rpt := range state {","\t\tm[rpt.PipelineTask.Name] = rpt","\t}","\treturn m","}","","// IsBeforeFirstTaskRun returns true if the PipelineRun has not yet started its first child PipelineRun/TaskRun/CustomRun","func (state PipelineRunState) IsBeforeFirstTaskRun() bool {","\tfor _, t := range state {","\t\tif len(t.ChildPipelineRuns) \u003e 0 || len(t.CustomRuns) \u003e 0 || len(t.TaskRuns) \u003e 0 {","\t\t\treturn false","\t\t}","\t}","\treturn true","}","","// AdjustStartTime adjusts potential drift in the PipelineRun's start time.","//","// The StartTime will only adjust earlier, so that the PipelineRun's StartTime","// is no later than any of its constituent TaskRuns.","//","// This drift could be due to us either failing to record the Run's start time","// previously, or our own failure to observe a prior update before reconciling","// the resource again.","func (state PipelineRunState) AdjustStartTime(unadjustedStartTime *metav1.Time) *metav1.Time {","\tadjustedStartTime := unadjustedStartTime","\tfor _, rpt := range state {","\t\tfor _, childPipelineRun := range rpt.ChildPipelineRuns {","\t\t\tif childPipelineRun.CreationTimestamp.Time.Before(adjustedStartTime.Time) {","\t\t\t\tadjustedStartTime = \u0026childPipelineRun.CreationTimestamp","\t\t\t}","\t\t}","","\t\tfor _, customRun := range rpt.CustomRuns {","\t\t\tcreationTime := customRun.GetObjectMeta().GetCreationTimestamp()","\t\t\tif creationTime.Time.Before(adjustedStartTime.Time) {","\t\t\t\tadjustedStartTime = \u0026creationTime","\t\t\t}","\t\t}","","\t\tfor _, taskRun := range rpt.TaskRuns {","\t\t\tif taskRun.CreationTimestamp.Time.Before(adjustedStartTime.Time) {","\t\t\t\tadjustedStartTime = \u0026taskRun.CreationTimestamp","\t\t\t}","\t\t}","\t}","","\treturn adjustedStartTime.DeepCopy()","}","","// GetTaskRunsResults returns a map of all successfully completed TaskRuns in the state, with the pipeline task name as","// the key and the results from the corresponding TaskRun as the value. It only includes tasks which have completed successfully.","func (state PipelineRunState) GetTaskRunsResults() map[string][]v1.TaskRunResult {","\tresults := make(map[string][]v1.TaskRunResult)","\tfor _, rpt := range state {","\t\tif rpt.IsChildPipeline() {","\t\t\tcontinue","\t\t}","\t\tif rpt.IsCustomTask() {","\t\t\tcontinue","\t\t}","\t\tif !rpt.isSuccessful() {","\t\t\tcontinue","\t\t}","\t\tif rpt.PipelineTask.IsMatrixed() {","\t\t\ttaskRunResults := ConvertResultsMapToTaskRunResults(rpt.ResultsCache)","\t\t\tif len(taskRunResults) \u003e 0 {","\t\t\t\tresults[rpt.PipelineTask.Name] = taskRunResults","\t\t\t}","\t\t} else {","\t\t\tresults[rpt.PipelineTask.Name] = rpt.TaskRuns[0].Status.Results","\t\t}","\t}","\treturn results","}","","// GetTaskRunsArtifacts returns a map of all successfully completed TaskRuns in the state, with the pipeline task name as","// the key and the artifacts from the corresponding TaskRun as the value. It only includes tasks which have completed successfully.","func (state PipelineRunState) GetTaskRunsArtifacts() map[string]*v1.Artifacts {","\tresults := make(map[string]*v1.Artifacts)","\tfor _, rpt := range state {","\t\tif rpt.IsChildPipeline() {","\t\t\tcontinue","\t\t}","\t\tif rpt.IsCustomTask() {","\t\t\tcontinue","\t\t}","\t\tif !rpt.isSuccessful() {","\t\t\tcontinue","\t\t}","\t\tif rpt.PipelineTask.IsMatrixed() {","\t\t\tvar ars v1.Artifacts","\t\t\tfor _, tr := range rpt.TaskRuns {","\t\t\t\tars.Merge(tr.Status.Artifacts)","\t\t\t}","\t\t\tresults[rpt.PipelineTask.Name] = \u0026ars","\t\t} else {","\t\t\tresults[rpt.PipelineTask.Name] = rpt.TaskRuns[0].Status.Artifacts","\t\t}","\t}","\treturn results","}","","// ConvertResultsMapToTaskRunResults converts the map of results from Matrixed PipelineTasks to a list","// of TaskRunResults to standard the format","func ConvertResultsMapToTaskRunResults(resultsMap map[string][]string) []v1.TaskRunResult {","\tvar taskRunResults []v1.TaskRunResult","\tfor result, val := range resultsMap {","\t\ttaskRunResult := v1.TaskRunResult{","\t\t\tName: result,","\t\t\tType: v1.ResultsTypeArray,","\t\t\tValue: v1.ParamValue{","\t\t\t\tType:     v1.ParamTypeArray,","\t\t\t\tArrayVal: val,","\t\t\t},","\t\t}","\t\ttaskRunResults = append(taskRunResults, taskRunResult)","\t}","\treturn taskRunResults","}","","// GetRunsResults returns a map of all successfully completed Runs in the state, with the pipeline task name as the key","// and the results from the corresponding TaskRun as the value. It only includes runs which have completed successfully.","func (state PipelineRunState) GetRunsResults() map[string][]v1beta1.CustomRunResult {","\tresults := make(map[string][]v1beta1.CustomRunResult)","\tfor _, rpt := range state {","\t\tif !rpt.IsCustomTask() {","\t\t\tcontinue","\t\t}","\t\tif !rpt.isSuccessful() {","\t\t\tcontinue","\t\t}","\t\t// Currently a Matrix cannot produce results so this is for a singular CustomRun","\t\tif len(rpt.CustomRuns) == 1 {","\t\t\tcr := rpt.CustomRuns[0]","\t\t\tresults[rpt.PipelineTask.Name] = cr.Status.Results","\t\t}","\t}","","\treturn results","}","","// GetChildReferences returns a slice of references, including version, kind, name, and pipeline task name, for all","// child PipelineRuns, TaskRuns and Runs in the state.","func (facts *PipelineRunFacts) GetChildReferences() []v1.ChildStatusReference {","\tvar childRefs []v1.ChildStatusReference","","\tfor _, rpt := range facts.State {","\t\t// try to replace the parameters of the reference result of when expression in the TaskRun that has ended","\t\tif rpt.isDone(facts) {","\t\t\tresolvedResultRefs, _, err := ResolveResultRefs(facts.State, PipelineRunState{rpt})","\t\t\tif err == nil {","\t\t\t\tApplyTaskResults(facts.State, resolvedResultRefs)","\t\t\t}","\t\t}","","\t\tswitch {","\t\tcase len(rpt.ChildPipelineRuns) != 0:","\t\t\tfor _, childPipelineRun := range rpt.ChildPipelineRuns {","\t\t\t\tif childPipelineRun != nil {","\t\t\t\t\tchildRefs = append(childRefs, rpt.getChildRefForChildPipelineRun(childPipelineRun))","\t\t\t\t}","\t\t\t}","\t\tcase len(rpt.TaskRuns) != 0:","\t\t\tfor _, taskRun := range rpt.TaskRuns {","\t\t\t\tif taskRun != nil {","\t\t\t\t\tchildRefs = append(childRefs, rpt.getChildRefForTaskRun(taskRun))","\t\t\t\t}","\t\t\t}","\t\tcase len(rpt.CustomRuns) != 0:","\t\t\tfor _, run := range rpt.CustomRuns {","\t\t\t\tchildRefs = append(childRefs, rpt.getChildRefForRun(run))","\t\t\t}","\t\t}","\t}","\treturn childRefs","}","","func (t *ResolvedPipelineTask) getDisplayName(pipelineRun *v1.PipelineRun, customRun *v1beta1.CustomRun, taskRun *v1.TaskRun, c v1.ChildStatusReference) v1.ChildStatusReference {","\treplacements := make(map[string]string)","\tif pipelineRun != nil {","\t\tfor _, p := range pipelineRun.Spec.Params {","\t\t\tif p.Value.Type == v1.ParamTypeString {","\t\t\t\treplacements[fmt.Sprintf(\"%s.%s\", v1.ParamsPrefix, p.Name)] = p.Value.StringVal","\t\t\t}","\t\t}","\t}","","\tif taskRun != nil {","\t\tfor _, p := range taskRun.Spec.Params {","\t\t\tif p.Value.Type == v1.ParamTypeString {","\t\t\t\treplacements[fmt.Sprintf(\"%s.%s\", v1.ParamsPrefix, p.Name)] = p.Value.StringVal","\t\t\t}","\t\t}","\t}","","\tif customRun != nil {","\t\tfor _, p := range customRun.Spec.Params {","\t\t\tif p.Value.Type == v1beta1.ParamTypeString {","\t\t\t\treplacements[fmt.Sprintf(\"%s.%s\", v1.ParamsPrefix, p.Name)] = p.Value.StringVal","\t\t\t}","\t\t}","\t}","","\tif t.PipelineTask.DisplayName != \"\" {","\t\tc.DisplayName = substitution.ApplyReplacements(t.PipelineTask.DisplayName, replacements)","\t}","\tif t.PipelineTask.Matrix != nil {","\t\tvar dn string","\t\tfor _, i := range t.PipelineTask.Matrix.Include {","\t\t\tif i.Name == \"\" {","\t\t\t\tcontinue","\t\t\t}","\t\t\tmatch := true","\t\t\tfor _, ip := range i.Params {","\t\t\t\tv, ok := replacements[fmt.Sprintf(\"%s.%s\", v1.ParamsPrefix, ip.Name)]","\t\t\t\tif !ok || (ip.Value.Type == v1.ParamTypeString \u0026\u0026 ip.Value.StringVal != v) {","\t\t\t\t\tmatch = false","\t\t\t\t\tbreak","\t\t\t\t}","\t\t\t}","\t\t\tif match {","\t\t\t\tdn = fmt.Sprintf(\"%s %s\", dn, substitution.ApplyReplacements(i.Name, replacements))","\t\t\t}","\t\t}","\t\tif dn != \"\" {","\t\t\tc.DisplayName = strings.TrimSpace(dn)","\t\t}","\t}","\treturn c","}","","func (t *ResolvedPipelineTask) getChildRefForChildPipelineRun(pipelineRun *v1.PipelineRun) v1.ChildStatusReference {","\tc := v1.ChildStatusReference{","\t\tTypeMeta: runtime.TypeMeta{","\t\t\tAPIVersion: v1.SchemeGroupVersion.String(),","\t\t\tKind:       pipeline.PipelineRunControllerName,","\t\t},","\t\tName:             pipelineRun.Name,","\t\tPipelineTaskName: t.PipelineTask.Name,","\t\tWhenExpressions:  t.PipelineTask.When,","\t}","\treturn t.getDisplayName(pipelineRun, nil, nil, c)","}","","func (t *ResolvedPipelineTask) getChildRefForRun(customRun *v1beta1.CustomRun) v1.ChildStatusReference {","\tc := v1.ChildStatusReference{","\t\tTypeMeta: runtime.TypeMeta{","\t\t\tAPIVersion: v1beta1.SchemeGroupVersion.String(),","\t\t\tKind:       pipeline.CustomRunControllerName,","\t\t},","\t\tName:             customRun.GetObjectMeta().GetName(),","\t\tPipelineTaskName: t.PipelineTask.Name,","\t\tWhenExpressions:  t.PipelineTask.When,","\t}","\treturn t.getDisplayName(nil, customRun, nil, c)","}","","func (t *ResolvedPipelineTask) getChildRefForTaskRun(taskRun *v1.TaskRun) v1.ChildStatusReference {","\tc := v1.ChildStatusReference{","\t\tTypeMeta: runtime.TypeMeta{","\t\t\tAPIVersion: v1.SchemeGroupVersion.String(),","\t\t\tKind:       pipeline.TaskRunControllerName,","\t\t},","\t\tName:             taskRun.Name,","\t\tPipelineTaskName: t.PipelineTask.Name,","\t\tWhenExpressions:  t.PipelineTask.When,","\t}","\treturn t.getDisplayName(nil, nil, taskRun, c)","}","","// getNextTasks returns a list of pipeline tasks which should be executed next i.e.","// a list of tasks from candidateTasks which aren't yet indicated in state to be running and","// a list of cancelled/failed tasks from candidateTasks which haven't exhausted their retries","func (state PipelineRunState) getNextTasks(candidateTasks sets.String) []*ResolvedPipelineTask {","\ttasks := []*ResolvedPipelineTask{}","\tfor _, t := range state {","\t\tif _, ok := candidateTasks[t.PipelineTask.Name]; ok {","\t\t\tif len(t.TaskRuns) == 0 \u0026\u0026 len(t.CustomRuns) == 0 \u0026\u0026 len(t.ChildPipelineRuns) == 0 {","\t\t\t\ttasks = append(tasks, t)","\t\t\t}","\t\t}","\t}","\treturn tasks","}","","// IsStopping returns true if the PipelineRun won't be scheduling any new Task because","// at least one task already failed (with onError: stopAndFail) or was cancelled in the specified dag","func (facts *PipelineRunFacts) IsStopping() bool {","\tfor _, t := range facts.State {","\t\tif facts.isDAGTask(t.PipelineTask.Name) {","\t\t\tif (t.isFailure() || t.isValidationFailed(facts.ValidationFailedTask)) \u0026\u0026 t.PipelineTask.OnError != v1.PipelineTaskContinue {","\t\t\t\treturn true","\t\t\t}","\t\t}","\t}","\treturn false","}","","// IsRunning returns true if the PipelineRun is still running tasks in the specified dag","func (facts *PipelineRunFacts) IsRunning() bool {","\tfor _, t := range facts.State {","\t\tif facts.isDAGTask(t.PipelineTask.Name) {","\t\t\tif t.IsRunning() {","\t\t\t\treturn true","\t\t\t}","\t\t}","\t}","\treturn false","}","","// IsCancelled returns true if the PipelineRun was cancelled","func (facts *PipelineRunFacts) IsCancelled() bool {","\treturn facts.SpecStatus == v1.PipelineRunSpecStatusCancelled","}","","// IsGracefullyCancelled returns true if the PipelineRun was gracefully cancelled","func (facts *PipelineRunFacts) IsGracefullyCancelled() bool {","\treturn facts.SpecStatus == v1.PipelineRunSpecStatusCancelledRunFinally","}","","// IsGracefullyStopped returns true if the PipelineRun was gracefully stopped","func (facts *PipelineRunFacts) IsGracefullyStopped() bool {","\treturn facts.SpecStatus == v1.PipelineRunSpecStatusStoppedRunFinally","}","","// DAGExecutionQueue returns a list of DAG tasks which needs to be scheduled next","func (facts *PipelineRunFacts) DAGExecutionQueue() (PipelineRunState, error) {","\tvar tasks PipelineRunState","\t// when pipelinerun is cancelled or gracefully cancelled, do not schedule any new tasks,","\t// and only wait for all running tasks to complete (without exhausting retries).","\tif facts.IsCancelled() || facts.IsGracefullyCancelled() {","\t\treturn tasks, nil","\t}","\t// candidateTasks is initialized to DAG root nodes to start pipeline execution","\t// candidateTasks is derived based on successfully finished tasks and/or skipped tasks","\tcandidateTasks, err := dag.GetCandidateTasks(facts.TasksGraph, facts.completedOrSkippedDAGTasks()...)","\tif err != nil {","\t\treturn tasks, err","\t}","\tif !facts.IsStopping() \u0026\u0026 !facts.IsGracefullyStopped() {","\t\ttasks = facts.State.getNextTasks(candidateTasks)","\t}","\treturn tasks, nil","}","","// GetFinalTaskNames returns a list of all final task names","func (facts *PipelineRunFacts) GetFinalTaskNames() sets.String {","\tnames := sets.NewString()","\t// return list of tasks with all final tasks","\tfor _, t := range facts.State {","\t\tif facts.isFinalTask(t.PipelineTask.Name) {","\t\t\tnames.Insert(t.PipelineTask.Name)","\t\t}","\t}","\treturn names","}","","// GetTaskNames returns a list of all non-final task names","func (facts *PipelineRunFacts) GetTaskNames() sets.String {","\tnames := sets.NewString()","\t// return list of tasks with all final tasks","\tfor _, t := range facts.State {","\t\tif !facts.isFinalTask(t.PipelineTask.Name) {","\t\t\tnames.Insert(t.PipelineTask.Name)","\t\t}","\t}","\treturn names","}","","// GetFinalTasks returns a list of final tasks which needs to be executed next","// GetFinalTasks returns final tasks only when all DAG tasks have finished executing or have been skipped","func (facts *PipelineRunFacts) GetFinalTasks() PipelineRunState {","\ttasks := PipelineRunState{}","\tfinalCandidates := sets.NewString()","\t// check either pipeline has finished executing all DAG pipelineTasks,","\t// where \"finished executing\" means succeeded, failed, or skipped.","\tif facts.checkDAGTasksDone() {","\t\t// return list of tasks with all final tasks","\t\tfor _, t := range facts.State {","\t\t\tif facts.isFinalTask(t.PipelineTask.Name) {","\t\t\t\tfinalCandidates.Insert(t.PipelineTask.Name)","\t\t\t}","\t\t}","\t\ttasks = facts.State.getNextTasks(finalCandidates)","\t}","\treturn tasks","}","","// IsFinalTaskStarted returns true if all DAG pipelineTasks is finished and one or more final tasks have been created.","func (facts *PipelineRunFacts) IsFinalTaskStarted() bool {","\t// check either pipeline has finished executing all DAG pipelineTasks,","\t// where \"finished executing\" means succeeded, failed, or skipped.","\tif facts.checkDAGTasksDone() {","\t\t// return list of tasks with all final tasks","\t\tfor _, t := range facts.State {","\t\t\tif facts.isFinalTask(t.PipelineTask.Name) \u0026\u0026 t.isScheduled() {","\t\t\t\treturn true","\t\t\t}","\t\t}","\t}","","\treturn false","}","","// GetPipelineConditionStatus will return the Condition that the PipelineRun prName should be","// updated with, based on the status of the child PipelineRuns/TaskRuns/CustomRuns in state.","func (facts *PipelineRunFacts) GetPipelineConditionStatus(ctx context.Context, pr *v1.PipelineRun, logger *zap.SugaredLogger, c clock.PassiveClock) *apis.Condition {","\t// We have 4 different states here:","\t// 1. Timed out -\u003e Failed","\t// 2. All tasks are done and at least one has failed or has been cancelled -\u003e Failed","\t// 3. All tasks are done or are skipped (i.e. condition check failed).-\u003e Success","\t// 4. A Task or Condition is running right now or there are things left to run -\u003e Running","\tif pr.HasTimedOut(ctx, c) {","\t\treturn \u0026apis.Condition{","\t\t\tType:    apis.ConditionSucceeded,","\t\t\tStatus:  corev1.ConditionFalse,","\t\t\tReason:  v1.PipelineRunReasonTimedOut.String(),","\t\t\tMessage: fmt.Sprintf(\"PipelineRun %q failed to finish within %q\", pr.Name, pr.PipelineTimeout(ctx).String()),","\t\t}","\t}","","\tif pr.HaveTasksTimedOut(ctx, c) {","\t\treturn \u0026apis.Condition{","\t\t\tType:    apis.ConditionSucceeded,","\t\t\tStatus:  corev1.ConditionFalse,","\t\t\tReason:  v1.PipelineRunReasonTimedOut.String(),","\t\t\tMessage: fmt.Sprintf(\"PipelineRun %q failed due to tasks failed to finish within %q\", pr.Name, pr.TasksTimeout().Duration.String()),","\t\t}","\t}","","\t// report the count in PipelineRun Status","\t// get the count of successful tasks, failed tasks, cancelled tasks, skipped task, and incomplete tasks","\ts := facts.getPipelineTasksCount()","\t// completed task is a collection of successful, failed, cancelled tasks","\t// (skipped tasks and validation failed tasks are reported separately)","\tcmTasks := s.Succeeded + s.Failed + s.Cancelled + s.IgnoredFailed","\ttotalFailedTasks := s.Failed + s.IgnoredFailed","","\t// The completion reason is set from the TaskRun completion reason","\t// by default, set it to ReasonRunning","\treason := v1.PipelineRunReasonRunning.String()","","\t// check if the pipeline is finished executing all tasks i.e. no incomplete tasks","\tif s.Incomplete == 0 {","\t\tstatus := corev1.ConditionTrue","\t\treason := v1.PipelineRunReasonSuccessful.String()","\t\tvar message string","\t\tif s.IgnoredFailed \u003e 0 {","\t\t\tmessage = fmt.Sprintf(\"Tasks Completed: %d (Failed: %d (Ignored: %d), Cancelled %d), Skipped: %d\",","\t\t\t\tcmTasks, totalFailedTasks, s.IgnoredFailed, s.Cancelled, s.Skipped)","\t\t} else {","\t\t\tmessage = fmt.Sprintf(\"Tasks Completed: %d (Failed: %d, Cancelled %d), Skipped: %d\",","\t\t\t\tcmTasks, totalFailedTasks, s.Cancelled, s.Skipped)","\t\t}","\t\t// append validation failed count in the message","\t\tif s.ValidationFailed \u003e 0 {","\t\t\tmessage += fmt.Sprintf(\", Failed Validation: %d\", s.ValidationFailed)","\t\t}","\t\t// Set reason to ReasonCompleted - At least one is skipped","\t\tif s.Skipped \u003e 0 {","\t\t\treason = v1.PipelineRunReasonCompleted.String()","\t\t}","","\t\tswitch {","\t\tcase s.ValidationFailed \u003e 0:","\t\t\treason = v1.PipelineRunReasonFailedValidation.String()","\t\t\tstatus = corev1.ConditionFalse","\t\tcase s.Failed \u003e 0 || s.SkippedDueToTimeout \u003e 0:","\t\t\t// Set reason to ReasonFailed - At least one failed","\t\t\treason = v1.PipelineRunReasonFailed.String()","\t\t\tstatus = corev1.ConditionFalse","\t\tcase pr.IsGracefullyCancelled() || pr.IsGracefullyStopped():","\t\t\t// Set reason to ReasonCancelled - Cancellation requested","\t\t\treason = v1.PipelineRunReasonCancelled.String()","\t\t\tstatus = corev1.ConditionFalse","\t\t\tmessage = fmt.Sprintf(\"PipelineRun %q was cancelled\", pr.Name)","\t\tcase s.Cancelled \u003e 0:","\t\t\t// Set reason to ReasonCancelled - At least one is cancelled and no failure yet","\t\t\treason = v1.PipelineRunReasonCancelled.String()","\t\t\tstatus = corev1.ConditionFalse","\t\t}","\t\tlogger.Infof(\"All child PipelineRuns/TaskRuns/CustomRuns have finished for PipelineRun %s so it has finished\", pr.Name)","\t\treturn \u0026apis.Condition{","\t\t\tType:    apis.ConditionSucceeded,","\t\t\tStatus:  status,","\t\t\tReason:  reason,","\t\t\tMessage: message,","\t\t}","\t}","","\t// Hasn't timed out; not all tasks have finished.... Must keep running then....","\tswitch {","\tcase pr.IsGracefullyCancelled():","\t\t// Transition pipeline into running finally state, when graceful cancel is in progress","\t\treason = v1.PipelineRunReasonCancelledRunningFinally.String()","\tcase pr.IsGracefullyStopped():","\t\t// Transition pipeline into running finally state, when graceful stop is in progress","\t\treason = v1.PipelineRunReasonStoppedRunningFinally.String()","\tcase s.Cancelled \u003e 0 || (s.Failed \u003e 0 \u0026\u0026 facts.checkFinalTasksDone()):","\t\t// Transition pipeline into stopping state when one of the tasks(dag/final) cancelled or one of the dag tasks failed","\t\t// for a pipeline with final tasks, single dag task failure does not transition to interim stopping state","\t\t// pipeline stays in running state until all final tasks are done before transitioning to failed state","\t\treason = v1.PipelineRunReasonStopping.String()","\t}","","\t// return the status","\treturn \u0026apis.Condition{","\t\tType:   apis.ConditionSucceeded,","\t\tStatus: corev1.ConditionUnknown,","\t\tReason: reason,","\t\tMessage: fmt.Sprintf(\"Tasks Completed: %d (Failed: %d, Cancelled %d), Incomplete: %d, Skipped: %d\",","\t\t\tcmTasks, s.Failed, s.Cancelled, s.Incomplete, s.Skipped),","\t}","}","","// GetSkippedTasks constructs a list of SkippedTask struct to be included in the PipelineRun Status","func (facts *PipelineRunFacts) GetSkippedTasks() []v1.SkippedTask {","\tvar skipped []v1.SkippedTask","\tfor _, rpt := range facts.State {","\t\tif rpt.Skip(facts).IsSkipped {","\t\t\tskippedTask := v1.SkippedTask{","\t\t\t\tName:            rpt.PipelineTask.Name,","\t\t\t\tReason:          rpt.Skip(facts).SkippingReason,","\t\t\t\tWhenExpressions: rpt.PipelineTask.When,","\t\t\t}","\t\t\tskipped = append(skipped, skippedTask)","\t\t}","\t\tif rpt.IsFinallySkipped(facts).IsSkipped {","\t\t\tskippedTask := v1.SkippedTask{","\t\t\t\tName:   rpt.PipelineTask.Name,","\t\t\t\tReason: rpt.IsFinallySkipped(facts).SkippingReason,","\t\t\t}","\t\t\t// include the when expressions only when the finally task was skipped because","\t\t\t// its when expressions evaluated to false (not because results variables were missing)","\t\t\tif rpt.IsFinallySkipped(facts).SkippingReason == v1.WhenExpressionsSkip {","\t\t\t\tskippedTask.WhenExpressions = rpt.PipelineTask.When","\t\t\t}","\t\t\tskipped = append(skipped, skippedTask)","\t\t}","\t}","\treturn skipped","}","","// GetPipelineTaskStatus returns the status of a PipelineTask depending on its child","// PipelineRun/TaskRun/CustomRun. The checks are implemented such that the finally tasks","// are requesting status of the dag tasks.","func (facts *PipelineRunFacts) GetPipelineTaskStatus() map[string]string {","\t// construct a map of tasks.\u003cpipelineTask\u003e.status and its state","\ttStatus := make(map[string]string)","\tfor _, t := range facts.State {","\t\tif facts.isDAGTask(t.PipelineTask.Name) {","\t\t\tvar s string","\t\t\tswitch {","\t\t\t// execution status is Succeeded when a task has succeeded condition with status set to true","\t\t\tcase t.isSuccessful():","\t\t\t\ts = v1.TaskRunReasonSuccessful.String()","\t\t\t// execution status is Failed when a task has succeeded condition with status set to false","\t\t\tcase t.haveAnyRunsFailed():","\t\t\t\ts = v1.TaskRunReasonFailed.String()","\t\t\tdefault:","\t\t\t\t// None includes skipped as well","\t\t\t\ts = PipelineTaskStateNone","\t\t\t}","\t\t\ttStatus[PipelineTaskStatusPrefix+t.PipelineTask.Name+PipelineTaskStatusSuffix] = s","\t\t\ttStatus[PipelineTaskStatusPrefix+t.PipelineTask.Name+PipelineTaskReasonSuffix] = t.getReason()","\t\t}","\t}","","\t// initialize aggregate status of all dag tasks to None","\taggregateStatus := PipelineTaskStateNone","\tif facts.checkDAGTasksDone() {","\t\t// all dag pipeline tasks are done, change the aggregate status to succeeded","\t\t// will reset it to failed/skipped if needed","\t\taggregateStatus = v1.PipelineRunReasonSuccessful.String()","\t\tfor _, t := range facts.State {","\t\t\tif facts.isDAGTask(t.PipelineTask.Name) {","\t\t\t\t// if any of the dag pipeline tasks failed, change the aggregate status to failed and return","\t\t\t\tif t.IsChildPipeline() \u0026\u0026 t.haveAnyChildPipelineRunsFailed() {","\t\t\t\t\taggregateStatus = v1.PipelineRunReasonFailed.String()","\t\t\t\t\tbreak","\t\t\t\t}","","\t\t\t\tif t.IsCustomTask() \u0026\u0026 t.haveAnyCustomRunsFailed() {","\t\t\t\t\taggregateStatus = v1.PipelineRunReasonFailed.String()","\t\t\t\t\tbreak","\t\t\t\t}","","\t\t\t\t// if it's not a custom task or a child pipeline it's a task so we only","\t\t\t\t// need to check if any TaskRuns failed","\t\t\t\tif t.haveAnyTaskRunsFailed() {","\t\t\t\t\taggregateStatus = v1.PipelineRunReasonFailed.String()","\t\t\t\t\tbreak","\t\t\t\t}","\t\t\t\t// if any of the dag task skipped, change the aggregate status to completed","\t\t\t\t// but continue checking for any other failure","\t\t\t\tif t.Skip(facts).IsSkipped {","\t\t\t\t\taggregateStatus = v1.PipelineRunReasonCompleted.String()","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\ttStatus[v1.PipelineTasksAggregateStatus] = aggregateStatus","\treturn tStatus","}","","// GetPipelineFinalTaskStatus returns the status of a PipelineFinalTask depending on its taskRun","func (facts *PipelineRunFacts) GetPipelineFinalTaskStatus() map[string]string {","\t// construct a map of tasks.\u003cpipelineTask\u003e.status and its state","\ttStatus := make(map[string]string)","\tfor _, t := range facts.State {","\t\tif facts.isFinalTask(t.PipelineTask.Name) {","\t\t\tvar s string","\t\t\tswitch {","\t\t\t// execution status is Succeeded when a task has succeeded condition with status set to true","\t\t\tcase t.isSuccessful():","\t\t\t\ts = v1.TaskRunReasonSuccessful.String()","\t\t\t// execution status is Failed when a task has succeeded condition with status set to false","\t\t\tcase t.haveAnyRunsFailed():","\t\t\t\ts = v1.TaskRunReasonFailed.String()","\t\t\tdefault:","\t\t\t\t// None includes skipped as well","\t\t\t\ts = PipelineTaskStateNone","\t\t\t}","\t\t\ttStatus[PipelineTaskStatusPrefix+t.PipelineTask.Name+PipelineTaskStatusSuffix] = s","\t\t}","\t}","\treturn tStatus","}","","// completedOrSkippedTasks returns a list of the names of all of the PipelineTasks in state","// which have completed or skipped","func (facts *PipelineRunFacts) completedOrSkippedDAGTasks() []string {","\ttasks := []string{}","\tfor _, t := range facts.State {","\t\tif facts.isDAGTask(t.PipelineTask.Name) {","\t\t\tif t.isDone(facts) {","\t\t\t\ttasks = append(tasks, t.PipelineTask.Name)","\t\t\t}","\t\t}","\t}","\treturn tasks","}","","// checkTasksDone returns true if all tasks from the specified graph are finished executing","// a task is considered done if it has failed/succeeded/skipped","func (facts *PipelineRunFacts) checkTasksDone(d *dag.Graph) bool {","\tfor _, t := range facts.State {","\t\tif isTaskInGraph(t.PipelineTask.Name, d) {","\t\t\tif !t.isDone(facts) {","\t\t\t\treturn false","\t\t\t}","\t\t}","\t}","\treturn true","}","","// check if all DAG tasks done executing (succeeded, failed, or skipped)","func (facts *PipelineRunFacts) checkDAGTasksDone() bool {","\treturn facts.checkTasksDone(facts.TasksGraph)","}","","// check if all finally tasks done executing (succeeded or failed)","func (facts *PipelineRunFacts) checkFinalTasksDone() bool {","\treturn facts.checkTasksDone(facts.FinalTasksGraph)","}","","// getPipelineTasksCount returns the count of successful tasks, failed tasks, cancelled tasks, skipped task, and incomplete tasks","func (facts *PipelineRunFacts) getPipelineTasksCount() pipelineRunStatusCount {","\ts := pipelineRunStatusCount{","\t\tSkipped:             0,","\t\tSucceeded:           0,","\t\tFailed:              0,","\t\tCancelled:           0,","\t\tIncomplete:          0,","\t\tSkippedDueToTimeout: 0,","\t\tIgnoredFailed:       0,","\t\tValidationFailed:    0,","\t}","\tfor _, t := range facts.State {","\t\tswitch {","\t\t// increment success counter since the task is successful","\t\tcase t.isSuccessful():","\t\t\ts.Succeeded++","\t\t// increment failure counter since the task is cancelled due to a timeout","\t\tcase t.isCancelledForTimeOut():","\t\t\ts.Failed++","\t\t// increment cancelled counter since the task is cancelled","\t\tcase t.isCancelled():","\t\t\ts.Cancelled++","\t\t// increment failure counter based on Task OnError type since the task has failed","\t\tcase t.isFailure():","\t\t\tif t.PipelineTask.OnError == v1.PipelineTaskContinue {","\t\t\t\ts.IgnoredFailed++","\t\t\t} else {","\t\t\t\ts.Failed++","\t\t\t}","\t\tcase t.isValidationFailed(facts.ValidationFailedTask):","\t\t\ts.ValidationFailed++","\t\t// increment skipped and skipped due to timeout counters since the task was skipped due to the pipeline, tasks, or finally timeout being reached before the task was launched","\t\tcase t.Skip(facts).SkippingReason == v1.PipelineTimedOutSkip ||","\t\t\tt.Skip(facts).SkippingReason == v1.TasksTimedOutSkip ||","\t\t\tt.IsFinallySkipped(facts).SkippingReason == v1.FinallyTimedOutSkip:","\t\t\ts.Skipped++","\t\t\ts.SkippedDueToTimeout++","\t\t// increment skip counter since the task is skipped","\t\tcase t.Skip(facts).IsSkipped:","\t\t\ts.Skipped++","\t\t// checking if any finally tasks were referring to invalid/missing task results","\t\tcase t.IsFinallySkipped(facts).IsSkipped:","\t\t\ts.Skipped++","\t\t// increment incomplete counter since the task is pending and not executed yet","\t\tdefault:","\t\t\ts.Incomplete++","\t\t}","\t}","\treturn s","}","","// check if a specified pipelineTask is defined under tasks(DAG) section","func (facts *PipelineRunFacts) isDAGTask(pipelineTaskName string) bool {","\tif _, ok := facts.TasksGraph.Nodes[pipelineTaskName]; ok {","\t\treturn true","\t}","\treturn false","}","","// check if a specified pipelineTask is defined under finally section","func (facts *PipelineRunFacts) isFinalTask(pipelineTaskName string) bool {","\tif _, ok := facts.FinalTasksGraph.Nodes[pipelineTaskName]; ok {","\t\treturn true","\t}","\treturn false","}","","// Check if a PipelineTask belongs to the specified Graph","func isTaskInGraph(pipelineTaskName string, d *dag.Graph) bool {","\tif _, ok := d.Nodes[pipelineTaskName]; ok {","\t\treturn true","\t}","\treturn false","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,0,2,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,0,2,2,2,2,0,0,0,2,0,0,0,0,2,2,2,2,2,0,2,2,0,2,2,0,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,1,0,2,2,0,2,2,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,0,2,2,0,0,2,2,2,2,0,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,0,2,2,2,0,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,0,0,2,0,0,0,0,2,2,2,2,2,2,0,0,2,0,0,0,2,2,2,2,2,2,0,0,2,0,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,2,2,0,0,2,2,1,1,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,1,1,0,2,2,2,0,2,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,0,2,2,2,2,2,2,2,0,2,2,0,2,2,2,2,2,0,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,1,1,0,0,0,0,2,2,2,0,0,0,2,2,2,0,0,0,0,2,2,0,0,0,2,2,2,2,2,2,2,0,2,2,0,2,2,2,2,2,0,2,0,0,2,0,0,0,0,2,2,2,2,2,2,2,0,0,2,0,0,0,0,2,2,2,2,2,2,0,0,2,0,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,0,2,2,0,2,2,0,2,2,2,2,2,2,1,1,0,0,0,2,2,2,0,2,2,0,2,2,0,2,2,0,0,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,0]},{"id":195,"path":"pkg/reconciler/pipelinerun/resources/resultrefresolution.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resources","","import (","\t\"encoding/json\"","\t\"errors\"","\t\"fmt\"","\t\"sort\"","","\tpipelineErrors \"github.com/tektoncd/pipeline/pkg/apis/pipeline/errors\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"",")","","// ErrInvalidTaskResultReference indicates that the reason for the failure status is that there","// is an invalid task result reference","var ErrInvalidTaskResultReference = pipelineErrors.WrapUserError(errors.New(\"Invalid task result reference\"))","","// ResolvedResultRefs represents all of the ResolvedResultRef for a pipeline task","type ResolvedResultRefs []*ResolvedResultRef","","// ResolvedResultRef represents a result ref reference that has been fully resolved (value has been populated).","// If the value is from a Result, then the ResultReference will be populated to point to the ResultReference","// which resulted in the value","type ResolvedResultRef struct {","\tValue           v1.ResultValue","\tResultReference v1.ResultRef","\tFromTaskRun     string","\tFromRun         string","}","","// ResolveResultRef resolves any ResultReference that are found in the target ResolvedPipelineTask","func ResolveResultRef(pipelineRunState PipelineRunState, target *ResolvedPipelineTask) (ResolvedResultRefs, string, error) {","\tresolvedResultRefs, pt, err := convertToResultRefs(pipelineRunState, target)","\tif err != nil {","\t\treturn nil, pt, err","\t}","\treturn removeDup(resolvedResultRefs), \"\", nil","}","","// ResolveResultRefs resolves any ResultReference that are found in the target ResolvedPipelineTask","func ResolveResultRefs(pipelineRunState PipelineRunState, targets PipelineRunState) (ResolvedResultRefs, string, error) {","\tvar allResolvedResultRefs ResolvedResultRefs","\tfor _, target := range targets {","\t\tresolvedResultRefs, pt, err := convertToResultRefs(pipelineRunState, target)","\t\tif err != nil {","\t\t\treturn nil, pt, err","\t\t}","\t\tallResolvedResultRefs = append(allResolvedResultRefs, resolvedResultRefs...)","\t}","\treturn removeDup(allResolvedResultRefs), \"\", nil","}","","// validateArrayResultsIndex checks if the result array indexing reference is out of bound of the array size","func validateArrayResultsIndex(allResolvedResultRefs ResolvedResultRefs) error {","\tfor _, r := range allResolvedResultRefs {","\t\tif r.Value.Type == v1.ParamTypeArray {","\t\t\tif r.ResultReference.ResultsIndex != nil \u0026\u0026 *r.ResultReference.ResultsIndex \u003e= len(r.Value.ArrayVal) {","\t\t\t\treturn fmt.Errorf(\"array Result Index %d for Task %s Result %s is out of bound of size %d\", *r.ResultReference.ResultsIndex, r.ResultReference.PipelineTask, r.ResultReference.Result, len(r.Value.ArrayVal))","\t\t\t}","\t\t}","\t}","\treturn nil","}","","func removeDup(refs ResolvedResultRefs) ResolvedResultRefs {","\tif refs == nil {","\t\treturn nil","\t}","\tresolvedResultRefByRef := make(map[v1.ResultRef]*ResolvedResultRef, len(refs))","\tfor _, resolvedResultRef := range refs {","\t\tresolvedResultRefByRef[resolvedResultRef.ResultReference] = resolvedResultRef","\t}","\tdeduped := make([]*ResolvedResultRef, 0, len(resolvedResultRefByRef))","","\t// Sort the resulting keys to produce a deterministic ordering.","\torder := make([]v1.ResultRef, 0, len(refs))","\tfor key := range resolvedResultRefByRef {","\t\torder = append(order, key)","\t}","\tsort.Slice(order, func(i, j int) bool {","\t\tif order[i].PipelineTask \u003e order[j].PipelineTask {","\t\t\treturn false","\t\t}","\t\tif order[i].Result \u003e order[j].Result {","\t\t\treturn false","\t\t}","\t\treturn true","\t})","","\tfor _, key := range order {","\t\tdeduped = append(deduped, resolvedResultRefByRef[key])","\t}","\treturn deduped","}","","// convertToResultRefs walks a PipelineTask looking for result references. If any are","// found they are resolved to a value by searching pipelineRunState. The list of resolved","// references are returned. If an error is encountered due to an invalid result reference","// then a nil list and error is returned instead.","func convertToResultRefs(pipelineRunState PipelineRunState, target *ResolvedPipelineTask) (ResolvedResultRefs, string, error) {","\tvar resolvedResultRefs ResolvedResultRefs","\tfor _, resultRef := range v1.PipelineTaskResultRefs(target.PipelineTask) {","\t\treferencedPipelineTask := pipelineRunState.ToMap()[resultRef.PipelineTask]","\t\tif referencedPipelineTask == nil {","\t\t\treturn nil, resultRef.PipelineTask, fmt.Errorf(\"could not find task %q referenced by result\", resultRef.PipelineTask)","\t\t}","","\t\tif !referencedPipelineTask.isSuccessful() \u0026\u0026 !referencedPipelineTask.isFailure() {","\t\t\treturn nil, resultRef.PipelineTask, fmt.Errorf(\"task %q referenced by result was not finished\", referencedPipelineTask.PipelineTask.Name)","\t\t}","\t\t// Custom Task","\t\tswitch {","\t\tcase referencedPipelineTask.IsCustomTask():","\t\t\tresolved, err := resolveCustomResultRef(referencedPipelineTask.CustomRuns, resultRef)","\t\t\tif err != nil {","\t\t\t\treturn nil, resultRef.PipelineTask, err","\t\t\t}","\t\t\tresolvedResultRefs = append(resolvedResultRefs, resolved)","\t\tdefault:","\t\t\t// Matrixed referenced Pipeline Task","\t\t\tif referencedPipelineTask.PipelineTask.IsMatrixed() {","\t\t\t\tarrayValues, err := findResultValuesForMatrix(referencedPipelineTask, resultRef)","\t\t\t\tif err != nil {","\t\t\t\t\treturn nil, resultRef.PipelineTask, err","\t\t\t\t}","\t\t\t\tfor _, taskRun := range referencedPipelineTask.TaskRuns {","\t\t\t\t\tresolved := createMatrixedTaskResultForParam(taskRun.Name, arrayValues, resultRef)","\t\t\t\t\tresolvedResultRefs = append(resolvedResultRefs, resolved)","\t\t\t\t}","\t\t\t} else {","\t\t\t\t// Regular PipelineTask","\t\t\t\tresolved, err := resolveResultRef(referencedPipelineTask.TaskRuns, resultRef)","\t\t\t\tif err != nil {","\t\t\t\t\treturn nil, resultRef.PipelineTask, err","\t\t\t\t}","\t\t\t\tresolvedResultRefs = append(resolvedResultRefs, resolved)","\t\t\t}","\t\t}","\t}","\treturn resolvedResultRefs, \"\", nil","}","","func resolveCustomResultRef(customRuns []*v1beta1.CustomRun, resultRef *v1.ResultRef) (*ResolvedResultRef, error) {","\tcustomRun := customRuns[0]","\trunName := customRun.GetObjectMeta().GetName()","\trunValue, err := findRunResultForParam(customRun, resultRef)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn \u0026ResolvedResultRef{","\t\tValue:           *paramValueFromCustomRunResult(runValue),","\t\tFromTaskRun:     \"\",","\t\tFromRun:         runName,","\t\tResultReference: *resultRef,","\t}, nil","}","","func paramValueFromCustomRunResult(result string) *v1.ParamValue {","\tvar arrayResult []string","\t// for fan out array result, which is represented as string, we should make it to array type param value","\tif err := json.Unmarshal([]byte(result), \u0026arrayResult); err == nil \u0026\u0026 len(arrayResult) \u003e 0 {","\t\tif len(arrayResult) \u003e 1 {","\t\t\treturn v1.NewStructuredValues(arrayResult[0], arrayResult[1:]...)","\t\t}","\t\treturn \u0026v1.ParamValue{","\t\t\tType:     v1.ParamTypeArray,","\t\t\tArrayVal: []string{arrayResult[0]},","\t\t}","\t}","\treturn v1.NewStructuredValues(result)","}","","func resolveResultRef(taskRuns []*v1.TaskRun, resultRef *v1.ResultRef) (*ResolvedResultRef, error) {","\ttaskRun := taskRuns[0]","\ttaskRunName := taskRun.Name","\tresultValue, err := findTaskResultForParam(taskRun, resultRef)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn \u0026ResolvedResultRef{","\t\tValue:           resultValue,","\t\tFromTaskRun:     taskRunName,","\t\tFromRun:         \"\",","\t\tResultReference: *resultRef,","\t}, nil","}","","func findRunResultForParam(customRun *v1beta1.CustomRun, reference *v1.ResultRef) (string, error) {","\tfor _, result := range customRun.Status.Results {","\t\tif result.Name == reference.Result {","\t\t\treturn result.Value, nil","\t\t}","\t}","\terr := fmt.Errorf(\"%w: Could not find result with name %s for pipeline task %s\", ErrInvalidTaskResultReference, reference.Result, reference.PipelineTask)","\treturn \"\", err","}","","func findTaskResultForParam(taskRun *v1.TaskRun, reference *v1.ResultRef) (v1.ResultValue, error) {","\tresults := taskRun.Status.TaskRunStatusFields.Results","\tfor _, result := range results {","\t\tif result.Name == reference.Result {","\t\t\treturn result.Value, nil","\t\t}","\t}","\terr := fmt.Errorf(\"%w: Could not find result with name %s for pipeline task %s\", ErrInvalidTaskResultReference, reference.Result, reference.PipelineTask)","\treturn v1.ResultValue{}, err","}","","// findResultValuesForMatrix checks the resultsCache of the referenced Matrixed TaskRun to retrieve the resultValues and aggregate them into","// arrayValues. If the resultCache is empty, it will create the ResultCache so that the results can be accessed in subsequent tasks.","func findResultValuesForMatrix(referencedPipelineTask *ResolvedPipelineTask, resultRef *v1.ResultRef) (v1.ParamValue, error) {","\tvar resultsCache *map[string][]string","\tif len(referencedPipelineTask.ResultsCache) == 0 {","\t\tcache := createResultsCacheMatrixedTaskRuns(referencedPipelineTask)","\t\tresultsCache = \u0026cache","\t\treferencedPipelineTask.ResultsCache = *resultsCache","\t}","\tif arrayValues, ok := referencedPipelineTask.ResultsCache[resultRef.Result]; ok {","\t\treturn v1.ParamValue{","\t\t\tType:     v1.ParamTypeArray,","\t\t\tArrayVal: arrayValues,","\t\t}, nil","\t}","\terr := fmt.Errorf(\"%w: Could not find result with name %s for task %s\", ErrInvalidTaskResultReference, resultRef.Result, resultRef.PipelineTask)","\treturn v1.ParamValue{}, err","}","","func createMatrixedTaskResultForParam(taskRunName string, paramValue v1.ParamValue, resultRef *v1.ResultRef) *ResolvedResultRef {","\treturn \u0026ResolvedResultRef{","\t\tValue:           paramValue,","\t\tFromTaskRun:     taskRunName,","\t\tFromRun:         \"\",","\t\tResultReference: *resultRef,","\t}","}","","func (rs ResolvedResultRefs) getStringReplacements() map[string]string {","\treplacements := map[string]string{}","\tfor _, r := range rs {","\t\tswitch r.Value.Type {","\t\tcase v1.ParamTypeArray:","\t\t\tfor i := range len(r.Value.ArrayVal) {","\t\t\t\tfor _, target := range r.getReplaceTargetfromArrayIndex(i) {","\t\t\t\t\treplacements[target] = r.Value.ArrayVal[i]","\t\t\t\t}","\t\t\t}","\t\tcase v1.ParamTypeObject:","\t\t\tfor key, element := range r.Value.ObjectVal {","\t\t\t\tfor _, target := range r.getReplaceTargetfromObjectKey(key) {","\t\t\t\t\treplacements[target] = element","\t\t\t\t}","\t\t\t}","","\t\tcase v1.ParamTypeString:","\t\t\tfallthrough","\t\tdefault:","\t\t\tfor _, target := range r.getReplaceTarget() {","\t\t\t\treplacements[target] = r.Value.StringVal","\t\t\t}","\t\t}","\t}","\treturn replacements","}","","func (rs ResolvedResultRefs) getArrayReplacements() map[string][]string {","\treplacements := map[string][]string{}","\tfor _, r := range rs {","\t\tif r.Value.Type == v1.ParamType(v1.ResultsTypeArray) {","\t\t\tfor _, target := range r.getReplaceTarget() {","\t\t\t\treplacements[target] = r.Value.ArrayVal","\t\t\t}","\t\t}","\t}","\treturn replacements","}","","func (rs ResolvedResultRefs) getObjectReplacements() map[string]map[string]string {","\treplacements := map[string]map[string]string{}","\tfor _, r := range rs {","\t\tif r.Value.Type == v1.ParamType(v1.ResultsTypeObject) {","\t\t\tfor _, target := range r.getReplaceTarget() {","\t\t\t\treplacements[target] = r.Value.ObjectVal","\t\t\t}","\t\t}","\t}","\treturn replacements","}","","func (r *ResolvedResultRef) getReplaceTarget() []string {","\treturn []string{","\t\tfmt.Sprintf(\"%s.%s.%s.%s\", v1.ResultTaskPart, r.ResultReference.PipelineTask, v1.ResultResultPart, r.ResultReference.Result),","\t\tfmt.Sprintf(\"%s.%s.%s[%q]\", v1.ResultTaskPart, r.ResultReference.PipelineTask, v1.ResultResultPart, r.ResultReference.Result),","\t\tfmt.Sprintf(\"%s.%s.%s['%s']\", v1.ResultTaskPart, r.ResultReference.PipelineTask, v1.ResultResultPart, r.ResultReference.Result),","\t}","}","","func (r *ResolvedResultRef) getReplaceTargetfromArrayIndex(idx int) []string {","\treturn []string{","\t\tfmt.Sprintf(\"%s.%s.%s.%s[%d]\", v1.ResultTaskPart, r.ResultReference.PipelineTask, v1.ResultResultPart, r.ResultReference.Result, idx),","\t\tfmt.Sprintf(\"%s.%s.%s[%q][%d]\", v1.ResultTaskPart, r.ResultReference.PipelineTask, v1.ResultResultPart, r.ResultReference.Result, idx),","\t\tfmt.Sprintf(\"%s.%s.%s['%s'][%d]\", v1.ResultTaskPart, r.ResultReference.PipelineTask, v1.ResultResultPart, r.ResultReference.Result, idx),","\t}","}","","func (r *ResolvedResultRef) getReplaceTargetfromObjectKey(key string) []string {","\treturn []string{","\t\tfmt.Sprintf(\"%s.%s.%s.%s.%s\", v1.ResultTaskPart, r.ResultReference.PipelineTask, v1.ResultResultPart, r.ResultReference.Result, key),","\t\tfmt.Sprintf(\"%s.%s.%s[%q][%s]\", v1.ResultTaskPart, r.ResultReference.PipelineTask, v1.ResultResultPart, r.ResultReference.Result, key),","\t\tfmt.Sprintf(\"%s.%s.%s['%s'][%s]\", v1.ResultTaskPart, r.ResultReference.PipelineTask, v1.ResultResultPart, r.ResultReference.Result, key),","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,0,0,2,2,2,2,0,0,0,0,0,0,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,2,2,0,0,2,2,2,2,2,2,0,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2]},{"id":196,"path":"pkg/reconciler/pipelinerun/resources/validate_dependencies.go","lines":["/*","Copyright 2021 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resources","","import (","\t\"fmt\"","","\tpipelineErrors \"github.com/tektoncd/pipeline/pkg/apis/pipeline/errors\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"k8s.io/apimachinery/pkg/util/sets\"",")","","// ValidatePipelineTaskResults ensures that any result references used by pipeline tasks","// resolve to valid results. This prevents a situation where a PipelineTask references","// a result in another PipelineTask that doesn't exist or where the user has either misspelled","// a result name or the referenced task just doesn't return a result with that name.","func ValidatePipelineTaskResults(state PipelineRunState) error {","\tptMap := state.ToMap()","\tfor _, rpt := range state {","\t\tfor _, ref := range v1.PipelineTaskResultRefs(rpt.PipelineTask) {","\t\t\tif err := validateResultRef(ref, ptMap); err != nil {","\t\t\t\treturn pipelineErrors.WrapUserError(fmt.Errorf(\"invalid result reference in pipeline task %q: %w\", rpt.PipelineTask.Name, err))","\t\t\t}","\t\t}","\t}","\treturn nil","}","","// ValidatePipelineResults ensures that any result references used by PipelineResults","// resolve to valid results. This prevents a situation where a PipelineResult references","// a result in a PipelineTask that doesn't exist or where the user has either misspelled","// a result name or the referenced task just doesn't return a result with that name.","func ValidatePipelineResults(ps *v1.PipelineSpec, state PipelineRunState) error {","\tptMap := state.ToMap()","\tfor _, result := range ps.Results {","\t\texpressions, _ := result.GetVarSubstitutionExpressions()","\t\trefs := v1.NewResultRefs(expressions)","\t\tfor _, ref := range refs {","\t\t\tif err := validateResultRef(ref, ptMap); err != nil {","\t\t\t\treturn fmt.Errorf(\"invalid pipeline result %q: %w\", result.Name, err)","\t\t\t}","\t\t}","\t}","\treturn nil","}","","// validateResultRef takes a ResultRef and searches for the result using the given","// map of PipelineTask name to ResolvedPipelineTask. If the ResultRef does not point","// to a pipeline task or named result then an error is returned.","func validateResultRef(ref *v1.ResultRef, ptMap map[string]*ResolvedPipelineTask) error {","\tif _, ok := ptMap[ref.PipelineTask]; !ok {","\t\treturn fmt.Errorf(\"referenced pipeline task %q does not exist\", ref.PipelineTask)","\t}","\ttaskProvidesResult := false","\tif ptMap[ref.PipelineTask].CustomTask {","\t\t// We're not able to validate results pointing to custom tasks because","\t\t// there's no facility to check what the result names will be before the","\t\t// custom task executes.","\t\treturn nil","\t}","\tif ptMap[ref.PipelineTask].ResolvedTask == nil || ptMap[ref.PipelineTask].ResolvedTask.TaskSpec == nil {","\t\treturn fmt.Errorf(\"unable to validate result referencing pipeline task %q: task spec not found\", ref.PipelineTask)","\t}","\tfor _, taskResult := range ptMap[ref.PipelineTask].ResolvedTask.TaskSpec.Results {","\t\tif taskResult.Name == ref.Result {","\t\t\ttaskProvidesResult = true","\t\t\tbreak","\t\t}","\t}","\tif !taskProvidesResult {","\t\treturn fmt.Errorf(\"%q is not a named result returned by pipeline task %q\", ref.Result, ref.PipelineTask)","\t}","\treturn nil","}","","// ValidateOptionalWorkspaces validates that any workspaces in the Pipeline that are","// marked as optional are also marked optional in the Tasks that receive them. This","// prevents a situation where a Task requires a workspace but a Pipeline does not offer","// the same guarantee the workspace will be provided at runtime.","func ValidateOptionalWorkspaces(pipelineWorkspaces []v1.PipelineWorkspaceDeclaration, state PipelineRunState) error {","\toptionalWorkspaces := sets.NewString()","\tfor _, ws := range pipelineWorkspaces {","\t\tif ws.Optional {","\t\t\toptionalWorkspaces.Insert(ws.Name)","\t\t}","\t}","","\tfor _, rpt := range state {","\t\tfor _, pws := range rpt.PipelineTask.Workspaces {","\t\t\tif rpt.ResolvedTask != nil \u0026\u0026 rpt.ResolvedTask.TaskSpec != nil \u0026\u0026 optionalWorkspaces.Has(pws.Workspace) {","\t\t\t\tfor _, tws := range rpt.ResolvedTask.TaskSpec.Workspaces {","\t\t\t\t\tif tws.Name == pws.Name \u0026\u0026 !tws.Optional {","\t\t\t\t\t\treturn fmt.Errorf(\"pipeline workspace %q is marked optional but pipeline task %q requires it be provided\", pws.Workspace, rpt.PipelineTask.Name)","\t\t\t\t\t}","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,0,0,2,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,0,0,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,0,0,2,0]},{"id":197,"path":"pkg/reconciler/pipelinerun/resources/validate_params.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resources","","import (","\t\"fmt\"","","\tpipelineErrors \"github.com/tektoncd/pipeline/pkg/apis/pipeline/errors\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/list\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/taskrun\"","\ttrresources \"github.com/tektoncd/pipeline/pkg/reconciler/taskrun/resources\"",")","","// ValidateParamTypesMatching validate that parameters in PipelineRun override corresponding parameters in Pipeline of the same type.","func ValidateParamTypesMatching(p *v1.PipelineSpec, pr *v1.PipelineRun) error {","\t// Build a map of parameter names/types declared in p.","\tparamTypes := make(map[string]v1.ParamType)","\tfor _, param := range p.Params {","\t\tparamTypes[param.Name] = param.Type","\t}","","\t// Build a list of parameter names from pr that have mismatching types with the map created above.","\tvar wrongTypeParamNames []string","\tfor _, param := range pr.Spec.Params {","\t\tif paramType, ok := paramTypes[param.Name]; ok {","\t\t\tif param.Value.Type != paramType {","\t\t\t\twrongTypeParamNames = append(wrongTypeParamNames, param.Name)","\t\t\t}","\t\t}","\t}","","\t// Return an error with the misconfigured parameters' names, or return nil if there are none.","\tif len(wrongTypeParamNames) != 0 {","\t\treturn pipelineErrors.WrapUserError(fmt.Errorf(\"parameters have inconsistent types : %s\", wrongTypeParamNames))","\t}","\treturn nil","}","","// ValidateRequiredParametersProvided validates that all the parameters expected by the Pipeline are provided by the PipelineRun.","// Extra Parameters are allowed, the Pipeline will use the Parameters it needs and ignore the other Parameters.","func ValidateRequiredParametersProvided(pipelineParameters *v1.ParamSpecs, pipelineRunParameters *v1.Params) error {","\t// Build a list of parameter names declared in pr.","\tvar providedParams []string","\tfor _, param := range *pipelineRunParameters {","\t\tprovidedParams = append(providedParams, param.Name)","\t}","","\tvar requiredParams []string","\tfor _, param := range *pipelineParameters {","\t\tif param.Default == nil { // include only parameters that don't have default values specified in the Pipeline","\t\t\trequiredParams = append(requiredParams, param.Name)","\t\t}","\t}","","\t// Build a list of parameter names in p that are missing from pr.","\tmissingParams := list.DiffLeft(requiredParams, providedParams)","","\t// Return an error with the missing parameters' names, or return nil if there are none.","\tif len(missingParams) != 0 {","\t\treturn pipelineErrors.WrapUserError(fmt.Errorf(\"pipelineRun missing parameters: %s\", missingParams))","\t}","\treturn nil","}","","// ValidateObjectParamRequiredKeys validates that the required keys of all the object parameters expected by the Pipeline are provided by the PipelineRun.","func ValidateObjectParamRequiredKeys(pipelineParameters []v1.ParamSpec, pipelineRunParameters []v1.Param) error {","\tmissings := taskrun.MissingKeysObjectParamNames(pipelineParameters, pipelineRunParameters)","\tif len(missings) != 0 {","\t\treturn pipelineErrors.WrapUserError(fmt.Errorf(\"pipelineRun missing object keys for parameters: %v\", missings))","\t}","","\treturn nil","}","","// ValidateParameterTypesInMatrix validates the type of Parameter for Matrix.Params","// and Matrix.Include.Params after any replacements are made from Task parameters or results","// Matrix.Params must be of type array. Matrix.Include.Params must be of type string.","func ValidateParameterTypesInMatrix(state PipelineRunState) error {","\tfor _, rpt := range state {","\t\tm := rpt.PipelineTask.Matrix","\t\tif m.HasInclude() {","\t\t\tfor _, include := range m.Include {","\t\t\t\tfor _, param := range include.Params {","\t\t\t\t\tif param.Value.Type != v1.ParamTypeString {","\t\t\t\t\t\treturn fmt.Errorf(\"parameters of type string only are allowed, but param \\\"%s\\\" has type \\\"%s\\\" in pipelineTask \\\"%s\\\"\",","\t\t\t\t\t\t\tparam.Name, string(param.Value.Type), rpt.PipelineTask.Name)","\t\t\t\t\t}","\t\t\t\t}","\t\t\t}","\t\t}","\t\tif m.HasParams() {","\t\t\tfor _, param := range m.Params {","\t\t\t\tif param.Value.Type != v1.ParamTypeArray {","\t\t\t\t\t// If it's an array type that contains result references because it's consuming results","\t\t\t\t\t// from a Matrixed PipelineTask continue","\t\t\t\t\tif ps, ok := param.GetVarSubstitutionExpressions(); ok {","\t\t\t\t\t\tif v1.LooksLikeContainsResultRefs(ps) {","\t\t\t\t\t\t\tcontinue","\t\t\t\t\t\t}","\t\t\t\t\t}","\t\t\t\t\treturn fmt.Errorf(\"parameters of type array only are allowed, but param \\\"%s\\\" has type \\\"%s\\\" in pipelineTask \\\"%s\\\"\",","\t\t\t\t\t\tparam.Name, string(param.Value.Type), rpt.PipelineTask.Name)","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn nil","}","","// ValidateParamArrayIndex validates if the param reference to an array param is out of bound.","// error is returned when the array indexing reference is out of bound of the array param","// e.g. if a param reference of $(params.array-param[2]) and the array param is of length 2.","func ValidateParamArrayIndex(ps *v1.PipelineSpec, params v1.Params) error {","\treturn trresources.ValidateOutOfBoundArrayParams(ps.Params, params, ps.GetIndexingReferencesToArrayParams())","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,0,0,2,2,2,2,0,0,0,0,2,2,2,2,2,2,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,0,0,0,0,2,0,0,0,0,0,2,2,2]},{"id":198,"path":"pkg/reconciler/pipelinerun/timeout.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pipelinerun","","import (","\t\"context\"","\t\"encoding/json\"","\t\"fmt\"","\t\"log\"","\t\"strings\"","\t\"time\"","","\tpipelineErrors \"github.com/tektoncd/pipeline/pkg/apis/pipeline/errors\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\tclientset \"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"","\t\"go.uber.org/zap\"","\t\"gomodules.xyz/jsonpatch/v2\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/api/errors\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/types\"","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"knative.dev/pkg/apis\"",")","","var timeoutTaskRunPatchBytes, timeoutCustomRunPatchBytes []byte","","func init() {","\tvar err error","\ttimeoutTaskRunPatchBytes, err = json.Marshal([]jsonpatch.JsonPatchOperation{","\t\t{","\t\t\tOperation: \"add\",","\t\t\tPath:      \"/spec/status\",","\t\t\tValue:     v1.TaskRunSpecStatusCancelled,","\t\t},","\t\t{","\t\t\tOperation: \"add\",","\t\t\tPath:      \"/spec/statusMessage\",","\t\t\tValue:     v1.TaskRunCancelledByPipelineTimeoutMsg,","\t\t}})","\tif err != nil {","\t\tlog.Fatalf(\"failed to marshal TaskRun timeout patch bytes: %v\", err)","\t}","\ttimeoutCustomRunPatchBytes, err = json.Marshal([]jsonpatch.JsonPatchOperation{","\t\t{","\t\t\tOperation: \"add\",","\t\t\tPath:      \"/spec/status\",","\t\t\tValue:     v1beta1.CustomRunSpecStatusCancelled,","\t\t},","\t\t{","\t\t\tOperation: \"add\",","\t\t\tPath:      \"/spec/statusMessage\",","\t\t\tValue:     v1beta1.CustomRunCancelledByPipelineTimeoutMsg,","\t\t}})","\tif err != nil {","\t\tlog.Fatalf(\"failed to marshal CustomRun timeout patch bytes: %v\", err)","\t}","}","","// timeoutPipelineRun marks the PipelineRun as timed out and any resolved TaskRun(s) too.","func timeoutPipelineRun(ctx context.Context, logger *zap.SugaredLogger, pr *v1.PipelineRun, clientSet clientset.Interface) error {","\terrs := timeoutPipelineTasks(ctx, logger, pr, clientSet)","","\t// If we successfully timed out all the TaskRuns and Runs, we can consider the PipelineRun timed out.","\tif len(errs) == 0 {","\t\tpr.SetTimeoutCondition(ctx)","\t\t// update pr completed time","\t\tpr.Status.CompletionTime = \u0026metav1.Time{Time: time.Now()}","\t} else {","\t\te := strings.Join(errs, \"\\n\")","\t\t// Indicate that we failed to time out the PipelineRun","\t\tpr.Status.SetCondition(\u0026apis.Condition{","\t\t\tType:    apis.ConditionSucceeded,","\t\t\tStatus:  corev1.ConditionUnknown,","\t\t\tReason:  v1.PipelineRunReasonCouldntTimeOut.String(),","\t\t\tMessage: fmt.Sprintf(\"PipelineRun %q was timed out but had errors trying to time out TaskRuns and/or Runs: %s\", pr.Name, e),","\t\t})","\t\treturn fmt.Errorf(\"error(s) from timing out TaskRun(s) from PipelineRun %s: %s\", pr.Name, e)","\t}","\treturn nil","}","","func timeoutCustomRun(ctx context.Context, customRunName string, namespace string, clientSet clientset.Interface) error {","\t_, err := clientSet.TektonV1beta1().CustomRuns(namespace).Patch(ctx, customRunName, types.JSONPatchType, timeoutCustomRunPatchBytes, metav1.PatchOptions{}, \"\")","\tif errors.IsNotFound(err) {","\t\treturn nil","\t}","\treturn err","}","","func timeoutTaskRun(ctx context.Context, taskRunName string, namespace string, clientSet clientset.Interface) error {","\t_, err := clientSet.TektonV1().TaskRuns(namespace).Patch(ctx, taskRunName, types.JSONPatchType, timeoutTaskRunPatchBytes, metav1.PatchOptions{}, \"\")","\tif errors.IsNotFound(err) {","\t\treturn nil","\t}","\treturn err","}","","// timeoutPipelineTaskRuns patches `TaskRun` and `Run` with canceled status and an appropriate message","func timeoutPipelineTasks(ctx context.Context, logger *zap.SugaredLogger, pr *v1.PipelineRun, clientSet clientset.Interface) []string {","\treturn timeoutPipelineTasksForTaskNames(ctx, logger, pr, clientSet, sets.NewString())","}","","// timeoutPipelineTasksForTaskNames patches `TaskRun`s and `Run`s for the given task names, or all if no task names are given, with canceled status and appropriate message","func timeoutPipelineTasksForTaskNames(ctx context.Context, logger *zap.SugaredLogger, pr *v1.PipelineRun, clientSet clientset.Interface, taskNames sets.String) []string {","\terrs := []string{}","","\ttrNames, customRunNames, err := getChildObjectsFromPRStatusForTaskNames(ctx, pr.Status, taskNames)","\tif err != nil {","\t\terrs = append(errs, err.Error())","\t}","","\tfor _, taskRunName := range trNames {","\t\tlogger.Infof(\"patching TaskRun %s for timeout\", taskRunName)","","\t\tif err := timeoutTaskRun(ctx, taskRunName, pr.Namespace, clientSet); err != nil {","\t\t\tif pipelineErrors.IsImmutableTaskRunSpecError(err) {","\t\t\t\t// The TaskRun may have completed and the spec field is immutable, we should ignore this error.","\t\t\t\tcontinue","\t\t\t}","\t\t\terrs = append(errs, fmt.Errorf(\"failed to patch TaskRun `%s` with timeout: %w\", taskRunName, err).Error())","\t\t\tcontinue","\t\t}","\t}","","\tfor _, custonRunName := range customRunNames {","\t\tlogger.Infof(\"patching CustomRun %s for timeout\", custonRunName)","","\t\tif err := timeoutCustomRun(ctx, custonRunName, pr.Namespace, clientSet); err != nil {","\t\t\terrs = append(errs, fmt.Errorf(\"failed to patch CustomRun `%s` with timeout: %w\", custonRunName, err).Error())","\t\t\tcontinue","\t\t}","\t}","\treturn errs","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,0,2,2,2,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,1,1,0,2,2,0,0,0,2,2,2,2,1,1,0,0,2,0]},{"id":199,"path":"pkg/reconciler/pipelinerun/tracing.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package pipelinerun","","import (","\t\"context\"","\t\"encoding/json\"","\t\"errors\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"go.opentelemetry.io/otel\"","\t\"go.opentelemetry.io/otel/attribute\"","\t\"go.opentelemetry.io/otel/propagation\"","\t\"go.opentelemetry.io/otel/trace\"","\t\"knative.dev/pkg/logging\"",")","","const (","\t// TracerName is the name of the tracer","\tTracerName = \"PipelineRunReconciler\"","\t// SpanContextAnnotation is the name of the Annotation for storing SpanContext","\tSpanContextAnnotation = \"tekton.dev/pipelinerunSpanContext\"","\t// TaskRunSpanContextAnnotation is the name of the Annotation used for propagating SpanContext to TaskRun","\tTaskRunSpanContextAnnotation = \"tekton.dev/taskrunSpanContext\"",")","","// initialize tracing by creating the root span and injecting the","// spanContext is propagated through annotations in the CR","func initTracing(ctx context.Context, tracerProvider trace.TracerProvider, pr *v1.PipelineRun) context.Context {","\tlogger := logging.FromContext(ctx)","\tpro := otel.GetTextMapPropagator()","","\t// SpanContext was created already","\tif len(pr.Status.SpanContext) \u003e 0 {","\t\treturn pro.Extract(ctx, propagation.MapCarrier(pr.Status.SpanContext))","\t}","","\tspanContext := make(map[string]string)","","\t// SpanContext was propagated through annotations","\tif pr.Annotations != nil \u0026\u0026 pr.Annotations[SpanContextAnnotation] != \"\" {","\t\terr := json.Unmarshal([]byte(pr.Annotations[SpanContextAnnotation]), \u0026spanContext)","\t\tif err != nil {","\t\t\tlogger.Error(\"unable to unmarshal spancontext, err: %s\", err)","\t\t}","","\t\tpr.Status.SpanContext = spanContext","\t\treturn pro.Extract(ctx, propagation.MapCarrier(pr.Status.SpanContext))","\t}","","\t// Create a new root span since there was no parent spanContext provided through annotations","\tctxWithTrace, span := tracerProvider.Tracer(TracerName).Start(ctx, \"PipelineRun:Reconciler\")","\tdefer span.End()","\tspan.SetAttributes(attribute.String(\"pipelinerun\", pr.Name), attribute.String(\"namespace\", pr.Namespace))","","\tpro.Inject(ctxWithTrace, propagation.MapCarrier(spanContext))","","\tlogger.Debug(\"got tracing carrier\", spanContext)","\tif len(spanContext) == 0 {","\t\tlogger.Debug(\"tracerProvider doesn't provide a traceId, tracing is disabled\")","\t\treturn ctx","\t}","","\tspan.AddEvent(\"updating PipelineRun status with SpanContext\")","\tpr.Status.SpanContext = spanContext","\treturn ctxWithTrace","}","","// Extract spanContext from the context and return it as json encoded string","func getMarshalledSpanFromContext(ctx context.Context) (string, error) {","\tcarrier := make(map[string]string)","\tpro := otel.GetTextMapPropagator()","","\tpro.Inject(ctx, propagation.MapCarrier(carrier))","","\tif len(carrier) == 0 {","\t\treturn \"\", errors.New(\"spanContext not present in the context, unable to marshall\")","\t}","","\tmarshalled, err := json.Marshal(carrier)","\tif err != nil {","\t\treturn \"\", err","\t}","\tif len(marshalled) \u003e= 1024 {","\t\treturn \"\", errors.New(\"marshalled spanContext size is too big\")","\t}","\treturn string(marshalled), nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,1,1,0,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,1,1,1,1,1,1,1,1,0]},{"id":200,"path":"pkg/reconciler/resolutionrequest/controller.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resolutionrequest","","import (","\t\"context\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\tresolutionrequestinformer \"github.com/tektoncd/pipeline/pkg/client/resolution/injection/informers/resolution/v1beta1/resolutionrequest\"","\tresolutionrequestreconciler \"github.com/tektoncd/pipeline/pkg/client/resolution/injection/reconciler/resolution/v1beta1/resolutionrequest\"","\t\"k8s.io/utils/clock\"","\t\"knative.dev/pkg/configmap\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/logging\"",")","","// NewController returns a func that returns a knative controller for processing","// ResolutionRequest objects.","func NewController(clock clock.PassiveClock) func(ctx context.Context, cmw configmap.Watcher) *controller.Impl {","\treturn func(ctx context.Context, cmw configmap.Watcher) *controller.Impl {","\t\tlogger := logging.FromContext(ctx)","","\t\tconfigStore := config.NewStore(logger.Named(\"config-store\"))","\t\tconfigStore.WatchConfigs(cmw)","","\t\tr := \u0026Reconciler{","\t\t\tclock: clock,","\t\t}","\t\timpl := resolutionrequestreconciler.NewImpl(ctx, r, func(impl *controller.Impl) controller.Options {","\t\t\treturn controller.Options{","\t\t\t\tConfigStore: configStore,","\t\t\t}","\t\t})","","\t\treqinformer := resolutionrequestinformer.Get(ctx)","\t\tif _, err := reqinformer.Informer().AddEventHandler(controller.HandleAll(impl.Enqueue)); err != nil {","\t\t\tlogging.FromContext(ctx).Panicf(\"Couldn't register ResolutionRequest informer event handler: %w\", err)","\t\t}","","\t\treturn impl","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,1,1,0,2,0,0]},{"id":201,"path":"pkg/reconciler/resolutionrequest/resolutionrequest.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resolutionrequest","","import (","\t\"context\"","\t\"fmt\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\trrreconciler \"github.com/tektoncd/pipeline/pkg/client/resolution/injection/reconciler/resolution/v1beta1/resolutionrequest\"","\tresolutioncommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\t\"k8s.io/utils/clock\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/reconciler\"",")","","// Reconciler is a knative reconciler for processing ResolutionRequest","// objects","type Reconciler struct {","\tclock clock.PassiveClock","}","","var _ rrreconciler.Interface = (*Reconciler)(nil)","","// ReconcileKind processes updates to ResolutionRequests, sets status","// fields on it, and returns any errors experienced along the way.","func (r *Reconciler) ReconcileKind(ctx context.Context, rr *v1beta1.ResolutionRequest) reconciler.Event {","\tif rr == nil {","\t\treturn nil","\t}","","\tif rr.IsDone() {","\t\treturn nil","\t}","","\tif rr.Status.GetCondition(apis.ConditionSucceeded) == nil {","\t\trr.Status.InitializeConditions()","\t}","","\tmaximumResolutionDuration := config.FromContextOrDefaults(ctx).Defaults.DefaultMaximumResolutionTimeout","\tswitch {","\tcase rr.Status.Data != \"\":","\t\trr.Status.MarkSucceeded()","\tcase requestDuration(rr) \u003e maximumResolutionDuration:","\t\trr.Status.MarkFailed(resolutioncommon.ReasonResolutionTimedOut, timeoutMessage(maximumResolutionDuration))","\tdefault:","\t\trr.Status.MarkInProgress(resolutioncommon.MessageWaitingForResolver)","\t\treturn controller.NewRequeueAfter(maximumResolutionDuration - requestDuration(rr))","\t}","","\treturn nil","}","","// requestDuration returns the amount of time that has passed since a","// given ResolutionRequest was created.","func requestDuration(rr *v1beta1.ResolutionRequest) time.Duration {","\tcreationTime := rr.ObjectMeta.CreationTimestamp.DeepCopy().Time.UTC()","\treturn time.Now().UTC().Sub(creationTime)","}","","func timeoutMessage(timeout time.Duration) string {","\treturn fmt.Sprintf(\"resolution took longer than global timeout of %s\", timeout)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,0,2,1,1,0,2,1,1,0,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,2,2,2,2,0,2,2,2]},{"id":202,"path":"pkg/reconciler/resources.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package reconciler","","import (","\t\"time\"","","\t\"knative.dev/pkg/kmeta\"",")","","const (","\t// minimumResourceAge is the age at which resources stop being IsYoungResource.","\tminimumResourceAge = 5 * time.Second",")","","// IsYoungResource checks whether the resource is younger than minimumResourceAge, based on its creation timestamp.","func IsYoungResource(obj kmeta.Accessor) bool {","\treturn time.Since(obj.GetCreationTimestamp().Time) \u003c minimumResourceAge","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2]},{"id":203,"path":"pkg/reconciler/taskrun/controller.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package taskrun","","import (","\t\"context\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tpipelineclient \"github.com/tektoncd/pipeline/pkg/client/injection/client\"","\ttaskruninformer \"github.com/tektoncd/pipeline/pkg/client/injection/informers/pipeline/v1/taskrun\"","\tverificationpolicyinformer \"github.com/tektoncd/pipeline/pkg/client/injection/informers/pipeline/v1alpha1/verificationpolicy\"","\ttaskrunreconciler \"github.com/tektoncd/pipeline/pkg/client/injection/reconciler/pipeline/v1/taskrun\"","\tresolutionclient \"github.com/tektoncd/pipeline/pkg/client/resolution/injection/client\"","\tresolutioninformer \"github.com/tektoncd/pipeline/pkg/client/resolution/injection/informers/resolution/v1beta1/resolutionrequest\"","\t\"github.com/tektoncd/pipeline/pkg/pod\"","\tcloudeventclient \"github.com/tektoncd/pipeline/pkg/reconciler/events/cloudevent\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/volumeclaim\"","\tresolution \"github.com/tektoncd/pipeline/pkg/remoteresolution/resource\"","\t\"github.com/tektoncd/pipeline/pkg/spire\"","\t\"github.com/tektoncd/pipeline/pkg/taskrunmetrics\"","\t\"github.com/tektoncd/pipeline/pkg/tracing\"","\t\"k8s.io/client-go/tools/cache\"","\t\"k8s.io/utils/clock\"","\tkubeclient \"knative.dev/pkg/client/injection/kube/client\"","\tlimitrangeinformer \"knative.dev/pkg/client/injection/kube/informers/core/v1/limitrange\"","\tfilteredpodinformer \"knative.dev/pkg/client/injection/kube/informers/core/v1/pod/filtered\"","\tsecretinformer \"knative.dev/pkg/client/injection/kube/informers/core/v1/secret\"","\t\"knative.dev/pkg/configmap\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/logging\"",")","","const (","\t// TracerProviderName is the name of TraceProvider","\tTracerProviderName = \"taskrun-reconciler\"",")","","var taskRunFilterManagedBy = func(obj interface{}) bool {","\ttr, ok := obj.(*v1.TaskRun)","\tif !ok {","\t\treturn true","\t}","\t// The taskrun-controller should not reconcile TaskRuns managed by other controllers.","\tif tr.Spec.ManagedBy != nil \u0026\u0026 *tr.Spec.ManagedBy != pipeline.ManagedBy {","\t\treturn false","\t}","\treturn true","}","","// NewController instantiates a new controller.Impl from knative.dev/pkg/controller","func NewController(opts *pipeline.Options, clock clock.PassiveClock) func(context.Context, configmap.Watcher) *controller.Impl {","\treturn func(ctx context.Context, cmw configmap.Watcher) *controller.Impl {","\t\tlogger := logging.FromContext(ctx)","\t\tkubeclientset := kubeclient.Get(ctx)","\t\tpipelineclientset := pipelineclient.Get(ctx)","\t\ttaskRunInformer := taskruninformer.Get(ctx)","\t\tpodInformer := filteredpodinformer.Get(ctx, v1.ManagedByLabelKey)","\t\tlimitrangeInformer := limitrangeinformer.Get(ctx)","\t\tverificationpolicyInformer := verificationpolicyinformer.Get(ctx)","\t\tresolutionInformer := resolutioninformer.Get(ctx)","\t\tsecretinformer := secretinformer.Get(ctx)","\t\tspireClient := spire.GetControllerAPIClient(ctx)","\t\ttracerProvider := tracing.New(TracerProviderName, logger.Named(\"tracing\"))","\t\ttaskrunmetricsRecorder := taskrunmetrics.Get(ctx)","\t\t//nolint:contextcheck // OnStore methods does not support context as a parameter","\t\tconfigStore := config.NewStore(logger.Named(\"config-store\"),","\t\t\ttaskrunmetrics.OnStore(logger, taskrunmetricsRecorder),","\t\t\tspire.OnStore(ctx, logger),","\t\t\ttracerProvider.OnStore(secretinformer.Lister()),","\t\t)","\t\tconfigStore.WatchConfigs(cmw)","","\t\tentrypointCache, err := pod.NewEntrypointCache(kubeclientset)","\t\tif err != nil {","\t\t\tlogger.Fatalf(\"Error creating entrypoint cache: %v\", err)","\t\t}","","\t\tc := \u0026Reconciler{","\t\t\tKubeClientSet:            kubeclientset,","\t\t\tPipelineClientSet:        pipelineclientset,","\t\t\tImages:                   opts.Images,","\t\t\tClock:                    clock,","\t\t\tspireClient:              spireClient,","\t\t\ttaskRunLister:            taskRunInformer.Lister(),","\t\t\tlimitrangeLister:         limitrangeInformer.Lister(),","\t\t\tverificationPolicyLister: verificationpolicyInformer.Lister(),","\t\t\tcloudEventClient:         cloudeventclient.Get(ctx),","\t\t\tmetrics:                  taskrunmetricsRecorder,","\t\t\tentrypointCache:          entrypointCache,","\t\t\tpodLister:                podInformer.Lister(),","\t\t\tpvcHandler:               volumeclaim.NewPVCHandler(kubeclientset, logger),","\t\t\tresolutionRequester:      resolution.NewCRDRequester(resolutionclient.Get(ctx), resolutionInformer.Lister()),","\t\t\ttracerProvider:           tracerProvider,","\t\t}","\t\timpl := taskrunreconciler.NewImpl(ctx, c, func(impl *controller.Impl) controller.Options {","\t\t\treturn controller.Options{","\t\t\t\tAgentName:         pipeline.TaskRunControllerName,","\t\t\t\tConfigStore:       configStore,","\t\t\t\tPromoteFilterFunc: taskRunFilterManagedBy,","\t\t\t}","\t\t})","","\t\tif _, err := secretinformer.Informer().AddEventHandler(controller.HandleAll(tracerProvider.Handler)); err != nil {","\t\t\tlogging.FromContext(ctx).Panicf(\"Couldn't register Secret informer event handler: %w\", err)","\t\t}","","\t\tif _, err := taskRunInformer.Informer().AddEventHandler(cache.FilteringResourceEventHandler{","\t\t\tFilterFunc: taskRunFilterManagedBy,","\t\t\tHandler:    controller.HandleAll(impl.Enqueue),","\t\t}); err != nil {","\t\t\tlogging.FromContext(ctx).Panicf(\"Couldn't register TaskRun informer event handler: %w\", err)","\t\t}","","\t\tif _, err := podInformer.Informer().AddEventHandler(cache.FilteringResourceEventHandler{","\t\t\tFilterFunc: controller.FilterController(\u0026v1.TaskRun{}),","\t\t\tHandler:    controller.HandleAll(impl.EnqueueControllerOf),","\t\t}); err != nil {","\t\t\tlogging.FromContext(ctx).Panicf(\"Couldn't register Pod informer event handler: %w\", err)","\t\t}","","\t\treturn impl","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,1,1,0,2,2,2,2,1,1,0,2,2,2,2,1,1,0,2,0,0]},{"id":204,"path":"pkg/reconciler/taskrun/resources/apply.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resources","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","\t\"path/filepath\"","\t\"regexp\"","\t\"sort\"","\t\"strconv\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/internal/artifactref\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tpodtpl \"github.com/tektoncd/pipeline/pkg/apis/pipeline/pod\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/container\"","\t\"github.com/tektoncd/pipeline/pkg/internal/resultref\"","\t\"github.com/tektoncd/pipeline/pkg/pod\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\t\"github.com/tektoncd/pipeline/pkg/workspace\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/util/sets\"",")","","const (","\t// objectIndividualVariablePattern is the reference pattern for object individual keys params.\u003cobject_param_name\u003e.\u003ckey_name\u003e","\tobjectIndividualVariablePattern = \"params.%s.%s\"",")","","var (","\tparamPatterns = []string{","\t\t\"params.%s\",","\t\t\"params[%q]\",","\t\t\"params['%s']\",","\t\t// FIXME(vdemeester) Remove that with deprecating v1beta1","\t\t\"inputs.params.%s\",","\t}","","\tsubstitutionToParamNamePatterns = []string{","\t\t`^params\\.(\\w+)$`,","\t\t`^params\\[\"([^\"]+)\"\\]$`,","\t\t`^params\\['([^']+)'\\]$`,","\t\t// FIXME(vdemeester) Remove that with deprecating v1beta1","\t\t`^inputs\\.params\\.(\\w+)$`,","\t}","","\tparamIndexRegexPatterns = []string{","\t\t`\\$\\(params.%s\\[([0-9]*)*\\*?\\]\\)`,","\t\t`\\$\\(params\\[%q\\]\\[([0-9]*)*\\*?\\]\\)`,","\t\t`\\$\\(params\\['%s'\\]\\[([0-9]*)*\\*?\\]\\)`,","\t}",")","","// applyStepActionParameters applies the params from the task and the underlying step to the referenced stepaction.","// substitution order:","// 1. taskrun parameter values in step parameters","// 2. step-provided parameter values","// 3. default values that reference other parameters","// 4. simple default values","// 5. step result references","func applyStepActionParameters(step *v1.Step, spec *v1.TaskSpec, tr *v1.TaskRun, stepParams v1.Params, defaults []v1.ParamSpec) (*v1.Step, error) {","\t// 1. taskrun parameter substitutions to step parameters","\tif stepParams != nil {","\t\tstringR, arrayR, objectR := getTaskParameters(spec, tr, spec.Params...)","\t\tstepParams = stepParams.ReplaceVariables(stringR, arrayR, objectR)","\t}","","\t// 2. step provided parameters","\tstepProvidedParams := make(map[string]v1.ParamValue)","\tfor _, sp := range stepParams {","\t\tstepProvidedParams[sp.Name] = sp.Value","\t}","\t// 3,4. get replacements from default params (both referenced and simple)","\tstringReplacements, arrayReplacements, objectReplacements := replacementsFromDefaultParams(defaults)","\t// process parameter values in order of substitution (2,3,4)","\tprocessedParams := make([]v1.Param, 0, len(defaults))","\t// keep track of parameters that need resolution and their references","\tparamsNeedingResolution := make(map[string]bool)","\tparamReferenceMap := make(map[string][]string) // maps param name to names of params it references","","\t// collect parameter references and handle parameters without references","\tfor _, p := range defaults {","\t\t// 2. step provided parameters","\t\tif value, exists := stepProvidedParams[p.Name]; exists {","\t\t\t// parameter provided by step, add it to processed","\t\t\tprocessedParams = append(processedParams, v1.Param{","\t\t\t\tName:  p.Name,","\t\t\t\tValue: value,","\t\t\t})","\t\t\tcontinue","\t\t}","","\t\t// 3. default params","\t\tif p.Default != nil {","\t\t\tif !strings.Contains(p.Default.StringVal, \"$(params.\") {","\t\t\t\t// parameter has no references, add it to processed","\t\t\t\tprocessedParams = append(processedParams, v1.Param{","\t\t\t\t\tName:  p.Name,","\t\t\t\t\tValue: *p.Default,","\t\t\t\t})","\t\t\t\tcontinue","\t\t\t}","","\t\t\t// parameter has references to other parameters, track them \u003e:(","\t\t\tparamsNeedingResolution[p.Name] = true","\t\t\tmatches, _ := substitution.ExtractVariableExpressions(p.Default.StringVal, \"params\")","\t\t\treferencedParams := make([]string, 0, len(matches))","\t\t\tfor _, match := range matches {","\t\t\t\tparamName := strings.TrimSuffix(strings.TrimPrefix(match, \"$(params.\"), \")\")","\t\t\t\treferencedParams = append(referencedParams, paramName)","\t\t\t}","\t\t\tparamReferenceMap[p.Name] = referencedParams","\t\t}","\t}","","\t// process parameters until no more can be resolved","\tfor len(paramsNeedingResolution) \u003e 0 {","\t\tparamWasResolved := false","\t\t// track unresolved params and their references","\t\tunresolvedParams := make(map[string][]string)","","\t\tfor paramName := range paramsNeedingResolution {","\t\t\tcanResolveParam := true","\t\t\tfor _, referencedParam := range paramReferenceMap[paramName] {","\t\t\t\t// Check if referenced parameter is processed","\t\t\t\tisReferenceResolved := false","\t\t\t\tfor _, pp := range processedParams {","\t\t\t\t\tif pp.Name == referencedParam {","\t\t\t\t\t\tisReferenceResolved = true","\t\t\t\t\t\tbreak","\t\t\t\t\t}","\t\t\t\t}","\t\t\t\tif !isReferenceResolved {","\t\t\t\t\tcanResolveParam = false","\t\t\t\t\tunresolvedParams[paramName] = append(unresolvedParams[paramName], referencedParam)","\t\t\t\t\tbreak","\t\t\t\t}","\t\t\t}","","\t\t\tif canResolveParam {","\t\t\t\t// process this parameter as all its references have been resolved","\t\t\t\tfor _, p := range defaults {","\t\t\t\t\tif p.Name == paramName {","\t\t\t\t\t\tdefaultValue := *p.Default","\t\t\t\t\t\tresolvedValue := defaultValue.StringVal","\t\t\t\t\t\t// hydrate parameter references","\t\t\t\t\t\tfor _, referencedParam := range paramReferenceMap[paramName] {","\t\t\t\t\t\t\tfor _, pp := range processedParams {","\t\t\t\t\t\t\t\tif pp.Name == referencedParam {","\t\t\t\t\t\t\t\t\tresolvedValue = strings.ReplaceAll(","\t\t\t\t\t\t\t\t\t\tresolvedValue,","\t\t\t\t\t\t\t\t\t\tfmt.Sprintf(\"$(params.%s)\", referencedParam),","\t\t\t\t\t\t\t\t\t\tpp.Value.StringVal,","\t\t\t\t\t\t\t\t\t)","\t\t\t\t\t\t\t\t\tbreak","\t\t\t\t\t\t\t\t}","\t\t\t\t\t\t\t}","\t\t\t\t\t\t}","\t\t\t\t\t\tdefaultValue.StringVal = resolvedValue","\t\t\t\t\t\tprocessedParams = append(processedParams, v1.Param{","\t\t\t\t\t\t\tName:  paramName,","\t\t\t\t\t\t\tValue: defaultValue,","\t\t\t\t\t\t})","\t\t\t\t\t\tdelete(paramsNeedingResolution, paramName)","\t\t\t\t\t\tparamWasResolved = true","\t\t\t\t\t\tbreak","\t\t\t\t\t}","\t\t\t\t}","\t\t\t}","\t\t}","","\t\t// unresolvable parameters or circular dependencies","\t\tif !paramWasResolved {","\t\t\t// check parameter references to a non-existent parameter","\t\t\tfor param, unresolvedRefs := range unresolvedParams {","\t\t\t\t// check referenced parameters in defaults","\t\t\t\tfor _, ref := range unresolvedRefs {","\t\t\t\t\texists := false","\t\t\t\t\tfor _, p := range defaults {","\t\t\t\t\t\tif p.Name == ref {","\t\t\t\t\t\t\texists = true","\t\t\t\t\t\t\tbreak","\t\t\t\t\t\t}","\t\t\t\t\t}","\t\t\t\t\tif !exists {","\t\t\t\t\t\treturn nil, fmt.Errorf(\"parameter %q references non-existent parameter %q\", param, ref)","\t\t\t\t\t}","\t\t\t\t}","\t\t\t\t// parameters exist but can't be resolved hence it's a circular dependency","\t\t\t\treturn nil, errors.New(\"circular dependency detected in parameter references\")","\t\t\t}","\t\t}","\t}","","\t// apply the processed parameters and merge all replacements (2,3,4)","\tprocStringReplacements, procArrayReplacements, procObjectReplacements := replacementsFromParams(processedParams)","\t// merge replacements from defaults and processed params","\tfor k, v := range procStringReplacements {","\t\tstringReplacements[k] = v","\t}","\tfor k, v := range procArrayReplacements {","\t\tarrayReplacements[k] = v","\t}","\tfor k, v := range procObjectReplacements {","\t\tif objectReplacements[k] == nil {","\t\t\tobjectReplacements[k] = v","\t\t} else {","\t\t\tfor key, val := range v {","\t\t\t\tobjectReplacements[k][key] = val","\t\t\t}","\t\t}","\t}","","\t// 5. set step result replacements last","\tif stepResultReplacements, err := replacementsFromStepResults(step, stepParams, defaults); err != nil {","\t\treturn nil, err","\t} else {","\t\t// merge step result replacements into string replacements last","\t\tfor k, v := range stepResultReplacements {","\t\t\tstringReplacements[k] = v","\t\t}","\t}","","\t// check if there are duplicate keys in the replacements","\t// if the same key is present in both stringReplacements and arrayReplacements, it means","\t// that the default value and the passed value have different types.","\tif err := checkForDuplicateKeys(stringReplacements, arrayReplacements); err != nil {","\t\treturn nil, err","\t}","","\tcontainer.ApplyStepReplacements(step, stringReplacements, arrayReplacements)","","\treturn step, nil","}","","// checkForDuplicateKeys checks if there are duplicate keys in the replacements","func checkForDuplicateKeys(stringReplacements map[string]string, arrayReplacements map[string][]string) error {","\tkeys := make([]string, 0, len(stringReplacements))","\tfor k := range stringReplacements {","\t\tkeys = append(keys, k)","\t}","\tsort.Strings(keys)","\tfor _, k := range keys {","\t\tif _, ok := arrayReplacements[k]; ok {","\t\t\tparamName := paramNameFromReplacementKey(k)","\t\t\treturn fmt.Errorf(\"invalid parameter substitution: %s. Please check the types of the default value and the passed value\", paramName)","\t\t}","\t}","\treturn nil","}","","// paramNameFromReplacementKey returns the param name from the replacement key in best effort","func paramNameFromReplacementKey(key string) string {","\tfor _, regexPattern := range substitutionToParamNamePatterns {","\t\tre := regexp.MustCompile(regexPattern)","\t\tif matches := re.FindStringSubmatch(key); matches != nil {","\t\t\treturn matches[1]","\t\t}","\t}","\t// If no match is found, return the key","\treturn key","}","","// findArrayIndexParamUsage finds the array index in a string using array param substitution","func findArrayIndexParamUsage(s string, paramName string, stepName string, resultName string, stringReplacements map[string]string) map[string]string {","\tfor _, pattern := range paramIndexRegexPatterns {","\t\tarrayIndexingRegex := regexp.MustCompile(fmt.Sprintf(pattern, paramName))","\t\tmatches := arrayIndexingRegex.FindAllStringSubmatch(s, -1)","\t\tfor _, match := range matches {","\t\t\tif len(match) == 2 {","\t\t\t\tkey := strings.TrimSuffix(strings.TrimPrefix(match[0], \"$(\"), \")\")","\t\t\t\tif match[1] != \"\" {","\t\t\t\t\tstringReplacements[key] = fmt.Sprintf(\"$(steps.%s.results.%s[%s])\", stepName, resultName, match[1])","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn stringReplacements","}","","// replacementsArrayIdxStepResults looks for Step Result array usage with index in the Step's command, args, env and script.","func replacementsArrayIdxStepResults(step *v1.Step, paramName string, stepName string, resultName string) map[string]string {","\tstringReplacements := map[string]string{}","\tfor _, c := range step.Command {","\t\tstringReplacements = findArrayIndexParamUsage(c, paramName, stepName, resultName, stringReplacements)","\t}","\tfor _, a := range step.Args {","\t\tstringReplacements = findArrayIndexParamUsage(a, paramName, stepName, resultName, stringReplacements)","\t}","\tfor _, e := range step.Env {","\t\tstringReplacements = findArrayIndexParamUsage(e.Value, paramName, stepName, resultName, stringReplacements)","\t}","\treturn stringReplacements","}","","// replacementsFromStepResults generates string replacements for params whose values is a variable substitution of a step result.","func replacementsFromStepResults(step *v1.Step, stepParams v1.Params, defaults []v1.ParamSpec) (map[string]string, error) {","\tstringReplacements := map[string]string{}","\tfor _, sp := range stepParams {","\t\tif sp.Value.StringVal != \"\" \u0026\u0026 strings.HasPrefix(sp.Value.StringVal, \"$(steps.\") {","\t\t\t// eg: when parameter p1 references a step result, replace:","\t\t\t// $(params.p1) with $(steps.step1.results.foo)","\t\t\tvalue := strings.TrimSuffix(strings.TrimPrefix(sp.Value.StringVal, \"$(\"), \")\")","\t\t\tpr, err := resultref.ParseStepExpression(value)","\t\t\tif err != nil {","\t\t\t\treturn nil, err","\t\t\t}","\t\t\tfor _, d := range defaults {","\t\t\t\tif d.Name == sp.Name {","\t\t\t\t\tswitch d.Type {","\t\t\t\t\tcase v1.ParamTypeObject:","\t\t\t\t\t\tfor k := range d.Properties {","\t\t\t\t\t\t\tstringReplacements[fmt.Sprintf(\"params.%s.%s\", d.Name, k)] = fmt.Sprintf(\"$(steps.%s.results.%s.%s)\", pr.ResourceName, pr.ResultName, k)","\t\t\t\t\t\t}","\t\t\t\t\tcase v1.ParamTypeArray:","\t\t\t\t\t\t// for array parameters","","\t\t\t\t\t\t// with star notation, replace:","\t\t\t\t\t\t// $(params.p1[*]) with $(steps.step1.results.foo[*])","\t\t\t\t\t\tfor _, pattern := range paramPatterns {","\t\t\t\t\t\t\tstringReplacements[fmt.Sprintf(pattern+\"[*]\", d.Name)] = fmt.Sprintf(\"$(steps.%s.results.%s[*])\", pr.ResourceName, pr.ResultName)","\t\t\t\t\t\t}","\t\t\t\t\t\t// with index notation, replace:","\t\t\t\t\t\t// $(params.p1[idx]) with $(steps.step1.results.foo[idx])","\t\t\t\t\t\tfor k, v := range replacementsArrayIdxStepResults(step, d.Name, pr.ResourceName, pr.ResultName) {","\t\t\t\t\t\t\tstringReplacements[k] = v","\t\t\t\t\t\t}","\t\t\t\t\tcase v1.ParamTypeString:","\t\t\t\t\t\tfallthrough","\t\t\t\t\tdefault:","\t\t\t\t\t\t// for string parameters and default case,","\t\t\t\t\t\t// replace any reference to the parameter with the step result reference","\t\t\t\t\t\t// since both use simple value substitution","\t\t\t\t\t\t// eg: replace $(params.p1) with $(steps.step1.results.foo)","\t\t\t\t\t\tfor _, pattern := range paramPatterns {","\t\t\t\t\t\t\tstringReplacements[fmt.Sprintf(pattern, d.Name)] = sp.Value.StringVal","\t\t\t\t\t\t}","\t\t\t\t\t}","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn stringReplacements, nil","}","","// getTaskParameters gets the string, array and object parameter variable replacements needed in the Task","func getTaskParameters(spec *v1.TaskSpec, tr *v1.TaskRun, defaults ...v1.ParamSpec) (map[string]string, map[string][]string, map[string]map[string]string) {","\t// This assumes that the TaskRun inputs have been validated against what the Task requests.","\t// Set params from Task defaults","\tstringReplacements, arrayReplacements, objectReplacements := replacementsFromDefaultParams(defaults)","","\t// Set and overwrite params with the ones from the TaskRun","\ttrStrings, trArrays, trObjects := replacementsFromParams(tr.Spec.Params)","\tfor k, v := range trStrings {","\t\tstringReplacements[k] = v","\t}","\tfor k, v := range trArrays {","\t\tarrayReplacements[k] = v","\t}","\tfor k, v := range trObjects {","\t\tfor key, val := range v {","\t\t\tif objectReplacements != nil {","\t\t\t\tif objectReplacements[k] != nil {","\t\t\t\t\tobjectReplacements[k][key] = val","\t\t\t\t} else {","\t\t\t\t\tobjectReplacements[k] = v","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\treturn stringReplacements, arrayReplacements, objectReplacements","}","","// ApplyParameters applies the params from a TaskRun.Parameters to a TaskSpec","func ApplyParameters(spec *v1.TaskSpec, tr *v1.TaskRun, defaults ...v1.ParamSpec) *v1.TaskSpec {","\tstringReplacements, arrayReplacements, objectReplacements := getTaskParameters(spec, tr, defaults...)","\treturn ApplyReplacements(spec, stringReplacements, arrayReplacements, objectReplacements)","}","","func replacementsFromDefaultParams(defaults v1.ParamSpecs) (map[string]string, map[string][]string, map[string]map[string]string) {","\tstringReplacements := map[string]string{}","\tarrayReplacements := map[string][]string{}","\tobjectReplacements := map[string]map[string]string{}","","\t// First pass: collect all non-reference default values","\tfor _, p := range defaults {","\t\tif p.Default != nil \u0026\u0026 !strings.Contains(p.Default.StringVal, \"$(params.\") {","\t\t\tswitch p.Default.Type {","\t\t\tcase v1.ParamTypeArray:","\t\t\t\tfor _, pattern := range paramPatterns {","\t\t\t\t\tfor i := range len(p.Default.ArrayVal) {","\t\t\t\t\t\tstringReplacements[fmt.Sprintf(pattern+\"[%d]\", p.Name, i)] = p.Default.ArrayVal[i]","\t\t\t\t\t}","\t\t\t\t\tarrayReplacements[fmt.Sprintf(pattern, p.Name)] = p.Default.ArrayVal","\t\t\t\t}","\t\t\tcase v1.ParamTypeObject:","\t\t\t\tfor _, pattern := range paramPatterns {","\t\t\t\t\tobjectReplacements[fmt.Sprintf(pattern, p.Name)] = p.Default.ObjectVal","\t\t\t\t}","\t\t\t\tfor k, v := range p.Default.ObjectVal {","\t\t\t\t\tstringReplacements[fmt.Sprintf(objectIndividualVariablePattern, p.Name, k)] = v","\t\t\t\t}","\t\t\tcase v1.ParamTypeString:","\t\t\t\tfallthrough","\t\t\tdefault:","\t\t\t\tfor _, pattern := range paramPatterns {","\t\t\t\t\tstringReplacements[fmt.Sprintf(pattern, p.Name)] = p.Default.StringVal","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\t// Second pass: handle parameter references in default values","\tfor _, p := range defaults {","\t\tif p.Default != nil \u0026\u0026 strings.Contains(p.Default.StringVal, \"$(params.\") {","\t\t\t// extract referenced parameter name","\t\t\tmatches, _ := substitution.ExtractVariableExpressions(p.Default.StringVal, \"params\")","\t\t\tfor _, match := range matches {","\t\t\t\tparamName := strings.TrimPrefix(match, \"$(params.\")","\t\t\t\tparamName = strings.TrimSuffix(paramName, \")\")","","\t\t\t\t// find referenced parameter value","\t\t\t\tfor _, pattern := range paramPatterns {","\t\t\t\t\tkey := fmt.Sprintf(pattern, paramName)","\t\t\t\t\tif value, exists := stringReplacements[key]; exists {","\t\t\t\t\t\t// Apply the value to this parameter's default","\t\t\t\t\t\tresolvedValue := strings.ReplaceAll(p.Default.StringVal, match, value)","\t\t\t\t\t\tfor _, pattern := range paramPatterns {","\t\t\t\t\t\t\tstringReplacements[fmt.Sprintf(pattern, p.Name)] = resolvedValue","\t\t\t\t\t\t}","\t\t\t\t\t\tbreak","\t\t\t\t\t}","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\treturn stringReplacements, arrayReplacements, objectReplacements","}","","func replacementsFromParams(params v1.Params) (map[string]string, map[string][]string, map[string]map[string]string) {","\t// stringReplacements is used for standard single-string stringReplacements, while arrayReplacements contains arrays","\t// and objectReplacements contains objects that need to be further processed.","\tstringReplacements := map[string]string{}","\tarrayReplacements := map[string][]string{}","\tobjectReplacements := map[string]map[string]string{}","","\tfor _, p := range params {","\t\tswitch p.Value.Type {","\t\tcase v1.ParamTypeArray:","\t\t\tfor _, pattern := range paramPatterns {","\t\t\t\tfor i := range len(p.Value.ArrayVal) {","\t\t\t\t\tstringReplacements[fmt.Sprintf(pattern+\"[%d]\", p.Name, i)] = p.Value.ArrayVal[i]","\t\t\t\t}","\t\t\t\tarrayReplacements[fmt.Sprintf(pattern, p.Name)] = p.Value.ArrayVal","\t\t\t}","\t\tcase v1.ParamTypeObject:","\t\t\tfor _, pattern := range paramPatterns {","\t\t\t\tobjectReplacements[fmt.Sprintf(pattern, p.Name)] = p.Value.ObjectVal","\t\t\t}","\t\t\tfor k, v := range p.Value.ObjectVal {","\t\t\t\tstringReplacements[fmt.Sprintf(objectIndividualVariablePattern, p.Name, k)] = v","\t\t\t}","\t\tcase v1.ParamTypeString:","\t\t\tfallthrough","\t\tdefault:","\t\t\tfor _, pattern := range paramPatterns {","\t\t\t\tstringReplacements[fmt.Sprintf(pattern, p.Name)] = p.Value.StringVal","\t\t\t}","\t\t}","\t}","","\treturn stringReplacements, arrayReplacements, objectReplacements","}","","func getContextReplacements(taskName string, tr *v1.TaskRun) map[string]string {","\treturn map[string]string{","\t\t\"context.taskRun.name\":      tr.Name,","\t\t\"context.task.name\":         taskName,","\t\t\"context.taskRun.namespace\": tr.Namespace,","\t\t\"context.taskRun.uid\":       string(tr.ObjectMeta.UID),","\t\t\"context.task.retry-count\":  strconv.Itoa(len(tr.Status.RetriesStatus)),","\t}","}","","// ApplyContexts applies the substitution from $(context.(taskRun|task).*) with the specified values.","// Uses \"\" as a default if a value is not available.","func ApplyContexts(spec *v1.TaskSpec, taskName string, tr *v1.TaskRun) *v1.TaskSpec {","\treturn ApplyReplacements(spec, getContextReplacements(taskName, tr), map[string][]string{}, map[string]map[string]string{})","}","","// ApplyWorkspaces applies the substitution from paths that the workspaces in declarations mounted to, the","// volumes that bindings are realized with in the task spec and the PersistentVolumeClaim names for the","// workspaces.","func ApplyWorkspaces(ctx context.Context, spec *v1.TaskSpec, declarations []v1.WorkspaceDeclaration, bindings []v1.WorkspaceBinding, vols map[string]corev1.Volume) *v1.TaskSpec {","\tstringReplacements := map[string]string{}","","\tbindNames := sets.NewString()","\tfor _, binding := range bindings {","\t\tbindNames.Insert(binding.Name)","\t}","","\tfor _, declaration := range declarations {","\t\tprefix := fmt.Sprintf(\"workspaces.%s.\", declaration.Name)","\t\tif declaration.Optional \u0026\u0026 !bindNames.Has(declaration.Name) {","\t\t\tstringReplacements[prefix+\"bound\"] = \"false\"","\t\t\tstringReplacements[prefix+\"path\"] = \"\"","\t\t} else {","\t\t\tstringReplacements[prefix+\"bound\"] = \"true\"","\t\t\tspec = applyWorkspaceMountPath(prefix+\"path\", spec, declaration)","\t\t}","\t}","","\tfor name, vol := range vols {","\t\tstringReplacements[fmt.Sprintf(\"workspaces.%s.volume\", name)] = vol.Name","\t}","\tfor _, binding := range bindings {","\t\tif binding.PersistentVolumeClaim != nil {","\t\t\tstringReplacements[fmt.Sprintf(\"workspaces.%s.claim\", binding.Name)] = binding.PersistentVolumeClaim.ClaimName","\t\t} else {","\t\t\tstringReplacements[fmt.Sprintf(\"workspaces.%s.claim\", binding.Name)] = \"\"","\t\t}","\t}","\treturn ApplyReplacements(spec, stringReplacements, map[string][]string{}, map[string]map[string]string{})","}","","// ApplyParametersToWorkspaceBindings applies parameters to the WorkspaceBindings of a TaskRun. It takes a TaskSpec and a TaskRun as input and returns the modified TaskRun.","func ApplyParametersToWorkspaceBindings(ts *v1.TaskSpec, tr *v1.TaskRun) *v1.TaskRun {","\ttsCopy := ts.DeepCopy()","\tparameters, _, _ := getTaskParameters(tsCopy, tr, tsCopy.Params...)","\ttr.Spec.Workspaces = workspace.ReplaceWorkspaceBindingsVars(tr.Spec.Workspaces, parameters)","\treturn tr","}","","// applyWorkspaceMountPath accepts a workspace path variable of the form $(workspaces.foo.path) and replaces","// it in the fields of the TaskSpec. A new updated TaskSpec is returned. Steps or Sidecars in the TaskSpec","// that override the mountPath will receive that mountPath in place of the variable's value. Other Steps and","// Sidecars will see either the workspace's declared mountPath or the default of /workspaces/\u003cname\u003e.","func applyWorkspaceMountPath(variable string, spec *v1.TaskSpec, declaration v1.WorkspaceDeclaration) *v1.TaskSpec {","\tstringReplacements := map[string]string{variable: \"\"}","\temptyArrayReplacements := map[string][]string{}","\tdefaultMountPath := declaration.GetMountPath()","\t// Replace instances of the workspace path variable that are overridden per-Step","\tfor i := range spec.Steps {","\t\tstep := \u0026spec.Steps[i]","\t\tfor _, usage := range step.Workspaces {","\t\t\tif usage.Name == declaration.Name \u0026\u0026 usage.MountPath != \"\" {","\t\t\t\tstringReplacements[variable] = usage.MountPath","\t\t\t\tcontainer.ApplyStepReplacements(step, stringReplacements, emptyArrayReplacements)","\t\t\t}","\t\t}","\t}","\t// Replace instances of the workspace path variable that are overridden per-Sidecar","\tfor i := range spec.Sidecars {","\t\tsidecar := \u0026spec.Sidecars[i]","\t\tfor _, usage := range sidecar.Workspaces {","\t\t\tif usage.Name == declaration.Name \u0026\u0026 usage.MountPath != \"\" {","\t\t\t\tstringReplacements[variable] = usage.MountPath","\t\t\t\tcontainer.ApplySidecarReplacements(sidecar, stringReplacements, emptyArrayReplacements)","\t\t\t}","\t\t}","\t}","\t// Replace any remaining instances of the workspace path variable, which should fall","\t// back to the mount path specified in the declaration.","\tstringReplacements[variable] = defaultMountPath","\treturn ApplyReplacements(spec, stringReplacements, emptyArrayReplacements, map[string]map[string]string{})","}","","// ApplyResults applies the substitution from values in results and step results which are referenced in spec as subitems","// of the replacementStr.","func ApplyResults(spec *v1.TaskSpec) *v1.TaskSpec {","\t// Apply all the Step Result replacements","\tfor i := range spec.Steps {","\t\tstringReplacements := getStepResultReplacements(spec.Steps[i], i)","\t\tcontainer.ApplyStepReplacements(\u0026spec.Steps[i], stringReplacements, map[string][]string{})","\t}","\tstringReplacements := getTaskResultReplacements(spec)","\treturn ApplyReplacements(spec, stringReplacements, map[string][]string{}, map[string]map[string]string{})","}","","// getStepResultReplacements creates all combinations of string replacements from Step Results.","func getStepResultReplacements(step v1.Step, idx int) map[string]string {","\tstringReplacements := map[string]string{}","","\tpatterns := []string{","\t\t\"step.results.%s.path\",","\t\t\"step.results[%q].path\",","\t\t\"step.results['%s'].path\",","\t}","\tstepName := pod.StepName(step.Name, idx)","\tfor _, result := range step.Results {","\t\tfor _, pattern := range patterns {","\t\t\tstringReplacements[fmt.Sprintf(pattern, result.Name)] = filepath.Join(pipeline.StepsDir, stepName, \"results\", result.Name)","\t\t}","\t}","\treturn stringReplacements","}","","// getTaskResultReplacements creates all combinations of string replacements from TaskResults.","func getTaskResultReplacements(spec *v1.TaskSpec) map[string]string {","\tstringReplacements := map[string]string{}","","\tpatterns := []string{","\t\t\"results.%s.path\",","\t\t\"results[%q].path\",","\t\t\"results['%s'].path\",","\t}","","\tfor _, result := range spec.Results {","\t\tfor _, pattern := range patterns {","\t\t\tstringReplacements[fmt.Sprintf(pattern, result.Name)] = filepath.Join(pipeline.DefaultResultPath, result.Name)","\t\t}","\t}","\treturn stringReplacements","}","","// ApplyArtifacts replaces the occurrences of artifacts.path and step.artifacts.path with the absolute tekton internal path","func ApplyArtifacts(spec *v1.TaskSpec) *v1.TaskSpec {","\tfor i := range spec.Steps {","\t\tstringReplacements := getArtifactReplacements(spec.Steps[i], i)","\t\tcontainer.ApplyStepReplacements(\u0026spec.Steps[i], stringReplacements, map[string][]string{})","\t}","\treturn spec","}","","func getArtifactReplacements(step v1.Step, idx int) map[string]string {","\tstringReplacements := map[string]string{}","\tstepName := pod.StepName(step.Name, idx)","\tstringReplacements[artifactref.StepArtifactPathPattern] = filepath.Join(pipeline.StepsDir, stepName, \"artifacts\", \"provenance.json\")","\tstringReplacements[artifactref.TaskArtifactPathPattern] = filepath.Join(pipeline.ArtifactsDir, \"provenance.json\")","","\treturn stringReplacements","}","","// ApplyStepExitCodePath replaces the occurrences of exitCode path with the absolute tekton internal path","// Replace $(steps.\u003cstep-name\u003e.exitCode.path) with pipeline.StepPath/\u003cstep-name\u003e/exitCode","func ApplyStepExitCodePath(spec *v1.TaskSpec) *v1.TaskSpec {","\tstringReplacements := map[string]string{}","","\tfor i, step := range spec.Steps {","\t\tstringReplacements[fmt.Sprintf(\"steps.%s.exitCode.path\", pod.StepName(step.Name, i))] = filepath.Join(pipeline.StepsDir, pod.StepName(step.Name, i), \"exitCode\")","\t}","\treturn ApplyReplacements(spec, stringReplacements, map[string][]string{}, map[string]map[string]string{})","}","","// ApplyCredentialsPath applies a substitution of the key $(credentials.path) with the path that credentials","// from annotated secrets are written to.","func ApplyCredentialsPath(spec *v1.TaskSpec, path string) *v1.TaskSpec {","\tstringReplacements := map[string]string{","\t\t\"credentials.path\": path,","\t}","\treturn ApplyReplacements(spec, stringReplacements, map[string][]string{}, map[string]map[string]string{})","}","","// ApplyReplacements replaces placeholders for declared parameters with the specified replacements.","func ApplyReplacements(spec *v1.TaskSpec, stringReplacements map[string]string, arrayReplacements map[string][]string, objectReplacements map[string]map[string]string) *v1.TaskSpec {","\tspec = spec.DeepCopy()","","\t// Apply variable expansion to steps fields.","\tsteps := spec.Steps","\tfor i := range steps {","\t\tif steps[i].Params != nil {","\t\t\tsteps[i].Params = steps[i].Params.ReplaceVariables(stringReplacements, arrayReplacements, objectReplacements)","\t\t}","\t\tcontainer.ApplyStepReplacements(\u0026steps[i], stringReplacements, arrayReplacements)","\t}","","\t// Apply variable expansion to stepTemplate fields.","\tif spec.StepTemplate != nil {","\t\tcontainer.ApplyStepTemplateReplacements(spec.StepTemplate, stringReplacements, arrayReplacements)","\t}","","\t// Apply variable expansion to the build's volumes","\tfor i, v := range spec.Volumes {","\t\tspec.Volumes[i].Name = substitution.ApplyReplacements(v.Name, stringReplacements)","\t\tif v.VolumeSource.ConfigMap != nil {","\t\t\tspec.Volumes[i].ConfigMap.Name = substitution.ApplyReplacements(v.ConfigMap.Name, stringReplacements)","\t\t\tfor index, item := range v.ConfigMap.Items {","\t\t\t\tspec.Volumes[i].ConfigMap.Items[index].Key = substitution.ApplyReplacements(item.Key, stringReplacements)","\t\t\t\tspec.Volumes[i].ConfigMap.Items[index].Path = substitution.ApplyReplacements(item.Path, stringReplacements)","\t\t\t}","\t\t}","\t\tif v.VolumeSource.Secret != nil {","\t\t\tspec.Volumes[i].Secret.SecretName = substitution.ApplyReplacements(v.Secret.SecretName, stringReplacements)","\t\t\tfor index, item := range v.Secret.Items {","\t\t\t\tspec.Volumes[i].Secret.Items[index].Key = substitution.ApplyReplacements(item.Key, stringReplacements)","\t\t\t\tspec.Volumes[i].Secret.Items[index].Path = substitution.ApplyReplacements(item.Path, stringReplacements)","\t\t\t}","\t\t}","\t\tif v.PersistentVolumeClaim != nil {","\t\t\tspec.Volumes[i].PersistentVolumeClaim.ClaimName = substitution.ApplyReplacements(v.PersistentVolumeClaim.ClaimName, stringReplacements)","\t\t}","\t\tif v.Projected != nil {","\t\t\tfor _, s := range spec.Volumes[i].Projected.Sources {","\t\t\t\tif s.ConfigMap != nil {","\t\t\t\t\ts.ConfigMap.Name = substitution.ApplyReplacements(s.ConfigMap.Name, stringReplacements)","\t\t\t\t}","\t\t\t\tif s.Secret != nil {","\t\t\t\t\ts.Secret.Name = substitution.ApplyReplacements(s.Secret.Name, stringReplacements)","\t\t\t\t}","\t\t\t\tif s.ServiceAccountToken != nil {","\t\t\t\t\ts.ServiceAccountToken.Audience = substitution.ApplyReplacements(s.ServiceAccountToken.Audience, stringReplacements)","\t\t\t\t}","\t\t\t}","\t\t}","\t\tif v.CSI != nil {","\t\t\tif v.CSI.NodePublishSecretRef != nil {","\t\t\t\tspec.Volumes[i].CSI.NodePublishSecretRef.Name = substitution.ApplyReplacements(v.CSI.NodePublishSecretRef.Name, stringReplacements)","\t\t\t}","\t\t\tif v.CSI.VolumeAttributes != nil {","\t\t\t\tfor key, value := range v.CSI.VolumeAttributes {","\t\t\t\t\tspec.Volumes[i].CSI.VolumeAttributes[key] = substitution.ApplyReplacements(value, stringReplacements)","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\tfor i, v := range spec.Workspaces {","\t\tspec.Workspaces[i].MountPath = substitution.ApplyReplacements(v.MountPath, stringReplacements)","\t}","","\t// Apply variable substitution to the sidecar definitions","\tsidecars := spec.Sidecars","\tfor i := range sidecars {","\t\tcontainer.ApplySidecarReplacements(\u0026sidecars[i], stringReplacements, arrayReplacements)","\t}","","\treturn spec","}","","// ApplyPodTemplateParameters applies parameter substitution to a PodTemplate","func ApplyPodTemplateReplacements(podTemplate *podtpl.Template, tr *v1.TaskRun, defaults ...v1.ParamSpec) *podtpl.Template {","\tif podTemplate == nil {","\t\treturn nil","\t}","","\tresult := podTemplate.DeepCopy()","","\tstringReplacements, _, _ := getTaskParameters(nil, tr, defaults...)","","\t// Apply substitution to NodeSelector","\tif result.NodeSelector != nil {","\t\tnewNodeSelector := make(map[string]string)","\t\tfor k, v := range result.NodeSelector {","\t\t\tnewKey := substitution.ApplyReplacements(k, stringReplacements)","\t\t\tnewValue := substitution.ApplyReplacements(v, stringReplacements)","\t\t\tnewNodeSelector[newKey] = newValue","\t\t}","\t\tresult.NodeSelector = newNodeSelector","\t}","","\t// Apply substitution to Tolerations","\tfor i := range result.Tolerations {","\t\tresult.Tolerations[i].Key = substitution.ApplyReplacements(result.Tolerations[i].Key, stringReplacements)","\t\tresult.Tolerations[i].Value = substitution.ApplyReplacements(result.Tolerations[i].Value, stringReplacements)","\t\tresult.Tolerations[i].Operator = corev1.TolerationOperator(substitution.ApplyReplacements(string(result.Tolerations[i].Operator), stringReplacements))","\t\tresult.Tolerations[i].Effect = corev1.TaintEffect(substitution.ApplyReplacements(string(result.Tolerations[i].Effect), stringReplacements))","\t}","","\t// Apply substitution to Affinity","\tif result.Affinity != nil {","\t\tapplyAffinityReplacements(result.Affinity, stringReplacements)","\t}","","\t// Apply substitution to SecurityContext labels and annotations","\tif result.SecurityContext != nil {","\t\tapplySecurityContextReplacements(result.SecurityContext, stringReplacements)","\t}","","\t// Apply substitution to RuntimeClassName","\tif result.RuntimeClassName != nil {","\t\truntimeClassName := substitution.ApplyReplacements(*result.RuntimeClassName, stringReplacements)","\t\tresult.RuntimeClassName = \u0026runtimeClassName","\t}","","\t// Apply substitution to SchedulerName","\tif result.SchedulerName != \"\" {","\t\tresult.SchedulerName = substitution.ApplyReplacements(result.SchedulerName, stringReplacements)","\t}","","\t// Apply substitution to PriorityClassName","\tif result.PriorityClassName != nil {","\t\tpriorityClassName := substitution.ApplyReplacements(*result.PriorityClassName, stringReplacements)","\t\tresult.PriorityClassName = \u0026priorityClassName","\t}","","\t// Apply substitution to ImagePullSecrets","\tfor i := range result.ImagePullSecrets {","\t\tresult.ImagePullSecrets[i].Name = substitution.ApplyReplacements(result.ImagePullSecrets[i].Name, stringReplacements)","\t}","","\t// Apply substitution to HostAliases","\tfor i := range result.HostAliases {","\t\tresult.HostAliases[i].IP = substitution.ApplyReplacements(result.HostAliases[i].IP, stringReplacements)","\t\tfor j := range result.HostAliases[i].Hostnames {","\t\t\tresult.HostAliases[i].Hostnames[j] = substitution.ApplyReplacements(result.HostAliases[i].Hostnames[j], stringReplacements)","\t\t}","\t}","","\t// Apply substitution to TopologySpreadConstraints","\tfor i := range result.TopologySpreadConstraints {","\t\tresult.TopologySpreadConstraints[i].TopologyKey = substitution.ApplyReplacements(result.TopologySpreadConstraints[i].TopologyKey, stringReplacements)","\t\tif result.TopologySpreadConstraints[i].LabelSelector != nil {","\t\t\tapplyLabelSelectorReplacements(result.TopologySpreadConstraints[i].LabelSelector, stringReplacements)","\t\t}","\t}","","\t// Apply substitution to DNSPolicy","\tif result.DNSPolicy != nil {","\t\tdnsPolicy := corev1.DNSPolicy(substitution.ApplyReplacements(string(*result.DNSPolicy), stringReplacements))","\t\tresult.DNSPolicy = \u0026dnsPolicy","\t}","","\t// Apply substitution to DNSConfig","\tif result.DNSConfig != nil {","\t\tapplyDNSConfigReplacements(result.DNSConfig, stringReplacements)","\t}","","\t// Apply substitution to Volumes","\tfor i := range result.Volumes {","\t\tapplyVolumeReplacements(\u0026result.Volumes[i], stringReplacements)","\t}","","\t// Apply substitution to Env","\tfor i := range result.Env {","\t\tresult.Env[i].Name = substitution.ApplyReplacements(result.Env[i].Name, stringReplacements)","\t\tresult.Env[i].Value = substitution.ApplyReplacements(result.Env[i].Value, stringReplacements)","\t\tif result.Env[i].ValueFrom != nil {","\t\t\tapplyEnvVarSourceReplacements(result.Env[i].ValueFrom, stringReplacements)","\t\t}","\t}","","\treturn result","}","","func applyAffinityReplacements(affinity *corev1.Affinity, stringReplacements map[string]string) {","\tif affinity.NodeAffinity != nil {","\t\tapplyNodeAffinityReplacements(affinity.NodeAffinity, stringReplacements)","\t}","\tif affinity.PodAffinity != nil {","\t\tapplyPodAffinityReplacements(affinity.PodAffinity, stringReplacements)","\t}","\tif affinity.PodAntiAffinity != nil {","\t\tapplyPodAntiAffinityReplacements(affinity.PodAntiAffinity, stringReplacements)","\t}","}","","func applyNodeAffinityReplacements(nodeAffinity *corev1.NodeAffinity, stringReplacements map[string]string) {","\tif nodeAffinity.RequiredDuringSchedulingIgnoredDuringExecution != nil {","\t\tfor i := range nodeAffinity.RequiredDuringSchedulingIgnoredDuringExecution.NodeSelectorTerms {","\t\t\tapplyNodeSelectorTermReplacements(\u0026nodeAffinity.RequiredDuringSchedulingIgnoredDuringExecution.NodeSelectorTerms[i], stringReplacements)","\t\t}","\t}","\tfor i := range nodeAffinity.PreferredDuringSchedulingIgnoredDuringExecution {","\t\tapplyNodeSelectorTermReplacements(\u0026nodeAffinity.PreferredDuringSchedulingIgnoredDuringExecution[i].Preference, stringReplacements)","\t}","}","","func applyNodeSelectorTermReplacements(term *corev1.NodeSelectorTerm, stringReplacements map[string]string) {","\tfor i := range term.MatchExpressions {","\t\tterm.MatchExpressions[i].Key = substitution.ApplyReplacements(term.MatchExpressions[i].Key, stringReplacements)","\t\tfor j := range term.MatchExpressions[i].Values {","\t\t\tterm.MatchExpressions[i].Values[j] = substitution.ApplyReplacements(term.MatchExpressions[i].Values[j], stringReplacements)","\t\t}","\t}","\tfor i := range term.MatchFields {","\t\tterm.MatchFields[i].Key = substitution.ApplyReplacements(term.MatchFields[i].Key, stringReplacements)","\t\tfor j := range term.MatchFields[i].Values {","\t\t\tterm.MatchFields[i].Values[j] = substitution.ApplyReplacements(term.MatchFields[i].Values[j], stringReplacements)","\t\t}","\t}","}","","func applyPodAffinityReplacements(podAffinity *corev1.PodAffinity, stringReplacements map[string]string) {","\tfor i := range podAffinity.RequiredDuringSchedulingIgnoredDuringExecution {","\t\tapplyPodAffinityTermReplacements(\u0026podAffinity.RequiredDuringSchedulingIgnoredDuringExecution[i], stringReplacements)","\t}","\tfor i := range podAffinity.PreferredDuringSchedulingIgnoredDuringExecution {","\t\tapplyPodAffinityTermReplacements(\u0026podAffinity.PreferredDuringSchedulingIgnoredDuringExecution[i].PodAffinityTerm, stringReplacements)","\t}","}","","func applyPodAntiAffinityReplacements(podAntiAffinity *corev1.PodAntiAffinity, stringReplacements map[string]string) {","\tfor i := range podAntiAffinity.RequiredDuringSchedulingIgnoredDuringExecution {","\t\tapplyPodAffinityTermReplacements(\u0026podAntiAffinity.RequiredDuringSchedulingIgnoredDuringExecution[i], stringReplacements)","\t}","\tfor i := range podAntiAffinity.PreferredDuringSchedulingIgnoredDuringExecution {","\t\tapplyPodAffinityTermReplacements(\u0026podAntiAffinity.PreferredDuringSchedulingIgnoredDuringExecution[i].PodAffinityTerm, stringReplacements)","\t}","}","","func applyPodAffinityTermReplacements(term *corev1.PodAffinityTerm, stringReplacements map[string]string) {","\tif term.LabelSelector != nil {","\t\tapplyLabelSelectorReplacements(term.LabelSelector, stringReplacements)","\t}","\tterm.TopologyKey = substitution.ApplyReplacements(term.TopologyKey, stringReplacements)","\tif term.NamespaceSelector != nil {","\t\tapplyLabelSelectorReplacements(term.NamespaceSelector, stringReplacements)","\t}","\tfor i := range term.Namespaces {","\t\tterm.Namespaces[i] = substitution.ApplyReplacements(term.Namespaces[i], stringReplacements)","\t}","}","","func applyLabelSelectorReplacements(selector *metav1.LabelSelector, stringReplacements map[string]string) {","\tif selector.MatchLabels != nil {","\t\tnewMatchLabels := make(map[string]string)","\t\tfor k, v := range selector.MatchLabels {","\t\t\tnewKey := substitution.ApplyReplacements(k, stringReplacements)","\t\t\tnewValue := substitution.ApplyReplacements(v, stringReplacements)","\t\t\tnewMatchLabels[newKey] = newValue","\t\t}","\t\tselector.MatchLabels = newMatchLabels","\t}","\tfor i := range selector.MatchExpressions {","\t\tselector.MatchExpressions[i].Key = substitution.ApplyReplacements(selector.MatchExpressions[i].Key, stringReplacements)","\t\tfor j := range selector.MatchExpressions[i].Values {","\t\t\tselector.MatchExpressions[i].Values[j] = substitution.ApplyReplacements(selector.MatchExpressions[i].Values[j], stringReplacements)","\t\t}","\t}","}","","func applySecurityContextReplacements(securityContext *corev1.PodSecurityContext, stringReplacements map[string]string) {","\t// Apply substitution to SELinuxOptions","\tif securityContext.SELinuxOptions != nil {","\t\tsecurityContext.SELinuxOptions.User = substitution.ApplyReplacements(securityContext.SELinuxOptions.User, stringReplacements)","\t\tsecurityContext.SELinuxOptions.Role = substitution.ApplyReplacements(securityContext.SELinuxOptions.Role, stringReplacements)","\t\tsecurityContext.SELinuxOptions.Type = substitution.ApplyReplacements(securityContext.SELinuxOptions.Type, stringReplacements)","\t\tsecurityContext.SELinuxOptions.Level = substitution.ApplyReplacements(securityContext.SELinuxOptions.Level, stringReplacements)","\t}","","\t// Apply substitution to WindowsOptions","\tif securityContext.WindowsOptions != nil {","\t\tif securityContext.WindowsOptions.GMSACredentialSpecName != nil {","\t\t\tgmsaCredentialSpecName := substitution.ApplyReplacements(*securityContext.WindowsOptions.GMSACredentialSpecName, stringReplacements)","\t\t\tsecurityContext.WindowsOptions.GMSACredentialSpecName = \u0026gmsaCredentialSpecName","\t\t}","\t\tif securityContext.WindowsOptions.GMSACredentialSpec != nil {","\t\t\tgmsaCredentialSpec := substitution.ApplyReplacements(*securityContext.WindowsOptions.GMSACredentialSpec, stringReplacements)","\t\t\tsecurityContext.WindowsOptions.GMSACredentialSpec = \u0026gmsaCredentialSpec","\t\t}","\t\tif securityContext.WindowsOptions.RunAsUserName != nil {","\t\t\trunAsUserName := substitution.ApplyReplacements(*securityContext.WindowsOptions.RunAsUserName, stringReplacements)","\t\t\tsecurityContext.WindowsOptions.RunAsUserName = \u0026runAsUserName","\t\t}","\t}","","\t// Apply substitution to SupplementalGroupsPolicy","\tif securityContext.SupplementalGroupsPolicy != nil {","\t\tsupplementalGroupsPolicy := corev1.SupplementalGroupsPolicy(substitution.ApplyReplacements(string(*securityContext.SupplementalGroupsPolicy), stringReplacements))","\t\tsecurityContext.SupplementalGroupsPolicy = \u0026supplementalGroupsPolicy","\t}","","\t// Apply substitution to Sysctls","\tfor i := range securityContext.Sysctls {","\t\tsecurityContext.Sysctls[i].Name = substitution.ApplyReplacements(securityContext.Sysctls[i].Name, stringReplacements)","\t\tsecurityContext.Sysctls[i].Value = substitution.ApplyReplacements(securityContext.Sysctls[i].Value, stringReplacements)","\t}","","\t// Apply substitution to FSGroupChangePolicy","\tif securityContext.FSGroupChangePolicy != nil {","\t\tfsGroupChangePolicy := corev1.PodFSGroupChangePolicy(substitution.ApplyReplacements(string(*securityContext.FSGroupChangePolicy), stringReplacements))","\t\tsecurityContext.FSGroupChangePolicy = \u0026fsGroupChangePolicy","\t}","","\t// Apply substitution to SeccompProfile","\tif securityContext.SeccompProfile != nil {","\t\tsecurityContext.SeccompProfile.Type = corev1.SeccompProfileType(substitution.ApplyReplacements(string(securityContext.SeccompProfile.Type), stringReplacements))","\t\tif securityContext.SeccompProfile.LocalhostProfile != nil {","\t\t\tlocalhostProfile := substitution.ApplyReplacements(*securityContext.SeccompProfile.LocalhostProfile, stringReplacements)","\t\t\tsecurityContext.SeccompProfile.LocalhostProfile = \u0026localhostProfile","\t\t}","\t}","","\t// Apply substitution to AppArmorProfile","\tif securityContext.AppArmorProfile != nil {","\t\tsecurityContext.AppArmorProfile.Type = corev1.AppArmorProfileType(substitution.ApplyReplacements(string(securityContext.AppArmorProfile.Type), stringReplacements))","\t\tif securityContext.AppArmorProfile.LocalhostProfile != nil {","\t\t\tlocalhostProfile := substitution.ApplyReplacements(*securityContext.AppArmorProfile.LocalhostProfile, stringReplacements)","\t\t\tsecurityContext.AppArmorProfile.LocalhostProfile = \u0026localhostProfile","\t\t}","\t}","","\t// Apply substitution to SELinuxChangePolicy","\tif securityContext.SELinuxChangePolicy != nil {","\t\tseLinuxChangePolicy := corev1.PodSELinuxChangePolicy(substitution.ApplyReplacements(string(*securityContext.SELinuxChangePolicy), stringReplacements))","\t\tsecurityContext.SELinuxChangePolicy = \u0026seLinuxChangePolicy","\t}","}","","func applyDNSConfigReplacements(dnsConfig *corev1.PodDNSConfig, stringReplacements map[string]string) {","\tfor i := range dnsConfig.Nameservers {","\t\tdnsConfig.Nameservers[i] = substitution.ApplyReplacements(dnsConfig.Nameservers[i], stringReplacements)","\t}","\tfor i := range dnsConfig.Searches {","\t\tdnsConfig.Searches[i] = substitution.ApplyReplacements(dnsConfig.Searches[i], stringReplacements)","\t}","\tfor i := range dnsConfig.Options {","\t\tdnsConfig.Options[i].Name = substitution.ApplyReplacements(dnsConfig.Options[i].Name, stringReplacements)","\t\tif dnsConfig.Options[i].Value != nil {","\t\t\tvalue := substitution.ApplyReplacements(*dnsConfig.Options[i].Value, stringReplacements)","\t\t\tdnsConfig.Options[i].Value = \u0026value","\t\t}","\t}","}","","func applyVolumeReplacements(volume *corev1.Volume, stringReplacements map[string]string) {","\tvolume.Name = substitution.ApplyReplacements(volume.Name, stringReplacements)","\tif volume.ConfigMap != nil {","\t\tvolume.ConfigMap.Name = substitution.ApplyReplacements(volume.ConfigMap.Name, stringReplacements)","\t\tfor i := range volume.ConfigMap.Items {","\t\t\tvolume.ConfigMap.Items[i].Key = substitution.ApplyReplacements(volume.ConfigMap.Items[i].Key, stringReplacements)","\t\t\tvolume.ConfigMap.Items[i].Path = substitution.ApplyReplacements(volume.ConfigMap.Items[i].Path, stringReplacements)","\t\t}","\t}","\tif volume.Secret != nil {","\t\tvolume.Secret.SecretName = substitution.ApplyReplacements(volume.Secret.SecretName, stringReplacements)","\t\tfor i := range volume.Secret.Items {","\t\t\tvolume.Secret.Items[i].Key = substitution.ApplyReplacements(volume.Secret.Items[i].Key, stringReplacements)","\t\t\tvolume.Secret.Items[i].Path = substitution.ApplyReplacements(volume.Secret.Items[i].Path, stringReplacements)","\t\t}","\t}","\tif volume.PersistentVolumeClaim != nil {","\t\tvolume.PersistentVolumeClaim.ClaimName = substitution.ApplyReplacements(volume.PersistentVolumeClaim.ClaimName, stringReplacements)","\t}","\tif volume.Projected != nil {","\t\tfor _, s := range volume.Projected.Sources {","\t\t\tif s.ConfigMap != nil {","\t\t\t\ts.ConfigMap.Name = substitution.ApplyReplacements(s.ConfigMap.Name, stringReplacements)","\t\t\t}","\t\t\tif s.Secret != nil {","\t\t\t\ts.Secret.Name = substitution.ApplyReplacements(s.Secret.Name, stringReplacements)","\t\t\t}","\t\t\tif s.ServiceAccountToken != nil {","\t\t\t\ts.ServiceAccountToken.Audience = substitution.ApplyReplacements(s.ServiceAccountToken.Audience, stringReplacements)","\t\t\t}","\t\t}","\t}","\tif volume.CSI != nil {","\t\tif volume.CSI.NodePublishSecretRef != nil {","\t\t\tvolume.CSI.NodePublishSecretRef.Name = substitution.ApplyReplacements(volume.CSI.NodePublishSecretRef.Name, stringReplacements)","\t\t}","\t\tif volume.CSI.VolumeAttributes != nil {","\t\t\tfor key, value := range volume.CSI.VolumeAttributes {","\t\t\t\tvolume.CSI.VolumeAttributes[key] = substitution.ApplyReplacements(value, stringReplacements)","\t\t\t}","\t\t}","\t}","}","","func applyEnvVarSourceReplacements(valueFrom *corev1.EnvVarSource, stringReplacements map[string]string) {","\tif valueFrom.ConfigMapKeyRef != nil {","\t\tvalueFrom.ConfigMapKeyRef.Name = substitution.ApplyReplacements(valueFrom.ConfigMapKeyRef.Name, stringReplacements)","\t\tvalueFrom.ConfigMapKeyRef.Key = substitution.ApplyReplacements(valueFrom.ConfigMapKeyRef.Key, stringReplacements)","\t}","\tif valueFrom.SecretKeyRef != nil {","\t\tvalueFrom.SecretKeyRef.Name = substitution.ApplyReplacements(valueFrom.SecretKeyRef.Name, stringReplacements)","\t\tvalueFrom.SecretKeyRef.Key = substitution.ApplyReplacements(valueFrom.SecretKeyRef.Key, stringReplacements)","\t}","\tif valueFrom.FieldRef != nil {","\t\tvalueFrom.FieldRef.FieldPath = substitution.ApplyReplacements(valueFrom.FieldRef.FieldPath, stringReplacements)","\t}","\tif valueFrom.ResourceFieldRef != nil {","\t\tvalueFrom.ResourceFieldRef.Resource = substitution.ApplyReplacements(valueFrom.ResourceFieldRef.Resource, stringReplacements)","\t\tvalueFrom.ResourceFieldRef.ContainerName = substitution.ApplyReplacements(valueFrom.ResourceFieldRef.ContainerName, stringReplacements)","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,0,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,0,0,1,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,0,0,0,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,0,0,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,0,0,0,2,2,0,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,0,0,2,1,1,0,0,2,2,2,2,0,2,0,0,0,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,2,0,0,2,2,2,0,0,2,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,0,2,2,2,0,0,2,2,2,2,2,2,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,1,1,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,0,0,2,2,2,2,0,0,2,2,2,2,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0]},{"id":205,"path":"pkg/reconciler/taskrun/resources/taskref.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resources","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","\t\"strings\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1alpha1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\tresolutionV1beta1 \"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\tclientset \"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/apiserver\"","\t\"github.com/tektoncd/pipeline/pkg/remote\"","\t\"github.com/tektoncd/pipeline/pkg/remoteresolution/remote/resolution\"","\tremoteresource \"github.com/tektoncd/pipeline/pkg/remoteresolution/resource\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\t\"github.com/tektoncd/pipeline/pkg/trustedresources\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/client-go/kubernetes\"","\t\"knative.dev/pkg/kmeta\"",")","","// GetTaskKind returns the referenced Task kind (Task, ...) if the TaskRun is using TaskRef.","func GetTaskKind(taskrun *v1.TaskRun) v1.TaskKind {","\tkind := v1.NamespacedTaskKind","\tif taskrun.Spec.TaskRef != nil \u0026\u0026 taskrun.Spec.TaskRef.Kind != \"\" {","\t\tkind = taskrun.Spec.TaskRef.Kind","\t}","\treturn kind","}","","// GetTaskFuncFromTaskRun is a factory function that will use the given TaskRef as context to return a valid GetTask function.","// It also requires a kubeclient, tektonclient, namespace, and service account in case it needs to find that task in","// cluster or authorize against an external repository. It will figure out whether it needs to look in the cluster or in","// a remote image to fetch the  reference. It will also return the \"kind\" of the task being referenced.","// OCI bundle and remote resolution tasks will be verified by trusted resources if the feature is enabled","func GetTaskFuncFromTaskRun(ctx context.Context, k8s kubernetes.Interface, tekton clientset.Interface, requester remoteresource.Requester, taskrun *v1.TaskRun, verificationPolicies []*v1alpha1.VerificationPolicy) GetTask {","\t// if the spec is already in the status, do not try to fetch it again, just use it as source of truth.","\t// Same for the RefSource field in the Status.Provenance.","\tif taskrun.Status.TaskSpec != nil {","\t\treturn func(_ context.Context, name string) (*v1.Task, *v1.RefSource, *trustedresources.VerificationResult, error) {","\t\t\tvar refSource *v1.RefSource","\t\t\tif taskrun.Status.Provenance != nil {","\t\t\t\trefSource = taskrun.Status.Provenance.RefSource","\t\t\t}","\t\t\treturn \u0026v1.Task{","\t\t\t\tObjectMeta: metav1.ObjectMeta{","\t\t\t\t\tName:      name,","\t\t\t\t\tNamespace: taskrun.Namespace,","\t\t\t\t},","\t\t\t\tSpec: *taskrun.Status.TaskSpec,","\t\t\t}, refSource, nil, nil","\t\t}","\t}","\treturn GetTaskFunc(ctx, k8s, tekton, requester, taskrun, taskrun.Spec.TaskRef, taskrun.Name, taskrun.Namespace, taskrun.Spec.ServiceAccountName, verificationPolicies)","}","","// GetTaskFunc is a factory function that will use the given TaskRef as context to return a valid GetTask function.","// It also requires a kubeclient, tektonclient, namespace, and service account in case it needs to find that task in","// cluster or authorize against an external repository. It will figure out whether it needs to look in the cluster or in","// a remote image to fetch the  reference. It will also return the \"kind\" of the task being referenced.","// OCI bundle and remote resolution tasks will be verified by trusted resources if the feature is enabled","func GetTaskFunc(ctx context.Context, k8s kubernetes.Interface, tekton clientset.Interface, requester remoteresource.Requester,","\towner kmeta.OwnerRefable, tr *v1.TaskRef, trName string, namespace, saName string, verificationPolicies []*v1alpha1.VerificationPolicy,",") GetTask {","\tkind := v1.NamespacedTaskKind","\tif tr != nil \u0026\u0026 tr.Kind != \"\" {","\t\tkind = tr.Kind","\t}","","\tswitch {","\tcase tr != nil \u0026\u0026 tr.Resolver != \"\" \u0026\u0026 requester != nil:","\t\t// Return an inline function that implements GetTask by calling Resolver.Get with the specified task type and","\t\t// casting it to a TaskObject.","\t\treturn func(ctx context.Context, name string) (*v1.Task, *v1.RefSource, *trustedresources.VerificationResult, error) {","\t\t\tvar replacedParams v1.Params","\t\t\tvar url string","\t\t\tif ownerAsTR, ok := owner.(*v1.TaskRun); ok {","\t\t\t\tstringReplacements, arrayReplacements, _ := replacementsFromParams(ownerAsTR.Spec.Params)","\t\t\t\tfor k, v := range getContextReplacements(\"\", ownerAsTR) {","\t\t\t\t\tstringReplacements[k] = v","\t\t\t\t}","\t\t\t\tfor _, p := range tr.Params {","\t\t\t\t\tp.Value.ApplyReplacements(stringReplacements, arrayReplacements, nil)","\t\t\t\t\treplacedParams = append(replacedParams, p)","\t\t\t\t}","\t\t\t\tif err := v1.RefNameLikeUrl(tr.Name); err == nil {","\t\t\t\t\t// The name is url-like so its not a local reference.","\t\t\t\t\ttr.Name = substitution.ApplyReplacements(tr.Name, stringReplacements)","\t\t\t\t\turl = tr.Name","\t\t\t\t}","\t\t\t} else {","\t\t\t\treplacedParams = append(replacedParams, tr.Params...)","\t\t\t}","\t\t\tresolverPayload := remoteresource.ResolverPayload{","\t\t\t\tName:      trName,","\t\t\t\tNamespace: namespace,","\t\t\t\tResolutionSpec: \u0026resolutionV1beta1.ResolutionRequestSpec{","\t\t\t\t\tParams: replacedParams,","\t\t\t\t\tURL:    url,","\t\t\t\t},","\t\t\t}","\t\t\tresolver := resolution.NewResolver(requester, owner, string(tr.Resolver), resolverPayload)","\t\t\treturn resolveTask(ctx, resolver, name, namespace, kind, k8s, tekton, verificationPolicies)","\t\t}","","\tdefault:","\t\t// Even if there is no task ref, we should try to return a local resolver.","\t\tlocal := \u0026LocalTaskRefResolver{","\t\t\tNamespace:    namespace,","\t\t\tKind:         kind,","\t\t\tTektonclient: tekton,","\t\t}","\t\treturn local.GetTask","\t}","}","","// GetStepActionFunc is a factory function that will use the given Ref as context to return a valid GetStepAction function.","// It also requires a kubeclient, tektonclient, requester in case it needs to find that task in","// cluster or authorize against an external repository. It will figure out whether it needs to look in the cluster or in","// a remote location to fetch the reference.","func GetStepActionFunc(tekton clientset.Interface, k8s kubernetes.Interface, requester remoteresource.Requester, tr *v1.TaskRun, taskSpec v1.TaskSpec, step *v1.Step) GetStepAction {","\ttrName := tr.Name","\tnamespace := tr.Namespace","\tif step.Ref != nil \u0026\u0026 step.Ref.Resolver != \"\" \u0026\u0026 requester != nil {","\t\t// Return an inline function that implements GetStepAction by calling Resolver.Get with the specified StepAction type and","\t\t// casting it to a StepAction.","\t\treturn func(ctx context.Context, name string) (*v1beta1.StepAction, *v1.RefSource, error) {","\t\t\t// Perform params replacements for StepAction resolver params","\t\t\tApplyParameterSubstitutionInResolverParams(tr, taskSpec, step)","\t\t\tresolverPayload := remoteresource.ResolverPayload{","\t\t\t\tName:      trName,","\t\t\t\tNamespace: namespace,","\t\t\t\tResolutionSpec: \u0026resolutionV1beta1.ResolutionRequestSpec{","\t\t\t\t\tParams: step.Ref.Params,","\t\t\t\t\tURL:    step.Ref.Name,","\t\t\t\t},","\t\t\t}","\t\t\tresolver := resolution.NewResolver(requester, tr, string(step.Ref.Resolver), resolverPayload)","\t\t\treturn resolveStepAction(ctx, resolver, name, namespace, k8s, tekton)","\t\t}","\t}","\tlocal := \u0026LocalStepActionRefResolver{","\t\tNamespace:    namespace,","\t\tTektonclient: tekton,","\t}","\treturn local.GetStepAction","}","","// ApplyParameterSubstitutionInResolverParams applies parameter substitutions in resolver params for Step Ref.","func ApplyParameterSubstitutionInResolverParams(tr *v1.TaskRun, taskSpec v1.TaskSpec, step *v1.Step) {","\tstringReplacements := make(map[string]string)","\tarrayReplacements := make(map[string][]string)","\tobjectReplacements := make(map[string]map[string]string)","","\tdefaultSR, defaultAR, defaultOR := replacementsFromDefaultParams(taskSpec.Params)","\tstringReplacements, arrayReplacements, objectReplacements = extendReplacements(stringReplacements, arrayReplacements, objectReplacements, defaultSR, defaultAR, defaultOR)","","\tparamSR, paramAR, paramOR := replacementsFromParams(tr.Spec.Params)","\tstringReplacements, arrayReplacements, objectReplacements = extendReplacements(stringReplacements, arrayReplacements, objectReplacements, paramSR, paramAR, paramOR)","\tstep.Ref.Params = step.Ref.Params.ReplaceVariables(stringReplacements, arrayReplacements, objectReplacements)","}","","func extendReplacements(stringReplacements map[string]string, arrayReplacements map[string][]string, objectReplacements map[string]map[string]string, stringReplacementsToAdd map[string]string, arrayReplacementsToAdd map[string][]string, objectReplacementsToAdd map[string]map[string]string) (map[string]string, map[string][]string, map[string]map[string]string) {","\tfor k, v := range stringReplacementsToAdd {","\t\tstringReplacements[k] = v","\t}","\tfor k, v := range arrayReplacementsToAdd {","\t\tarrayReplacements[k] = v","\t}","\tobjectReplacements = extendObjectReplacements(objectReplacements, objectReplacementsToAdd)","\treturn stringReplacements, arrayReplacements, objectReplacements","}","","func extendObjectReplacements(objectReplacements map[string]map[string]string, objectReplacementsToAdd map[string]map[string]string) map[string]map[string]string {","\tfor k, v := range objectReplacementsToAdd {","\t\tfor key, val := range v {","\t\t\tif objectReplacements != nil {","\t\t\t\tif objectReplacements[k] != nil {","\t\t\t\t\tobjectReplacements[k][key] = val","\t\t\t\t} else {","\t\t\t\t\tobjectReplacements[k] = v","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn objectReplacements","}","","// resolveTask accepts an impl of remote.Resolver and attempts to","// fetch a task with given name and verify the v1beta1 task if trusted resources is enabled.","// An error is returned if the remoteresource doesn't work","// A VerificationResult is returned if trusted resources is enabled, VerificationResult contains the result type and err.","// or the returned data isn't a valid *v1beta1.Task.","func resolveTask(ctx context.Context, resolver remote.Resolver, name, namespace string, kind v1.TaskKind, k8s kubernetes.Interface, tekton clientset.Interface, verificationPolicies []*v1alpha1.VerificationPolicy) (*v1.Task, *v1.RefSource, *trustedresources.VerificationResult, error) {","\t// Because the resolver will only return references with the same kind, this will ensure we","\t// don't accidentally return a Task with the same name but different kind.","\tobj, refSource, err := resolver.Get(ctx, strings.TrimSuffix(strings.ToLower(string(kind)), \"s\"), name)","\tif err != nil {","\t\treturn nil, nil, nil, err","\t}","\ttaskObj, vr, err := readRuntimeObjectAsTask(ctx, namespace, obj, k8s, tekton, refSource, verificationPolicies)","\tif err != nil {","\t\treturn nil, nil, nil, err","\t}","\treturn taskObj, refSource, vr, nil","}","","func resolveStepAction(ctx context.Context, resolver remote.Resolver, name, namespace string, k8s kubernetes.Interface, tekton clientset.Interface) (*v1beta1.StepAction, *v1.RefSource, error) {","\tobj, refSource, err := resolver.Get(ctx, \"StepAction\", name)","\tif err != nil {","\t\treturn nil, nil, err","\t}","\tswitch obj := obj.(type) {","\tcase *v1beta1.StepAction:","\t\t// Cleanup object from things we don't care about","\t\t// FIXME: extract this in a function","\t\tobj.ObjectMeta.OwnerReferences = nil","\t\to, err := apiserver.DryRunValidate(ctx, namespace, obj, tekton)","\t\tif err != nil {","\t\t\treturn nil, nil, err","\t\t}","\t\tif mutatedStepAction, ok := o.(*v1beta1.StepAction); ok {","\t\t\tmutatedStepAction.ObjectMeta = obj.ObjectMeta","\t\t\treturn mutatedStepAction, refSource, nil","\t\t}","\tcase *v1alpha1.StepAction:","\t\tobj.SetDefaults(ctx)","\t\t// Cleanup object from things we don't care about","\t\t// FIXME: extract this in a function","\t\tobj.ObjectMeta.OwnerReferences = nil","\t\to, err := apiserver.DryRunValidate(ctx, namespace, obj, tekton)","\t\tif err != nil {","\t\t\treturn nil, nil, err","\t\t}","\t\tif mutatedStepAction, ok := o.(*v1alpha1.StepAction); ok {","\t\t\tmutatedStepAction.ObjectMeta = obj.ObjectMeta","\t\t\tv1BetaStepAction := v1beta1.StepAction{","\t\t\t\tTypeMeta: metav1.TypeMeta{","\t\t\t\t\tKind:       \"StepAction\",","\t\t\t\t\tAPIVersion: \"tekton.dev/v1beta1\",","\t\t\t\t},","\t\t\t}","\t\t\terr := mutatedStepAction.ConvertTo(ctx, \u0026v1BetaStepAction)","\t\t\tif err != nil {","\t\t\t\treturn nil, nil, err","\t\t\t}","\t\t\treturn \u0026v1BetaStepAction, refSource, nil","\t\t}","\t}","\treturn nil, nil, errors.New(\"resource is not a StepAction\")","}","","// readRuntimeObjectAsTask tries to convert a generic runtime.Object","// into a *v1.Task type so that its meta and spec fields","// can be read. v1beta1 object will be converted to v1 and returned.","// An error is returned if the given object is not a Task","// or if there is an error validating or upgrading an older TaskObject into","// its v1beta1 equivalent.","// A VerificationResult is returned if trusted resources is enabled, VerificationResult contains the result type and err.","// v1beta1 task will be verified by trusted resources if the feature is enabled","// TODO(#5541): convert v1beta1 obj to v1 once we use v1 as the stored version","func readRuntimeObjectAsTask(ctx context.Context, namespace string, obj runtime.Object, k8s kubernetes.Interface, tekton clientset.Interface, refSource *v1.RefSource, verificationPolicies []*v1alpha1.VerificationPolicy) (*v1.Task, *trustedresources.VerificationResult, error) {","\tswitch obj := obj.(type) {","\tcase *v1beta1.Task:","\t\tobj.SetDefaults(ctx)","\t\t// Cleanup object from things we don't care about","\t\t// FIXME: extract this in a function","\t\tobj.ObjectMeta.OwnerReferences = nil","\t\t// Verify the Task once we fetch from the remote resolution, mutating, validation and conversion of the task should happen after the verification, since signatures are based on the remote task contents","\t\tvr := trustedresources.VerifyResource(ctx, obj, k8s, refSource, verificationPolicies)","\t\t// Issue a dry-run request to create the remote Task, so that it can undergo validation from validating admission webhooks","\t\t// without actually creating the Task on the cluster.","\t\to, err := apiserver.DryRunValidate(ctx, namespace, obj, tekton)","\t\tif err != nil {","\t\t\treturn nil, nil, err","\t\t}","\t\tif mutatedTask, ok := o.(*v1beta1.Task); ok {","\t\t\tt := \u0026v1.Task{","\t\t\t\tTypeMeta: metav1.TypeMeta{","\t\t\t\t\tKind:       \"Task\",","\t\t\t\t\tAPIVersion: \"tekton.dev/v1\",","\t\t\t\t},","\t\t\t}","\t\t\tmutatedTask.ObjectMeta = obj.ObjectMeta","\t\t\tif err := mutatedTask.ConvertTo(ctx, t); err != nil {","\t\t\t\treturn nil, nil, fmt.Errorf(\"failed to convert obj %s into Pipeline\", mutatedTask.GetObjectKind().GroupVersionKind().String())","\t\t\t}","\t\t\treturn t, \u0026vr, nil","\t\t}","\tcase *v1.Task:","\t\t// This SetDefaults is currently not necessary, but for consistency, it is recommended to add it.","\t\t// Avoid forgetting to add it in the future when there is a v2 version, causing similar problems.","\t\tobj.SetDefaults(ctx)","\t\t// Cleanup object from things we don't care about","\t\t// FIXME: extract this in a function","\t\tobj.ObjectMeta.OwnerReferences = nil","\t\tvr := trustedresources.VerifyResource(ctx, obj, k8s, refSource, verificationPolicies)","\t\t// Issue a dry-run request to create the remote Task, so that it can undergo validation from validating admission webhooks","\t\t// without actually creating the Task on the cluster","\t\to, err := apiserver.DryRunValidate(ctx, namespace, obj, tekton)","\t\tif err != nil {","\t\t\treturn nil, nil, err","\t\t}","\t\tif mutatedTask, ok := o.(*v1.Task); ok {","\t\t\tmutatedTask.ObjectMeta = obj.ObjectMeta","\t\t\treturn mutatedTask, \u0026vr, nil","\t\t}","\t}","\treturn nil, nil, errors.New(\"resource is not a task\")","}","","// LocalTaskRefResolver uses the current cluster to resolve a task reference.","type LocalTaskRefResolver struct {","\tNamespace    string","\tKind         v1.TaskKind","\tTektonclient clientset.Interface","}","","// GetTask will resolve a Task from the local cluster using a versioned Tekton client. It will","// return an error if it can't find an appropriate Task for any reason.","// TODO(#6666): support local task verification","func (l *LocalTaskRefResolver) GetTask(ctx context.Context, name string) (*v1.Task, *v1.RefSource, *trustedresources.VerificationResult, error) {","\t// If we are going to resolve this reference locally, we need a namespace scope.","\tif l.Namespace == \"\" {","\t\treturn nil, nil, nil, fmt.Errorf(\"must specify namespace to resolve reference to task %s\", name)","\t}","\ttask, err := l.Tektonclient.TektonV1().Tasks(l.Namespace).Get(ctx, name, metav1.GetOptions{})","\tif err != nil {","\t\treturn nil, nil, nil, err","\t}","\treturn task, nil, nil, nil","}","","// LocalStepActionRefResolver uses the current cluster to resolve a StepAction reference.","type LocalStepActionRefResolver struct {","\tNamespace    string","\tTektonclient clientset.Interface","}","","// GetStepAction will resolve a StepAction from the local cluster using a versioned Tekton client.","// It will return an error if it can't find an appropriate StepAction for any reason.","func (l *LocalStepActionRefResolver) GetStepAction(ctx context.Context, name string) (*v1beta1.StepAction, *v1.RefSource, error) {","\t// If we are going to resolve this reference locally, we need a namespace scope.","\tif l.Namespace == \"\" {","\t\treturn nil, nil, fmt.Errorf(\"must specify namespace to resolve reference to step action %s\", name)","\t}","\tstepAction, err := l.Tektonclient.TektonV1beta1().StepActions(l.Namespace).Get(ctx, name, metav1.GetOptions{})","\tif err != nil {","\t\treturn nil, nil, err","\t}","\treturn stepAction, nil, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,1,0,0,0,0,0,0,0,0,0,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,1,1,2,0,0,2,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,1,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0]},{"id":206,"path":"pkg/reconciler/taskrun/resources/taskspec.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resources","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\tclientset \"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"","\tresolutionutil \"github.com/tektoncd/pipeline/pkg/internal/resolution\"","\t\"github.com/tektoncd/pipeline/pkg/pod\"","\tremoteresource \"github.com/tektoncd/pipeline/pkg/remoteresolution/resource\"","\t\"github.com/tektoncd/pipeline/pkg/trustedresources\"","\t\"golang.org/x/sync/errgroup\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/client-go/kubernetes\"",")","","// ResolvedTask contains the data that is needed to execute","// the TaskRun.","type ResolvedTask struct {","\tTaskName string","\tKind     v1.TaskKind","\tTaskSpec *v1.TaskSpec","\t// VerificationResult is the result from trusted resources if the feature is enabled.","\tVerificationResult *trustedresources.VerificationResult","}","","// GetStepAction is a function used to retrieve StepActions.","type GetStepAction func(context.Context, string) (*v1beta1.StepAction, *v1.RefSource, error)","","// GetTask is a function used to retrieve Tasks.","// VerificationResult is the result from trusted resources if the feature is enabled.","type GetTask func(context.Context, string) (*v1.Task, *v1.RefSource, *trustedresources.VerificationResult, error)","","// GetTaskRun is a function used to retrieve TaskRuns","type GetTaskRun func(string) (*v1.TaskRun, error)","","// GetTaskData will retrieve the Task metadata and Spec associated with the","// provided TaskRun. This can come from a reference Task or from the TaskRun's","// metadata and embedded TaskSpec.","func GetTaskData(ctx context.Context, taskRun *v1.TaskRun, getTask GetTask) (*resolutionutil.ResolvedObjectMeta, *v1.TaskSpec, error) {","\ttaskMeta := metav1.ObjectMeta{}","\ttaskSpec := v1.TaskSpec{}","\tvar refSource *v1.RefSource","\tvar verificationResult *trustedresources.VerificationResult","\tswitch {","\tcase taskRun.Spec.TaskRef != nil \u0026\u0026 taskRun.Spec.TaskRef.Name != \"\":","\t\t// Get related task for taskrun","\t\tt, source, vr, err := getTask(ctx, taskRun.Spec.TaskRef.Name)","\t\tif err != nil {","\t\t\treturn nil, nil, fmt.Errorf(\"error when listing tasks for taskRun %s: %w\", taskRun.Name, err)","\t\t}","\t\ttaskMeta = t.ObjectMeta","\t\ttaskSpec = t.Spec","\t\trefSource = source","\t\tverificationResult = vr","\tcase taskRun.Spec.TaskSpec != nil:","\t\ttaskMeta = taskRun.ObjectMeta","\t\ttaskSpec = *taskRun.Spec.TaskSpec","\t\t// TODO: if we want to set RefSource for embedded taskspec, set it here.","\t\t// https://github.com/tektoncd/pipeline/issues/5522","\tcase taskRun.Spec.TaskRef != nil \u0026\u0026 taskRun.Spec.TaskRef.Resolver != \"\":","\t\ttask, source, vr, err := getTask(ctx, taskRun.Name)","\t\tswitch {","\t\tcase err != nil:","\t\t\treturn nil, nil, err","\t\tcase task == nil:","\t\t\treturn nil, nil, errors.New(\"resolution of remote resource completed successfully but no task was returned\")","\t\tdefault:","\t\t\ttaskMeta = task.ObjectMeta","\t\t\ttaskSpec = task.Spec","\t\t}","\t\trefSource = source","\t\tverificationResult = vr","\tdefault:","\t\treturn nil, nil, fmt.Errorf(\"taskRun %s not providing TaskRef or TaskSpec\", taskRun.Name)","\t}","","\ttaskSpec.SetDefaults(ctx)","\treturn \u0026resolutionutil.ResolvedObjectMeta{","\t\tObjectMeta:         \u0026taskMeta,","\t\tRefSource:          refSource,","\t\tVerificationResult: verificationResult,","\t}, \u0026taskSpec, nil","}","","// stepRefResolution holds the outcome of resolving a step referencing a StepAction.","type stepRefResolution struct {","\tresolvedStep *v1.Step","\tsource       *v1.RefSource","}","","// hasStepRefs provides a fast check to see if any steps in a TaskSpec contain a reference to a StepAction.","func hasStepRefs(taskSpec *v1.TaskSpec) bool {","\tfor _, step := range taskSpec.Steps {","\t\tif step.Ref != nil {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","// resolveStepRef resolves a step referecing a StepAction by fetching the remote StepAction, merging it with the Step's specification, and returning the resolved step.","func resolveStepRef(ctx context.Context, taskSpec v1.TaskSpec, taskRun *v1.TaskRun, tekton clientset.Interface, k8s kubernetes.Interface, requester remoteresource.Requester, step *v1.Step) (*v1.Step, *v1.RefSource, error) {","\tresolvedStep := step.DeepCopy()","","\tgetStepAction := GetStepActionFunc(tekton, k8s, requester, taskRun, taskSpec, resolvedStep)","\tstepAction, source, err := getStepAction(ctx, resolvedStep.Ref.Name)","\tif err != nil {","\t\treturn nil, nil, err","\t}","","\tstepActionSpec := stepAction.StepActionSpec()","\tstepActionSpec.SetDefaults(ctx)","","\tstepFromStepAction := stepActionSpec.ToStep()","\tif err := validateStepHasStepActionParameters(resolvedStep.Params, stepActionSpec.Params); err != nil {","\t\treturn nil, nil, err","\t}","","\tstepFromStepAction, err = applyStepActionParameters(stepFromStepAction, \u0026taskSpec, taskRun, resolvedStep.Params, stepActionSpec.Params)","\tif err != nil {","\t\treturn nil, nil, err","\t}","","\t// Merge fields from the resolved StepAction into the step","\tresolvedStep.Image = stepFromStepAction.Image","\tresolvedStep.SecurityContext = stepFromStepAction.SecurityContext","\tif len(stepFromStepAction.Command) \u003e 0 {","\t\tresolvedStep.Command = stepFromStepAction.Command","\t}","\tif len(stepFromStepAction.Args) \u003e 0 {","\t\tresolvedStep.Args = stepFromStepAction.Args","\t}","\tif stepFromStepAction.Script != \"\" {","\t\tresolvedStep.Script = stepFromStepAction.Script","\t}","\tresolvedStep.WorkingDir = stepFromStepAction.WorkingDir","\tif stepFromStepAction.Env != nil {","\t\tresolvedStep.Env = stepFromStepAction.Env","\t}","\tif len(stepFromStepAction.VolumeMounts) \u003e 0 {","\t\tresolvedStep.VolumeMounts = stepFromStepAction.VolumeMounts","\t}","\tif len(stepFromStepAction.Results) \u003e 0 {","\t\tresolvedStep.Results = stepFromStepAction.Results","\t}","","\t// Finalize by clearing Ref and Params, as they have been resolved","\tresolvedStep.Ref = nil","\tresolvedStep.Params = nil","","\treturn resolvedStep, source, nil","}","","// updateTaskRunProvenance update the TaskRun's status with source provenance information for a given step","func updateTaskRunProvenance(taskRun *v1.TaskRun, stepName string, stepIndex int, source *v1.RefSource, stepStatusIndex map[string]int) {","\tvar provenance *v1.Provenance","","\t// The StepState already exists. Update it in place","\tif index, found := stepStatusIndex[stepName]; found {","\t\tif taskRun.Status.Steps[index].Provenance == nil {","\t\t\ttaskRun.Status.Steps[index].Provenance = \u0026v1.Provenance{}","\t\t}","\t\ttaskRun.Status.Steps[index].Provenance.RefSource = source","\t\treturn","\t}","","\tprovenance = \u0026v1.Provenance{RefSource: source}","","\t// No existing StepState found. Create and append a new one","\tnewState := v1.StepState{","\t\tName:       pod.TrimStepPrefix(pod.StepName(stepName, stepIndex)),","\t\tProvenance: provenance,","\t}","\ttaskRun.Status.Steps = append(taskRun.Status.Steps, newState)","}","","// GetStepActionsData extracts the StepActions and merges them with the inlined Step specification.","func GetStepActionsData(ctx context.Context, taskSpec v1.TaskSpec, taskRun *v1.TaskRun, tekton clientset.Interface, k8s kubernetes.Interface, requester remoteresource.Requester) ([]v1.Step, error) {","\tsteps := make([]v1.Step, len(taskSpec.Steps))","","\t// Init step states and known step states indexes lookup map","\tif taskRun.Status.Steps == nil {","\t\ttaskRun.Status.Steps = []v1.StepState{}","\t}","\tstepStatusIndex := make(map[string]int, len(taskRun.Status.Steps))","\tfor i, stepState := range taskRun.Status.Steps {","\t\tstepStatusIndex[stepState.Name] = i","\t}","","\t// If there are no step-ref to resolve, return immediately with nil provenance","\tif !hasStepRefs(\u0026taskSpec) {","\t\tfor i, step := range taskSpec.Steps {","\t\t\tsteps[i] = step","\t\t\tupdateTaskRunProvenance(taskRun, step.Name, i, nil, stepStatusIndex) // create StepState with nil provenance","\t\t}","\t\treturn steps, nil","\t}","","\t// Phase 1: Concurrently resolve all StepActions","\tstepRefConcurrencyLimit := config.FromContextOrDefaults(ctx).Defaults.DefaultStepRefConcurrencyLimit","\tg, ctx := errgroup.WithContext(ctx)","\t// This limit prevents overwhelming the API server or remote git servers","\tg.SetLimit(stepRefConcurrencyLimit)","","\tstepRefResolutions := make([]*stepRefResolution, len(taskSpec.Steps))","\tfor i, step := range taskSpec.Steps {","\t\tif step.Ref == nil { // Only process steps with a Ref","\t\t\tcontinue","\t\t}","","\t\tg.Go(func() error {","\t\t\tresolvedStep, source, err := resolveStepRef(ctx, taskSpec, taskRun, tekton, k8s, requester, \u0026step)","\t\t\tif err != nil {","\t\t\t\treturn fmt.Errorf(\"failed to resolve step ref for step %q (index %d): %w\", step.Name, i, err)","\t\t\t}","\t\t\tstepRefResolutions[i] = \u0026stepRefResolution{resolvedStep: resolvedStep, source: source}","\t\t\treturn nil","\t\t})","\t}","","\tif err := g.Wait(); err != nil {","\t\treturn nil, err","\t}","","\t// Phase 2: Sequentially merge results into the final step list and update status","\tfor i, step := range taskSpec.Steps {","\t\tif step.Ref == nil {","\t\t\tsteps[i] = step","\t\t\tupdateTaskRunProvenance(taskRun, step.Name, i, nil, stepStatusIndex) // create StepState for inline step with nil provenance","\t\t\tcontinue","\t\t}","","\t\tstepRefResolution := stepRefResolutions[i]","\t\tsteps[i] = *stepRefResolution.resolvedStep","\t\tupdateTaskRunProvenance(taskRun, stepRefResolution.resolvedStep.Name, i, stepRefResolution.source, stepStatusIndex)","\t}","","\treturn steps, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,0,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,0,0,2,2,2,2,2,0,0,2,2,2,0,0,2,0]},{"id":207,"path":"pkg/reconciler/taskrun/resources/validate_params.go","lines":["package resources","","import (","\t\"fmt\"","","\tpipelineErrors \"github.com/tektoncd/pipeline/pkg/apis/pipeline/errors\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\t\"k8s.io/apimachinery/pkg/util/sets\"",")","","// ValidateParamArrayIndex validates if the param reference to an array param is out of bound.","// error is returned when the array indexing reference is out of bound of the array param","// e.g. if a param reference of $(params.array-param[2]) and the array param is of length 2.","// - `params` are params from taskrun.","// - `ts` contains params declarations and references to array params.","func ValidateParamArrayIndex(ts *v1.TaskSpec, params v1.Params) error {","\treturn ValidateOutOfBoundArrayParams(ts.Params, params, ts.GetIndexingReferencesToArrayParams())","}","","// ValidateOutOfBoundArrayParams returns an error if the array indexing params are out of bounds,","// based on the param declarations, the parameters passed in at runtime, and the indexing references","// to array params from a task or pipeline spec.","// Example of arrayIndexingReferences: [\"$(params.a-array-param[1])\", \"$(params.b-array-param[2])\"]","func ValidateOutOfBoundArrayParams(declarations v1.ParamSpecs, params v1.Params, arrayIndexingReferences sets.String) error {","\tarrayParamLengths := declarations.ExtractDefaultParamArrayLengths()","\tfor k, v := range params.ExtractParamArrayLengths() {","\t\tarrayParamLengths[k] = v","\t}","\toutofBoundParams := sets.String{}","\tfor val := range arrayIndexingReferences {","\t\tindexString := substitution.ExtractIndexString(val)","\t\tidx, _ := substitution.ExtractIndex(indexString)","\t\t// this will extract the param name from reference","\t\t// e.g. $(params.a-array-param[1]) -\u003e a-array-param","\t\tparamName, _, _ := substitution.ExtractVariablesFromString(substitution.TrimArrayIndex(val), \"params\")","","\t\tif paramLength, ok := arrayParamLengths[paramName[0]]; ok {","\t\t\tif idx \u003e= paramLength {","\t\t\t\toutofBoundParams.Insert(val)","\t\t\t}","\t\t}","\t}","\tif outofBoundParams.Len() \u003e 0 {","\t\treturn pipelineErrors.WrapUserError(fmt.Errorf(\"non-existent param references:%v\", outofBoundParams.List()))","\t}","\treturn nil","}","","func validateStepHasStepActionParameters(stepParams v1.Params, stepActionDefaults []v1.ParamSpec) error {","\tstepActionParams := sets.String{}","\trequiredStepActionParams := []string{}","\tfor _, sa := range stepActionDefaults {","\t\tstepActionParams.Insert(sa.Name)","\t\tif sa.Default == nil {","\t\t\trequiredStepActionParams = append(requiredStepActionParams, sa.Name)","\t\t}","\t}","","\tstepProvidedParams := sets.String{}","\textra := []string{}","\tfor _, sp := range stepParams {","\t\tstepProvidedParams.Insert(sp.Name)","\t\tif !stepActionParams.Has(sp.Name) {","\t\t\t// Extra parameter that is not needed","\t\t\textra = append(extra, sp.Name)","\t\t}","\t}","\tif len(extra) \u003e 0 {","\t\treturn fmt.Errorf(\"extra params passed by Step to StepAction: %v\", extra)","\t}","","\tmissing := []string{}","","\tfor _, requiredParam := range requiredStepActionParams {","\t\tif !stepProvidedParams.Has(requiredParam) {","\t\t\t// Missing required param","\t\t\tmissing = append(missing, requiredParam)","\t\t}","\t}","\tif len(missing) \u003e 0 {","\t\treturn fmt.Errorf(\"non-existent params in Step: %v\", missing)","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,1,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,2,0]},{"id":208,"path":"pkg/reconciler/taskrun/taskrun.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package taskrun","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","\t\"reflect\"","\t\"slices\"","\t\"strings\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/internal/sidecarlogresults\"","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tpipelineErrors \"github.com/tektoncd/pipeline/pkg/apis/pipeline/errors\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/pod\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tclientset \"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"","\ttaskrunreconciler \"github.com/tektoncd/pipeline/pkg/client/injection/reconciler/pipeline/v1/taskrun\"","\tlisters \"github.com/tektoncd/pipeline/pkg/client/listers/pipeline/v1\"","\talphalisters \"github.com/tektoncd/pipeline/pkg/client/listers/pipeline/v1alpha1\"","\tctrl \"github.com/tektoncd/pipeline/pkg/controller\"","\t\"github.com/tektoncd/pipeline/pkg/internal/affinityassistant\"","\t\"github.com/tektoncd/pipeline/pkg/internal/computeresources\"","\t\"github.com/tektoncd/pipeline/pkg/internal/defaultresourcerequirements\"","\tresolutionutil \"github.com/tektoncd/pipeline/pkg/internal/resolution\"","\tpodconvert \"github.com/tektoncd/pipeline/pkg/pod\"","\ttknreconciler \"github.com/tektoncd/pipeline/pkg/reconciler\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/apiserver\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/events\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/events/cloudevent\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/taskrun/resources\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/volumeclaim\"","\t\"github.com/tektoncd/pipeline/pkg/remote\"","\tresolution \"github.com/tektoncd/pipeline/pkg/remoteresolution/resource\"","\tresolutioncommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\t\"github.com/tektoncd/pipeline/pkg/spire\"","\t\"github.com/tektoncd/pipeline/pkg/taskrunmetrics\"","\t\"github.com/tektoncd/pipeline/pkg/trustedresources\"","\t\"github.com/tektoncd/pipeline/pkg/workspace\"","\t\"go.opentelemetry.io/otel/attribute\"","\t\"go.opentelemetry.io/otel/codes\"","\t\"go.opentelemetry.io/otel/trace\"","\t\"go.uber.org/zap\"","\tcorev1 \"k8s.io/api/core/v1\"","\tk8serrors \"k8s.io/apimachinery/pkg/api/errors\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/labels\"","\t\"k8s.io/apimachinery/pkg/util/wait\"","\t\"k8s.io/client-go/kubernetes\"","\tcorev1Listers \"k8s.io/client-go/listers/core/v1\"","\t\"k8s.io/utils/clock\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/changeset\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/kmap\"","\t\"knative.dev/pkg/kmeta\"","\t\"knative.dev/pkg/logging\"","\tpkgreconciler \"knative.dev/pkg/reconciler\"","\t\"sigs.k8s.io/yaml\"",")","","// Reconciler implements controller.Reconciler for Configuration resources.","type Reconciler struct {","\tKubeClientSet     kubernetes.Interface","\tPipelineClientSet clientset.Interface","\tImages            pipeline.Images","\tClock             clock.PassiveClock","","\t// listers index properties about resources","\tspireClient              spire.ControllerAPIClient","\ttaskRunLister            listers.TaskRunLister","\tlimitrangeLister         corev1Listers.LimitRangeLister","\tpodLister                corev1Listers.PodLister","\tverificationPolicyLister alphalisters.VerificationPolicyLister","\tcloudEventClient         cloudevent.CEClient","\tentrypointCache          podconvert.EntrypointCache","\tmetrics                  *taskrunmetrics.Recorder","\tpvcHandler               volumeclaim.PvcHandler","\tresolutionRequester      resolution.Requester","\ttracerProvider           trace.TracerProvider","}","","const (","\tImagePullBackOff           = \"ImagePullBackOff\"","\tInvalidImageName           = \"InvalidImageName\"           // Invalid image reference","\tCreateContainerConfigError = \"CreateContainerConfigError\" // Missing ConfigMap/Secret, invalid env vars, etc.","\tCreateContainerError       = \"CreateContainerError\"       // Other container creation failures","\tErrImagePull               = \"ErrImagePull\"               // Initial image pull failure",")","","var (","\t// Check that our Reconciler implements taskrunreconciler.Interface","\t_ taskrunreconciler.Interface = (*Reconciler)(nil)","","\t// Pod failure reasons that trigger failure of the TaskRun","\t// Note: ErrImagePull is intentionally not included as it's a transient state","\t// that Kubernetes will automatically retry before transitioning to ImagePullBackOff","\tpodFailureReasons = map[string]struct{}{","\t\tImagePullBackOff:           {},","\t\tInvalidImageName:           {},","\t\tCreateContainerConfigError: {},","\t\tCreateContainerError:       {},","\t}",")","","// ReconcileKind compares the actual state with the desired, and attempts to","// converge the two. It then updates the Status block of the Task Run","// resource with the current status of the resource.","func (c *Reconciler) ReconcileKind(ctx context.Context, tr *v1.TaskRun) pkgreconciler.Event {","\tlogger := logging.FromContext(ctx)","\tctx = cloudevent.ToContext(ctx, c.cloudEventClient)","\tctx = initTracing(ctx, c.tracerProvider, tr)","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"TaskRun:ReconcileKind\")","\tdefer span.End()","","\tspan.SetAttributes(attribute.String(\"taskrun\", tr.Name), attribute.String(\"namespace\", tr.Namespace))","\t// Read the initial condition","\tbefore := tr.Status.GetCondition(apis.ConditionSucceeded)","","\t// Record the duration and count after the reconcile cycle.","\tdefer c.durationAndCountMetrics(ctx, tr, before)","","\t// If the TaskRun is just starting, this will also set the starttime,","\t// from which the timeout will immediately begin counting down.","\tif !tr.HasStarted() {","\t\ttr.Status.InitializeConditions()","\t\t// In case node time was not synchronized, when controller has been scheduled to other nodes.","\t\tif tr.Status.StartTime.Sub(tr.CreationTimestamp.Time) \u003c 0 {","\t\t\tlogger.Warnf(\"TaskRun %s createTimestamp %s is after the taskRun started %s\", tr.GetNamespacedName().String(), tr.CreationTimestamp, tr.Status.StartTime)","\t\t\ttr.Status.StartTime = \u0026tr.CreationTimestamp","\t\t}","\t\t// Emit events. During the first reconcile the status of the TaskRun may change twice","\t\t// from not Started to Started and then to Running, so we need to sent the event here","\t\t// and at the end of 'Reconcile' again.","\t\t// We also want to send the \"Started\" event as soon as possible for anyone who may be waiting","\t\t// on the event to perform user facing initialisations, such has reset a CI check status","\t\tafterCondition := tr.Status.GetCondition(apis.ConditionSucceeded)","\t\tevents.Emit(ctx, nil, afterCondition, tr)","\t}","","\t// If the TaskRun is complete, run some post run fixtures when applicable","\tif tr.IsDone() {","\t\tlogger.Infof(\"taskrun done : %s \\n\", tr.Name)","","\t\t// We may be reading a version of the object that was stored at an older version","\t\t// and may not have had all of the assumed default specified.","\t\ttr.SetDefaults(ctx)","","\t\tuseTektonSidecar := true","\t\tif config.FromContextOrDefaults(ctx).FeatureFlags.EnableKubernetesSidecar {","\t\t\tdc := c.KubeClientSet.Discovery()","\t\t\tsv, err := dc.ServerVersion()","\t\t\tif err != nil {","\t\t\t\treturn err","\t\t\t}","\t\t\tif podconvert.IsNativeSidecarSupport(sv) {","\t\t\t\tuseTektonSidecar = false","\t\t\t\tlogger.Infof(\"Using Kubernetes Native Sidecars \\n\")","\t\t\t}","\t\t}","\t\tif useTektonSidecar {","\t\t\tif err := c.stopSidecars(ctx, tr); err != nil {","\t\t\t\treturn err","\t\t\t}","\t\t}","","\t\treturn c.finishReconcileUpdateEmitEvents(ctx, tr, before, nil)","\t}","","\t// If the TaskRun is cancelled, kill resources and update status","\tif tr.IsCancelled() {","\t\tmessage := fmt.Sprintf(\"TaskRun %q was cancelled. %s\", tr.Name, tr.Spec.StatusMessage)","\t\terr := c.failTaskRun(ctx, tr, v1.TaskRunReasonCancelled, message)","\t\treturn c.finishReconcileUpdateEmitEvents(ctx, tr, before, err)","\t}","","\t// Check if the TaskRun has timed out; if it is, this will set its status","\t// accordingly.","\tif tr.HasTimedOut(ctx, c.Clock) {","\t\t// Before failing the TaskRun, ensure step statuses are populated from the pod","\t\t// This prevents a race condition where the timeout occurs before pod status is fetched","\t\tif err := c.updateStepStatusesFromPod(ctx, tr); err != nil {","\t\t\tlogger.Warnf(\"Failed to update step statuses from pod before timeout: %v\", err)","\t\t}","\t\tmessage := fmt.Sprintf(\"TaskRun %q failed to finish within %q\", tr.Name, tr.GetTimeout(ctx))","\t\terr := c.failTaskRun(ctx, tr, v1.TaskRunReasonTimedOut, message)","\t\treturn c.finishReconcileUpdateEmitEvents(ctx, tr, before, err)","\t}","","\t// Check for Pod Failures","\tif failed, reason, message := c.checkPodFailed(ctx, tr); failed {","\t\terr := c.failTaskRun(ctx, tr, reason, message)","\t\treturn c.finishReconcileUpdateEmitEvents(ctx, tr, before, err)","\t}","","\t// prepare fetches all required resources, validates them together with the","\t// taskrun, runs API conversions. In case of error we update, emit events and return.","\t_, rtr, err := c.prepare(ctx, tr)","\tif err != nil {","\t\tlogger.Errorf(\"TaskRun prepare error: %v\", err.Error())","\t\t// We only return an error if update failed, otherwise we don't want to","\t\t// reconcile an invalid TaskRun anymore","\t\tspan.SetStatus(codes.Error, \"taskrun prepare error\")","\t\tspan.RecordError(err)","\t\treturn c.finishReconcileUpdateEmitEvents(ctx, tr, nil, err)","\t}","","\t// Store the condition before reconcile","\tbefore = tr.Status.GetCondition(apis.ConditionSucceeded)","","\t// Reconcile this copy of the task run and then write back any status","\t// updates regardless of whether the reconciliation errored out.","\tif err = c.reconcile(ctx, tr, rtr); err != nil {","\t\tlogger.Errorf(\"Reconcile: %v\", err.Error())","\t\tif errors.Is(err, sidecarlogresults.ErrSizeExceeded) {","\t\t\tmessage := fmt.Sprintf(\"%s TaskRun \\\"%q\\\" failed: %s\", pipelineErrors.UserErrorLabel, tr.Name, err.Error())","\t\t\terr := c.failTaskRun(ctx, tr, v1.TaskRunReasonResultLargerThanAllowedLimit, message)","\t\t\treturn c.finishReconcileUpdateEmitEvents(ctx, tr, before, err)","\t\t}","\t}","","\t// Emit events (only when ConditionSucceeded was changed)","\tif err = c.finishReconcileUpdateEmitEvents(ctx, tr, before, err); err != nil {","\t\treturn err","\t}","","\tif tr.Status.StartTime != nil {","\t\t// Compute the time since the task started.","\t\telapsed := c.Clock.Since(tr.Status.StartTime.Time)","\t\t// Snooze this resource until the timeout has elapsed.","\t\ttimeout := tr.GetTimeout(ctx)","\t\t// If timeout is NoTimeoutDuration (0), it means no timeout is configured.","\t\t// This can happen in two ways:","\t\t// 1. User explicitly set tr.Spec.Timeout.Duration to 0 (wants no timeout)","\t\t// 2. User didn't set tr.Spec.Timeout (nil) AND default-timeout-minutes config is \"0\"","\t\t// In both cases, we should not requeue based on timeout. The reconciler will","\t\t// still be triggered appropriately by pod watch events when the TaskRun changes.","\t\tif timeout == config.NoTimeoutDuration {","\t\t\treturn nil","\t\t}","\t\twaitTime := timeout - elapsed","\t\treturn controller.NewRequeueAfter(waitTime)","\t}","\treturn nil","}","","func (c *Reconciler) checkPodFailed(ctx context.Context, tr *v1.TaskRun) (bool, v1.TaskRunReason, string) {","\tfor _, step := range tr.Status.Steps {","\t\tif step.Waiting == nil {","\t\t\tcontinue","\t\t}","","\t\tif _, found := podFailureReasons[step.Waiting.Reason]; !found {","\t\t\tcontinue","\t\t}","","\t\tfailed, reason, message := c.checkContainerFailure(","\t\t\tctx,","\t\t\ttr,","\t\t\tstep.Waiting,","\t\t\tstep.Name,","\t\t\tstep.ImageID,","\t\t\t\"step\",","\t\t)","\t\tif failed {","\t\t\treturn true, reason, message","\t\t}","\t}","","\tfor _, sidecar := range tr.Status.Sidecars {","\t\tif sidecar.Waiting == nil {","\t\t\tcontinue","\t\t}","","\t\tif _, found := podFailureReasons[sidecar.Waiting.Reason]; !found {","\t\t\tcontinue","\t\t}","","\t\tfailed, reason, message := c.checkContainerFailure(","\t\t\tctx,","\t\t\ttr,","\t\t\tsidecar.Waiting,","\t\t\tsidecar.Name,","\t\t\tsidecar.ImageID,","\t\t\t\"sidecar\",","\t\t)","\t\tif failed {","\t\t\treturn true, reason, message","\t\t}","\t}","","\treturn false, \"\", \"\"","}","","func (c *Reconciler) checkContainerFailure(","\tctx context.Context,","\ttr *v1.TaskRun,","\twaiting *corev1.ContainerStateWaiting,","\tname,","\timageID,","\tcontainerType string,",") (bool, v1.TaskRunReason, string) {","\tif waiting.Reason == ImagePullBackOff {","\t\timagePullBackOffTimeOut := config.FromContextOrDefaults(ctx).Defaults.DefaultImagePullBackOffTimeout","\t\t// only attempt to recover from the imagePullBackOff if specified","\t\tif imagePullBackOffTimeOut.Seconds() != 0 {","\t\t\tp, err := c.KubeClientSet.CoreV1().Pods(tr.Namespace).Get(ctx, tr.Status.PodName, metav1.GetOptions{})","\t\t\tif err != nil {","\t\t\t\tmessage := fmt.Sprintf(`the %s %q in TaskRun %q failed to pull the image %q. Failed to get pod with error: \"%s.\"`, containerType, name, tr.Name, imageID, err)","\t\t\t\treturn true, v1.TaskRunReasonImagePullFailed, message","\t\t\t}","\t\t\timagePullBackOffTimeoutPodConditions := []string{string(corev1.PodInitialized), \"PodReadyToStartContainers\"}","\t\t\tfor _, condition := range p.Status.Conditions {","\t\t\t\t// check the pod condition to get the time when the pod was ready to start containers / initialized.","\t\t\t\t// keep trying until the pod schedule time has exceeded the specified imagePullBackOff timeout duration","\t\t\t\tif slices.Contains(imagePullBackOffTimeoutPodConditions, string(condition.Type)) {","\t\t\t\t\tif c.Clock.Since(condition.LastTransitionTime.Time) \u003c imagePullBackOffTimeOut {","\t\t\t\t\t\treturn false, \"\", \"\"","\t\t\t\t\t}","\t\t\t\t}","\t\t\t}","\t\t}","\t\t// ImagePullBackOff timeout exceeded or not configured","\t\tmessage := fmt.Sprintf(`the %s %q in TaskRun %q failed to pull the image %q. The pod errored with the message: \"%s.\"`, containerType, name, tr.Name, imageID, waiting.Message)","\t\treturn true, v1.TaskRunReasonImagePullFailed, message","\t}","","\t// Handle CreateContainerConfigError (missing ConfigMap/Secret, invalid env vars, etc.)","\tif waiting.Reason == CreateContainerConfigError {","\t\tmessage := fmt.Sprintf(`the %s %q in TaskRun %q failed to start. The pod errored with the message: \"%s.\"`, containerType, name, tr.Name, waiting.Message)","\t\treturn true, v1.TaskRunReasonCreateContainerConfigError, message","\t}","","\t// Handle InvalidImageName (unrecoverable error)","\tif waiting.Reason == InvalidImageName {","\t\tmessage := fmt.Sprintf(`the %s %q in TaskRun %q failed to pull the image %q. The pod errored with the message: \"%s.\"`, containerType, name, tr.Name, imageID, waiting.Message)","\t\treturn true, v1.TaskRunReasonImagePullFailed, message","\t}","","\t// Handle CreateContainerError and other generic failures","\tmessage := fmt.Sprintf(`the %s %q in TaskRun %q failed to start. The pod errored with the message: \"%s.\"`, containerType, name, tr.Name, waiting.Message)","\treturn true, v1.TaskRunReasonPodCreationFailed, message","}","","func (c *Reconciler) durationAndCountMetrics(ctx context.Context, tr *v1.TaskRun, beforeCondition *apis.Condition) {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"durationAndCountMetrics\")","\tdefer span.End()","\tlogger := logging.FromContext(ctx)","\tif tr.IsDone() {","\t\tif err := c.metrics.DurationAndCount(ctx, tr, beforeCondition); err != nil {","\t\t\tlogger.Warnf(\"Failed to log the duration and count of taskruns : %v\", err)","\t\t}","\t}","}","","func (c *Reconciler) stopSidecars(ctx context.Context, tr *v1.TaskRun) error {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"stopSidecars\")","\tdefer span.End()","\tlogger := logging.FromContext(ctx)","\t// do not continue without knowing the associated pod","\tif tr.Status.PodName == \"\" {","\t\treturn nil","\t}","","\t// do not continue if the TaskRun was canceled or timed out as this caused the pod to be deleted in failTaskRun","\tcondition := tr.Status.GetCondition(apis.ConditionSucceeded)","\tif condition != nil {","\t\treason := v1.TaskRunReason(condition.Reason)","\t\tif reason == v1.TaskRunReasonCancelled || reason == v1.TaskRunReasonTimedOut {","\t\t\treturn nil","\t\t}","\t}","","\tpod, err := podconvert.StopSidecars(ctx, c.Images.NopImage, c.KubeClientSet, tr.Namespace, tr.Status.PodName)","\tif err == nil {","\t\t// Check if any SidecarStatuses are still shown as Running after stopping","\t\t// Sidecars. If any Running, update SidecarStatuses based on Pod ContainerStatuses.","\t\tif podconvert.IsSidecarStatusRunning(tr) {","\t\t\terr = updateStoppedSidecarStatus(pod, tr)","\t\t}","\t}","\tif k8serrors.IsNotFound(err) {","\t\t// At this stage the TaskRun has been completed if the pod is not found, it won't come back,","\t\t// it has probably evicted. We can return the error, but we consider it a permanent one.","\t\treturn controller.NewPermanentError(err)","\t} else if err != nil {","\t\t// It is admissible for Pods to fail with concurrentModification errors","\t\t// when stopping sideCars. Instead of failing the TaskRun, we shall just","\t\t// let the reconciler requeue.","\t\tif isConcurrentModificationError(err) {","\t\t\treturn controller.NewRequeueAfter(time.Second)","\t\t}","\t\tlogger.Errorf(\"Error stopping sidecars for TaskRun %q: %v\", tr.Name, err)","\t\ttr.Status.MarkResourceFailed(v1.TaskRunReasonStopSidecarFailed, err)","\t}","\treturn nil","}","","func (c *Reconciler) finishReconcileUpdateEmitEvents(ctx context.Context, tr *v1.TaskRun, beforeCondition *apis.Condition, previousError error) error {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"finishReconcileUpdateEmitEvents\")","\tdefer span.End()","\tlogger := logging.FromContext(ctx)","","\tafterCondition := tr.Status.GetCondition(apis.ConditionSucceeded)","\tif afterCondition.IsFalse() \u0026\u0026 !tr.IsCancelled() \u0026\u0026 tr.IsRetriable() {","\t\tretryTaskRun(tr, afterCondition.Message)","\t\tafterCondition = tr.Status.GetCondition(apis.ConditionSucceeded)","\t}","\t// Send k8s events and cloud events (when configured)","\tevents.Emit(ctx, beforeCondition, afterCondition, tr)","","\terrs := []error{previousError}","","\t// If the Run has been completed before and remains so at present,","\t// no need to update the labels and annotations","\tskipUpdateLabelsAndAnnotations := !afterCondition.IsUnknown() \u0026\u0026 !beforeCondition.IsUnknown()","\tif !skipUpdateLabelsAndAnnotations {","\t\t_, err := c.updateLabelsAndAnnotations(ctx, tr)","\t\tif err != nil {","\t\t\tlogger.Warn(\"Failed to update TaskRun labels/annotations\", zap.Error(err))","\t\t\tevents.EmitError(controller.GetEventRecorder(ctx), err, tr)","\t\t\terrs = append(errs, err)","\t\t}","\t}","\tjoinedErr := errors.Join(errs...)","\tif controller.IsPermanentError(previousError) {","\t\treturn controller.NewPermanentError(joinedErr)","\t}","\treturn joinedErr","}","","// `prepare` fetches resources the taskrun depends on, runs validation and conversion","// It may report errors back to Reconcile, it updates the taskrun status in case of","// error but it does not sync updates back to etcd. It does not emit events.","// All errors returned by `prepare` are always handled by `Reconcile`, so they don't cause","// the key to be re-queued directly.","// `prepare` returns spec and resources. In future we might store","// them in the TaskRun.Status so we don't need to re-run `prepare` at every","// reconcile (see https://github.com/tektoncd/pipeline/issues/2473).","func (c *Reconciler) prepare(ctx context.Context, tr *v1.TaskRun) (*v1.TaskSpec, *resources.ResolvedTask, error) {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"prepare\")","\tdefer span.End()","\tlogger := logging.FromContext(ctx)","\ttr.SetDefaults(ctx)","","\t// list VerificationPolicies for trusted resources","\tvp, err := c.verificationPolicyLister.VerificationPolicies(tr.Namespace).List(labels.Everything())","\tif err != nil {","\t\treturn nil, nil, fmt.Errorf(\"failed to list VerificationPolicies from namespace %s with error %w\", tr.Namespace, err)","\t}","\tgetTaskfunc := resources.GetTaskFuncFromTaskRun(ctx, c.KubeClientSet, c.PipelineClientSet, c.resolutionRequester, tr, vp)","","\ttaskMeta, taskSpec, err := resources.GetTaskData(ctx, tr, getTaskfunc)","\tswitch {","\tcase errors.Is(err, remote.ErrRequestInProgress):","\t\tmessage := fmt.Sprintf(\"TaskRun %s/%s awaiting remote resource\", tr.Namespace, tr.Name)","\t\ttr.Status.MarkResourceOngoing(v1.TaskRunReasonResolvingTaskRef, message)","\t\treturn nil, nil, err","\tcase errors.Is(err, apiserver.ErrReferencedObjectValidationFailed), errors.Is(err, apiserver.ErrCouldntValidateObjectPermanent):","\t\ttr.Status.MarkResourceFailed(v1.TaskRunReasonTaskFailedValidation, err)","\t\treturn nil, nil, controller.NewPermanentError(err)","\tcase errors.Is(err, apiserver.ErrCouldntValidateObjectRetryable):","\t\treturn nil, nil, err","\tcase err != nil:","\t\tlogger.Errorf(\"Failed to determine Task spec to use for taskrun %s: %v\", tr.Name, err)","\t\tif resolutioncommon.IsErrTransient(err) {","\t\t\treturn nil, nil, err","\t\t}","\t\ttr.Status.MarkResourceFailed(v1.TaskRunReasonFailedResolution, err)","\t\treturn nil, nil, controller.NewPermanentError(err)","\tdefault:","\t\t// Store the fetched TaskSpec on the TaskRun for auditing","\t\tif err := storeTaskSpecAndMergeMeta(ctx, tr, taskSpec, taskMeta); err != nil {","\t\t\tlogger.Errorf(\"Failed to store TaskSpec on TaskRun.Status for taskrun %s: %v\", tr.Name, err)","\t\t}","\t}","","\tsteps, err := resources.GetStepActionsData(ctx, *taskSpec, tr, c.PipelineClientSet, c.KubeClientSet, c.resolutionRequester)","\tswitch {","\tcase errors.Is(err, remote.ErrRequestInProgress):","\t\tmessage := fmt.Sprintf(\"TaskRun %s/%s awaiting remote StepAction\", tr.Namespace, tr.Name)","\t\ttr.Status.MarkResourceOngoing(v1.TaskRunReasonResolvingStepActionRef, message)","\t\treturn nil, nil, err","\tcase errors.Is(err, apiserver.ErrReferencedObjectValidationFailed), errors.Is(err, apiserver.ErrCouldntValidateObjectPermanent):","\t\ttr.Status.MarkResourceFailed(v1.TaskRunReasonTaskFailedValidation, err)","\t\treturn nil, nil, controller.NewPermanentError(err)","\tcase errors.Is(err, apiserver.ErrCouldntValidateObjectRetryable):","\t\treturn nil, nil, err","\tcase err != nil:","\t\tlogger.Errorf(\"Failed to determine StepAction to use for TaskRun %s: %v\", tr.Name, err)","\t\tif resolutioncommon.IsErrTransient(err) {","\t\t\treturn nil, nil, err","\t\t}","\t\ttr.Status.MarkResourceFailed(v1.TaskRunReasonFailedResolution, err)","\t\treturn nil, nil, controller.NewPermanentError(err)","\tdefault:","\t\t// Store the fetched StepActions to TaskSpec, and update the stored TaskSpec again","\t\ttaskSpec.Steps = steps","\t\tif err := storeTaskSpecAndMergeMeta(ctx, tr, taskSpec, taskMeta); err != nil {","\t\t\tlogger.Errorf(\"Failed to store TaskSpec on TaskRun.Status for taskrun %s: %v\", tr.Name, err)","\t\t}","\t}","","\tif taskMeta.VerificationResult != nil {","\t\tswitch taskMeta.VerificationResult.VerificationResultType {","\t\tcase trustedresources.VerificationError:","\t\t\tlogger.Errorf(\"TaskRun %s/%s referred task failed signature verification\", tr.Namespace, tr.Name)","\t\t\ttr.Status.MarkResourceFailed(v1.TaskRunReasonResourceVerificationFailed, taskMeta.VerificationResult.Err)","\t\t\ttr.Status.SetCondition(\u0026apis.Condition{","\t\t\t\tType:    trustedresources.ConditionTrustedResourcesVerified,","\t\t\t\tStatus:  corev1.ConditionFalse,","\t\t\t\tMessage: taskMeta.VerificationResult.Err.Error(),","\t\t\t})","\t\t\treturn nil, nil, controller.NewPermanentError(taskMeta.VerificationResult.Err)","\t\tcase trustedresources.VerificationSkip:","\t\t\t// do nothing","\t\tcase trustedresources.VerificationWarn:","\t\t\ttr.Status.SetCondition(\u0026apis.Condition{","\t\t\t\tType:    trustedresources.ConditionTrustedResourcesVerified,","\t\t\t\tStatus:  corev1.ConditionFalse,","\t\t\t\tMessage: taskMeta.VerificationResult.Err.Error(),","\t\t\t})","\t\tcase trustedresources.VerificationPass:","\t\t\ttr.Status.SetCondition(\u0026apis.Condition{","\t\t\t\tType:   trustedresources.ConditionTrustedResourcesVerified,","\t\t\t\tStatus: corev1.ConditionTrue,","\t\t\t})","\t\t}","\t}","","\trtr := \u0026resources.ResolvedTask{","\t\tTaskName: taskMeta.Name,","\t\tTaskSpec: taskSpec,","\t\tKind:     resources.GetTaskKind(tr),","\t}","","\tif err := validateTaskSpecRequestResources(taskSpec); err != nil {","\t\tlogger.Errorf(\"TaskRun %s taskSpec request resources are invalid: %v\", tr.Name, err)","\t\ttr.Status.MarkResourceFailed(v1.TaskRunReasonFailedValidation, err)","\t\treturn nil, nil, controller.NewPermanentError(err)","\t}","","\tif err := ValidateResolvedTask(ctx, tr.Spec.Params, \u0026v1.Matrix{}, rtr); err != nil {","\t\tlogger.Errorf(\"TaskRun %q resources are invalid: %v\", tr.Name, err)","\t\ttr.Status.MarkResourceFailed(v1.TaskRunReasonFailedValidation, err)","\t\treturn nil, nil, controller.NewPermanentError(err)","\t}","","\tif config.FromContextOrDefaults(ctx).FeatureFlags.EnableParamEnum {","\t\tif err := ValidateEnumParam(ctx, tr.Spec.Params, rtr.TaskSpec.Params); err != nil {","\t\t\tlogger.Errorf(\"TaskRun %q Param Enum validation failed: %v\", tr.Name, err)","\t\t\ttr.Status.MarkResourceFailed(v1.TaskRunReasonInvalidParamValue, err)","\t\t\treturn nil, nil, controller.NewPermanentError(err)","\t\t}","\t}","","\tif err := resources.ValidateParamArrayIndex(rtr.TaskSpec, tr.Spec.Params); err != nil {","\t\tlogger.Errorf(\"TaskRun %q Param references are invalid: %v\", tr.Name, err)","\t\ttr.Status.MarkResourceFailed(v1.TaskRunReasonFailedValidation, err)","\t\treturn nil, nil, controller.NewPermanentError(err)","\t}","","\tif err := c.updateTaskRunWithDefaultWorkspaces(ctx, tr, taskSpec); err != nil {","\t\tlogger.Errorf(\"Failed to update taskrun %s with default workspace: %v\", tr.Name, err)","\t\ttr.Status.MarkResourceFailed(v1.TaskRunReasonFailedResolution, err)","\t\treturn nil, nil, controller.NewPermanentError(err)","\t}","","\tvar workspaceDeclarations []v1.WorkspaceDeclaration","\t// Propagating workspaces allows users to skip declarations","\t// In order to validate the workspace bindings we create declarations based on","\t// the workspaces provided in the task run spec. We only allow this feature for embedded taskSpec.","\tif tr.Spec.TaskSpec != nil {","\t\tfor _, ws := range tr.Spec.Workspaces {","\t\t\twspaceDeclaration := v1.WorkspaceDeclaration{Name: ws.Name}","\t\t\tworkspaceDeclarations = append(workspaceDeclarations, wspaceDeclaration)","\t\t}","\t\tworkspaceDeclarations = append(workspaceDeclarations, taskSpec.Workspaces...)","\t} else {","\t\tworkspaceDeclarations = taskSpec.Workspaces","\t}","\tif err := workspace.ValidateBindings(ctx, workspaceDeclarations, tr.Spec.Workspaces); err != nil {","\t\tlogger.Errorf(\"TaskRun %q workspaces are invalid: %v\", tr.Name, err)","\t\ttr.Status.MarkResourceFailed(v1.TaskRunReasonFailedValidation, err)","\t\treturn nil, nil, controller.NewPermanentError(err)","\t}","","\taaBehavior, err := affinityassistant.GetAffinityAssistantBehavior(ctx)","\tif err != nil {","\t\treturn nil, nil, controller.NewPermanentError(err)","\t}","\tif aaBehavior == affinityassistant.AffinityAssistantPerWorkspace {","\t\tif err := workspace.ValidateOnlyOnePVCIsUsed(tr.Spec.Workspaces); err != nil {","\t\t\tlogger.Errorf(\"TaskRun %q workspaces incompatible with Affinity Assistant: %v\", tr.Name, err)","\t\t\ttr.Status.MarkResourceFailed(v1.TaskRunReasonFailedValidation, err)","\t\t\treturn nil, nil, controller.NewPermanentError(err)","\t\t}","\t}","","\tif err := validateOverrides(taskSpec, \u0026tr.Spec); err != nil {","\t\tlogger.Errorf(\"TaskRun %q step or sidecar overrides are invalid: %v\", tr.Name, err)","\t\ttr.Status.MarkResourceFailed(v1.TaskRunReasonFailedValidation, err)","\t\treturn nil, nil, controller.NewPermanentError(err)","\t}","","\treturn taskSpec, rtr, nil","}","","// `reconcile` creates the Pod associated to the TaskRun, and it pulls back status","// updates from the Pod to the TaskRun.","// It reports errors back to Reconcile, it updates the taskrun status in case of","// error but it does not sync updates back to etcd. It does not emit events.","// `reconcile` consumes spec and resources returned by `prepare`","func (c *Reconciler) reconcile(ctx context.Context, tr *v1.TaskRun, rtr *resources.ResolvedTask) error {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"reconcile\")","\tdefer span.End()","","\tlogger := logging.FromContext(ctx)","\trecorder := controller.GetEventRecorder(ctx)","\tvar err error","","\t// Get the TaskRun's Pod if it should have one. Otherwise, create the Pod.","\tvar pod *corev1.Pod","","\tif tr.Status.PodName != \"\" {","\t\tpod, err = c.podLister.Pods(tr.Namespace).Get(tr.Status.PodName)","\t\tif k8serrors.IsNotFound(err) {","\t\t\t// Keep going, this will result in the Pod being created below.","\t\t} else if err != nil {","\t\t\t// This is considered a transient error, so we return error, do not update","\t\t\t// the task run condition, and return an error which will cause this key to","\t\t\t// be requeued for reconcile.","\t\t\tlogger.Errorf(\"Error getting pod %q: %v\", tr.Status.PodName, err)","\t\t\treturn err","\t\t}","\t} else {","\t\t// List pods that have a label with this TaskRun name.  Do not include other labels from the","\t\t// TaskRun in this selector.  The user could change them during the lifetime of the TaskRun so the","\t\t// current labels may not be set on a previously created Pod.","\t\tlabelSelector := labels.Set{pipeline.TaskRunLabelKey: tr.Name}","\t\tpos, err := c.podLister.Pods(tr.Namespace).List(labelSelector.AsSelector())","\t\tif err != nil {","\t\t\tlogger.Errorf(\"Error listing pods: %v\", err)","\t\t\treturn err","\t\t}","\t\tfor index := range pos {","\t\t\tpo := pos[index]","\t\t\tif metav1.IsControlledBy(po, tr) \u0026\u0026 !podconvert.DidTaskRunFail(po) \u0026\u0026 !podconvert.IsPodArchived(po, \u0026tr.Status) {","\t\t\t\tpod = po","\t\t\t}","\t\t}","\t}","","\t// Please note that this block is required to run before `applyParamsContextsResultsAndWorkspaces` is called the first time,","\t// and that `applyParamsContextsResultsAndWorkspaces` _must_ be called on every reconcile.","\tif pod == nil \u0026\u0026 tr.HasVolumeClaimTemplate() {","\t\tfor _, ws := range tr.Spec.Workspaces {","\t\t\tif err := c.pvcHandler.CreatePVCFromVolumeClaimTemplate(ctx, ws, *kmeta.NewControllerRef(tr), tr.Namespace); err != nil {","\t\t\t\tlogger.Errorf(\"Failed to create PVC for TaskRun %s: %v\", tr.Name, err)","\t\t\t\ttr.Status.MarkResourceFailed(volumeclaim.ReasonCouldntCreateWorkspacePVC,","\t\t\t\t\tfmt.Errorf(\"failed to create PVC for TaskRun %s workspaces correctly: %w\",","\t\t\t\t\t\tfmt.Sprintf(\"%s/%s\", tr.Namespace, tr.Name), err))","\t\t\t\treturn controller.NewPermanentError(err)","\t\t\t}","\t\t}","","\t\ttaskRunWorkspaces := applyVolumeClaimTemplates(tr.Spec.Workspaces, *kmeta.NewControllerRef(tr))","\t\t// This is used by createPod below. Changes to the Spec are not updated.","\t\ttr.Spec.Workspaces = taskRunWorkspaces","\t}","","\tresources.ApplyParametersToWorkspaceBindings(rtr.TaskSpec, tr)","\t// Get the randomized volume names assigned to workspace bindings","\tworkspaceVolumes := workspace.CreateVolumes(tr.Spec.Workspaces)","","\tts, err := applyParamsContextsResultsAndWorkspaces(ctx, tr, rtr, workspaceVolumes)","\tif err != nil {","\t\tlogger.Errorf(\"Error updating task spec parameters, contexts, results and workspaces: %s\", err)","\t\treturn err","\t}","\ttr.Status.TaskSpec = ts","","\tif len(tr.Status.TaskSpec.Steps) \u003e 0 {","\t\tlogger.Debugf(\"set taskspec for %s/%s - script: %s\", tr.Namespace, tr.Name, tr.Status.TaskSpec.Steps[0].Script)","\t}","","\tif pod == nil {","\t\tpod, err = c.createPod(ctx, ts, tr, rtr, workspaceVolumes)","\t\tif err != nil {","\t\t\tnewErr := c.handlePodCreationError(tr, err)","\t\t\tlogger.Errorf(\"Failed to create task run pod for taskrun %q: %v\", tr.Name, newErr)","\t\t\treturn newErr","\t\t}","\t}","","\tif podconvert.IsPodExceedingNodeResources(pod) {","\t\trecorder.Eventf(tr, corev1.EventTypeWarning, podconvert.ReasonExceededNodeResources, \"Insufficient resources to schedule pod %q\", pod.Name)","\t}","","\tif podconvert.SidecarsReady(pod.Status) {","\t\tif err := podconvert.UpdateReady(ctx, c.KubeClientSet, *pod); err != nil {","\t\t\treturn err","\t\t}","\t\tif err := c.metrics.RecordPodLatency(ctx, pod, tr); err != nil {","\t\t\tlogger.Warnf(\"Failed to log the metrics : %v\", err)","\t\t}","\t}","","\t// Convert the Pod's status to the equivalent TaskRun Status.","\ttr.Status, err = podconvert.MakeTaskRunStatus(ctx, logger, *tr, pod, c.KubeClientSet, rtr.TaskSpec)","\tif err != nil {","\t\treturn err","\t}","","\tif err := validateTaskRunResults(tr, rtr.TaskSpec); err != nil {","\t\ttr.Status.MarkResourceFailed(v1.TaskRunReasonFailedValidation, err)","\t\treturn err","\t}","","\tlogger.Infof(\"Successfully reconciled taskrun %s/%s with status: %#v\", tr.Name, tr.Namespace, tr.Status.GetCondition(apis.ConditionSucceeded))","\treturn nil","}","","func (c *Reconciler) updateTaskRunWithDefaultWorkspaces(ctx context.Context, tr *v1.TaskRun, taskSpec *v1.TaskSpec) error {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"updateTaskRunWithDefaultWorkspaces\")","\tdefer span.End()","\tconfigMap := config.FromContextOrDefaults(ctx)","\tdefaults := configMap.Defaults","\tif defaults.DefaultTaskRunWorkspaceBinding != \"\" {","\t\tvar defaultWS v1.WorkspaceBinding","\t\tif err := yaml.Unmarshal([]byte(defaults.DefaultTaskRunWorkspaceBinding), \u0026defaultWS); err != nil {","\t\t\treturn fmt.Errorf(\"failed to unmarshal %v\", defaults.DefaultTaskRunWorkspaceBinding)","\t\t}","\t\tworkspaceBindings := map[string]v1.WorkspaceBinding{}","\t\tfor _, tsWorkspace := range taskSpec.Workspaces {","\t\t\tif !tsWorkspace.Optional {","\t\t\t\tworkspaceBindings[tsWorkspace.Name] = v1.WorkspaceBinding{","\t\t\t\t\tName:                  tsWorkspace.Name,","\t\t\t\t\tSubPath:               defaultWS.SubPath,","\t\t\t\t\tVolumeClaimTemplate:   defaultWS.VolumeClaimTemplate,","\t\t\t\t\tPersistentVolumeClaim: defaultWS.PersistentVolumeClaim,","\t\t\t\t\tEmptyDir:              defaultWS.EmptyDir,","\t\t\t\t\tConfigMap:             defaultWS.ConfigMap,","\t\t\t\t\tSecret:                defaultWS.Secret,","\t\t\t\t}","\t\t\t}","\t\t}","","\t\tfor _, trWorkspace := range tr.Spec.Workspaces {","\t\t\tworkspaceBindings[trWorkspace.Name] = trWorkspace","\t\t}","","\t\ttr.Spec.Workspaces = []v1.WorkspaceBinding{}","\t\tfor _, wsBinding := range workspaceBindings {","\t\t\ttr.Spec.Workspaces = append(tr.Spec.Workspaces, wsBinding)","\t\t}","\t}","\treturn nil","}","","func (c *Reconciler) updateLabelsAndAnnotations(ctx context.Context, tr *v1.TaskRun) (*v1.TaskRun, error) {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"updateLabelsAndAnnotations\")","\tdefer span.End()","\t// Ensure the TaskRun is properly decorated with the version of the Tekton controller processing it.","\tif tr.Annotations == nil {","\t\ttr.Annotations = make(map[string]string, 1)","\t}","\ttr.Annotations[podconvert.ReleaseAnnotation] = changeset.Get()","","\tnewTr, err := c.taskRunLister.TaskRuns(tr.Namespace).Get(tr.Name)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"error getting TaskRun %s when updating labels/annotations: %w\", tr.Name, err)","\t}","\tif !reflect.DeepEqual(tr.ObjectMeta.Labels, newTr.ObjectMeta.Labels) || !reflect.DeepEqual(tr.ObjectMeta.Annotations, newTr.ObjectMeta.Annotations) {","\t\t// Note that this uses Update vs. Patch because the former is significantly easier to test.","\t\t// If we want to switch this to Patch, then we will need to teach the utilities in test/controller.go","\t\t// to deal with Patch (setting resourceVersion, and optimistic concurrency checks).","\t\tnewTr = newTr.DeepCopy()","\t\tnewTr.Labels = kmap.Union(newTr.Labels, tr.Labels)","\t\tnewTr.Annotations = kmap.Union(kmap.ExcludeKeys(newTr.Annotations, tknreconciler.KubectlLastAppliedAnnotationKey), tr.Annotations)","\t\treturn c.PipelineClientSet.TektonV1().TaskRuns(tr.Namespace).Update(ctx, newTr, metav1.UpdateOptions{})","\t}","\treturn newTr, nil","}","","func (c *Reconciler) handlePodCreationError(tr *v1.TaskRun, err error) error {","\tswitch {","\tcase isResourceQuotaConflictError(err):","\t\t// Requeue if it runs into ResourceQuotaConflictError Error i.e https://github.com/kubernetes/kubernetes/issues/67761","\t\ttr.Status.StartTime = nil","\t\ttr.Status.MarkResourceOngoing(podconvert.ReasonPodPending, \"tried to create pod, but it failed with ResourceQuotaConflictError\")","\t\treturn controller.NewRequeueAfter(time.Second)","\tcase isExceededResourceQuotaError(err):","\t\t// If we are struggling to create the pod, then it hasn't started.","\t\ttr.Status.StartTime = nil","\t\ttr.Status.MarkResourceOngoing(podconvert.ReasonExceededResourceQuota, fmt.Sprint(\"TaskRun Pod exceeded available resources: \", err))","\t\treturn controller.NewRequeueAfter(time.Minute)","\tcase isTaskRunValidationFailed(err):","\t\ttr.Status.MarkResourceFailed(v1.TaskRunReasonFailedValidation, err)","\tcase k8serrors.IsAlreadyExists(err):","\t\ttr.Status.MarkResourceOngoing(podconvert.ReasonPodPending, \"tried to create pod, but it already exists\")","\tcase isPodAdmissionFailed(err):","\t\ttr.Status.MarkResourceFailed(podconvert.ReasonPodAdmissionFailed, err)","\tdefault:","\t\t// The pod creation failed with unknown reason. The most likely","\t\t// reason is that something is wrong with the spec of the Task, that we could","\t\t// not check with validation before - i.e. pod template fields","\t\tmsg := fmt.Sprintf(\"failed to create task run pod %q: %v. Maybe \", tr.Name, err)","\t\tif tr.Spec.TaskRef != nil {","\t\t\tmsg += fmt.Sprintf(\"missing or invalid Task %s/%s\", tr.Namespace, tr.Spec.TaskRef.Name)","\t\t} else {","\t\t\tmsg += \"invalid TaskSpec\"","\t\t}","\t\terr = controller.NewPermanentError(errors.New(msg))","\t\ttr.Status.MarkResourceFailed(podconvert.ReasonPodCreationFailed, err)","\t}","\treturn err","}","","// failTaskRun stops a TaskRun with the provided Reason","// If a pod is associated to the TaskRun, it stops it","// failTaskRun function may return an error in case the pod could not be deleted","// failTaskRun may update the local TaskRun status, but it won't push the updates to etcd","func (c *Reconciler) failTaskRun(ctx context.Context, tr *v1.TaskRun, reason v1.TaskRunReason, message string) error {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"failTaskRun\")","\tdefer span.End()","\tlogger := logging.FromContext(ctx)","","\tlogger.Warnf(\"stopping task run %q because of %q\", tr.Name, reason)","\ttr.Status.MarkResourceFailed(reason, errors.New(message))","","\tcompletionTime := metav1.Time{Time: c.Clock.Now()}","\t// update tr completed time","\ttr.Status.CompletionTime = \u0026completionTime","","\tif tr.Status.PodName == \"\" {","\t\tlogger.Warnf(\"task run %q has no pod running yet\", tr.Name)","\t\treturn nil","\t}","","\t// When the TaskRun is failed, we mark all running/waiting steps as failed","\t// This is regardless of what happens with the Pod, which may be cancelled,","\t// deleted, non existing or fail to delete","\t// See https://github.com/tektoncd/pipeline/issues/8293 for more details.","\tterminateStepsInPod(tr, reason)","","\tvar err error","\tif (reason == v1.TaskRunReasonCancelled || reason == v1.TaskRunReasonTimedOut) \u0026\u0026 (config.FromContextOrDefaults(ctx).FeatureFlags.EnableKeepPodOnCancel) {","\t\tlogger.Infof(\"Canceling task run %q by entrypoint, Reason: %s\", tr.Name, reason)","\t\terr = podconvert.CancelPod(ctx, c.KubeClientSet, tr.Namespace, tr.Status.PodName)","\t} else {","\t\terr = c.KubeClientSet.CoreV1().Pods(tr.Namespace).Delete(ctx, tr.Status.PodName, metav1.DeleteOptions{})","\t}","\tif err != nil \u0026\u0026 !k8serrors.IsNotFound(err) {","\t\tlogger.Errorf(\"Failed to terminate pod %s: %v\", tr.Status.PodName, err)","\t\treturn err","\t}","","\treturn nil","}","","// updateStepStatusesFromPod fetches the pod and updates step statuses in the TaskRun","// This is called before failing a TaskRun to ensure step statuses are populated","func (c *Reconciler) updateStepStatusesFromPod(ctx context.Context, tr *v1.TaskRun) error {","\tlogger := logging.FromContext(ctx)","","\t// If there's no pod yet, nothing to update","\tif tr.Status.PodName == \"\" {","\t\treturn nil","\t}","","\t// Fetch the pod","\tpod, err := c.podLister.Pods(tr.Namespace).Get(tr.Status.PodName)","\tif k8serrors.IsNotFound(err) {","\t\t// Pod doesn't exist yet, nothing to update","\t\treturn nil","\t} else if err != nil {","\t\treturn err","\t}","","\t// Update step statuses from pod using the existing MakeTaskRunStatus function","\t// This ensures consistency with the normal reconciliation path","\tstatus, err := podconvert.MakeTaskRunStatus(ctx, logger, *tr, pod, c.KubeClientSet, tr.Status.TaskSpec)","\tif err != nil {","\t\treturn err","\t}","","\t// Only update the Steps field to avoid overwriting other status fields","\ttr.Status.Steps = status.Steps","\treturn nil","}","","// terminateStepsInPod updates step states for TaskRun on TaskRun object since pod has been deleted for cancel or timeout","func terminateStepsInPod(tr *v1.TaskRun, taskRunReason v1.TaskRunReason) {","\tfor i, step := range tr.Status.Steps {","\t\t// If running, include StartedAt for when step began running","\t\tif step.Running != nil {","\t\t\tstep.Terminated = \u0026corev1.ContainerStateTerminated{","\t\t\t\tExitCode:   1,","\t\t\t\tStartedAt:  step.Running.StartedAt,","\t\t\t\tFinishedAt: *tr.Status.CompletionTime,","\t\t\t\t// TODO(#7385): replace with more pod/container termination reason instead of overloading taskRunReason","\t\t\t\tReason:  taskRunReason.String(),","\t\t\t\tMessage: fmt.Sprintf(\"Step %s terminated as pod %s is terminated\", step.Name, tr.Status.PodName),","\t\t\t}","\t\t\tstep.TerminationReason = taskRunReason.String()","\t\t\tstep.Running = nil","\t\t\ttr.Status.Steps[i] = step","\t\t}","","\t\tif step.Waiting != nil {","\t\t\tstep.Terminated = \u0026corev1.ContainerStateTerminated{","\t\t\t\tExitCode:   1,","\t\t\t\tStartedAt:  tr.CreationTimestamp, // startedAt cannot be null due to CRD schema validation","\t\t\t\tFinishedAt: *tr.Status.CompletionTime,","\t\t\t\t// TODO(#7385): replace with more pod/container termination reason instead of overloading taskRunReason","\t\t\t\tReason:  taskRunReason.String(),","\t\t\t\tMessage: fmt.Sprintf(\"Step %s terminated as pod %s is terminated\", step.Name, tr.Status.PodName),","\t\t\t}","\t\t\tstep.TerminationReason = taskRunReason.String()","\t\t\tstep.Waiting = nil","\t\t\ttr.Status.Steps[i] = step","\t\t}","\t}","}","","// createPod creates a Pod based on the Task's configuration, with pvcName as a volumeMount","// TODO(dibyom): Refactor resource setup/substitution logic to its own function in the resources package","func (c *Reconciler) createPod(ctx context.Context, ts *v1.TaskSpec, tr *v1.TaskRun, rtr *resources.ResolvedTask, workspaceVolumes map[string]corev1.Volume) (*corev1.Pod, error) {","\tctx, span := c.tracerProvider.Tracer(TracerName).Start(ctx, \"createPod\")","\tdefer span.End()","\tlogger := logging.FromContext(ctx)","","\t// We don't want to mutate tr.Status.TaskSpec inside","\t// the createPod function. It's possible that pod will","\t// be killed before running and when rescheduling it","\t// will cause bugs. As this function could be called","\t// multiple times, we copy tr.Status.TaskSpec to help","\t// in scheduling Pod.","\tts = ts.DeepCopy()","","\t// By this time, params and workspaces should be propagated down so we can","\t// validate that all parameter variables and workspaces used in the TaskSpec are declared by the Task.","\tif validateErr := v1.ValidateUsageOfDeclaredParameters(ctx, ts.Steps, ts.Params); validateErr != nil {","\t\tlogger.Errorf(\"Failed to create a pod for taskrun: %s due to task validation error %v\", tr.Name, validateErr)","\t\treturn nil, validateErr","\t}","\tif validateErr := ts.Validate(ctx); validateErr != nil {","\t\tlogger.Errorf(\"Failed to create a pod for taskrun: %s due to task validation error %v\", tr.Name, validateErr)","\t\treturn nil, validateErr","\t}","","\tvar err error","\tts, err = workspace.Apply(ctx, *ts, tr.Spec.Workspaces, workspaceVolumes)","\tif err != nil {","\t\tlogger.Errorf(\"Failed to create a pod for taskrun: %s due to workspace error %v\", tr.Name, err)","\t\treturn nil, err","\t}","","\t// Apply path substitutions for the legacy credentials helper (aka \"creds-init\")","\tts = resources.ApplyCredentialsPath(ts, pipeline.CredsDir)","","\t// Apply parameter substitution to PodTemplate if it exists","\tif tr.Spec.PodTemplate != nil {","\t\tvar defaults []v1.ParamSpec","\t\tif len(ts.Params) \u003e 0 {","\t\t\tdefaults = append(defaults, ts.Params...)","\t\t}","\t\tupdatedPodTemplate := resources.ApplyPodTemplateReplacements(tr.Spec.PodTemplate, tr, defaults...)","\t\tif updatedPodTemplate != nil {","\t\t\ttrCopy := tr.DeepCopy()","\t\t\ttrCopy.Spec.PodTemplate = updatedPodTemplate","\t\t\ttr = trCopy","\t\t}","\t}","","\tpodbuilder := podconvert.Builder{","\t\tImages:          c.Images,","\t\tKubeClient:      c.KubeClientSet,","\t\tEntrypointCache: c.entrypointCache,","\t}","\tpod, err := podbuilder.Build(ctx, tr, *ts,","\t\tdefaultresourcerequirements.NewTransformer(ctx),","\t\tcomputeresources.NewTransformer(ctx, tr.Namespace, c.limitrangeLister),","\t\taffinityassistant.NewTransformer(ctx, tr.Annotations),","\t)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"translating TaskSpec to Pod: %w\", err)","\t}","","\t// Stash the podname in case there's create conflict so that we can try","\t// to fetch it.","\tpodName := pod.Name","","\tcfg := config.FromContextOrDefaults(ctx)","\tif !cfg.FeatureFlags.EnableWaitExponentialBackoff {","\t\tpod, err = c.KubeClientSet.CoreV1().Pods(tr.Namespace).Create(ctx, pod, metav1.CreateOptions{})","\t} else {","\t\tbackoff := wait.Backoff{","\t\t\tDuration: cfg.WaitExponentialBackoff.Duration, // Initial delay before retry","\t\t\tFactor:   cfg.WaitExponentialBackoff.Factor,   // Multiplier for exponential growth","\t\t\tSteps:    cfg.WaitExponentialBackoff.Steps,    // Maximum number of retry attempts","\t\t\tCap:      cfg.WaitExponentialBackoff.Cap,      // Maximum time spent before giving up","\t\t}","\t\tvar result *corev1.Pod","\t\terr = wait.ExponentialBackoff(backoff, func() (bool, error) {","\t\t\tresult = nil","\t\t\tresult, err = c.KubeClientSet.CoreV1().Pods(tr.Namespace).Create(ctx, pod, metav1.CreateOptions{})","\t\t\tif err != nil {","\t\t\t\tif ctrl.IsWebhookTimeout(err) {","\t\t\t\t\treturn false, nil // retry","\t\t\t\t}","\t\t\t\treturn false, err // do not retry","\t\t\t}","\t\t\tpod = result","\t\t\treturn true, nil","\t\t})","\t}","","\tif err == nil \u0026\u0026 willOverwritePodSetAffinity(tr) {","\t\tif recorder := controller.GetEventRecorder(ctx); recorder != nil {","\t\t\trecorder.Eventf(tr, corev1.EventTypeWarning, \"PodAffinityOverwrite\", \"Pod template affinity is overwritten by affinity assistant for pod %q\", pod.Name)","\t\t}","\t}","\t// If the pod failed to be created because it already exists, try to fetch","\t// from the informer and return if successful. Otherwise, return the","\t// original error.","\tif err != nil \u0026\u0026 k8serrors.IsAlreadyExists(err) {","\t\tif p, getErr := c.podLister.Pods(tr.Namespace).Get(podName); getErr == nil {","\t\t\treturn p, nil","\t\t}","\t}","\tif err != nil {","\t\treturn nil, err","\t}","\treturn pod, nil","}","","// applyParamsContextsResultsAndWorkspaces applies paramater, context, results and workspace substitutions to the TaskSpec.","func applyParamsContextsResultsAndWorkspaces(ctx context.Context, tr *v1.TaskRun, rtr *resources.ResolvedTask, workspaceVolumes map[string]corev1.Volume) (*v1.TaskSpec, error) {","\tts := rtr.TaskSpec.DeepCopy()","\tvar defaults []v1.ParamSpec","\tif len(ts.Params) \u003e 0 {","\t\tdefaults = append(defaults, ts.Params...)","\t}","\t// Apply parameter substitution from the taskrun.","\tts = resources.ApplyParameters(ts, tr, defaults...)","","\t// Apply context substitution from the taskrun","\tts = resources.ApplyContexts(ts, rtr.TaskName, tr)","","\t// Apply task result substitution","\tts = resources.ApplyResults(ts)","","\t// Apply step Artifacts substitution","\tts = resources.ApplyArtifacts(ts)","\t// Apply step exitCode path substitution","\tts = resources.ApplyStepExitCodePath(ts)","","\t// Apply workspace resource substitution","\t// propagate workspaces from taskrun to task.","\ttwn := []string{}","\tfor _, tw := range ts.Workspaces {","\t\ttwn = append(twn, tw.Name)","\t}","","\tfor _, trw := range tr.Spec.Workspaces {","\t\tskip := false","\t\tfor _, tw := range twn {","\t\t\tif tw == trw.Name {","\t\t\t\tskip = true","\t\t\t\tbreak","\t\t\t}","\t\t}","\t\tif !skip {","\t\t\tts.Workspaces = append(ts.Workspaces, v1.WorkspaceDeclaration{Name: trw.Name})","\t\t}","\t}","\tts = resources.ApplyWorkspaces(ctx, ts, ts.Workspaces, tr.Spec.Workspaces, workspaceVolumes)","","\treturn ts, nil","}","","func isExceededResourceQuotaError(err error) bool {","\treturn err != nil \u0026\u0026 k8serrors.IsForbidden(err) \u0026\u0026 strings.Contains(err.Error(), \"exceeded quota\")","}","","func isTaskRunValidationFailed(err error) bool {","\treturn err != nil \u0026\u0026 strings.Contains(err.Error(), \"TaskRun validation failed\")","}","","func isPodAdmissionFailed(err error) bool {","\treturn err != nil \u0026\u0026 k8serrors.IsForbidden(err) \u0026\u0026 (strings.Contains(err.Error(), \"violates PodSecurity\") ||","\t\tstrings.Contains(err.Error(), \"security context constraint\"))","}","","// updateStoppedSidecarStatus updates SidecarStatus for sidecars that were","// terminated by nop image","func updateStoppedSidecarStatus(pod *corev1.Pod, tr *v1.TaskRun) error {","\ttr.Status.Sidecars = []v1.SidecarState{}","\tfor _, s := range pod.Status.ContainerStatuses {","\t\tif podconvert.IsContainerSidecar(s.Name) {","\t\t\tvar sidecarState corev1.ContainerState","\t\t\tif s.LastTerminationState.Terminated != nil {","\t\t\t\t// Sidecar has successfully by terminated by nop image","\t\t\t\tlastTerminatedState := s.LastTerminationState.Terminated","\t\t\t\tsidecarState = corev1.ContainerState{","\t\t\t\t\tTerminated: \u0026corev1.ContainerStateTerminated{","\t\t\t\t\t\tExitCode:    lastTerminatedState.ExitCode,","\t\t\t\t\t\tReason:      \"Completed\",","\t\t\t\t\t\tMessage:     \"Sidecar container successfully stopped by nop image\",","\t\t\t\t\t\tStartedAt:   lastTerminatedState.StartedAt,","\t\t\t\t\t\tFinishedAt:  lastTerminatedState.FinishedAt,","\t\t\t\t\t\tContainerID: lastTerminatedState.ContainerID,","\t\t\t\t\t},","\t\t\t\t}","\t\t\t} else {","\t\t\t\t// Sidecar has not been terminated","\t\t\t\tsidecarState = s.State","\t\t\t}","","\t\t\ttr.Status.Sidecars = append(tr.Status.Sidecars, v1.SidecarState{","\t\t\t\tContainerState: *sidecarState.DeepCopy(),","\t\t\t\tName:           podconvert.TrimSidecarPrefix(s.Name),","\t\t\t\tContainer:      s.Name,","\t\t\t\tImageID:        s.ImageID,","\t\t\t})","\t\t}","\t}","\treturn nil","}","","// applyVolumeClaimTemplates and return WorkspaceBindings were templates is translated to PersistentVolumeClaims","func applyVolumeClaimTemplates(workspaceBindings []v1.WorkspaceBinding, owner metav1.OwnerReference) []v1.WorkspaceBinding {","\ttaskRunWorkspaceBindings := make([]v1.WorkspaceBinding, 0, len(workspaceBindings))","\tfor _, wb := range workspaceBindings {","\t\tif wb.VolumeClaimTemplate == nil {","\t\t\ttaskRunWorkspaceBindings = append(taskRunWorkspaceBindings, wb)","\t\t\tcontinue","\t\t}","","\t\t// apply template","\t\tb := v1.WorkspaceBinding{","\t\t\tName:    wb.Name,","\t\t\tSubPath: wb.SubPath,","\t\t\tPersistentVolumeClaim: \u0026corev1.PersistentVolumeClaimVolumeSource{","\t\t\t\tClaimName: volumeclaim.GeneratePVCNameFromWorkspaceBinding(wb.VolumeClaimTemplate.Name, wb, owner),","\t\t\t},","\t\t}","\t\ttaskRunWorkspaceBindings = append(taskRunWorkspaceBindings, b)","\t}","\treturn taskRunWorkspaceBindings","}","","func storeTaskSpecAndMergeMeta(ctx context.Context, tr *v1.TaskRun, ts *v1.TaskSpec, meta *resolutionutil.ResolvedObjectMeta) error {","\t// Only store the TaskSpec once, if it has never been set before.","\tif tr.Status.TaskSpec == nil {","\t\ttr.Status.TaskSpec = ts","\t\tif meta == nil {","\t\t\treturn nil","\t\t}","","\t\t// Propagate annotations from Task to TaskRun. TaskRun annotations take precedences over Task.","\t\ttr.ObjectMeta.Annotations = kmap.Union(kmap.ExcludeKeys(meta.Annotations, tknreconciler.KubectlLastAppliedAnnotationKey), tr.ObjectMeta.Annotations)","\t\t// Propagate labels from Task to TaskRun. TaskRun labels take precedences over Task.","\t\ttr.ObjectMeta.Labels = kmap.Union(meta.Labels, tr.ObjectMeta.Labels)","\t\tif tr.Spec.TaskRef != nil {","\t\t\ttr.ObjectMeta.Labels[pipeline.TaskLabelKey] = meta.Name","\t\t}","\t}","","\tcfg := config.FromContextOrDefaults(ctx)","\tif cfg.FeatureFlags.EnableProvenanceInStatus {","\t\tif tr.Status.Provenance == nil {","\t\t\ttr.Status.Provenance = \u0026v1.Provenance{}","\t\t}","\t\t// Store FeatureFlags in the Provenance.","\t\ttr.Status.Provenance.FeatureFlags = cfg.FeatureFlags","\t\t// Propagate RefSource from remote resolution to TaskRun Status","\t\t// This lives outside of the status.spec check to avoid the case where only the spec is available in the first reconcile and refSource comes in next reconcile.","\t\tif meta != nil \u0026\u0026 meta.RefSource != nil \u0026\u0026 tr.Status.Provenance.RefSource == nil {","\t\t\ttr.Status.Provenance.RefSource = meta.RefSource","\t\t}","\t}","","\treturn nil","}","","// willOverwritePodSetAffinity returns a bool indicating whether the","// affinity for pods will be overwritten with affinity assistant.","func willOverwritePodSetAffinity(taskRun *v1.TaskRun) bool {","\tvar podTemplate pod.Template","\tif taskRun.Spec.PodTemplate != nil {","\t\tpodTemplate = *taskRun.Spec.PodTemplate","\t}","\treturn taskRun.Annotations[workspace.AnnotationAffinityAssistantName] != \"\" \u0026\u0026 podTemplate.Affinity != nil","}","","// isResourceQuotaConflictError returns a bool indicating whether the","// k8 error is of kind resourcequotas or not","func isResourceQuotaConflictError(err error) bool {","\tvar k8Err k8serrors.APIStatus","\tif !errors.As(err, \u0026k8Err) {","\t\treturn false","\t}","\tk8ErrStatus := k8Err.Status()","\tif k8ErrStatus.Reason != metav1.StatusReasonConflict {","\t\treturn false","\t}","\treturn k8ErrStatus.Details != nil \u0026\u0026 k8ErrStatus.Details.Kind == \"resourcequotas\"","}","","const (","\t// optimisticLockErrorMsg is an error message exported from k8s.io/apiserver/pkg/registry/generic/registry.OptimisticLockErrorMsg","\t// We made a tradeoff here because importing the package would introduce approximately 94klines","\t// of code as a new dependency, and it would only be used to export one constant in one place.","\t// In future we might find a better way to maintain consistency for this upstream error message.","\toptimisticLockErrorMsg = \"the object has been modified; please apply your changes to the latest version and try again\"",")","","// isConcurrentModificationError determines whether it is a concurrent","// modification  error depending on its error type and error message.","func isConcurrentModificationError(err error) bool {","\tif !k8serrors.IsConflict(err) {","\t\treturn false","\t}","","\tvar se *k8serrors.StatusError","\tif !errors.As(err, \u0026se) {","\t\treturn false","\t}","","\treturn strings.Contains(err.Error(), optimisticLockErrorMsg)","}","","// retryTaskRun archives taskRun.Status to taskRun.Status.RetriesStatus, and set","// taskRun status to Unknown with Reason v1.TaskRunReasonToBeRetried.","func retryTaskRun(tr *v1.TaskRun, message string) {","\tnewStatus := tr.Status.DeepCopy()","\tnewStatus.RetriesStatus = nil","\ttr.Status.RetriesStatus = append(tr.Status.RetriesStatus, *newStatus)","\ttr.Status.StartTime = nil","\ttr.Status.CompletionTime = nil","\ttr.Status.PodName = \"\"","\ttr.Status.Results = nil","\ttaskRunCondSet := apis.NewBatchConditionSet()","\ttaskRunCondSet.Manage(\u0026tr.Status).MarkUnknown(apis.ConditionSucceeded, v1.TaskRunReasonToBeRetried.String(), message)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,0,0,0,0,0,2,2,0,0,0,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,0,2,2,1,1,0,0,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,1,1,2,2,2,0,0,0,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,1,0,0,2,2,2,2,0,0,2,1,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,0,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,0,0,0,2,2,2,2,0,0,2,2,2,2,0,0,2,2,0,0,2,2,2,2,2,2,1,1,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,2,1,1,1,2,1,1,1,1,1,1,1,1,0,2,0,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,1,1,1,1,0,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,1,1,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,1,1,1,1,0,2,1,1,1,1,0,2,2,2,2,2,2,0,0,2,1,1,1,1,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,1,1,2,2,2,2,2,2,0,0,2,1,1,1,1,0,2,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,1,1,1,1,1,1,2,2,2,2,2,2,2,1,1,1,2,2,2,2,2,0,0,0,0,0,2,2,2,1,1,1,1,1,1,0,0,2,2,2,0,0,2,2,2,2,2,2,1,1,1,2,2,2,2,2,0,2,2,2,2,2,2,2,0,0,2,1,1,0,2,1,1,1,1,1,1,0,0,0,2,2,2,2,0,2,2,2,2,0,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,1,1,0,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,1,1,1,0,2,0,0,0,0,2,2,2,2,2,2,2,0,0,2,2,1,1,2,1,1,0,0,0,2,2,1,1,0,0,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,2,2,2,2,0,2,2,2,1,1,1,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,0,0,0,2,1,1,1,0,0,0,0,2,1,1,1,0,2,2,2,2,0,0,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,0,2,2,2,0,2,2,2,0,0,2,2,2,0,2,2,2,0,2,2,2,2,0,0,0,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,0,2,2,2,2,2,2,0,0,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,1,1,0,0,2,2,2,2,2,2,0,0,2,2,2,2,2,0,2,2,2,2,2,2,0,0,2,0,0,0,0,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,2,2,1,1,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2]},{"id":209,"path":"pkg/reconciler/taskrun/tracing.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package taskrun","","import (","\t\"context\"","\t\"encoding/json\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"go.opentelemetry.io/otel\"","\t\"go.opentelemetry.io/otel/attribute\"","\t\"go.opentelemetry.io/otel/propagation\"","\t\"go.opentelemetry.io/otel/trace\"","\t\"knative.dev/pkg/logging\"",")","","const (","\t// TracerName is the name of the tracer","\tTracerName = \"TaskRunReconciler\"","\t// SpanContextAnnotation is the name of the Annotation used for propogating SpanContext","\tSpanContextAnnotation = \"tekton.dev/taskrunSpanContext\"",")","","// initialize tracing by creating the root span and injecting the","// spanContext is propogated through annotations in the CR","func initTracing(ctx context.Context, tracerProvider trace.TracerProvider, tr *v1.TaskRun) context.Context {","\tlogger := logging.FromContext(ctx)","\tpro := otel.GetTextMapPropagator()","","\t// SpanContext was created already","\tif len(tr.Status.SpanContext) \u003e 0 {","\t\treturn pro.Extract(ctx, propagation.MapCarrier(tr.Status.SpanContext))","\t}","","\tspanContext := make(map[string]string)","","\t// SpanContext was propogated through annotations","\tif tr.Annotations != nil \u0026\u0026 tr.Annotations[SpanContextAnnotation] != \"\" {","\t\terr := json.Unmarshal([]byte(tr.Annotations[SpanContextAnnotation]), \u0026spanContext)","\t\tif err != nil {","\t\t\tlogger.Error(\"unable to unmarshal spancontext, err: %s\", err)","\t\t}","","\t\ttr.Status.SpanContext = spanContext","\t\treturn pro.Extract(ctx, propagation.MapCarrier(tr.Status.SpanContext))","\t}","","\t// Create a new root span since there was no parent spanContext provided through annotations","\tctxWithTrace, span := tracerProvider.Tracer(TracerName).Start(ctx, \"TaskRun:Reconciler\")","\tdefer span.End()","\tspan.SetAttributes(attribute.String(\"taskrun\", tr.Name), attribute.String(\"namespace\", tr.Namespace))","","\tpro.Inject(ctxWithTrace, propagation.MapCarrier(spanContext))","","\tlogger.Debug(\"got tracing carrier\", spanContext)","\tif len(spanContext) == 0 {","\t\tlogger.Debug(\"tracerProvider doesn't provide a traceId, tracing is disabled\")","\t\treturn ctx","\t}","","\tspan.AddEvent(\"updating TaskRun status with SpanContext\")","\ttr.Status.SpanContext = spanContext","\treturn ctxWithTrace","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,1,1,0,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,0]},{"id":210,"path":"pkg/reconciler/taskrun/validate_taskrun.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package taskrun","","import (","\t\"context\"","\t\"fmt\"","\t\"sort\"","\t\"strings\"","","\t\"errors\"","","\tpipelineErrors \"github.com/tektoncd/pipeline/pkg/apis/pipeline/errors\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/list\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/taskrun/resources\"","","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"k8s.io/utils/strings/slices\"",")","","// validateParams validates that all Pipeline Task, Matrix.Params and Matrix.Include parameters all have values, match the specified","// type and object params have all the keys required","func validateParams(ctx context.Context, paramSpecs []v1.ParamSpec, params v1.Params, matrixParams v1.Params) error {","\tif paramSpecs == nil {","\t\treturn nil","\t}","\tneededParamsNames, neededParamsTypes := neededParamsNamesAndTypes(paramSpecs)","\tprovidedParams := params","\tprovidedParams = append(providedParams, matrixParams...)","\tprovidedParamsNames := providedParams.ExtractNames()","\tif missingParamsNames := missingParamsNames(neededParamsNames, providedParamsNames, paramSpecs); len(missingParamsNames) != 0 {","\t\treturn fmt.Errorf(\"missing values for these params which have no default values: %s\", missingParamsNames)","\t}","\tif wrongTypeParamNames := wrongTypeParamsNames(params, matrixParams, neededParamsTypes); len(wrongTypeParamNames) != 0 {","\t\treturn fmt.Errorf(\"param types don't match the user-specified type: %s\", wrongTypeParamNames)","\t}","\tif missingKeysObjectParamNames := MissingKeysObjectParamNames(paramSpecs, params); len(missingKeysObjectParamNames) != 0 {","\t\treturn fmt.Errorf(\"missing keys for these params which are required in ParamSpec's properties %v\", missingKeysObjectParamNames)","\t}","\treturn nil","}","","// neededParamsNamesAndTypes returns the needed parameter names and types based on the paramSpec","func neededParamsNamesAndTypes(paramSpecs []v1.ParamSpec) (sets.String, map[string]v1.ParamType) {","\tneededParamsNames := sets.String{}","\tneededParamsTypes := make(map[string]v1.ParamType)","\tfor _, inputResourceParam := range paramSpecs {","\t\tneededParamsNames.Insert(inputResourceParam.Name)","\t\tneededParamsTypes[inputResourceParam.Name] = inputResourceParam.Type","\t}","\treturn neededParamsNames, neededParamsTypes","}","","// missingParamsNames returns a slice of missing parameter names that have not been declared with a default value","// in the paramSpec","func missingParamsNames(neededParams sets.String, providedParams sets.String, paramSpecs []v1.ParamSpec) []string {","\tmissingParamsNames := neededParams.Difference(providedParams)","\tvar missingParamsNamesWithNoDefaults []string","\tfor _, inputResourceParam := range paramSpecs {","\t\tif missingParamsNames.Has(inputResourceParam.Name) \u0026\u0026 inputResourceParam.Default == nil {","\t\t\tmissingParamsNamesWithNoDefaults = append(missingParamsNamesWithNoDefaults, inputResourceParam.Name)","\t\t}","\t}","\treturn missingParamsNamesWithNoDefaults","}","func wrongTypeParamsNames(params []v1.Param, matrix v1.Params, neededParamsTypes map[string]v1.ParamType) []string {","\t// TODO(#4723): validate that $(task.taskname.result.resultname) is invalid for array and object type.","\t// It should be used to refer string and need to add [*] to refer to array or object.","\tvar wrongTypeParamNames []string","\tfor _, param := range params {","\t\tif _, ok := neededParamsTypes[param.Name]; !ok {","\t\t\t// Ignore any missing params - this happens when extra params were","\t\t\t// passed to the task that aren't being used.","\t\t\tcontinue","\t\t}","\t\t// This is needed to support array replacements in params. Users want to use $(tasks.taskName.results.resultname[*])","\t\t// to pass array result to array param, yet in yaml format this will be","\t\t// unmarshalled to string for ParamValues. So we need to check and skip this validation.","\t\t// Please refer issue #4879 for more details and examples.","\t\tif param.Value.Type == v1.ParamTypeString \u0026\u0026 (neededParamsTypes[param.Name] == v1.ParamTypeArray || neededParamsTypes[param.Name] == v1.ParamTypeObject) \u0026\u0026 v1.VariableSubstitutionRegex.MatchString(param.Value.StringVal) {","\t\t\tcontinue","\t\t}","\t\tif param.Value.Type != neededParamsTypes[param.Name] {","\t\t\twrongTypeParamNames = append(wrongTypeParamNames, param.Name)","\t\t}","\t}","\tfor _, param := range matrix {","\t\tif _, ok := neededParamsTypes[param.Name]; !ok {","\t\t\t// Ignore any missing params - this happens when extra params were","\t\t\t// passed to the task that aren't being used.","\t\t\tcontinue","\t\t}","\t\t// Matrix param replacements must be of type String","\t\tif neededParamsTypes[param.Name] != v1.ParamTypeString {","\t\t\twrongTypeParamNames = append(wrongTypeParamNames, param.Name)","\t\t}","\t}","\treturn wrongTypeParamNames","}","","// MissingKeysObjectParamNames checks if all required keys of object type param definitions are provided in params or param definitions' defaults.","func MissingKeysObjectParamNames(paramSpecs []v1.ParamSpec, params v1.Params) map[string][]string {","\tneededKeys := make(map[string][]string)","\tprovidedKeys := make(map[string][]string)","","\tfor _, spec := range paramSpecs {","\t\tif spec.Type == v1.ParamTypeObject {","\t\t\t// collect required keys from properties section","\t\t\tfor key := range spec.Properties {","\t\t\t\tneededKeys[spec.Name] = append(neededKeys[spec.Name], key)","\t\t\t}","","\t\t\t// collect provided keys from default","\t\t\tif spec.Default != nil \u0026\u0026 spec.Default.ObjectVal != nil {","\t\t\t\tfor key := range spec.Default.ObjectVal {","\t\t\t\t\tprovidedKeys[spec.Name] = append(providedKeys[spec.Name], key)","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\t// collect provided keys from run level value","\tfor _, p := range params {","\t\tif p.Value.Type == v1.ParamTypeObject {","\t\t\tfor key := range p.Value.ObjectVal {","\t\t\t\tprovidedKeys[p.Name] = append(providedKeys[p.Name], key)","\t\t\t}","\t\t}","\t}","","\treturn findMissingKeys(neededKeys, providedKeys)","}","","// findMissingKeys checks if objects have missing keys in its providers (taskrun value and default)","func findMissingKeys(neededKeys, providedKeys map[string][]string) map[string][]string {","\tmissings := map[string][]string{}","\tfor p, keys := range providedKeys {","\t\tif _, ok := neededKeys[p]; !ok {","\t\t\t// Ignore any missing objects - this happens when object param is provided with default","\t\t\tcontinue","\t\t}","\t\tmissedKeys := list.DiffLeft(neededKeys[p], keys)","\t\tif len(missedKeys) != 0 {","\t\t\tmissings[p] = missedKeys","\t\t}","\t}","","\treturn missings","}","","// ValidateResolvedTask validates that all parameters declared in the TaskSpec are present in the taskrun","// It also validates that all parameters have values, parameter types match the specified type and","// object params have all the keys required","func ValidateResolvedTask(ctx context.Context, params []v1.Param, matrix *v1.Matrix, rtr *resources.ResolvedTask) error {","\tvar paramSpecs v1.ParamSpecs","\tif rtr != nil {","\t\tparamSpecs = rtr.TaskSpec.Params","\t}","\tif err := validateParams(ctx, paramSpecs, params, matrix.GetAllParams()); err != nil {","\t\treturn pipelineErrors.WrapUserError(fmt.Errorf(\"invalid input params for task %s: %w\", rtr.TaskName, err))","\t}","\treturn nil","}","","// ValidateEnumParam validates the param values are in the defined enum list in the corresponding paramSpecs if provided.","// A validation error is returned otherwise.","func ValidateEnumParam(ctx context.Context, params []v1.Param, paramSpecs v1.ParamSpecs) error {","\tparamSpecNameToEnum := map[string][]string{}","\tfor _, ps := range paramSpecs {","\t\tif len(ps.Enum) == 0 {","\t\t\tcontinue","\t\t}","\t\tparamSpecNameToEnum[ps.Name] = ps.Enum","\t}","","\tfor _, p := range params {","\t\t// skip validation for and non-string typed and optional params (using default value)","\t\t// the default value of param is validated at validation webhook dryrun","\t\tif p.Value.Type != v1.ParamTypeString || p.Value.StringVal == \"\" {","\t\t\tcontinue","\t\t}","\t\t// skip validation for paramSpec without enum","\t\tif _, ok := paramSpecNameToEnum[p.Name]; !ok {","\t\t\tcontinue","\t\t}","","\t\tif !slices.Contains(paramSpecNameToEnum[p.Name], p.Value.StringVal) {","\t\t\treturn pipelineErrors.WrapUserError(fmt.Errorf(\"param `%s` value: %s is not in the enum list\", p.Name, p.Value.StringVal))","\t\t}","\t}","\treturn nil","}","","func validateTaskSpecRequestResources(taskSpec *v1.TaskSpec) error {","\tif taskSpec != nil {","\t\tfor _, step := range taskSpec.Steps {","\t\t\tfor k, request := range step.ComputeResources.Requests {","\t\t\t\t// First validate the limit in step","\t\t\t\tif limit, ok := step.ComputeResources.Limits[k]; ok {","\t\t\t\t\tif (\u0026limit).Cmp(request) == -1 {","\t\t\t\t\t\treturn pipelineErrors.WrapUserError(fmt.Errorf(\"invalid request resource value: %v must be less or equal to limit %v\", request.String(), limit.String()))","\t\t\t\t\t}","\t\t\t\t} else if taskSpec.StepTemplate != nil {","\t\t\t\t\t// If step doesn't configure the limit, validate the limit in stepTemplate","\t\t\t\t\tif limit, ok := taskSpec.StepTemplate.ComputeResources.Limits[k]; ok {","\t\t\t\t\t\tif (\u0026limit).Cmp(request) == -1 {","\t\t\t\t\t\t\treturn pipelineErrors.WrapUserError(fmt.Errorf(\"invalid request resource value: %v must be less or equal to limit %v\", request.String(), limit.String()))","\t\t\t\t\t\t}","\t\t\t\t\t}","\t\t\t\t}","\t\t\t}","\t\t}","\t}","","\treturn nil","}","","// validateOverrides validates that all stepOverrides map to valid steps, and likewise for sidecarOverrides","func validateOverrides(ts *v1.TaskSpec, trs *v1.TaskRunSpec) error {","\tstepErr := validateStepOverrides(ts, trs)","\tsidecarErr := validateSidecarOverrides(ts, trs)","\treturn errors.Join(stepErr, sidecarErr)","}","","func validateStepOverrides(ts *v1.TaskSpec, trs *v1.TaskRunSpec) error {","\tvar errs []error","\tstepNames := sets.NewString()","\tfor _, step := range ts.Steps {","\t\tstepNames.Insert(step.Name)","\t}","\tfor _, stepOverride := range trs.StepSpecs {","\t\tif !stepNames.Has(stepOverride.Name) {","\t\t\terrs = append(errs, pipelineErrors.WrapUserError(fmt.Errorf(\"invalid StepOverride: No Step named %s\", stepOverride.Name)))","\t\t}","\t}","\treturn errors.Join(errs...)","}","","func validateSidecarOverrides(ts *v1.TaskSpec, trs *v1.TaskRunSpec) error {","\tvar errs []error","\tsidecarNames := sets.NewString()","\tfor _, sidecar := range ts.Sidecars {","\t\tsidecarNames.Insert(sidecar.Name)","\t}","\tfor _, sidecarOverride := range trs.SidecarSpecs {","\t\tif !sidecarNames.Has(sidecarOverride.Name) {","\t\t\terrs = append(errs, pipelineErrors.WrapUserError(fmt.Errorf(\"invalid SidecarOverride: No Sidecar named %s\", sidecarOverride.Name)))","\t\t}","\t}","\treturn errors.Join(errs...)","}","","// validateResults checks the emitted results type and object properties against the ones defined in spec.","func validateTaskRunResults(tr *v1.TaskRun, resolvedTaskSpec *v1.TaskSpec) error {","\tspecResults := []v1.TaskResult{}","\tif tr.Spec.TaskSpec != nil {","\t\tspecResults = append(specResults, tr.Spec.TaskSpec.Results...)","\t}","","\tif resolvedTaskSpec != nil {","\t\tspecResults = append(specResults, resolvedTaskSpec.Results...)","\t}","","\t// When get the results, check if the type of result is the expected one","\tif missmatchedTypes := mismatchedTypesResults(tr, specResults); len(missmatchedTypes) != 0 {","\t\tvar s []string","\t\tfor k, v := range missmatchedTypes {","\t\t\ts = append(s, fmt.Sprintf(\" \\\"%v\\\": %v\", k, v))","\t\t}","\t\tsort.Strings(s)","\t\treturn pipelineErrors.WrapUserError(fmt.Errorf(\"Provided results don't match declared results; may be invalid JSON or missing result declaration: %v\", strings.Join(s, \",\")))","\t}","","\t// When get the results, for object value need to check if they have missing keys.","\tif missingKeysObjectNames := missingKeysofObjectResults(tr, specResults); len(missingKeysObjectNames) != 0 {","\t\treturn pipelineErrors.WrapUserError(fmt.Errorf(\"missing keys for these results which are required in TaskResult's properties %v\", missingKeysObjectNames))","\t}","\treturn nil","}","","// mismatchedTypesResults checks and returns all the mismatched types of emitted results against specified results.","func mismatchedTypesResults(tr *v1.TaskRun, specResults []v1.TaskResult) map[string]string {","\tneededTypes := make(map[string]string)","\tmismatchedTypes := make(map[string]string)","\tvar filteredResults []v1.TaskRunResult","\t// collect needed types for results","\tfor _, r := range specResults {","\t\tneededTypes[r.Name] = string(r.Type)","\t}","","\t// collect mismatched types for results, and correct results in filteredResults","\t// TODO(#6097): Validate if the emitted results are defined in taskspec","\tfor _, trr := range tr.Status.Results {","\t\tneeded, ok := neededTypes[trr.Name]","\t\tif ok \u0026\u0026 needed != string(trr.Type) {","\t\t\tmismatchedTypes[trr.Name] = fmt.Sprintf(\"task result is expected to be \\\"%v\\\" type but was initialized to a different type \\\"%v\\\"\", needed, trr.Type)","\t\t} else {","\t\t\tfilteredResults = append(filteredResults, trr)","\t\t}","\t}","\t// remove the mismatched results","\ttr.Status.Results = filteredResults","\treturn mismatchedTypes","}","","// missingKeysofObjectResults checks and returns the missing keys of object results.","func missingKeysofObjectResults(tr *v1.TaskRun, specResults []v1.TaskResult) map[string][]string {","\tneededKeys := make(map[string][]string)","\tprovidedKeys := make(map[string][]string)","\t// collect needed keys for object results","\tfor _, r := range specResults {","\t\tif string(r.Type) == string(v1.ParamTypeObject) {","\t\t\tfor key := range r.Properties {","\t\t\t\tneededKeys[r.Name] = append(neededKeys[r.Name], key)","\t\t\t}","\t\t}","\t}","","\t// collect provided keys for object results","\tfor _, trr := range tr.Status.Results {","\t\tif trr.Value.Type == v1.ParamTypeObject {","\t\t\tfor key := range trr.Value.ObjectVal {","\t\t\t\tprovidedKeys[trr.Name] = append(providedKeys[trr.Name], key)","\t\t\t}","\t\t}","\t}","\treturn findMissingKeys(neededKeys, providedKeys)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,0,2,0,2,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,0,2,2,2,0,2,2,2,2,2,0,0,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,0,0,0,0,2,2,2,2,2,0,0,0,2,0,0,0,2,2,2,2,2,2,0,2,2,2,2,0,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,0,2,0,0,2,2,2,2,2,0,0,2,2,0,0,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,2,0,0,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,0,2,2,2,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,0,0,2,2,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,0,0,2,0]},{"id":211,"path":"pkg/reconciler/testing/configmap.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package testing","","import (","\t\"fmt\"","\t\"os\"","\t\"strconv\"","\t\"testing\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"knative.dev/pkg/system\"","\t\"sigs.k8s.io/yaml\"",")","","const (","\tapiFieldsFeatureFlag           = \"enable-api-fields\"","\tmaxMatrixCombinationsCountFlag = \"default-max-matrix-combinations-count\"",")","","// ConfigMapFromTestFile creates a v1.ConfigMap from a YAML file","// It loads the YAML file from the testdata folder.","func ConfigMapFromTestFile(t *testing.T, name string) *corev1.ConfigMap {","\tt.Helper()","","\tb, err := os.ReadFile(fmt.Sprintf(\"testdata/%s.yaml\", name))","\tif err != nil {","\t\tt.Fatalf(\"ReadFile() = %v\", err)","\t}","","\tvar cm corev1.ConfigMap","","\t// Use \"sigs.k8s.io/yaml\" since it reads json struct","\t// tags so things unmarshal properly","\tif err := yaml.Unmarshal(b, \u0026cm); err != nil {","\t\tt.Fatalf(\"yaml.Unmarshal() = %v\", err)","\t}","","\treturn \u0026cm","}","","func NewFeatureFlagsConfigMapInSlice() []*corev1.ConfigMap {","\treturn []*corev1.ConfigMap{newFeatureFlagsConfigMap()}","}","","func newFeatureFlagsConfigMap() *corev1.ConfigMap {","\treturn \u0026corev1.ConfigMap{","\t\tObjectMeta: metav1.ObjectMeta{","\t\t\tName:      config.GetFeatureFlagsConfigName(),","\t\t\tNamespace: system.Namespace(),","\t\t},","\t\tData: make(map[string]string),","\t}","}","","func NewAlphaFeatureFlagsConfigMapInSlice() []*corev1.ConfigMap {","\treturn []*corev1.ConfigMap{withEnabledAlphaAPIFields(newFeatureFlagsConfigMap())}","}","","func withEnabledAlphaAPIFields(cm *corev1.ConfigMap) *corev1.ConfigMap {","\tnewCM := cm.DeepCopy()","\tnewCM.Data[apiFieldsFeatureFlag] = config.AlphaAPIFields","\treturn newCM","}","","func NewFeatureFlagsConfigMapWithMatrixInSlice(count int) []*corev1.ConfigMap {","\treturn append(","\t\tNewFeatureFlagsConfigMapInSlice(),","\t\twithMaxMatrixCombinationsCount(newDefaultsConfigMap(), count),","\t)","}","","func withMaxMatrixCombinationsCount(cm *corev1.ConfigMap, count int) *corev1.ConfigMap {","\tnewCM := cm.DeepCopy()","\tnewCM.Data[maxMatrixCombinationsCountFlag] = strconv.Itoa(count)","\treturn newCM","}","","func newDefaultsConfigMap() *corev1.ConfigMap {","\treturn \u0026corev1.ConfigMap{","\t\tObjectMeta: metav1.ObjectMeta{","\t\t\tName:      config.GetDefaultsConfigName(),","\t\t\tNamespace: system.Namespace(),","\t\t},","\t\tData: make(map[string]string),","\t}","}","","func NewAlphaFeatureFlagsConfigMapWithMatrixInSlice(count int) []*corev1.ConfigMap {","\treturn append(","\t\tNewAlphaFeatureFlagsConfigMapInSlice(),","\t\twithMaxMatrixCombinationsCount(newDefaultsConfigMap(), count),","\t)","}","","func NewDefaultsCofigMapInSlice() []*corev1.ConfigMap {","\treturn []*corev1.ConfigMap{newDefaultsConfigMap()}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,0,0,1,1,1,0,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1]},{"id":212,"path":"pkg/reconciler/testing/factory.go","lines":["package testing","","import (","\t\"fmt\"","\t\"testing\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/test/parse\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/types\"",")","","var (","\ttrueb = true",")","","// TwoPipelinesInPipelineMixedTasks creates a parent Pipeline with two embedded child Pipelines:","// one using an embedded taskSpec and the other using a taskRef. It also creates a PipelineRun","// for the parent Pipeline, the expected child PipelineRuns for each child Pipeline and the","// referenced task.","func TwoPipelinesInPipelineMixedTasks(t *testing.T, namespace, parentPipelineRunName string) (*v1.Task, *v1.Pipeline, *v1.PipelineRun, []*v1.PipelineRun) {","\tt.Helper()","\tuid := \"bar\"","\ttaskName := \"ref-task\"","\tparentPipelineName := \"parent-pipeline-mixed\"","\tchildPipelineName1 := \"child-pipeline-taskspec\"","\tchildPipelineName2 := \"child-pipeline-taskref\"","\tchildPipelineTaskName1 := \"child-taskspec\"","\tchildPipelineTaskName2 := \"child-taskref\"","","\ttask := parse.MustParseV1Task(t, fmt.Sprintf(`","metadata:","  name: %s","  namespace: %s","spec:","  steps:","  - name: mystep","    image: mirror.gcr.io/busybox","    script: 'echo \"Hello from referenced task in child PipelineRun 2!\"'","`, taskName, namespace))","","\tparentPipeline := parse.MustParseV1Pipeline(t, fmt.Sprintf(`","metadata:","  name: %s","  namespace: %s","spec:","  tasks:","  - name: %s","    pipelineSpec:","      tasks:","      - name: %s","        taskSpec:","          steps:","          - name: mystep","            image: mirror.gcr.io/busybox","            script: 'echo \"Hello from child PipelineRun 1!\"'","  - name: %s","    pipelineSpec:","      tasks:","      - name: %s","        taskRef:","          name: %s","`, parentPipelineName, namespace, childPipelineName1, childPipelineTaskName1, childPipelineName2, childPipelineTaskName2, taskName))","","\tparentPipelineRun := parse.MustParseV1PipelineRun(t, fmt.Sprintf(`","metadata:","  name: %s","  namespace: %s","  uid: %s","spec:","  pipelineRef:","    name: %s","`, parentPipelineRunName, namespace, uid, parentPipelineName))","","\texpectedName1 := parentPipelineRunName + \"-\" + childPipelineName1","\texpectedChildPipelineRun1 := parse.MustParseChildPipelineRunWithObjectMeta(","\t\tt,","\t\tchildPipelineRunWithObjectMeta(","\t\t\texpectedName1,","\t\t\tnamespace,","\t\t\tparentPipelineRunName,","\t\t\tparentPipelineName,","\t\t\tchildPipelineName1,","\t\t\tuid,","\t\t),","\t\tfmt.Sprintf(`","spec:","  pipelineSpec:","    tasks:","    - name: %s","      taskSpec:","        steps:","        - name: mystep","          image: mirror.gcr.io/busybox","          script: 'echo \"Hello from child PipelineRun 1!\"'","`, childPipelineTaskName1),","\t)","","\texpectedName2 := parentPipelineRunName + \"-\" + childPipelineName2","\texpectedChildPipelineRun2 := parse.MustParseChildPipelineRunWithObjectMeta(","\t\tt,","\t\tchildPipelineRunWithObjectMeta(","\t\t\texpectedName2,","\t\t\tnamespace,","\t\t\tparentPipelineRunName,","\t\t\tparentPipelineName,","\t\t\tchildPipelineName2,","\t\t\tuid,","\t\t),","\t\tfmt.Sprintf(`","spec:","  pipelineSpec:","    tasks:","    - name: %s","      taskRef:","        name: %s","`, childPipelineTaskName2, taskName),","\t)","","\treturn task, parentPipeline, parentPipelineRun, []*v1.PipelineRun{expectedChildPipelineRun1, expectedChildPipelineRun2}","}","","// OnePipelineInPipeline creates a single Pipeline with one child pipeline using","// PipelineSpec with TaskSpec. It also creates the according PipelineRun for it","// and the expected child PipelineRun against which the test will validate.","func OnePipelineInPipeline(t *testing.T, namespace, parentPipelineRunName string) (*v1.Pipeline, *v1.PipelineRun, *v1.PipelineRun) {","\tt.Helper()","\tuid := \"bar\"","\tparentPipelineName := \"parent-pipeline\"","\tchildPipelineName := \"child-pipeline\"","\tchildPipelineTaskName := \"child-pipeline-task\"","","\tparentPipeline := parse.MustParseV1Pipeline(t, fmt.Sprintf(`","metadata:","  name: %s","  namespace: %s","spec:","  tasks:","  - name: %s","    pipelineSpec:","      tasks:","      - name: %s","        taskSpec:","          steps:","          - name: mystep","            image: mirror.gcr.io/busybox","            script: 'echo \"Hello from child PipelineRun!\"'","`, parentPipelineName, namespace, childPipelineName, childPipelineTaskName))","","\tparentPipelineRun := parse.MustParseV1PipelineRun(t, fmt.Sprintf(`","metadata:","  name: %s","  namespace: %s","  uid: %s","spec:","  pipelineRef:","    name: %s","`, parentPipelineRunName, namespace, uid, parentPipelineName))","","\texpectedName := parentPipelineRunName + \"-\" + childPipelineName","\texpectedChildPipelineRun := parse.MustParseChildPipelineRunWithObjectMeta(","\t\tt,","\t\tchildPipelineRunWithObjectMeta(","\t\t\texpectedName,","\t\t\tnamespace,","\t\t\tparentPipelineRunName,","\t\t\tparentPipelineName,","\t\t\tchildPipelineName,","\t\t\tuid,","\t\t),","\t\tfmt.Sprintf(`","spec:","  pipelineSpec:","    tasks:","    - name: %s","      taskSpec:","        steps:","        - name: mystep","          image: mirror.gcr.io/busybox","          script: 'echo \"Hello from child PipelineRun!\"'","`, childPipelineTaskName),","\t)","","\treturn parentPipeline, parentPipelineRun, expectedChildPipelineRun","}","","func WithAnnotationAndLabel(pr *v1.PipelineRun, withUnused bool) *v1.PipelineRun {","\tif pr.Annotations == nil {","\t\tpr.Annotations = map[string]string{}","\t}","\tpr.Annotations[\"tekton.test/annotation\"] = \"test-annotation-value\"","","\tif pr.Labels == nil {","\t\tpr.Labels = map[string]string{}","\t}","\tpr.Labels[\"tekton.test/label\"] = \"test-label-value\"","","\tif withUnused {","\t\tpr.Labels[\"tekton.dev/pipeline\"] = \"will-not-be-used\"","\t}","","\treturn pr","}","","func childPipelineRunWithObjectMeta(","\tchildPipelineRunName,","\tns,","\tparentPipelineRunName,","\tparentPipelineName,","\tpipelineTaskName,","\tuid string,",") metav1.ObjectMeta {","\tom := metav1.ObjectMeta{","\t\tName:      childPipelineRunName,","\t\tNamespace: ns,","\t\tOwnerReferences: []metav1.OwnerReference{{","\t\t\tKind:               pipeline.PipelineRunControllerName,","\t\t\tName:               parentPipelineRunName,","\t\t\tAPIVersion:         \"tekton.dev/v1\",","\t\t\tController:         \u0026trueb,","\t\t\tBlockOwnerDeletion: \u0026trueb,","\t\t\tUID:                types.UID(uid),","\t\t}},","\t\tLabels: map[string]string{","\t\t\tpipeline.PipelineLabelKey:       parentPipelineName,","\t\t\tpipeline.PipelineRunLabelKey:    parentPipelineRunName,","\t\t\tpipeline.PipelineTaskLabelKey:   pipelineTaskName,","\t\t\tpipeline.PipelineRunUIDLabelKey: uid,","\t\t\tpipeline.MemberOfLabelKey:       v1.PipelineTasks,","\t\t},","\t\tAnnotations: map[string]string{},","\t}","","\treturn om","}","","// NestedPipelinesInPipeline creates a three-level nested pipeline structure:","// Parent Pipeline -\u003e Child Pipeline -\u003e Grandchild Pipeline","// Returns the parent pipeline, parent pipelinerun, expected child pipelinerun, and expected grandchild pipelinerun","func NestedPipelinesInPipeline(t *testing.T, namespace, parentPipelineRunName string) (*v1.Pipeline, *v1.PipelineRun, *v1.PipelineRun, *v1.PipelineRun) {","\tt.Helper()","\tuid := \"nested\"","\tparentPipelineName := \"parent-pipeline\"","\tchildPipelineName := \"child-ppl\"","\tgrandchildPipelineName := \"grandchild-ppl\"","\tgrandchildPipelineTaskName := \"grandchild-task\"","","\tparentPipeline := parse.MustParseV1Pipeline(t, fmt.Sprintf(`","metadata:","  name: %s","  namespace: %s","spec:","  tasks:","  - name: %s","    pipelineSpec:","      tasks:","      - name: %s","        pipelineSpec:","          tasks:","          - name: %s","            taskSpec:","              steps:","              - name: mystep","                image: mirror.gcr.io/busybox","                script: 'echo \"Hello from grandchild Pipeline!\"'","`, parentPipelineName, namespace, childPipelineName, grandchildPipelineName, grandchildPipelineTaskName))","","\tparentPipelineRun := parse.MustParseV1PipelineRun(t, fmt.Sprintf(`","metadata:","  name: %s","  namespace: %s","  uid: %s","spec:","  pipelineRef:","    name: %s","`, parentPipelineRunName, namespace, uid, parentPipelineName))","","\t// expected child pipeline run created by parent","\texpectedChildName := parentPipelineRunName + \"-\" + childPipelineName","\texpectedChildPipelineRun := parse.MustParseChildPipelineRunWithObjectMeta(","\t\tt,","\t\tchildPipelineRunWithObjectMeta(","\t\t\texpectedChildName,","\t\t\tnamespace,","\t\t\tparentPipelineRunName,","\t\t\tparentPipelineName,","\t\t\tchildPipelineName,","\t\t\tuid,","\t\t),","\t\tfmt.Sprintf(`","spec:","  pipelineSpec:","    tasks:","    - name: %s","      pipelineSpec:","        tasks:","        - name: %s","          taskSpec:","            steps:","            - name: mystep","              image: mirror.gcr.io/busybox","              script: 'echo \"Hello from grandchild Pipeline!\"'","`, grandchildPipelineName, grandchildPipelineTaskName),","\t)","","\t// expected grandchild pipeline run created by child","\texpectedGrandchildName := expectedChildName + \"-\" + grandchildPipelineName","\texpectedGrandchildPipelineRun := parse.MustParseChildPipelineRunWithObjectMeta(","\t\tt,","\t\tchildPipelineRunWithObjectMeta(","\t\t\texpectedGrandchildName,","\t\t\tnamespace,","\t\t\texpectedChildName,","\t\t\texpectedChildName,","\t\t\tgrandchildPipelineName,","\t\t\t\"\", // keep empty, UID is not set on actual child PipelineRun by fake client","\t\t),","\t\tfmt.Sprintf(`","spec:","  pipelineSpec:","    tasks:","    - name: %s","      taskSpec:","        steps:","        - name: mystep","          image: mirror.gcr.io/busybox","          script: 'echo \"Hello from grandchild Pipeline!\"'","`, grandchildPipelineTaskName),","\t)","","\treturn parentPipeline, parentPipelineRun, expectedChildPipelineRun, expectedGrandchildPipelineRun","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]},{"id":213,"path":"pkg/reconciler/testing/logger.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","\thttp://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package testing","","import (","\t\"context\"","\t\"testing\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/reconciler/events/cloudevent\"","\t\"go.uber.org/zap\"","\t\"go.uber.org/zap/zaptest\"","\t\"k8s.io/client-go/rest\"","\t\"k8s.io/client-go/tools/record\"","\tfilteredinformerfactory \"knative.dev/pkg/client/injection/kube/informers/factory/filtered\"","","\t// Import for creating fake filtered factory in the test","\t_ \"knative.dev/pkg/client/injection/kube/informers/factory/filtered/fake\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/injection\"","\t\"knative.dev/pkg/logging\"","\tlogtesting \"knative.dev/pkg/logging/testing\"",")","","// SetupFakeContext sets up the Context and the fake filtered informers for the tests.","func SetupFakeContext(t *testing.T) (context.Context, []controller.Informer) {","\tt.Helper()","\tctx, _, informer := setupFakeContextWithLabelKey(t)","\treturn WithLogger(ctx, t), informer","}","","// SetupFakeCloudClientContext sets up the fakeclient to context","func SetupFakeCloudClientContext(ctx context.Context, expectedEventCount int) context.Context {","\tcloudEventClientBehaviour := cloudevent.FakeClientBehaviour{","\t\tSendSuccessfully: true,","\t}","\treturn cloudevent.WithFakeClient(ctx, \u0026cloudEventClientBehaviour, expectedEventCount)","}","","// SetupDefaultContext sets up the Context and the default filtered informers for the tests.","func SetupDefaultContext(t *testing.T) (context.Context, []controller.Informer) {","\tt.Helper()","\tctx, _, informer := setupDefaultContextWithLabelKey(t)","\treturn WithLogger(ctx, t), informer","}","","// WithLogger returns the Logger","func WithLogger(ctx context.Context, t *testing.T) context.Context {","\tt.Helper()","\treturn logging.WithLogger(ctx, TestLogger(t))","}","","// TestLogger sets up the Logger","func TestLogger(t *testing.T) *zap.SugaredLogger {","\tlogger := zaptest.NewLogger(t, zaptest.WrapOptions(zap.AddCaller()))","\treturn logger.Sugar().Named(t.Name())","}","","// setupFakeContextWithLabelKey sets up the Context and the fake informers for the tests","// The provided context includes the FilteredInformerFactory LabelKey.","func setupFakeContextWithLabelKey(t zaptest.TestingT) (context.Context, context.CancelFunc, []controller.Informer) {","\tctx, c := context.WithCancel(logtesting.TestContextWithLogger(t))","\tctx = controller.WithEventRecorder(ctx, record.NewFakeRecorder(1000))","\tctx = filteredinformerfactory.WithSelectors(ctx, v1.ManagedByLabelKey)","\tctx, is := injection.Fake.SetupInformers(ctx, \u0026rest.Config{})","\treturn ctx, c, is","}","","// setupDefaultContextWithLabelKey sets up the Context and the default informers for the tests","// The provided context includes the FilteredInformerFactory LabelKey.","func setupDefaultContextWithLabelKey(t zaptest.TestingT) (context.Context, context.CancelFunc, []controller.Informer) {","\tctx, c := context.WithCancel(logtesting.TestContextWithLogger(t))","\tctx = filteredinformerfactory.WithSelectors(ctx, v1.ManagedByLabelKey)","\tctx, is := injection.Default.SetupInformers(ctx, \u0026rest.Config{})","\treturn ctx, c, is","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,1,1,1,1,1,1,0,0,1,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1]},{"id":214,"path":"pkg/reconciler/testing/status.go","lines":["package testing","","import (","\t\"testing\"","","\t\"github.com/google/go-cmp/cmp\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/test/diff\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"knative.dev/pkg/apis\"",")","","const (","\ttaskRun     = pipeline.TaskRunControllerName","\tcustomRun   = pipeline.CustomRunControllerName","\tpipelineRun = pipeline.PipelineRunControllerName",")","","func CheckPipelineRunConditionStatusAndReason(","\tt *testing.T,","\tprStatus v1.PipelineRunStatus,","\texpectedStatus corev1.ConditionStatus,","\texpectedReason string,",") {","\tt.Helper()","","\tactualCondition := prStatus.GetCondition(apis.ConditionSucceeded)","\tif actualCondition == nil {","\t\tt.Fatalf(\"want condition, got nil\")","\t}","\tif actualCondition.Status != expectedStatus {","\t\tt.Errorf(\"want status %v, got %v\", expectedStatus, actualCondition.Status)","\t}","\tif actualCondition.Reason != expectedReason {","\t\tt.Errorf(\"want reason %s, got %s\", expectedReason, actualCondition.Reason)","\t}","}","","func VerifyTaskRunStatusesCount(t *testing.T, prStatus v1.PipelineRunStatus, expectedCount int) {","\tt.Helper()","\tverifyCount(t, prStatus, expectedCount, taskRun)","}","","func verifyCount(t *testing.T, prStatus v1.PipelineRunStatus, expectedCount int, kind string) {","\tt.Helper()","","\tactualCount := len(filterChildRefsForKind(prStatus.ChildReferences, kind))","\tif actualCount != expectedCount {","\t\toneOrMany := kind","\t\tif expectedCount \u003e 1 {","\t\t\toneOrMany += \"s\"","\t\t}","\t\tt.Errorf(\"Expected PipelineRun status ChildReferences to have %d %s, but was %d\", expectedCount, oneOrMany, actualCount)","\t}","}","","func filterChildRefsForKind(childRefs []v1.ChildStatusReference, kind string) []v1.ChildStatusReference {","\tvar filtered []v1.ChildStatusReference","\tfor _, cr := range childRefs {","\t\tif cr.Kind == kind {","\t\t\tfiltered = append(filtered, cr)","\t\t}","\t}","\treturn filtered","}","","func VerifyTaskRunStatusesNames(t *testing.T, prStatus v1.PipelineRunStatus, expectedNames ...string) {","\tt.Helper()","\tverifyNames(t, prStatus, expectedNames, taskRun)","}","","func verifyNames(t *testing.T, prStatus v1.PipelineRunStatus, expectedNames []string, kind string) {","\tt.Helper()","","\tactualNames := make(map[string]bool)","\tfor _, cr := range filterChildRefsForKind(prStatus.ChildReferences, kind) {","\t\tactualNames[cr.Name] = true","\t}","","\tfor _, expectedName := range expectedNames {","\t\tif actualNames[expectedName] {","\t\t\tcontinue","\t\t}","","\t\tt.Errorf(\"Expected PipelineRun status to include %s status for %s but was %v\", kind, expectedName, prStatus.ChildReferences)","\t}","}","","func VerifyTaskRunStatusesWhenExpressions(t *testing.T, prStatus v1.PipelineRunStatus, trName string, expectedWhen []v1.WhenExpression) {","\tt.Helper()","","\tvar actualWhen []v1.WhenExpression","\tfor _, cr := range prStatus.ChildReferences {","\t\tif cr.Name == trName {","\t\t\tactualWhen = append(actualWhen, cr.WhenExpressions...)","\t\t}","\t}","","\tif d := cmp.Diff(expectedWhen, actualWhen); d != \"\" {","\t\tt.Errorf(\"Expected to see When Expressions %v created. Diff %s\", trName, diff.PrintWantGot(d))","\t}","}","","func VerifyCustomRunOrRunStatusesCount(t *testing.T, prStatus v1.PipelineRunStatus, expectedCount int) {","\tt.Helper()","\tverifyCount(t, prStatus, expectedCount, customRun)","}","","func VerifyCustomRunOrRunStatusesNames(t *testing.T, prStatus v1.PipelineRunStatus, expectedNames ...string) {","\tt.Helper()","\tverifyNames(t, prStatus, expectedNames, customRun)","}","","func VerifyChildPipelineRunStatusesCount(t *testing.T, prStatus v1.PipelineRunStatus, expectedCount int) {","\tt.Helper()","\tverifyCount(t, prStatus, expectedCount, pipelineRun)","}","","func VerifyChildPipelineRunStatusesNames(t *testing.T, prStatus v1.PipelineRunStatus, expectedNames ...string) {","\tt.Helper()","\tverifyNames(t, prStatus, expectedNames, pipelineRun)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,0,1,0,0,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,0,0,1,0,0,0,1,1,1,1,1,1,1,1,0,0,1,1,1,0,0,1,1,1,1,0,1,1,1,1,0,1,1,1,1,0,1,1,1,1]},{"id":215,"path":"pkg/reconciler/volumeclaim/pvchandler.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package volumeclaim","","import (","\t\"context\"","\t\"crypto/sha256\"","\t\"encoding/hex\"","\t\"encoding/json\"","\t\"errors\"","\t\"fmt\"","\t\"strings\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"go.uber.org/zap\"","\t\"gomodules.xyz/jsonpatch/v2\"","\tcorev1 \"k8s.io/api/core/v1\"","\tapierrors \"k8s.io/apimachinery/pkg/api/errors\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/types\"","\tclientset \"k8s.io/client-go/kubernetes\"",")","","const (","\t// ReasonCouldntCreateWorkspacePVC indicates that a Pipeline expects a workspace from a","\t// volumeClaimTemplate but couldn't create a claim.","\tReasonCouldntCreateWorkspacePVC = \"CouldntCreateWorkspacePVC\"",")","","var (","\tErrPvcCreationFailed          = errors.New(\"PVC creation error\")","\tErrPvcCreationFailedRetryable = errors.New(\"PVC creation error, retryable\")",")","","// PvcHandler is used to create PVCs for workspaces","type PvcHandler interface {","\tCreatePVCFromVolumeClaimTemplate(ctx context.Context, wb v1.WorkspaceBinding, ownerReference metav1.OwnerReference, namespace string) error","\tPurgeFinalizerAndDeletePVCForWorkspace(ctx context.Context, pvcName, namespace string) error","}","","type defaultPVCHandler struct {","\tclientset clientset.Interface","\tlogger    *zap.SugaredLogger","}","","// NewPVCHandler returns a new defaultPVCHandler","func NewPVCHandler(clientset clientset.Interface, logger *zap.SugaredLogger) PvcHandler {","\treturn \u0026defaultPVCHandler{clientset, logger}","}","","// CreatePVCFromVolumeClaimTemplate checks if a PVC named \u003cclaim-name\u003e-\u003cworkspace-name\u003e-\u003cowner-name\u003e exists;","// where claim-name is provided by the user in the volumeClaimTemplate, and owner-name is the name of the","// resource with the volumeClaimTemplate declared, a PipelineRun or TaskRun. If the PVC did not exist, a new PVC","// with that name is created with the provided OwnerReference.","func (c *defaultPVCHandler) CreatePVCFromVolumeClaimTemplate(ctx context.Context, wb v1.WorkspaceBinding, ownerReference metav1.OwnerReference, namespace string) error {","\tclaim := c.getPVCFromVolumeClaimTemplate(wb, ownerReference, namespace)","\tif claim == nil {","\t\treturn nil","\t}","","\t_, err := c.clientset.CoreV1().PersistentVolumeClaims(claim.Namespace).Get(ctx, claim.Name, metav1.GetOptions{})","\tswitch {","\tcase apierrors.IsNotFound(err):","\t\t_, err := c.clientset.CoreV1().PersistentVolumeClaims(claim.Namespace).Create(ctx, claim, metav1.CreateOptions{})","\t\tif err != nil {","\t\t\tif apierrors.IsAlreadyExists(err) {","\t\t\t\tc.logger.Infof(\"Tried to create PersistentVolumeClaim %s in namespace %s, but it already exists\",","\t\t\t\t\tclaim.Name, claim.Namespace)","\t\t\t} else if isRetryableError(err) {","\t\t\t\t// This is a retry-able error","\t\t\t\treturn fmt.Errorf(\"%w for %s: %v\", ErrPvcCreationFailedRetryable, claim.Name, err.Error())","\t\t\t} else {","\t\t\t\treturn fmt.Errorf(\"%w for %s: %v\", ErrPvcCreationFailed, claim.Name, err.Error())","\t\t\t}","\t\t} else {","\t\t\tc.logger.Infof(\"Created PersistentVolumeClaim %s in namespace %s\", claim.Name, claim.Namespace)","\t\t}","\tcase err != nil:","\t\treturn fmt.Errorf(\"failed to retrieve PVC %s: %w\", claim.Name, err)","\t}","","\treturn nil","}","","// PurgeFinalizerAndDeletePVCForWorkspace deletes pvcs and then purges the `kubernetes.io/pvc-protection` finalizer protection.","// Purging the `kubernetes.io/pvc-protection` finalizer allows the pvc to be deleted even when it is referenced by a taskrun pod.","// See mode details in https://kubernetes.io/docs/concepts/storage/persistent-volumes/#storage-object-in-use-protection.","func (c *defaultPVCHandler) PurgeFinalizerAndDeletePVCForWorkspace(ctx context.Context, pvcName, namespace string) error {","\tp, err := c.clientset.CoreV1().PersistentVolumeClaims(namespace).Get(ctx, pvcName, metav1.GetOptions{})","\tif err != nil {","\t\t// check if the PVC exists, otherwise skip the deletion","\t\tif apierrors.IsNotFound(err) {","\t\t\tc.logger.Debugf(\"PVC %s no longer exists, skipping deletion as it has already been removed\", pvcName)","\t\t\treturn nil","\t\t}","\t\treturn fmt.Errorf(\"failed to get the PVC %s: %w\", pvcName, err)","\t}","","\t// get the list of existing finalizers and drop `pvc-protection` if exists","\tvar finalizers []string","\tfor _, f := range p.ObjectMeta.Finalizers {","\t\tif f == \"kubernetes.io/pvc-protection\" {","\t\t\tcontinue","\t\t}","\t\tfinalizers = append(finalizers, f)","\t}","","\t// prepare data to remove pvc-protection from the list of finalizers","\tremoveFinalizerBytes, err := json.Marshal([]jsonpatch.JsonPatchOperation{{","\t\tPath:      \"/metadata/finalizers\",","\t\tOperation: \"replace\",","\t\tValue:     finalizers,","\t}})","\tif err != nil {","\t\treturn fmt.Errorf(\"failed to marshal jsonpatch: %w\", err)","\t}","","\t// delete PVC","\terr = c.clientset.CoreV1().PersistentVolumeClaims(namespace).Delete(ctx, pvcName, metav1.DeleteOptions{})","\tif err != nil {","\t\treturn fmt.Errorf(\"failed to delete the PVC %s: %w\", pvcName, err)","\t}","","\t// remove finalizer","\t_, err = c.clientset.CoreV1().PersistentVolumeClaims(namespace).Patch(ctx, pvcName, types.JSONPatchType, removeFinalizerBytes, metav1.PatchOptions{})","\tif err != nil {","\t\treturn fmt.Errorf(\"failed to patch the PVC %s: %w\", pvcName, err)","\t}","","\treturn nil","}","","// getPVCFromVolumeClaimTemplate returns a PersistentVolumeClaim based on given workspaceBinding (using VolumeClaimTemplate), ownerReference and namespace","func (c *defaultPVCHandler) getPVCFromVolumeClaimTemplate(workspaceBinding v1.WorkspaceBinding, ownerReference metav1.OwnerReference, namespace string) *corev1.PersistentVolumeClaim {","\tif workspaceBinding.VolumeClaimTemplate == nil {","\t\tc.logger.Infof(\"workspace binding %v does not contain VolumeClaimTemplate, skipping creating PVC\", workspaceBinding.Name)","\t\treturn nil","\t}","","\tclaim := workspaceBinding.VolumeClaimTemplate.DeepCopy()","\tclaim.Name = GeneratePVCNameFromWorkspaceBinding(workspaceBinding.VolumeClaimTemplate.Name, workspaceBinding, ownerReference)","\tclaim.Namespace = namespace","\tclaim.OwnerReferences = []metav1.OwnerReference{ownerReference}","","\treturn claim","}","","// GeneratePVCNameFromWorkspaceBinding gets the name of PersistentVolumeClaim for a Workspace and PipelineRun or TaskRun. claim","// must be a PersistentVolumeClaim from a volumeClaimTemplate. The returned name must be consistent given the same","// workspaceBinding name and ownerReference UID - because it is first used for creating a PVC and later,","// possibly several TaskRuns to lookup the PVC to mount.","// We use ownerReference UID over ownerReference name to distinguish runs with the same name.","// If the given volumeClaimTemplate name is empty, the prefix \"pvc\" will be applied to the PersistentVolumeClaim name.","// See function `getPersistentVolumeClaimNameWithAffinityAssistant` when the PersistentVolumeClaim is created by Affinity Assistant StatefulSet.","func GeneratePVCNameFromWorkspaceBinding(claimName string, wb v1.WorkspaceBinding, owner metav1.OwnerReference) string {","\tif claimName == \"\" {","\t\treturn fmt.Sprintf(\"%s-%s\", \"pvc\", getPersistentVolumeClaimIdentity(wb.Name, string(owner.UID)))","\t}","\treturn fmt.Sprintf(\"%s-%s\", claimName, getPersistentVolumeClaimIdentity(wb.Name, string(owner.UID)))","}","","func getPersistentVolumeClaimIdentity(workspaceName, ownerName string) string {","\thashBytes := sha256.Sum256([]byte(workspaceName + ownerName))","\thashString := hex.EncodeToString(hashBytes[:])","\treturn hashString[:10]","}","","func isRetryableError(err error) bool {","\tif (apierrors.IsForbidden(err) \u0026\u0026 strings.Contains(err.Error(), \"exceeded quota\")) || apierrors.IsConflict(err) {","\t\treturn true","\t}","\treturn false","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,0,2,2,2,2,2,2,2,2,1,0,0,0,2,2,2,2,0,1,0,0,0,2,2,2,2,2,2,1,1,0,0,2,2,1,1,0,0,2,2,1,1,0,2,0,0,0,2,2,2,2,2,0,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,2,2,2,2,2,0,2,2,2,2,2,0]},{"id":216,"path":"pkg/remote/oci/resolver.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package oci","","import (","\t\"archive/tar\"","\t\"context\"","\t\"errors\"","\t\"fmt\"","\t\"io\"","\t\"strings\"","\t\"time\"","","\t\"github.com/google/go-containerregistry/pkg/authn\"","\timgname \"github.com/google/go-containerregistry/pkg/name\"","\tv1 \"github.com/google/go-containerregistry/pkg/v1\"","\tociremote \"github.com/google/go-containerregistry/pkg/v1/remote\"","\tpipelinev1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/client/clientset/versioned/scheme\"","\t\"github.com/tektoncd/pipeline/pkg/remote\"","\t\"k8s.io/apimachinery/pkg/runtime\"",")","","const (","\t// KindAnnotation is an OCI annotation for the bundle kind","\tKindAnnotation = \"dev.tekton.image.kind\"","\t// APIVersionAnnotation is an OCI annotation for the bundle version","\tAPIVersionAnnotation = \"dev.tekton.image.apiVersion\"","\t// TitleAnnotation is an OCI annotation for the bundle title","\tTitleAnnotation = \"dev.tekton.image.name\"","\t// MaximumBundleObjects defines the maximum number of objects in a bundle","\tMaximumBundleObjects = 20",")","","// Resolver implements the Resolver interface using OCI images.","type Resolver struct {","\timageReference string","\tkeychain       authn.Keychain","\ttimeout        time.Duration","}","","// NewResolver is a convenience function to return a new OCI resolver instance as a remote.Resolver with a short, 1m","// timeout for resolving an individual image.","func NewResolver(ref string, keychain authn.Keychain) remote.Resolver {","\treturn \u0026Resolver{imageReference: ref, keychain: keychain, timeout: time.Second * 60}","}","","// List retrieves a flat set of Tekton objects","func (o *Resolver) List(ctx context.Context) ([]remote.ResolvedObject, error) {","\ttimeoutCtx, cancel := context.WithTimeout(ctx, o.timeout)","\tdefer cancel()","\timg, err := o.retrieveImage(timeoutCtx)","\tif err != nil {","\t\treturn nil, err","\t}","","\tmanifest, err := img.Manifest()","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"Could not parse image manifest: %w\", err)","\t}","","\tif err := o.checkImageCompliance(manifest); err != nil {","\t\treturn nil, err","\t}","","\tcontents := make([]remote.ResolvedObject, 0, len(manifest.Layers))","\tfor _, l := range manifest.Layers {","\t\tcontents = append(contents, remote.ResolvedObject{","\t\t\tKind:       l.Annotations[KindAnnotation],","\t\t\tAPIVersion: l.Annotations[APIVersionAnnotation],","\t\t\tName:       l.Annotations[TitleAnnotation],","\t\t})","\t}","","\treturn contents, nil","}","","// Get retrieves a specific object with the given Kind and name","func (o *Resolver) Get(ctx context.Context, kind, name string) (runtime.Object, *pipelinev1.RefSource, error) {","\ttimeoutCtx, cancel := context.WithTimeout(ctx, o.timeout)","\tdefer cancel()","\timg, err := o.retrieveImage(timeoutCtx)","\tif err != nil {","\t\treturn nil, nil, err","\t}","","\tmanifest, err := img.Manifest()","\tif err != nil {","\t\treturn nil, nil, fmt.Errorf(\"could not parse image manifest: %w\", err)","\t}","","\tif err := o.checkImageCompliance(manifest); err != nil {","\t\treturn nil, nil, err","\t}","","\tlayers, err := img.Layers()","\tif err != nil {","\t\treturn nil, nil, fmt.Errorf(\"could not read image layers: %w\", err)","\t}","","\tlayerMap := map[string]v1.Layer{}","\tfor _, l := range layers {","\t\tdigest, err := l.Digest()","\t\tif err != nil {","\t\t\treturn nil, nil, fmt.Errorf(\"failed to find digest for layer: %w\", err)","\t\t}","\t\tlayerMap[digest.String()] = l","\t}","","\tfor idx, l := range manifest.Layers {","\t\tlKind := l.Annotations[KindAnnotation]","\t\tlName := l.Annotations[TitleAnnotation]","","\t\tif kind == lKind \u0026\u0026 name == lName {","\t\t\tobj, err := readTarLayer(layerMap[l.Digest.String()])","\t\t\tif err != nil {","\t\t\t\t// This could still be a raw layer so try to read it as that instead.","\t\t\t\tobj, err := readRawLayer(layers[idx])","\t\t\t\treturn obj, nil, err","\t\t\t}","\t\t\treturn obj, nil, nil","\t\t}","\t}","\treturn nil, nil, fmt.Errorf(\"could not find object in image with kind: %s and name: %s\", kind, name)","}","","// retrieveImage will fetch the image's contents and manifest.","func (o *Resolver) retrieveImage(ctx context.Context) (v1.Image, error) {","\timgRef, err := imgname.ParseReference(o.imageReference)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"%s is an unparseable image reference: %w\", o.imageReference, err)","\t}","\treturn ociremote.Image(imgRef, ociremote.WithAuthFromKeychain(o.keychain), ociremote.WithContext(ctx))","}","","// checkImageCompliance will perform common checks to ensure the Tekton Bundle is compliant to our spec.","func (o *Resolver) checkImageCompliance(manifest *v1.Manifest) error {","\t// Check the manifest's layers to ensure there are a maximum of 10.","\tif len(manifest.Layers) \u003e MaximumBundleObjects {","\t\treturn fmt.Errorf(\"bundle %s contained more than the maximum %d allow objects\", o.imageReference, MaximumBundleObjects)","\t}","","\t// Ensure each layer complies to the spec.","\tfor _, l := range manifest.Layers {","\t\trefDigest := fmt.Sprintf(\"%s:%s\", o.imageReference, l.Digest.String())","\t\tif _, ok := l.Annotations[APIVersionAnnotation]; !ok {","\t\t\treturn fmt.Errorf(\"invalid tekton bundle: %s does not contain a %s annotation\", refDigest, APIVersionAnnotation)","\t\t}","","\t\tif _, ok := l.Annotations[TitleAnnotation]; !ok {","\t\t\treturn fmt.Errorf(\"invalid tekton bundle: %s does not contain a %s annotation\", refDigest, TitleAnnotation)","\t\t}","","\t\tkind, ok := l.Annotations[KindAnnotation]","\t\tif !ok {","\t\t\treturn fmt.Errorf(\"invalid tekton bundle: %s does not contain a %s annotation\", refDigest, KindAnnotation)","\t\t}","\t\tif strings.TrimSuffix(strings.ToLower(kind), \"s\") != kind {","\t\t\treturn fmt.Errorf(\"invalid tekton bundle: %s annotation for %s must be lowercased and singular, found %s\", KindAnnotation, refDigest, kind)","\t\t}","\t}","","\treturn nil","}","","// Utility function to read out the contents of an image layer, assumed to be a tarball, as a parsed Tekton resource.","func readTarLayer(layer v1.Layer) (runtime.Object, error) {","\trc, err := layer.Uncompressed()","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"Failed to read image layer: %w\", err)","\t}","\tdefer rc.Close()","","\t// If the user bundled this up as a tar file then we need to untar it.","\ttreader := tar.NewReader(rc)","\theader, err := treader.Next()","\tif err != nil {","\t\treturn nil, errors.New(\"layer is not a tarball\")","\t}","","\tcontents := make([]byte, header.Size)","\tif _, err := treader.Read(contents); err != nil \u0026\u0026 !errors.Is(err, io.EOF) {","\t\t// We only allow 1 resource per layer so this tar bundle should have one and only one file.","\t\treturn nil, fmt.Errorf(\"failed to read tar bundle: %w\", err)","\t}","","\tobj, _, err := scheme.Codecs.UniversalDeserializer().Decode(contents, nil, nil)","\treturn obj, err","}","","// Utility function to read out the contents of an image layer, assumed to be raw bytes, as a parsed Tekton resource.","func readRawLayer(layer v1.Layer) (runtime.Object, error) {","\trc, err := layer.Uncompressed()","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"failed to read image layer: %w\", err)","\t}","\tdefer rc.Close()","","\tcontents, err := io.ReadAll(rc)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"could not read contents of image layer: %w\", err)","\t}","","\tobj, _, err := scheme.Codecs.UniversalDeserializer().Decode(contents, nil, nil)","\treturn obj, err","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,2,2,2,2,2,1,1,0,2,2,1,1,0,2,2,2,0,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,1,1,0,2,2,1,1,0,2,1,1,0,2,2,1,1,0,2,2,2,2,1,1,2,0,0,2,2,2,2,2,2,2,1,1,1,1,2,0,0,1,0,0,0,2,2,2,1,1,2,0,0,0,2,2,2,2,2,0,0,2,2,2,2,2,0,2,1,1,0,2,2,2,2,2,2,2,0,0,2,0,0,0,2,2,2,1,1,2,2,2,2,2,2,1,1,0,2,2,1,1,1,0,2,2,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0]},{"id":217,"path":"pkg/remote/resolution/error.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resolution","","import (","\t\"errors\"","\t\"fmt\"",")","","// ErrNilResource is returned when remote resolution","// appears to have succeeded but the resolved resource is nil.","var ErrNilResource = errors.New(\"unknown error occurred: requested resource is nil\")","","// InvalidRuntimeObjectError is returned when remote resolution","// succeeded but the returned data is not a valid runtime.Object.","type InvalidRuntimeObjectError struct {","\tOriginal error","}","","var _ error = \u0026InvalidRuntimeObjectError{}","","// Error returns the string representation of this error.","func (e *InvalidRuntimeObjectError) Error() string {","\treturn fmt.Sprintf(\"invalid runtime object: %v\", e.Original)","}","","// Unwrap returns the underlying original error.","func (e *InvalidRuntimeObjectError) Unwrap() error {","\treturn e.Original","}","","// Is returns true if the given error coerces into an error of this type.","func (e *InvalidRuntimeObjectError) Is(that error) bool {","\treturn errors.As(that, \u0026e)","}","","// DataAccessError is returned when remote resolution succeeded but","// attempting to access the resolved data failed. An example of this","// type of error would be if a ResolutionRequest contained malformed base64.","type DataAccessError struct {","\tOriginal error","}","","var _ error = \u0026DataAccessError{}","","// Error returns the string representation of this error.","func (e *DataAccessError) Error() string {","\treturn fmt.Sprintf(\"error accessing data from remote resource: %v\", e.Original)","}","","// Unwrap returns the underlying original error.","func (e *DataAccessError) Unwrap() error {","\treturn e.Original","}","","// Is returns true if the given error coerces into an error of this type.","func (e *DataAccessError) Is(that error) bool {","\treturn errors.As(that, \u0026e)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,2,2,2]},{"id":218,"path":"pkg/remote/resolution/request.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resolution","","import (","\tresolution \"github.com/tektoncd/pipeline/pkg/resolution/resource\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"knative.dev/pkg/kmeta\"",")","","var _ resolution.Request = \u0026resolutionRequest{}","var _ resolution.OwnedRequest = \u0026resolutionRequest{}","","type resolutionRequest struct {","\tresolution.Request","\towner kmeta.OwnerRefable","}","","func (req *resolutionRequest) OwnerRef() metav1.OwnerReference {","\treturn *kmeta.NewControllerRef(req.owner)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2]},{"id":219,"path":"pkg/remote/resolution/resolver.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resolution","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/client/clientset/versioned/scheme\"","\t\"github.com/tektoncd/pipeline/pkg/remote\"","\tresolutioncommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\tremoteresource \"github.com/tektoncd/pipeline/pkg/resolution/resource\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"k8s.io/apimachinery/pkg/runtime/serializer\"","\t\"knative.dev/pkg/kmeta\"",")","","// Resolver implements remote.Resolver and encapsulates the majority of","// code required to interface with the tektoncd/resolution project. It","// is used to make async requests for resources like pipelines from","// remote places like git repos.","type Resolver struct {","\trequester       remoteresource.Requester","\towner           kmeta.OwnerRefable","\tresolverName    string","\tparams          v1.Params","\ttargetName      string","\ttargetNamespace string","}","","var _ remote.Resolver = \u0026Resolver{}","","// NewResolver returns an implementation of remote.Resolver capable","// of performing asynchronous remote resolution.","func NewResolver(requester remoteresource.Requester, owner kmeta.OwnerRefable, resolverName string, targetName string, targetNamespace string, params v1.Params) remote.Resolver {","\treturn \u0026Resolver{","\t\trequester:       requester,","\t\towner:           owner,","\t\tresolverName:    resolverName,","\t\tparams:          params,","\t\ttargetName:      targetName,","\t\ttargetNamespace: targetNamespace,","\t}","}","","// Get implements remote.Resolver.","func (resolver *Resolver) Get(ctx context.Context, _, _ string) (runtime.Object, *v1.RefSource, error) {","\tresolverName := remoteresource.ResolverName(resolver.resolverName)","\treq, err := buildRequest(resolver.resolverName, resolver.owner, resolver.targetName, resolver.targetNamespace, resolver.params)","\tif err != nil {","\t\treturn nil, nil, fmt.Errorf(\"error building request for remote resource: %w\", err)","\t}","\tresolved, err := resolver.requester.Submit(ctx, resolverName, req)","\treturn ResolvedRequest(resolved, err)","}","","// List implements remote.Resolver but is unused for remote resolution.","func (resolver *Resolver) List(_ context.Context) ([]remote.ResolvedObject, error) {","\treturn nil, nil","}","","func buildRequest(resolverName string, owner kmeta.OwnerRefable, name string, namespace string, params v1.Params) (*resolutionRequest, error) {","\trr := \u0026v1beta1.ResolutionRequestSpec{","\t\tParams: params,","\t}","\tname, namespace, err := remoteresource.GetNameAndNamespace(resolverName, owner, name, namespace, rr)","\tif err != nil {","\t\treturn nil, err","\t}","\treq := \u0026resolutionRequest{","\t\tRequest: remoteresource.NewRequest(name, namespace, params),","\t\towner:   owner,","\t}","\treturn req, nil","}","","func ResolvedRequest(resolved resolutioncommon.ResolvedResource, err error) (runtime.Object, *v1.RefSource, error) {","\tswitch {","\tcase errors.Is(err, resolutioncommon.ErrRequestInProgress):","\t\treturn nil, nil, remote.ErrRequestInProgress","\tcase err != nil:","\t\treturn nil, nil, fmt.Errorf(\"error requesting remote resource: %w\", err)","\tcase resolved == nil:","\t\treturn nil, nil, ErrNilResource","\tdefault:","\t}","\tdata, err := resolved.Data()","\tif err != nil {","\t\treturn nil, nil, \u0026DataAccessError{Original: err}","\t}","\tcodecs := serializer.NewCodecFactory(scheme.Scheme, serializer.EnableStrict)","\tobj, _, err := codecs.UniversalDeserializer().Decode(data, nil, nil)","\tif err != nil {","\t\treturn nil, nil, \u0026InvalidRuntimeObjectError{Original: err}","\t}","\treturn obj, resolved.RefSource(), nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,1,1,2,2,0,0,0,1,1,1,0,2,2,2,2,2,2,1,1,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,0]},{"id":220,"path":"pkg/remoteresolution/remote/resolution/request.go","lines":["/*","Copyright 2024 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resolution","","import (","\tresolution \"github.com/tektoncd/pipeline/pkg/remoteresolution/resource\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"knative.dev/pkg/kmeta\"",")","","var _ resolution.Request = \u0026resolutionRequest{}","var _ resolution.OwnedRequest = \u0026resolutionRequest{}","","type resolutionRequest struct {","\tresolution.Request","\towner kmeta.OwnerRefable","}","","func (req *resolutionRequest) OwnerRef() metav1.OwnerReference {","\treturn *kmeta.NewControllerRef(req.owner)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2]},{"id":221,"path":"pkg/remoteresolution/remote/resolution/resolver.go","lines":["/*","Copyright 2024 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resolution","","import (","\t\"context\"","\t\"fmt\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/remote\"","\tresolution \"github.com/tektoncd/pipeline/pkg/remote/resolution\"","\tremoteresource \"github.com/tektoncd/pipeline/pkg/remoteresolution/resource\"","\tresource \"github.com/tektoncd/pipeline/pkg/resolution/resource\"","\t\"k8s.io/apimachinery/pkg/runtime\"","\t\"knative.dev/pkg/kmeta\"",")","","var _ remote.Resolver = (*Resolver)(nil)","","// Resolver implements remote.Resolver and encapsulates the majority of","// code required to interface with the tektoncd/resolution project. It","// is used to make async requests for resources like pipelines from","// remote places like git repos.","type Resolver struct {","\trequester       remoteresource.Requester","\towner           kmeta.OwnerRefable","\tresolverName    string","\tresolverPayload remoteresource.ResolverPayload","}","","// NewResolver returns an implementation of remote.Resolver capable","// of performing asynchronous remote resolution.","func NewResolver(requester remoteresource.Requester, owner kmeta.OwnerRefable, resolverName string, resolverPayload remoteresource.ResolverPayload) remote.Resolver {","\treturn \u0026Resolver{","\t\trequester:       requester,","\t\towner:           owner,","\t\tresolverName:    resolverName,","\t\tresolverPayload: resolverPayload,","\t}","}","","// Get implements remote.Resolver.","func (resolver *Resolver) Get(ctx context.Context, _, _ string) (runtime.Object, *v1.RefSource, error) {","\tresolverName := remoteresource.ResolverName(resolver.resolverName)","\treq, err := buildRequest(resolver.resolverName, resolver.owner, \u0026resolver.resolverPayload)","\tif err != nil {","\t\treturn nil, nil, fmt.Errorf(\"error building request for remote resource: %w\", err)","\t}","\tresolved, err := resolver.requester.Submit(ctx, resolverName, req)","\treturn resolution.ResolvedRequest(resolved, err)","}","","// List implements remote.Resolver but is unused for remote resolution.","func (resolver *Resolver) List(_ context.Context) ([]remote.ResolvedObject, error) {","\treturn nil, nil","}","","func buildRequest(resolverName string, owner kmeta.OwnerRefable, resolverPayload *remoteresource.ResolverPayload) (*resolutionRequest, error) {","\tvar name string","\tvar namespace string","\tvar url string","\tvar params v1.Params","\tif resolverPayload != nil {","\t\tname = resolverPayload.Name","\t\tnamespace = resolverPayload.Namespace","\t\tif resolverPayload.ResolutionSpec != nil {","\t\t\tparams = resolverPayload.ResolutionSpec.Params","\t\t\turl = resolverPayload.ResolutionSpec.URL","\t\t}","\t}","\trr := \u0026v1beta1.ResolutionRequestSpec{","\t\tParams: params,","\t\tURL:    url,","\t}","\tname, namespace, err := resource.GetNameAndNamespace(resolverName, owner, name, namespace, rr)","\tif err != nil {","\t\treturn nil, err","\t}","\tresolverPayload.Name = name","\tresolverPayload.Namespace = namespace","\treq := \u0026resolutionRequest{","\t\tRequest: remoteresource.NewRequest(*resolverPayload),","\t\towner:   owner,","\t}","\treturn req, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,1,1,2,2,0,0,0,1,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,0]},{"id":222,"path":"pkg/remoteresolution/resolver/bundle/resolver.go","lines":["/*","Copyright 2024 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package bundle","","import (","\t\"context\"","\t\"errors\"","\t\"strings\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/remoteresolution/resolver/framework\"","\t\"github.com/tektoncd/pipeline/pkg/remoteresolution/resolver/framework/cache\"","\tresolutioncommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\tbundleresolution \"github.com/tektoncd/pipeline/pkg/resolution/resolver/bundle\"","\tresolutionframework \"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"","\t\"k8s.io/client-go/kubernetes\"","\tkubeclient \"knative.dev/pkg/client/injection/kube/client\"",")","","const (","\t// LabelValueBundleResolverType is the value to use for the","\t// resolution.tekton.dev/type label on resource requests","\tLabelValueBundleResolverType = \"bundles\"","","\t// BundleResolverName is the name that the bundle resolver should be associated with.","\tBundleResolverName = \"bundleresolver\"",")","","var _ framework.Resolver = (*Resolver)(nil)","var _ resolutionframework.ConfigWatcher = (*Resolver)(nil)","var _ cache.ImmutabilityChecker = (*Resolver)(nil)","","// Resolver implements a framework.Resolver that can fetch files from OCI bundles.","type Resolver struct {","\tkubeClientSet      kubernetes.Interface","\tresolveRequestFunc func(context.Context, kubernetes.Interface, *v1beta1.ResolutionRequestSpec) (resolutionframework.ResolvedResource, error)","}","","// Initialize sets up any dependencies needed by the Resolver. None atm.","func (r *Resolver) Initialize(ctx context.Context) error {","\tr.kubeClientSet = kubeclient.Get(ctx)","\tif r.resolveRequestFunc == nil {","\t\tr.resolveRequestFunc = bundleresolution.ResolveRequest","\t}","\treturn nil","}","","// GetName returns a string name to refer to this Resolver by.","func (r *Resolver) GetName(_ context.Context) string {","\treturn BundleResolverName","}","","// GetSelector returns a map of labels to match against tasks requesting","// resolution from this Resolver.","func (r *Resolver) GetSelector(_ context.Context) map[string]string {","\treturn map[string]string{","\t\tresolutioncommon.LabelKeyResolverType: LabelValueBundleResolverType,","\t}","}","","// GetConfigName returns the name of the bundle resolver's configmap.","func (r *Resolver) GetConfigName(_ context.Context) string {","\treturn bundleresolution.ConfigMapName","}","","// Validate ensures parameters from a request are as expected.","func (r *Resolver) Validate(ctx context.Context, req *v1beta1.ResolutionRequestSpec) error {","\treturn bundleresolution.ValidateParams(ctx, req.Params)","}","","// IsImmutable implements ImmutabilityChecker.IsImmutable","// Returns true if the bundle parameter contains a digest reference (@sha256:...)","func (r *Resolver) IsImmutable(params []v1.Param) bool {","\tvar bundleRef string","\tfor _, param := range params {","\t\tif param.Name == bundleresolution.ParamBundle {","\t\t\tbundleRef = param.Value.StringVal","\t\t\tbreak","\t\t}","\t}","","\t// Checks if the given string looks like an OCI pull spec by digest.","\t// Only SHA-256 digests are considered immutable.","\t// Examples:","\t// - image@sha256:abc123...","\t// - registry.io/image@sha256:abc123...","\t// - registry.io/image:tag@sha256:abc123... (tag is ignored when digest is present)","\treturn strings.Contains(bundleRef, \"@sha256:\")","}","","// Resolve uses the given params to resolve the requested file or resource.","func (r *Resolver) Resolve(ctx context.Context, req *v1beta1.ResolutionRequestSpec) (resolutionframework.ResolvedResource, error) {","\tif len(req.Params) == 0 {","\t\treturn nil, errors.New(\"no params\")","\t}","","\tif cache.ShouldUse(ctx, r, req.Params, LabelValueBundleResolverType) {","\t\treturn cache.GetFromCacheOrResolve(","\t\t\tctx,","\t\t\treq.Params,","\t\t\tLabelValueBundleResolverType,","\t\t\tfunc() (resolutionframework.ResolvedResource, error) {","\t\t\t\treturn r.resolveRequestFunc(ctx, r.kubeClientSet, req)","\t\t\t},","\t\t)","\t}","","\treturn r.resolveRequestFunc(ctx, r.kubeClientSet, req)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,0,0,0,2,2,2,0,0,0,2,2,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,0,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,2,0,0,0,2,2,1,1,0,2,2,2,2,2,2,2,2,0,0,0,2,0]},{"id":223,"path":"pkg/remoteresolution/resolver/cluster/resolver.go","lines":["/*","Copyright 2024 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package cluster","","import (","\t\"context\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"","\tpipelineclient \"github.com/tektoncd/pipeline/pkg/client/injection/client\"","\t\"github.com/tektoncd/pipeline/pkg/remoteresolution/resolver/framework\"","\t\"github.com/tektoncd/pipeline/pkg/remoteresolution/resolver/framework/cache\"","\tresolutioncommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\tclusterresolution \"github.com/tektoncd/pipeline/pkg/resolution/resolver/cluster\"","\tresolutionframework \"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"",")","","const (","\t// LabelValueClusterResolverType is the value to use for the","\t// resolution.tekton.dev/type label on resource requests","\tLabelValueClusterResolverType = \"cluster\"","","\t// ClusterResolverName is the name that the cluster resolver should be","\t// associated with","\tClusterResolverName = \"Cluster\"",")","","var _ framework.Resolver = (*Resolver)(nil)","var _ resolutionframework.ConfigWatcher = (*Resolver)(nil)","var _ cache.ImmutabilityChecker = (*Resolver)(nil)","","// Resolver implements a framework.Resolver that can fetch resources from the same cluster.","type Resolver struct {","\tpipelineClientSet versioned.Interface","}","","// Initialize sets up any dependencies needed by the Resolver.","func (r *Resolver) Initialize(ctx context.Context) error {","\tr.pipelineClientSet = pipelineclient.Get(ctx)","\treturn nil","}","","// GetName returns a string name to refer to this Resolver by.","func (r *Resolver) GetName(_ context.Context) string {","\treturn ClusterResolverName","}","","// GetSelector returns a map of labels to match against tasks requesting","// resolution from this Resolver.","func (r *Resolver) GetSelector(_ context.Context) map[string]string {","\treturn map[string]string{","\t\tresolutioncommon.LabelKeyResolverType: LabelValueClusterResolverType,","\t}","}","","// GetConfigName returns the name of the cluster resolver's configmap.","func (r *Resolver) GetConfigName(_ context.Context) string {","\treturn clusterresolution.ConfigMapName","}","","// Validate ensures parameters from a request are as expected.","func (r *Resolver) Validate(ctx context.Context, req *v1beta1.ResolutionRequestSpec) error {","\treturn clusterresolution.ValidateParams(ctx, req.Params)","}","","// IsImmutable implements ImmutabilityChecker.IsImmutable","// Returns false because cluster resources don't have immutable references","func (r *Resolver) IsImmutable([]v1.Param) bool {","\t// Cluster resources (Tasks, Pipelines, etc.) don't have immutable references","\t// like Git commit hashes or bundle digests, so we always return false","\treturn false","}","","// Resolve uses the given params to resolve the requested file or resource.","func (r *Resolver) Resolve(ctx context.Context, req *v1beta1.ResolutionRequestSpec) (resolutionframework.ResolvedResource, error) {","\tif cache.ShouldUse(ctx, r, req.Params, LabelValueClusterResolverType) {","\t\treturn cache.GetFromCacheOrResolve(","\t\t\tctx,","\t\t\treq.Params,","\t\t\tLabelValueClusterResolverType,","\t\t\tfunc() (resolutionframework.ResolvedResource, error) {","\t\t\t\treturn clusterresolution.ResolveFromParams(ctx, req.Params, r.pipelineClientSet)","\t\t\t},","\t\t)","\t}","","\treturn clusterresolution.ResolveFromParams(ctx, req.Params, r.pipelineClientSet)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,0,2,2,2,0,0,0,2,2,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0,0,0,2,0]},{"id":224,"path":"pkg/remoteresolution/resolver/framework/cache/annotated_resource.go","lines":["/*","Copyright 2025 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package cache","","import (","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tresolutionframework \"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"",")","","const (","\t// cacheAnnotationKey is the annotation key indicating if a resource was cached","\tcacheAnnotationKey = \"resolution.tekton.dev/cached\"","\t// cacheTimestampKey is the annotation key for when the resource was cached","\tcacheTimestampKey = \"resolution.tekton.dev/cache-timestamp\"","\t// cacheResolverTypeKey is the annotation key for the resolver type that cached it","\tcacheResolverTypeKey = \"resolution.tekton.dev/cache-resolver-type\"","\t// cacheOperationKey is the annotation key for the cache operation type","\tcacheOperationKey = \"resolution.tekton.dev/cache-operation\"","\t// cacheValueTrue is the value used for cache annotations","\tcacheValueTrue = \"true\"","\t// cacheOperationStore is the value for cache store operations","\tcacheOperationStore = \"store\"","\t// cacheOperationRetrieve is the value for cache retrieve operations","\tcacheOperationRetrieve = \"retrieve\"",")","","// annotatedResource wraps a ResolvedResource with cache annotations","type annotatedResource struct {","\tresource    resolutionframework.ResolvedResource","\tannotations map[string]string","}","","func newAnnotatedResource(","\tresource resolutionframework.ResolvedResource,","\tresolverType,","\toperation string,","\ttimestamp string,",") *annotatedResource {","\t// Create a new map to avoid concurrent map writes when the same resource","\t// is being annotated from multiple goroutines","\texistingAnnotations := resource.Annotations()","\tannotations := make(map[string]string)","","\tfor k, v := range existingAnnotations {","\t\tannotations[k] = v","\t}","","\tannotations[cacheAnnotationKey] = cacheValueTrue","\tannotations[cacheTimestampKey] = timestamp","\tannotations[cacheResolverTypeKey] = resolverType","\tannotations[cacheOperationKey] = operation","","\treturn \u0026annotatedResource{","\t\tresource:    resource,","\t\tannotations: annotations,","\t}","}","","// Data returns the bytes of the resource","func (a *annotatedResource) Data() []byte {","\treturn a.resource.Data()","}","","// Annotations returns the annotations with cache metadata","func (a *annotatedResource) Annotations() map[string]string {","\treturn a.annotations","}","","// RefSource returns the source reference of the remote data","func (a *annotatedResource) RefSource() *v1.RefSource {","\treturn a.resource.RefSource()","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2]},{"id":225,"path":"pkg/remoteresolution/resolver/framework/cache/cache.go","lines":["/*","Copyright 2025 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package cache","","import (","\t\"context\"","\t\"crypto/sha256\"","\t\"encoding/hex\"","\t\"sort\"","\t\"time\"","","\tpipelinev1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tresolutionframework \"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"","\t\"go.uber.org/zap\"","\tutilcache \"k8s.io/apimachinery/pkg/util/cache\"",")","","var _ resolutionframework.ConfigWatcher = (*resolverCache)(nil)","","// resolverCache is a wrapper around utilcache.LRUExpireCache that provides","// type-safe methods for caching resolver results.","type resolverCache struct {","\tcache   *utilcache.LRUExpireCache","\tlogger  *zap.SugaredLogger","\tttl     time.Duration","\tmaxSize int","\tclock   utilcache.Clock","}","","func newResolverCache(maxSize int, ttl time.Duration) *resolverCache {","\treturn newResolverCacheWithClock(maxSize, ttl, realClock{})","}","","func newResolverCacheWithClock(maxSize int, ttl time.Duration, clock utilcache.Clock) *resolverCache {","\treturn \u0026resolverCache{","\t\tcache:   utilcache.NewLRUExpireCacheWithClock(maxSize, clock),","\t\tttl:     ttl,","\t\tmaxSize: maxSize,","\t\tclock:   clock,","\t}","}","","// GetConfigName returns the name of the cache's configmap.","func (c *resolverCache) GetConfigName(_ context.Context) string {","\treturn getCacheConfigName()","}","","// withLogger returns a new ResolverCache instance with the provided logger.","// This prevents state leak by not storing logger in the global singleton.","func (c *resolverCache) withLogger(logger *zap.SugaredLogger) *resolverCache {","\treturn \u0026resolverCache{logger: logger, cache: c.cache, ttl: c.ttl, maxSize: c.maxSize, clock: c.clock}","}","","// TTL returns the time-to-live duration for cache entries.","func (c *resolverCache) TTL() time.Duration {","\treturn c.ttl","}","","// MaxSize returns the maximum number of entries the cache can hold.","func (c *resolverCache) MaxSize() int {","\treturn c.maxSize","}","","// Get retrieves a cached resource by resolver type and parameters, returning","// the resource and whether it was found.","func (c *resolverCache) Get(resolverType string, params []pipelinev1.Param) (resolutionframework.ResolvedResource, bool) {","\tkey := generateCacheKey(resolverType, params)","\tvalue, found := c.cache.Get(key)","\tif !found {","\t\tc.infow(\"Cache miss\", \"key\", key)","\t\treturn nil, found","\t}","","\tresource, ok := value.(resolutionframework.ResolvedResource)","\tif !ok {","\t\tc.infow(\"Failed casting cached resource\", \"key\", key)","\t\treturn nil, false","\t}","","\tc.infow(\"Cache hit\", \"key\", key)","\ttimestamp := c.clock.Now().Format(time.RFC3339)","\treturn newAnnotatedResource(resource, resolverType, cacheOperationRetrieve, timestamp), true","}","","func (c *resolverCache) infow(msg string, keysAndValues ...any) {","\tif c.logger != nil {","\t\tc.logger.Infow(msg, keysAndValues...)","\t}","}","","// Add stores a resource in the cache with the configured TTL and returns an","// annotated version of the resource.","func (c *resolverCache) Add(","\tresolverType string,","\tparams []pipelinev1.Param,","\tresource resolutionframework.ResolvedResource,",") resolutionframework.ResolvedResource {","\tkey := generateCacheKey(resolverType, params)","\tc.infow(\"Adding to cache\", \"key\", key, \"expiration\", c.ttl)","","\ttimestamp := c.clock.Now().Format(time.RFC3339)","\tannotatedResource := newAnnotatedResource(resource, resolverType, cacheOperationStore, timestamp)","","\tc.cache.Add(key, annotatedResource, c.ttl)","","\treturn annotatedResource","}","","// Remove deletes a cached resource identified by resolver type and parameters.","func (c *resolverCache) Remove(resolverType string, params []pipelinev1.Param) {","\tkey := generateCacheKey(resolverType, params)","\tc.infow(\"Removing from cache\", \"key\", key)","","\tc.cache.Remove(key)","}","","// Clear removes all entries from the cache.","func (c *resolverCache) Clear() {","\tc.infow(\"Clearing all cache entries\")","\t// predicate that returns true clears all entries","\tc.cache.RemoveAll(func(_ any) bool { return true })","}","","func generateCacheKey(resolverType string, params []pipelinev1.Param) string {","\t// Create a deterministic string representation of the parameters","\tparamStr := resolverType + \":\"","","\t// Filter out the 'cache' parameter and sort remaining params by name for determinism","\tfilteredParams := make([]pipelinev1.Param, 0, len(params))","\tfor _, p := range params {","\t\tif p.Name != CacheParam {","\t\t\tfilteredParams = append(filteredParams, p)","\t\t}","\t}","","\t// Sort params by name to ensure deterministic ordering","\tsort.Slice(filteredParams, func(i, j int) bool {","\t\treturn filteredParams[i].Name \u003c filteredParams[j].Name","\t})","","\tfor _, p := range filteredParams {","\t\tparamStr += p.Name + \"=\"","","\t\tswitch p.Value.Type {","\t\tcase pipelinev1.ParamTypeString:","\t\t\tparamStr += p.Value.StringVal","\t\tcase pipelinev1.ParamTypeArray:","\t\t\t// Sort array values for determinism","\t\t\tarrayVals := make([]string, len(p.Value.ArrayVal))","\t\t\tcopy(arrayVals, p.Value.ArrayVal)","\t\t\tsort.Strings(arrayVals)","\t\t\tfor i, val := range arrayVals {","\t\t\t\tif i \u003e 0 {","\t\t\t\t\tparamStr += \",\"","\t\t\t\t}","\t\t\t\tparamStr += val","\t\t\t}","\t\tcase pipelinev1.ParamTypeObject:","\t\t\t// Sort object keys for determinism","\t\t\tkeys := make([]string, 0, len(p.Value.ObjectVal))","\t\t\tfor k := range p.Value.ObjectVal {","\t\t\t\tkeys = append(keys, k)","\t\t\t}","\t\t\tsort.Strings(keys)","\t\t\tfor i, key := range keys {","\t\t\t\tif i \u003e 0 {","\t\t\t\t\tparamStr += \",\"","\t\t\t\t}","\t\t\t\tparamStr += key + \":\" + p.Value.ObjectVal[key]","\t\t\t}","\t\tdefault:","\t\t\t// For unknown types, use StringVal as fallback","\t\t\tparamStr += p.Value.StringVal","\t\t}","\t\tparamStr += \";\"","\t}","","\t// Generate a SHA-256 hash of the parameter string","\thash := sha256.Sum256([]byte(paramStr))","\treturn hex.EncodeToString(hash[:])","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,2,2,2,2,2,2,2,2,0,0,1,1,1,0,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,0,2,2,2,2,2,2,2,0,2,2,1,1,1,0,2,2,2,0,0,2,2,2,2,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,1,1,1,1,1,1,0,0,1,1,1,1,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,0,2,0,0,0,2,2,0]},{"id":226,"path":"pkg/remoteresolution/resolver/framework/cache/clock.go","lines":["/*","Copyright 2025 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package cache","","import \"time\"","","// realClock implements Clock using the actual system time.","type realClock struct{}","","func (realClock) Now() time.Time {","\treturn time.Now()","}","","// fakeClock implements Clock with a controllable time for testing.","type fakeClock struct {","\tnow time.Time","}","","// Now returns the current time of the fake clock.","func (f *fakeClock) Now() time.Time {","\treturn f.now","}","","// Advance moves the fake clock forward by the given duration.","func (f *fakeClock) Advance(d time.Duration) {","\tf.now = f.now.Add(d)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,0,0,0,2,2,2,0,0,2,2,2]},{"id":227,"path":"pkg/remoteresolution/resolver/framework/cache/configstore.go","lines":["/*","Copyright 2025 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package cache","","import (","\t\"context\"","\t\"os\"","\t\"strconv\"","\t\"sync\"","\t\"time\"","","\tresolutionframework \"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"","\t\"knative.dev/pkg/configmap\"",")","","const (","\t// resolverCacheConfigMapNameEnv env var overwrites the cache ConfigMap name","\t// defaults to \"resolver-cache-config\"","\tresolverCacheConfigMapNameEnv = \"RESOLVER_CACHE_CONFIG_MAP_NAME\"","\t// defaultConfigMapName is the default name of the ConfigMap that configures resolver cache settings","\t// the ConfigMap contains max-size and ttl configuration for the shared resolver cache","\tdefaultConfigMapName = \"resolver-cache-config\"","\tmaxSizeConfigMapKey  = \"max-size\"","\tttlConfigMapKey      = \"ttl\"","\tdefaultCacheSize     = 1000","\tdefaultExpiration    = 5 * time.Minute",")","","var (","\tcacheMu           sync.Mutex","\tstartWatchingOnce sync.Once",")","","type cacheConfigKey struct{}","","type CacheConfigStore struct {","\tuntyped         *configmap.UntypedStore","\tcacheConfigName string","}","","func NewCacheConfigStore(cacheConfigName string, logger configmap.Logger) *CacheConfigStore {","\treturn \u0026CacheConfigStore{","\t\tcacheConfigName: cacheConfigName,","\t\tuntyped: configmap.NewUntypedStore(","\t\t\tdefaultConfigMapName,","\t\t\tlogger,","\t\t\tconfigmap.Constructors{","\t\t\t\tgetCacheConfigName(): resolutionframework.DataFromConfigMap,","\t\t\t},","\t\t\tonCacheConfigChanged,","\t\t),","\t}","}","","func (store *CacheConfigStore) WatchConfigs(w configmap.Watcher) {","\tstartWatchingOnce.Do(func() {","\t\tstore.untyped.WatchConfigs(w)","\t})","}","","func (store *CacheConfigStore) GetResolverConfig() map[string]string {","\tresolverConfig := map[string]string{}","\tuntypedConf := store.untyped.UntypedLoad(store.cacheConfigName)","\tif conf, ok := untypedConf.(map[string]string); ok {","\t\tfor key, val := range conf {","\t\t\tresolverConfig[key] = val","\t\t}","\t}","\treturn resolverConfig","}","","// ToContext returns a new context with the cache's configuration","// data stored in it.","func (store *CacheConfigStore) ToContext(ctx context.Context) context.Context {","\treturn context.WithValue(ctx, cacheConfigKey{}, store.GetResolverConfig())","}","","// getCacheConfigName returns the name of the cache configuration ConfigMap.","// This can be overridden via the cacheConfigEnv environment variable.","func getCacheConfigName() string {","\tif configMapName := os.Getenv(resolverCacheConfigMapNameEnv); configMapName != \"\" {","\t\treturn configMapName","\t}","","\treturn defaultConfigMapName","}","","func onCacheConfigChanged(_ string, value any) {","\tconf, ok := value.(map[string]string)","\tif !ok {","\t\treturn","\t}","","\tmaxSize := defaultCacheSize","\tif maxSizeStr, ok := conf[maxSizeConfigMapKey]; ok {","\t\tif parsed, err := strconv.Atoi(maxSizeStr); err == nil \u0026\u0026 parsed \u003e 0 {","\t\t\tmaxSize = parsed","\t\t}","\t}","","\tttl := defaultExpiration","\tif ttlStr, ok := conf[ttlConfigMapKey]; ok {","\t\tif parsed, err := time.ParseDuration(ttlStr); err == nil \u0026\u0026 parsed \u003e 0 {","\t\t\tttl = parsed","\t\t}","\t}","","\tcacheMu.Lock()","\tdefer cacheMu.Unlock()","","\tsharedCache = newResolverCache(maxSize, ttl)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,0,1,1,1,1,1,1,1,0,1,0,0,0,0,1,1,1,0,0,0,1,1,1,1,0,1,0,0,2,2,2,2,2,0,2,2,2,2,2,0,0,2,2,2,2,2,0,0,2,2,2,2,0]},{"id":228,"path":"pkg/remoteresolution/resolver/framework/cache/operations.go","lines":["/*","Copyright 2025 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package cache","","import (","\t\"context\"","\t\"fmt\"","\t\"slices\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tresolutionframework \"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"",")","","const (","\tcacheModeAlways              = \"always\"","\tcacheModeNever               = \"never\"","\tcacheModeAuto                = \"auto\"","\tCacheParam                   = \"cache\"","\tdefaultCacheModeConfigMapKey = \"default-cache-mode\"",")","","// ImmutabilityChecker extends the base Resolver interface with cache-specific methods.","// Each resolver implements IsImmutable to define what \"auto\" mode means in their context.","type ImmutabilityChecker interface {","\tIsImmutable(params []v1.Param) bool","}","","// ShouldUse determines whether caching should be used based on:","// 1. Task/Pipeline cache parameter (highest priority)","// 2. ConfigMap default-cache-mode (middle priority)","// 3. System default for resolver type (lowest priority)","func ShouldUse(","\tctx context.Context,","\tresolver ImmutabilityChecker,","\tparams []v1.Param,","\tresolverType string,",") bool {","\t// Get cache mode from task parameter","\tcacheMode := \"\"","\tfor _, param := range params {","\t\tif param.Name == CacheParam {","\t\t\tcacheMode = param.Value.StringVal","\t\t\tbreak","\t\t}","\t}","","\t// If no task parameter, get default from ConfigMap","\tif cacheMode == \"\" {","\t\tconf := resolutionframework.GetResolverConfigFromContext(ctx)","\t\t// This can be optionally set in individual resolver ConfigMaps (e.g., bundleresolver-config,","\t\t// git-resolver-config, cluster-resolver-config) to override the system default cache","\t\t// mode for that resolver. Valid values: \"always\", \"never\", \"auto\"","\t\tif defaultMode, ok := conf[defaultCacheModeConfigMapKey]; ok {","\t\t\tcacheMode = defaultMode","\t\t}","\t}","","\t// If still no mode, use system default","\tif cacheMode == \"\" {","\t\tcacheMode = cacheModeAuto","\t}","","\tswitch cacheMode {","\tcase cacheModeAlways:","\t\treturn true","\tcase cacheModeNever:","\t\treturn false","\tcase cacheModeAuto:","\t\treturn resolver.IsImmutable(params)","\tdefault:","\t\treturn resolver.IsImmutable(params)","\t}","}","","// Validate returns an error if the cache mode is not \"always\", \"never\",","// \"auto\", or empty string (which defaults to auto).","func Validate(cacheMode string) error {","\t// Empty string is valid - it will default to auto mode in ShouldUse","\tif cacheMode == \"\" {","\t\treturn nil","\t}","","\tvalidCacheModes := []string{cacheModeAlways, cacheModeNever, cacheModeAuto}","\tif slices.Contains(validCacheModes, cacheMode) {","\t\treturn nil","\t}","","\treturn fmt.Errorf(\"invalid cache mode '%s', must be one of: %v (or empty for default)\", cacheMode, validCacheModes)","}","","type resolveFn = func() (resolutionframework.ResolvedResource, error)","","func GetFromCacheOrResolve(","\tctx context.Context,","\tparams []v1.Param,","\tresolverType string,","\tresolve resolveFn,",") (resolutionframework.ResolvedResource, error) {","\tcacheInstance := Get(ctx)","","\tif cached, ok := cacheInstance.Get(resolverType, params); ok {","\t\treturn cached, nil","\t}","","\t// If cache miss, resolve from params","\tresource, err := resolve()","\tif err != nil {","\t\treturn nil, err","\t}","","\t// Store annotated resource with store operation and return annotated resource","\t// to indicate it was stored in cache","\treturn cacheInstance.Add(resolverType, params, resource), nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,0,0,0,2,2,2,0,2,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,0,2,2,2,2,0,2,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,0,0,2,2,2,2,0,0,0,2,0]},{"id":229,"path":"pkg/remoteresolution/resolver/framework/cache/setup.go","lines":["/*","Copyright 2025 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package cache","","import (","\t\"context\"","\t\"sync\"","","\t\"k8s.io/client-go/rest\"","\t\"knative.dev/pkg/injection\"","\t\"knative.dev/pkg/logging\"",")","","var (","\tsharedCache   *resolverCache","\tcacheInitOnce sync.Once",")","","type resolverCacheKey struct{}","","func init() {","\tinjection.Default.RegisterClient(addCacheWithLoggerToCtx)","}","","func addCacheWithLoggerToCtx(ctx context.Context, _ *rest.Config) context.Context {","\treturn context.WithValue(ctx, resolverCacheKey{}, createCacheOnce(ctx))","}","","func createCacheOnce(ctx context.Context) *resolverCache {","\tcacheInitOnce.Do(func() {","\t\tcacheMu.Lock()","\t\tdefer cacheMu.Unlock()","","\t\tsharedCache = newResolverCache(defaultCacheSize, defaultExpiration)","\t})","","\treturn sharedCache.withLogger(","\t\tlogging.FromContext(ctx),","\t)","}","","// Get extracts the ResolverCache from the context.","// If the cache is not available in the context (e.g., in tests),","// it falls back to the shared cache with a logger from the context.","func Get(ctx context.Context) *resolverCache {","\tif untyped := ctx.Value(resolverCacheKey{}); untyped != nil {","\t\treturn untyped.(*resolverCache)","\t}","","\treturn createCacheOnce(ctx)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,1,1,1,0,2,2,2,2,2,2,2,0,2,2,2,0,0,0,0,0,2,2,2,2,0,2,0]},{"id":230,"path":"pkg/remoteresolution/resolver/framework/controller.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package framework","","import (","\t\"context\"","\t\"strings\"","","\trrclient \"github.com/tektoncd/pipeline/pkg/client/resolution/injection/client\"","\trrinformer \"github.com/tektoncd/pipeline/pkg/client/resolution/injection/informers/resolution/v1beta1/resolutionrequest\"","\trrcache \"github.com/tektoncd/pipeline/pkg/remoteresolution/resolver/framework/cache\"","\tframework \"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"","\t\"k8s.io/client-go/tools/cache\"","\t\"k8s.io/utils/clock\"","\tkubeclient \"knative.dev/pkg/client/injection/kube/client\"","\t\"knative.dev/pkg/configmap\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/logging\"",")","","// ReconcilerModifier is a func that can access and modify a reconciler","// in the moments before a resolver is started. It allows for","// things like injecting a test clock.","type ReconcilerModifier = func(reconciler *Reconciler)","","// NewController returns a knative controller for a Tekton Resolver.","// This sets up a lot of the boilerplate that individual resolvers","// shouldn't need to be concerned with since it's common to all of them.","func NewController(ctx context.Context, resolver Resolver, modifiers ...ReconcilerModifier) func(context.Context, configmap.Watcher) *controller.Impl {","\tif err := framework.ValidateResolver(ctx, resolver.GetSelector(ctx)); err != nil {","\t\tpanic(err.Error())","\t}","\treturn func(ctx context.Context, cmw configmap.Watcher) *controller.Impl {","\t\tlogger := logging.FromContext(ctx)","\t\tkubeclientset := kubeclient.Get(ctx)","\t\trrclientset := rrclient.Get(ctx)","\t\trrInformer := rrinformer.Get(ctx)","","\t\tif err := resolver.Initialize(ctx); err != nil {","\t\t\tpanic(err.Error())","\t\t}","","\t\tr := \u0026Reconciler{","\t\t\tLeaderAwareFuncs:           framework.LeaderAwareFuncs(rrInformer.Lister()),","\t\t\tkubeClientSet:              kubeclientset,","\t\t\tresolutionRequestLister:    rrInformer.Lister(),","\t\t\tresolutionRequestClientSet: rrclientset,","\t\t\tresolver:                   resolver,","\t\t}","","\t\twatchConfigChanges(ctx, r, cmw)","\t\twatchCacheConfigChanges(ctx, r, cmw)","","\t\t// TODO(sbwsg): Do better sanitize.","\t\tresolverName := resolver.GetName(ctx)","\t\tresolverName = strings.ReplaceAll(resolverName, \"/\", \"\")","\t\tresolverName = strings.ReplaceAll(resolverName, \" \", \"\")","","\t\tapplyModifiersAndDefaults(ctx, r, modifiers)","","\t\timpl := controller.NewContext(ctx, r, controller.ControllerOptions{","\t\t\tWorkQueueName: \"TektonResolverFramework.\" + resolverName,","\t\t\tLogger:        logger,","\t\t})","","\t\t_, err := rrInformer.Informer().AddEventHandler(cache.FilteringResourceEventHandler{","\t\t\tFilterFunc: framework.FilterResolutionRequestsBySelector(resolver.GetSelector(ctx)),","\t\t\tHandler: cache.ResourceEventHandlerFuncs{","\t\t\t\tAddFunc: impl.Enqueue,","\t\t\t\tUpdateFunc: func(oldObj, newObj interface{}) {","\t\t\t\t\timpl.Enqueue(newObj)","\t\t\t\t},","\t\t\t\t// TODO(sbwsg): should we deliver delete events","\t\t\t\t// to the resolver?","\t\t\t\t// DeleteFunc: impl.Enqueue,","\t\t\t},","\t\t})","\t\tif err != nil {","\t\t\tlogging.FromContext(ctx).Panicf(\"Couldn't register ResolutionRequest informer event handler: %w\", err)","\t\t}","","\t\treturn impl","\t}","}","","// watchConfigChanges binds a framework.Resolver to updates on its","// configmap, using knative's configmap helpers. This is only done if","// the resolver implements the framework.ConfigWatcher interface.","func watchConfigChanges(ctx context.Context, reconciler *Reconciler, cmw configmap.Watcher) {","\tif configWatcher, ok := reconciler.resolver.(framework.ConfigWatcher); ok {","\t\tlogger := logging.FromContext(ctx)","\t\tresolverConfigName := configWatcher.GetConfigName(ctx)","\t\tif resolverConfigName == \"\" {","\t\t\tpanic(\"resolver returned empty config name\")","\t\t}","\t\treconciler.configStore = framework.NewConfigStore(resolverConfigName, logger)","\t\treconciler.configStore.WatchConfigs(cmw)","\t}","}","","func watchCacheConfigChanges(ctx context.Context, reconciler *Reconciler, cmw configmap.Watcher) {","\tlogger := logging.FromContext(ctx)","\tcacheInstance := rrcache.Get(ctx)","\tcacheConfigName := cacheInstance.GetConfigName(ctx)","\tif cacheConfigName == \"\" {","\t\tlogger.Error(\"failed to setup cache config watcher, cache returned empty config name\")","\t\treturn","\t}","","\tcacheConfigStore := rrcache.NewCacheConfigStore(cacheConfigName, logger)","\tcacheConfigStore.WatchConfigs(cmw)","}","","// applyModifiersAndDefaults applies the given modifiers to","// a reconciler and, after doing so, sets any default values for things","// that weren't set by a modifier.","func applyModifiersAndDefaults(ctx context.Context, r *Reconciler, modifiers []ReconcilerModifier) {","\tfor _, mod := range modifiers {","\t\tmod(r)","\t}","","\tif r.Clock == nil {","\t\tr.Clock = clock.RealClock{}","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,0,2,2,2,2,2,2,2,1,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,0,0,0,0,2,1,1,0,2,0,0,0,0,0,0,2,2,1,1,1,1,0,1,1,0,0,0,2,2,2,2,2,1,1,1,0,2,2,0,0,0,0,0,2,2,2,2,0,2,1,1,0]},{"id":231,"path":"pkg/remoteresolution/resolver/framework/fakeresolver.go","lines":["/*"," Copyright 2022 The Tekton Authors",""," Licensed under the Apache License, Version 2.0 (the \"License\");"," you may not use this file except in compliance with the License."," You may obtain a copy of the License at","","     http://www.apache.org/licenses/LICENSE-2.0",""," Unless required by applicable law or agreed to in writing, software"," distributed under the License is distributed on an \"AS IS\" BASIS,"," WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied."," See the License for the specific language governing permissions and"," limitations under the License.","*/","","package framework","","import (","\t\"context\"","\t\"fmt\"","\t\"time\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\tresolutioncommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"",")","","const FakeUrl string = \"fake://url\"","","var _ Resolver = \u0026FakeResolver{}","","// FakeResolver implements a framework.Resolver that can fetch pre-configured strings based on a parameter value, or return","// resolution attempts with a configured error.","type FakeResolver framework.FakeResolver","","// Initialize performs any setup required by the fake resolver.","func (r *FakeResolver) Initialize(ctx context.Context) error {","\tif r.ForParam == nil {","\t\tr.ForParam = make(map[string]*framework.FakeResolvedResource)","\t}","\treturn nil","}","","// GetName returns the string name that the fake resolver should be","// associated with.","func (r *FakeResolver) GetName(_ context.Context) string {","\treturn framework.FakeResolverName","}","","// GetSelector returns the labels that resource requests are required to have for","// the fake resolver to process them.","func (r *FakeResolver) GetSelector(_ context.Context) map[string]string {","\treturn map[string]string{","\t\tresolutioncommon.LabelKeyResolverType: framework.LabelValueFakeResolverType,","\t}","}","","// Validate returns an error if the given parameter map is not","// valid for a resource request targeting the fake resolver.","func (r *FakeResolver) Validate(_ context.Context, req *v1beta1.ResolutionRequestSpec) error {","\tif len(req.Params) \u003e 0 {","\t\treturn framework.ValidateParams(req.Params)","\t}","\tif req.URL != FakeUrl {","\t\treturn fmt.Errorf(\"Wrong url. Expected: %s,  Got: %s\", FakeUrl, req.URL)","\t}","\treturn nil","}","","// Resolve performs the work of fetching a file from the fake resolver given a map of","// parameters.","func (r *FakeResolver) Resolve(_ context.Context, req *v1beta1.ResolutionRequestSpec) (framework.ResolvedResource, error) {","\tif len(req.Params) \u003e 0 {","\t\treturn framework.Resolve(req.Params, r.ForParam)","\t}","\tfrr, ok := r.ForParam[req.URL]","\tif !ok {","\t\treturn nil, fmt.Errorf(\"couldn't find resource for url %s\", req.URL)","\t}","\treturn frr, nil","}","","var _ framework.TimedResolution = \u0026FakeResolver{}","","// GetResolutionTimeout returns the configured timeout for the reconciler, or the default time.Duration if not configured.","func (r *FakeResolver) GetResolutionTimeout(ctx context.Context, defaultTimeout time.Duration, params map[string]string) (time.Duration, error) {","\treturn framework.GetResolutionTimeout(r.Timeout, defaultTimeout), nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,0,0,2,2,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2]},{"id":232,"path":"pkg/remoteresolution/resolver/framework/reconciler.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package framework","","import (","\t\"context\"","\t\"encoding/base64\"","\t\"encoding/json\"","\t\"errors\"","\t\"fmt\"","\t\"time\"","","\tpipelinev1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tpipelinev1beta1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\trrclient \"github.com/tektoncd/pipeline/pkg/client/resolution/clientset/versioned\"","\trrv1beta1 \"github.com/tektoncd/pipeline/pkg/client/resolution/listers/resolution/v1beta1\"","\trrcache \"github.com/tektoncd/pipeline/pkg/remoteresolution/resolver/framework/cache\"","\tresolutioncommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/types\"","\t\"k8s.io/client-go/kubernetes\"","\t\"k8s.io/client-go/tools/cache\"","\t\"k8s.io/utils/clock\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/logging\"","\t\"knative.dev/pkg/reconciler\"",")","","// defaultMaximumResolutionDuration is the maximum amount of time","// resolution may take.","","// defaultMaximumResolutionDuration is the max time that a call to","// Resolve() may take. It can be overridden by a resolver implementing","// the framework.TimedResolution interface.","const defaultMaximumResolutionDuration = time.Minute","","// statusDataPatch is the json structure that will be PATCHed into","// a ResolutionRequest with its data and annotations once successfully","// resolved.","type statusDataPatch struct {","\tAnnotations map[string]string             `json:\"annotations\"`","\tData        string                        `json:\"data\"`","\tSource      *pipelinev1beta1.ConfigSource `json:\"source\"`","\tRefSource   *pipelinev1.RefSource         `json:\"refSource\"`","}","","// Reconciler handles ResolutionRequest objects, performs functionality","// common to all resolvers and delegates resolver-specific actions","// to its embedded type-specific Resolver object.","type Reconciler struct {","\t// Implements reconciler.LeaderAware","\treconciler.LeaderAwareFuncs","","\t// Clock is used by the reconciler to track the passage of time","\t// and can be overridden for tests.","\tClock clock.PassiveClock","","\tresolver                   Resolver","\tkubeClientSet              kubernetes.Interface","\tresolutionRequestLister    rrv1beta1.ResolutionRequestLister","\tresolutionRequestClientSet rrclient.Interface","","\tconfigStore *framework.ConfigStore","}","","var _ reconciler.LeaderAware = \u0026Reconciler{}","","// Reconcile receives the string key of a ResolutionRequest object, looks","// it up, checks it for common errors, and then delegates","// resolver-specific functionality to the reconciler's embedded","// type-specific resolver. Any errors that occur during validation or","// resolution are handled by updating or failing the ResolutionRequest.","func (r *Reconciler) Reconcile(ctx context.Context, key string) error {","\tnamespace, name, err := cache.SplitMetaNamespaceKey(key)","\tif err != nil {","\t\terr = \u0026resolutioncommon.InvalidResourceKeyError{Key: key, Original: err}","\t\treturn controller.NewPermanentError(err)","\t}","","\trr, err := r.resolutionRequestLister.ResolutionRequests(namespace).Get(name)","\tif err != nil {","\t\terr := \u0026resolutioncommon.GetResourceError{ResolverName: \"resolutionrequest\", Key: key, Original: err}","\t\treturn controller.NewPermanentError(err)","\t}","","\tif rr.IsDone() {","\t\treturn nil","\t}","","\t// Inject request-scoped information into the context, such as","\t// the namespace that the request originates from and the","\t// configuration from the configmap this resolver is watching.","\tctx = resolutioncommon.InjectRequestNamespace(ctx, namespace)","\tctx = resolutioncommon.InjectRequestName(ctx, name)","\tif r.configStore != nil {","\t\tctx = r.configStore.ToContext(ctx)","\t}","","\treturn r.resolve(ctx, key, rr)","}","","func (r *Reconciler) resolve(ctx context.Context, key string, rr *v1beta1.ResolutionRequest) error {","\terrChan := make(chan error)","\tresourceChan := make(chan framework.ResolvedResource)","","\tparamsMap := make(map[string]string)","\tfor _, p := range rr.Spec.Params {","\t\tparamsMap[p.Name] = p.Value.StringVal","\t}","","\t// Centralized cache parameter validation for all resolvers","\tif cacheMode, exists := paramsMap[rrcache.CacheParam]; exists \u0026\u0026 cacheMode != \"\" {","\t\tif err := rrcache.Validate(cacheMode); err != nil {","\t\t\treturn \u0026resolutioncommon.InvalidRequestError{","\t\t\t\tResolutionRequestKey: key,","\t\t\t\tMessage:              err.Error(),","\t\t\t}","\t\t}","\t}","","\ttimeoutDuration := defaultMaximumResolutionDuration","\tif timed, ok := r.resolver.(framework.TimedResolution); ok {","\t\tvar err error","\t\ttimeoutDuration, err = timed.GetResolutionTimeout(ctx, defaultMaximumResolutionDuration, paramsMap)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t}","","\t// A new context is created for resolution so that timeouts can","\t// be enforced without affecting other uses of ctx (e.g. sending","\t// Updates to ResolutionRequest objects).","\tresolutionCtx, cancelFn := context.WithTimeout(ctx, timeoutDuration)","\tdefer cancelFn()","","\tgo func() {","\t\tvalidationError := r.resolver.Validate(resolutionCtx, \u0026rr.Spec)","\t\tif validationError != nil {","\t\t\terrChan \u003c- \u0026resolutioncommon.InvalidRequestError{","\t\t\t\tResolutionRequestKey: key,","\t\t\t\tMessage:              validationError.Error(),","\t\t\t}","\t\t\treturn","\t\t}","\t\tresource, resolveErr := r.resolver.Resolve(resolutionCtx, \u0026rr.Spec)","\t\tif resolveErr != nil {","\t\t\terrChan \u003c- \u0026resolutioncommon.GetResourceError{","\t\t\t\tResolverName: r.resolver.GetName(resolutionCtx),","\t\t\t\tKey:          key,","\t\t\t\tOriginal:     resolveErr,","\t\t\t}","\t\t\treturn","\t\t}","\t\tresourceChan \u003c- resource","\t}()","","\tselect {","\tcase err := \u003c-errChan:","\t\tif err != nil {","\t\t\treturn r.OnError(ctx, rr, err)","\t\t}","\tcase \u003c-resolutionCtx.Done():","\t\tif err := resolutionCtx.Err(); err != nil {","\t\t\treturn r.OnError(ctx, rr, err)","\t\t}","\tcase resource := \u003c-resourceChan:","\t\treturn r.writeResolvedData(ctx, rr, resource)","\t}","","\treturn errors.New(\"unknown error\")","}","","// OnError is used to handle any situation where a ResolutionRequest has","// reached a terminal situation that cannot be recovered from.","func (r *Reconciler) OnError(ctx context.Context, rr *v1beta1.ResolutionRequest, err error) error {","\tif resolutioncommon.IsErrTransient(err) {","\t\treturn err","\t}","\tif rr == nil {","\t\treturn controller.NewPermanentError(err)","\t}","\tif err != nil {","\t\t_ = r.MarkFailed(ctx, rr, err)","\t\treturn controller.NewPermanentError(err)","\t}","\treturn nil","}","","// MarkFailed updates a ResolutionRequest as having failed. It returns","// errors that occur during the update process or nil if the update","// appeared to succeed.","func (r *Reconciler) MarkFailed(ctx context.Context, rr *v1beta1.ResolutionRequest, resolutionErr error) error {","\tkey := fmt.Sprintf(\"%s/%s\", rr.Namespace, rr.Name)","\treason, resolutionErr := resolutioncommon.ReasonError(resolutionErr)","\tlatestGeneration, err := r.resolutionRequestClientSet.ResolutionV1beta1().ResolutionRequests(rr.Namespace).Get(ctx, rr.Name, metav1.GetOptions{})","\tif err != nil {","\t\tlogging.FromContext(ctx).Warnf(\"error getting latest generation of resolutionrequest %q: %v\", key, err)","\t\treturn err","\t}","\tif latestGeneration.IsDone() {","\t\treturn nil","\t}","\tlatestGeneration.Status.MarkFailed(reason, resolutionErr.Error())","\t_, err = r.resolutionRequestClientSet.ResolutionV1beta1().ResolutionRequests(rr.Namespace).UpdateStatus(ctx, latestGeneration, metav1.UpdateOptions{})","\tif err != nil {","\t\tlogging.FromContext(ctx).Warnf(\"error marking resolutionrequest %q as failed: %v\", key, err)","\t\treturn err","\t}","\treturn nil","}","","func (r *Reconciler) writeResolvedData(ctx context.Context, rr *v1beta1.ResolutionRequest, resource framework.ResolvedResource) error {","\tencodedData := base64.StdEncoding.Strict().EncodeToString(resource.Data())","\tpatchBytes, err := json.Marshal(map[string]statusDataPatch{","\t\t\"status\": {","\t\t\tData:        encodedData,","\t\t\tAnnotations: resource.Annotations(),","\t\t\tRefSource:   resource.RefSource(),","\t\t\tSource:      (*pipelinev1beta1.ConfigSource)(resource.RefSource()),","\t\t},","\t})","\tif err != nil {","\t\tlogging.FromContext(ctx).Warnf(\"writeResolvedData error serializing resource request patch for resolution request %s:%s: %s\", rr.Namespace, rr.Name, err.Error())","\t\treturn r.OnError(ctx, rr, \u0026resolutioncommon.UpdatingRequestError{","\t\t\tResolutionRequestKey: fmt.Sprintf(\"%s/%s\", rr.Namespace, rr.Name),","\t\t\tOriginal:             fmt.Errorf(\"error serializing resource request patch: %w\", err),","\t\t})","\t}","\t_, err = r.resolutionRequestClientSet.ResolutionV1beta1().ResolutionRequests(rr.Namespace).Patch(ctx, rr.Name, types.MergePatchType, patchBytes, metav1.PatchOptions{}, \"status\")","\tif err != nil {","\t\tlogging.FromContext(ctx).Warnf(\"writeResolvedData error patching resolution request %s:%s: %s\", rr.Namespace, rr.Name, err.Error())","\t\treturn r.OnError(ctx, rr, \u0026resolutioncommon.UpdatingRequestError{","\t\t\tResolutionRequestKey: fmt.Sprintf(\"%s/%s\", rr.Namespace, rr.Name),","\t\t\tOriginal:             err,","\t\t})","\t}","","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,1,1,1,0,2,2,1,1,1,0,2,1,1,0,0,0,0,2,2,2,1,1,0,2,0,0,2,2,2,2,2,2,2,2,0,0,2,1,1,1,1,1,1,0,0,2,2,2,2,2,1,1,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,1,0,0,0,0,2,2,2,2,2,1,1,2,2,2,2,1,0,0,0,0,0,2,2,2,2,2,1,1,1,2,1,1,2,2,2,1,1,1,2,0,0,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,2,2,1,1,1,1,1,1,0,2,0]},{"id":233,"path":"pkg/remoteresolution/resolver/framework/testing/fakecontroller.go","lines":["/*"," Copyright 2022 The Tekton Authors",""," Licensed under the Apache License, Version 2.0 (the \"License\");"," you may not use this file except in compliance with the License."," You may obtain a copy of the License at","","     http://www.apache.org/licenses/LICENSE-2.0",""," Unless required by applicable law or agreed to in writing, software"," distributed under the License is distributed on an \"AS IS\" BASIS,"," WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied."," See the License for the specific language governing permissions and"," limitations under the License.","*/","","package testing","","import (","\t\"context\"","\t\"encoding/base64\"","\t\"strings\"","\t\"testing\"","\t\"time\"","","\t\"github.com/google/go-cmp/cmp\"","\t\"github.com/google/go-cmp/cmp/cmpopts\"","\tresolverconfig \"github.com/tektoncd/pipeline/pkg/apis/config/resolver\"","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/remoteresolution/resolver/framework\"","\t\"github.com/tektoncd/pipeline/test\"","\t\"github.com/tektoncd/pipeline/test/diff\"","\t\"github.com/tektoncd/pipeline/test/names\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/types\"","\t\"k8s.io/client-go/tools/record\"","\ttestclock \"k8s.io/utils/clock/testing\"","\t\"knative.dev/pkg/apis\"","\tcminformer \"knative.dev/pkg/configmap/informer\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/logging\"","\tpkgreconciler \"knative.dev/pkg/reconciler\"","\t\"knative.dev/pkg/system\"",")","","var (","\tnow                      = time.Date(2022, time.January, 1, 0, 0, 0, 0, time.UTC)","\ttestClock                = testclock.NewFakePassiveClock(now)","\tignoreLastTransitionTime = cmpopts.IgnoreFields(apis.Condition{}, \"LastTransitionTime.Inner.Time\")","\tignoreCacheTimestamp     = cmpopts.IgnoreMapEntries(func(k, v string) bool {","\t\treturn strings.HasPrefix(k, \"resolution.tekton.dev/cache\")","\t})",")","","// ResolverReconcileTestModifier is a function thaat will be invoked after the test assets and controller have been created","type ResolverReconcileTestModifier = func(resolver framework.Resolver, testAssets test.Assets)","","// RunResolverReconcileTest takes data to seed clients and informers, a Resolver, a ResolutionRequest, and the expected","// ResolutionRequestStatus and error, both of which can be nil. It instantiates a controller for that resolver and","// reconciles the given request. It then checks for the expected error, if any, and compares the resulting status with","// the expected status.","func RunResolverReconcileTest(ctx context.Context, t *testing.T, d test.Data, resolver framework.Resolver, request *v1beta1.ResolutionRequest,","\texpectedStatus *v1beta1.ResolutionRequestStatus, expectedErr error, resolverModifiers ...ResolverReconcileTestModifier) {","\tt.Helper()","","\ttestAssets, cancel := GetResolverFrameworkController(ctx, t, d, resolver, setClockOnReconciler)","\tdefer cancel()","","\tfor _, rm := range resolverModifiers {","\t\trm(resolver, testAssets)","\t}","","\terr := testAssets.Controller.Reconciler.Reconcile(testAssets.Ctx, getRequestName(request)) //nolint","\tif expectedErr != nil {","\t\tif err == nil {","\t\t\tt.Fatalf(\"expected to get error: `%v`, but got nothing\", expectedErr)","\t\t}","\t\tif expectedErr.Error() != err.Error() {","\t\t\tt.Fatalf(\"expected to get error `%v`, but got `%v`\", expectedErr, err)","\t\t}","\t} else if err != nil {","\t\tif ok, _ := controller.IsRequeueKey(err); !ok {","\t\t\tt.Fatalf(\"did not expect an error, but got `%v`\", err)","\t\t}","\t}","","\tc := testAssets.Clients.ResolutionRequests.ResolutionV1beta1()","\treconciledRR, err := c.ResolutionRequests(request.Namespace).Get(testAssets.Ctx, request.Name, metav1.GetOptions{}) //nolint","\tif err != nil {","\t\tt.Fatalf(\"getting updated ResolutionRequest: %v\", err)","\t}","\tif expectedStatus != nil {","\t\tif d := cmp.Diff(*expectedStatus, reconciledRR.Status, ignoreLastTransitionTime, ignoreCacheTimestamp); d != \"\" {","\t\t\tt.Errorf(\"ResolutionRequest status doesn't match %s\", diff.PrintWantGot(d))","\t\t\tif expectedStatus.Data != \"\" \u0026\u0026 expectedStatus.Data != reconciledRR.Status.Data {","\t\t\t\tdecodedExpectedData, err := base64.StdEncoding.Strict().DecodeString(expectedStatus.Data)","\t\t\t\tif err != nil {","\t\t\t\t\tt.Errorf(\"couldn't decode expected data: %v\", err)","\t\t\t\t\treturn","\t\t\t\t}","\t\t\t\tdecodedGotData, err := base64.StdEncoding.Strict().DecodeString(reconciledRR.Status.Data)","\t\t\t\tif err != nil {","\t\t\t\t\tt.Errorf(\"couldn't decode reconciled data: %v\", err)","\t\t\t\t\treturn","\t\t\t\t}","\t\t\t\tif d := cmp.Diff(decodedExpectedData, decodedGotData); d != \"\" {","\t\t\t\t\tt.Errorf(\"decoded data did not match expected: %s\", diff.PrintWantGot(d))","\t\t\t\t}","\t\t\t}","\t\t}","\t}","}","","// GetResolverFrameworkController returns an instance of the resolver framework controller/reconciler using the given resolver,","// seeded with d, where d represents the state of the system (existing resources) needed for the test.","func GetResolverFrameworkController(ctx context.Context, t *testing.T, d test.Data, resolver framework.Resolver, modifiers ...framework.ReconcilerModifier) (test.Assets, func()) {","\tt.Helper()","\tnames.TestingSeed()","\treturn initializeResolverFrameworkControllerAssets(ctx, t, d, resolver, modifiers...)","}","","func initializeResolverFrameworkControllerAssets(ctx context.Context, t *testing.T, d test.Data, resolver framework.Resolver, modifiers ...framework.ReconcilerModifier) (test.Assets, func()) {","\tt.Helper()","\tctx, cancel := context.WithCancel(ctx)","\tensureConfigurationConfigMapsExist(\u0026d)","\tc, informers := test.SeedTestData(t, ctx, d)","\tconfigMapWatcher := cminformer.NewInformedWatcher(c.Kube, resolverconfig.ResolversNamespace(system.Namespace()))","\tctl := framework.NewController(ctx, resolver, modifiers...)(ctx, configMapWatcher)","\tif err := configMapWatcher.Start(ctx.Done()); err != nil {","\t\tt.Fatalf(\"error starting configmap watcher: %v\", err)","\t}","","\tif la, ok := ctl.Reconciler.(pkgreconciler.LeaderAware); ok {","\t\t_ = la.Promote(pkgreconciler.UniversalBucket(), func(pkgreconciler.Bucket, types.NamespacedName) {})","\t}","","\treturn test.Assets{","\t\tLogger:     logging.FromContext(ctx),","\t\tController: ctl,","\t\tClients:    c,","\t\tInformers:  informers,","\t\tRecorder:   controller.GetEventRecorder(ctx).(*record.FakeRecorder),","\t\tCtx:        ctx,","\t}, cancel","}","","func getRequestName(rr *v1beta1.ResolutionRequest) string {","\treturn strings.Join([]string{rr.Namespace, rr.Name}, \"/\")","}","","func setClockOnReconciler(r *framework.Reconciler) {","\tif r.Clock == nil {","\t\tr.Clock = testClock","\t}","}","","func ensureConfigurationConfigMapsExist(d *test.Data) {","\tvar featureFlagsExists bool","\tvar resolverCacheConfigExists bool","\tfor _, cm := range d.ConfigMaps {","\t\tif cm.Name == resolverconfig.GetFeatureFlagsConfigName() {","\t\t\tfeatureFlagsExists = true","\t\t}","\t\tif cm.Name == \"resolver-cache-config\" {","\t\t\tresolverCacheConfigExists = true","\t\t}","\t}","\tif !featureFlagsExists {","\t\td.ConfigMaps = append(d.ConfigMaps, \u0026corev1.ConfigMap{","\t\t\tObjectMeta: metav1.ObjectMeta{","\t\t\t\tName:      resolverconfig.GetFeatureFlagsConfigName(),","\t\t\t\tNamespace: resolverconfig.ResolversNamespace(system.Namespace()),","\t\t\t},","\t\t\tData: map[string]string{},","\t\t})","\t}","\tif !resolverCacheConfigExists {","\t\td.ConfigMaps = append(d.ConfigMaps, \u0026corev1.ConfigMap{","\t\t\tObjectMeta: metav1.ObjectMeta{","\t\t\t\tName:      \"resolver-cache-config\",","\t\t\t\tNamespace: resolverconfig.ResolversNamespace(system.Namespace()),","\t\t\t},","\t\t\tData: map[string]string{},","\t\t})","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0,1,1,0,0,1,1,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0]},{"id":234,"path":"pkg/remoteresolution/resolver/git/resolver.go","lines":["/*","Copyright 2024 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package git","","import (","\t\"context\"","\t\"encoding/hex\"","\t\"errors\"","\t\"time\"","","\t\"github.com/jenkins-x/go-scm/scm\"","\t\"github.com/jenkins-x/go-scm/scm/factory\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/remoteresolution/resolver/framework\"","\t\"github.com/tektoncd/pipeline/pkg/remoteresolution/resolver/framework/cache\"","\tresolutioncommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\tresolutionframework \"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/resolver/git\"","\t\"go.uber.org/zap\"","\tk8scache \"k8s.io/apimachinery/pkg/util/cache\"","\t\"k8s.io/client-go/kubernetes\"","\tkubeclient \"knative.dev/pkg/client/injection/kube/client\"","\t\"knative.dev/pkg/logging\"",")","","const (","\tdisabledError   = \"cannot handle resolution request, enable-git-resolver feature flag not true\"","\tgitResolverName = \"Git\"","","\t// labelValueGitResolverType is the value to use for the","\t// resolution.tekton.dev/type label on resource requests","\tlabelValueGitResolverType = \"git\"","","\t// size of the LRU secrets cache","\tcacheSize = 1024","\t// the time to live for a cache entry","\tttl = 5 * time.Minute","","\t// git revision parameter name","\trevisionParam = \"revision\"","","\t// git SHA-XX commit hash length","\tsha1Length   = 40","\tsha256Length = 64",")","","var _ framework.Resolver = (*Resolver)(nil)","var _ resolutionframework.ConfigWatcher = (*Resolver)(nil)","var _ cache.ImmutabilityChecker = (*Resolver)(nil)","var _ resolutionframework.TimedResolution = (*Resolver)(nil)","","// Resolver implements a framework.Resolver that can fetch files from git.","type Resolver struct {","\tkubeClient kubernetes.Interface","\tlogger     *zap.SugaredLogger","\tcache      *k8scache.LRUExpireCache","\tttl        time.Duration","","\t// Function for creating a SCM client so we can change it in tests.","\tclientFunc func(string, string, string, ...factory.ClientOptionFunc) (*scm.Client, error)","}","","// Initialize performs any setup required by the git resolver.","func (r *Resolver) Initialize(ctx context.Context) error {","\tr.kubeClient = kubeclient.Get(ctx)","\tr.logger = logging.FromContext(ctx).Named(gitResolverName)","\tif r.cache == nil {","\t\tr.cache = k8scache.NewLRUExpireCache(cacheSize)","\t}","\tif r.ttl == 0 {","\t\tr.ttl = ttl","\t}","\tif r.clientFunc == nil {","\t\tr.clientFunc = factory.NewClient","\t}","\treturn nil","}","","// GetName returns the string name that the git resolver should be","// associated with.","func (r *Resolver) GetName(_ context.Context) string {","\treturn gitResolverName","}","","// GetSelector returns the labels that resource requests are required to have for","// the gitresolver to process them.","func (r *Resolver) GetSelector(_ context.Context) map[string]string {","\treturn map[string]string{","\t\tresolutioncommon.LabelKeyResolverType: labelValueGitResolverType,","\t}","}","","// GetConfigName returns the name of the git resolver's configmap.","func (r *Resolver) GetConfigName(_ context.Context) string {","\treturn git.ConfigMapName","}","","// Validate returns an error if the given parameter map is not","// valid for a resource request targeting the gitresolver.","func (r *Resolver) Validate(ctx context.Context, req *v1beta1.ResolutionRequestSpec) error {","\treturn git.ValidateParams(ctx, req.Params)","}","","// IsImmutable implements ImmutabilityChecker.IsImmutable","// Returns true if the revision parameter is a commit SHA (40-character SHA-1 or 64-character SHA-256 hex string)","func (r *Resolver) IsImmutable(params []v1.Param) bool {","\tvar revision string","\tfor _, param := range params {","\t\tif param.Name == revisionParam {","\t\t\trevision = param.Value.StringVal","\t\t\tbreak","\t\t}","\t}","","\t// Check if length is valid (40 for SHA-1 or 64 for SHA-256)","\tif len(revision) != sha1Length \u0026\u0026 len(revision) != sha256Length {","\t\treturn false","\t}","","\t_, err := hex.DecodeString(revision)","\treturn err == nil","}","","// GetResolutionTimeout returns the configured timeout for git resolution requests.","func (r *Resolver) GetResolutionTimeout(ctx context.Context, defaultTimeout time.Duration, params map[string]string) (time.Duration, error) {","\tconf, err := git.GetScmConfigForParamConfigKey(ctx, params)","\tif err != nil {","\t\treturn time.Duration(0), err","\t}","\tif timeoutString := conf.Timeout; timeoutString != \"\" {","\t\ttimeout, err := time.ParseDuration(timeoutString)","\t\tif err != nil {","\t\t\treturn time.Duration(0), err","\t\t}","\t\treturn timeout, nil","\t}","\treturn defaultTimeout, nil","}","","// Resolve performs the work of fetching a file from git given a map of","// parameters.","func (r *Resolver) Resolve(ctx context.Context, req *v1beta1.ResolutionRequestSpec) (resolutionframework.ResolvedResource, error) {","\tif len(req.Params) == 0 {","\t\treturn nil, errors.New(\"no params\")","\t}","","\tif git.IsDisabled(ctx) {","\t\treturn nil, errors.New(disabledError)","\t}","","\tparams, err := git.PopulateDefaultParams(ctx, req.Params)","\tif err != nil {","\t\treturn nil, err","\t}","","\tif cache.ShouldUse(ctx, r, req.Params, labelValueGitResolverType) {","\t\treturn cache.GetFromCacheOrResolve(","\t\t\tctx,","\t\t\treq.Params,","\t\t\tlabelValueGitResolverType,","\t\t\tfunc() (resolutionframework.ResolvedResource, error) {","\t\t\t\treturn r.resolveViaGit(ctx, params)","\t\t\t},","\t\t)","\t}","\treturn r.resolveViaGit(ctx, params)","}","","func (r *Resolver) resolveViaGit(ctx context.Context, params map[string]string) (resolutionframework.ResolvedResource, error) {","\tg := \u0026git.GitResolver{","\t\tKubeClient: r.kubeClient,","\t\tLogger:     r.logger,","\t\tCache:      r.cache,","\t\tTTL:        r.ttl,","\t\tParams:     params,","\t}","","\tif params[git.UrlParam] != \"\" {","\t\treturn g.ResolveGitClone(ctx)","\t}","","\treturn g.ResolveAPIGit(ctx, r.clientFunc)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,1,1,2,0,0,0,0,2,2,2,0,0,0,2,2,2,2,2,0,0,2,2,2,0,0,0,2,2,2,0,0,0,2,2,2,2,2,2,0,0,0,0,2,2,2,0,2,2,0,0,0,2,2,2,1,1,2,2,2,1,1,2,0,2,0,0,0,0,2,2,1,1,0,2,2,2,0,2,2,1,1,0,2,2,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0]},{"id":235,"path":"pkg/remoteresolution/resolver/http/resolver.go","lines":["/*","Copyright 2024 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package http","","import (","\t\"context\"","\t\"errors\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/remoteresolution/resolver/framework\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/common\"","\tresolutionframework \"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/resolver/http\"","\t\"go.uber.org/zap\"","\t\"k8s.io/client-go/kubernetes\"","\tkubeclient \"knative.dev/pkg/client/injection/kube/client\"","\t\"knative.dev/pkg/logging\"",")","","const (","\t// LabelValueHttpResolverType is the value to use for the","\t// resolution.tekton.dev/type label on resource requests","\tLabelValueHttpResolverType = \"http\"","\tdisabledError              = \"cannot handle resolution request, enable-http-resolver feature flag not true\"","\thttpResolverName           = \"Http\"","\tconfigMapName              = \"http-resolver-config\"","\tdefaultHttpTimeoutValue    = \"1m\"","\tdefaultBasicAuthSecretKey  = \"password\" // default key in the HTTP password secret",")","","var _ framework.Resolver = (*Resolver)(nil)","var _ resolutionframework.ConfigWatcher = (*Resolver)(nil)","","// Resolver implements a framework.Resolver that can fetch files from an HTTP URL","type Resolver struct {","\tkubeClient kubernetes.Interface","\tlogger     *zap.SugaredLogger","}","","func (r *Resolver) Initialize(ctx context.Context) error {","\tr.kubeClient = kubeclient.Get(ctx)","\tr.logger = logging.FromContext(ctx)","\treturn nil","}","","// GetName returns a string name to refer to this resolver by.","func (r *Resolver) GetName(_ context.Context) string {","\treturn httpResolverName","}","","// GetConfigName returns the name of the http resolver's configmap.","func (r *Resolver) GetConfigName(_ context.Context) string {","\treturn configMapName","}","","// GetSelector returns a map of labels to match requests to this resolver.","func (r *Resolver) GetSelector(_ context.Context) map[string]string {","\treturn map[string]string{","\t\tcommon.LabelKeyResolverType: LabelValueHttpResolverType,","\t}","}","","// Validate ensures parameters from a request are as expected.","func (r *Resolver) Validate(ctx context.Context, req *v1beta1.ResolutionRequestSpec) error {","\treturn http.ValidateParams(ctx, req.Params)","}","","// Resolve uses the given params to resolve the requested file or resource.","func (r *Resolver) Resolve(ctx context.Context, req *v1beta1.ResolutionRequestSpec) (resolutionframework.ResolvedResource, error) {","\tif http.IsDisabled(ctx) {","\t\treturn nil, errors.New(disabledError)","\t}","","\tparams, err := http.PopulateDefaultParams(ctx, req.Params)","\tif err != nil {","\t\treturn nil, err","\t}","","\treturn http.FetchHttpResource(ctx, params, r.kubeClient, r.logger)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,0,0,2,2,2,0,0,2,2,2,2,0,2,2,2,2,0,2,0]},{"id":236,"path":"pkg/remoteresolution/resolver/hub/resolver.go","lines":["/*","Copyright 2024 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package hub","","import (","\t\"context\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/remoteresolution/resolver/framework\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/common\"","\tresolutionframework \"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/resolver/hub\"",")","","const (","\t// LabelValueHubResolverType is the value to use for the","\t// resolution.tekton.dev/type label on resource requests","\tLabelValueHubResolverType = \"hub\"","\thubResolverName           = \"Hub\"","\tconfigMapName             = \"hubresolver-config\"","","\t// ArtifactHubType is the value to use setting the type field to artifact","\tArtifactHubType = \"artifact\"","","\t// TektonHubType is the value to use setting the type field to tekton","\tTektonHubType = \"tekton\"",")","","var _ framework.Resolver = (*Resolver)(nil)","var _ resolutionframework.ConfigWatcher = (*Resolver)(nil)","","// Resolver implements a framework.Resolver that can fetch files from OCI bundles.","type Resolver struct {","\t// TektonHubURL is the URL for hub resolver with type tekton","\tTektonHubURL string","\t// ArtifactHubURL is the URL for hub resolver with type artifact","\tArtifactHubURL string","}","","// Initialize sets up any dependencies needed by the resolver. None atm.","func (r *Resolver) Initialize(_ context.Context) error {","\treturn nil","}","","// GetName returns a string name to refer to this resolver by.","func (r *Resolver) GetName(_ context.Context) string {","\treturn hubResolverName","}","","// GetConfigName returns the name of the bundle resolver's configmap.","func (r *Resolver) GetConfigName(_ context.Context) string {","\treturn configMapName","}","","// GetSelector returns a map of labels to match requests to this resolver.","func (r *Resolver) GetSelector(_ context.Context) map[string]string {","\treturn map[string]string{","\t\tcommon.LabelKeyResolverType: LabelValueHubResolverType,","\t}","}","","// Validate ensures parameters from a request are as expected.","func (r *Resolver) Validate(ctx context.Context, req *v1beta1.ResolutionRequestSpec) error {","\treturn hub.ValidateParams(ctx, req.Params, r.TektonHubURL)","}","","// Resolve uses the given params to resolve the requested file or resource.","func (r *Resolver) Resolve(ctx context.Context, req *v1beta1.ResolutionRequestSpec) (resolutionframework.ResolvedResource, error) {","\treturn hub.Resolve(ctx, req.Params, r.TektonHubURL, r.ArtifactHubURL)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,2,2,2,2,2,0,0,2,2,2,0,0,2,2,2]},{"id":237,"path":"pkg/remoteresolution/resource/crd_resource.go","lines":["/*","Copyright 2024 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resource","","import (","\t\"context\"","\t\"errors\"","","\trrclient \"github.com/tektoncd/pipeline/pkg/client/resolution/clientset/versioned\"","\trrlisters \"github.com/tektoncd/pipeline/pkg/client/resolution/listers/resolution/v1beta1\"","\tresolutioncommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\tresolutionresource \"github.com/tektoncd/pipeline/pkg/resolution/resource\"","\tapierrors \"k8s.io/apimachinery/pkg/api/errors\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"knative.dev/pkg/apis\"",")","","// CRDRequester implements the Requester interface using","// ResolutionRequest CRDs.","type CRDRequester struct {","\tclientset rrclient.Interface","\tlister    rrlisters.ResolutionRequestLister","}","","// NewCRDRequester returns an implementation of Requester that uses","// ResolutionRequest CRD objects to mediate between the caller who wants a","// resource (e.g. Tekton Pipelines) and the responder who can fetch","// it (e.g. the gitresolver)","func NewCRDRequester(clientset rrclient.Interface, lister rrlisters.ResolutionRequestLister) *CRDRequester {","\treturn \u0026CRDRequester{clientset, lister}","}","","var _ Requester = \u0026CRDRequester{}","","// Submit constructs a ResolutionRequest object and submits it to the","// kubernetes cluster, returning any errors experienced while doing so.","// If ResolutionRequest is succeeded then it returns the resolved data.","func (r *CRDRequester) Submit(ctx context.Context, resolver ResolverName, req Request) (ResolvedResource, error) {","\trr, _ := r.lister.ResolutionRequests(req.ResolverPayload().Namespace).Get(req.ResolverPayload().Name)","\tif rr == nil {","\t\tif err := r.createResolutionRequest(ctx, resolver, req); err != nil \u0026\u0026","\t\t\t// When the request reconciles frequently, the creation may fail","\t\t\t// because the list informer cache is not updated.","\t\t\t// If the request already exists then we can assume that is in progress.","\t\t\t// The next reconcile will handle it based on the actual situation.","\t\t\t!apierrors.IsAlreadyExists(err) {","\t\t\treturn nil, err","\t\t}","\t\treturn nil, resolutioncommon.ErrRequestInProgress","\t}","","\tif rr.Status.GetCondition(apis.ConditionSucceeded).IsUnknown() {","\t\t// TODO(sbwsg): This should be where an existing","\t\t// resource is given an additional owner reference so","\t\t// that it doesn't get deleted until the caller is done","\t\t// with it. Use appendOwnerReference and then submit","\t\t// update to ResolutionRequest.","\t\treturn nil, resolutioncommon.ErrRequestInProgress","\t}","","\tif rr.Status.GetCondition(apis.ConditionSucceeded).IsTrue() {","\t\treturn resolutionresource.CrdIntoResource(rr), nil","\t}","","\tmessage := rr.Status.GetCondition(apis.ConditionSucceeded).GetMessage()","\terr := resolutioncommon.NewError(resolutioncommon.ReasonResolutionFailed, errors.New(message))","\treturn nil, err","}","","func (r *CRDRequester) createResolutionRequest(ctx context.Context, resolver ResolverName, req Request) error {","\tvar owner metav1.OwnerReference","\tif ownedReq, ok := req.(OwnedRequest); ok {","\t\towner = ownedReq.OwnerRef()","\t}","\trr := resolutionresource.CreateResolutionRequest(ctx, resolver, req.ResolverPayload().Name, req.ResolverPayload().Namespace, req.ResolverPayload().ResolutionSpec.Params, owner)","\trr.Spec.URL = req.ResolverPayload().ResolutionSpec.URL","\t_, err := r.clientset.ResolutionV1beta1().ResolutionRequests(rr.Namespace).Create(ctx, rr, metav1.CreateOptions{})","\treturn err","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,1,1,2,0,0,2,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0]},{"id":238,"path":"pkg/remoteresolution/resource/request.go","lines":["/*","Copyright 2024 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resource","","import (","\t\"context\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"",")","","type BasicRequest struct {","\tresolverPayload ResolverPayload","}","","var _ Request = \u0026BasicRequest{}","","// NewRequest returns an instance of a BasicRequestV2 with the given resolverPayload.","func NewRequest(resolverPayload ResolverPayload) Request {","\treturn \u0026BasicRequest{resolverPayload}","}","","var _ Request = \u0026BasicRequest{}","","// Params are the map of parameters associated with this request","func (req *BasicRequest) ResolverPayload() ResolverPayload {","\treturn req.resolverPayload","}","","// Requester is the interface implemented by a type that knows how to","// submit requests for remote resources.","type Requester interface {","\t// Submit accepts the name of a resolver to submit a request to","\t// along with the request itself.","\tSubmit(ctx context.Context, name ResolverName, req Request) (ResolvedResource, error)","}","","// Request is implemented by any type that represents a single request","// for a remote resource. Implementing this interface gives the underlying","// type an opportunity to control properties such as whether the name of","// a request has particular properties, whether the request should be made","// to a specific namespace, and precisely which parameters should be included.","type Request interface {","\tResolverPayload() ResolverPayload","}","","// ResolverPayload is the struct which holds the payload to create","// the Resolution Request CRD.","type ResolverPayload struct {","\tName           string","\tNamespace      string","\tResolutionSpec *v1beta1.ResolutionRequestSpec","}","","// ResolutionRequester is the interface implemented by a type that knows how to","// submit requests for remote resources.","type ResolutionRequester interface {","\t// SubmitResolutionRequest accepts the name of a resolver to submit a request to","\t// along with the request itself.","\tSubmitResolutionRequest(ctx context.Context, name ResolverName, req RequestRemoteResource) (ResolvedResource, error)","}","","// RequestRemoteResource is implemented by any type that represents a single request","// for a remote resource. Implementing this interface gives the underlying","// type an opportunity to control properties such as whether the name of","// a request has particular properties, whether the request should be made","// to a specific namespace, and precisely which parameters should be included.","type RequestRemoteResource interface {","\tResolverPayload() ResolverPayload","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]},{"id":239,"path":"pkg/resolution/common/context.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package common","","import \"context\"","","// contextKey is a unique type to map common request-scoped","// context information.","type contextKey struct{}","","// requestNamespaceContextKey is the key stored in a context alongside","// the string namespace of a resolution request.","var requestNamespaceContextKey = contextKey{}","","// InjectRequestNamespace returns a new context with a request-scoped","// namespace. This value may only be set once per request; subsequent","// calls with the same context or a derived context will be ignored.","func InjectRequestNamespace(ctx context.Context, namespace string) context.Context {","\t// Once set don't allow the value to be overwritten.","\tif val := ctx.Value(requestNamespaceContextKey); val != nil {","\t\treturn ctx","\t}","\treturn context.WithValue(ctx, requestNamespaceContextKey, namespace)","}","","// RequestNamespace returns the namespace of the resolution request","// currently being processed or an empty string if the request somehow","// does not originate from a namespaced location.","func RequestNamespace(ctx context.Context) string {","\tif val := ctx.Value(requestNamespaceContextKey); val != nil {","\t\tif str, ok := val.(string); ok {","\t\t\treturn str","\t\t}","\t}","\treturn \"\"","}","","// requestNameContextKey is the key stored in a context alongside","// the string name of a resolution request.","var requestNameContextKey = contextKey{}","","// InjectRequestName returns a new context with a request-scoped","// name. This value may only be set once per request; subsequent","// calls with the same context or a derived context will be ignored.","func InjectRequestName(ctx context.Context, name string) context.Context {","\t// Once set don't allow the value to be overwritten.","\tif val := ctx.Value(requestNameContextKey); val != nil {","\t\treturn ctx","\t}","\treturn context.WithValue(ctx, requestNameContextKey, name)","}","","// RequestName returns the name of the resolution request","// currently being processed or an empty string if none were registered.","func RequestName(ctx context.Context) string {","\tif val := ctx.Value(requestNameContextKey); val != nil {","\t\tif str, ok := val.(string); ok {","\t\t\treturn str","\t\t}","\t}","\treturn \"\"","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,0,0,0,0,0,2,2,2,2,2,0,2,0,0,0,0,0,0,0,0,0,2,2,2,1,1,2,0,0,0,0,2,2,2,2,2,0,2,0]},{"id":240,"path":"pkg/resolution/common/errors.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package common","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","\t\"slices\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/reconciler/apiserver\"","\tapierrors \"k8s.io/apimachinery/pkg/api/errors\"",")","","// This error is defined in etcd at","// https://github.com/etcd-io/etcd/blob/5b226e0abf4100253c94bb71f47d6815877ed5a2/server/etcdserver/errors.go#L30","// TODO: If/when https://github.com/kubernetes/kubernetes/issues/106491 is addressed,","// we should stop relying on a hardcoded string.","var errEtcdLeaderChange = \"etcdserver: leader changed\"","","// Error embeds both a short machine-readable string reason for resolution","// problems alongside the original error generated during the resolution flow.","type Error struct {","\tReason   string","\tOriginal error","}","","var _ error = \u0026Error{}","","// Error returns the original error's message. This is intended to meet the error.Error interface.","func (e *Error) Error() string {","\treturn e.Original.Error()","}","","// Unwrap returns the original error without the Reason annotation. This is","// intended to support usage of errors.Is and errors.As with Errors.","func (e *Error) Unwrap() error {","\treturn e.Original","}","","// NewError returns a Error with the given reason and underlying","// original error.","func NewError(reason string, err error) *Error {","\treturn \u0026Error{","\t\tReason:   reason,","\t\tOriginal: err,","\t}","}","","// ErrRequestInProgress is a sentinel value to indicate that","// a resource request is still in progress.","var ErrRequestInProgress = NewError(\"RequestInProgress\", errors.New(\"Resource request is still in-progress\"))","","// InvalidResourceKeyError indicates that a string key given to the","// Reconcile function does not match the expected \"name\" or \"namespace/name\"","// format.","type InvalidResourceKeyError struct {","\tKey      string","\tOriginal error","}","","var _ error = \u0026InvalidResourceKeyError{}","","func (e *InvalidResourceKeyError) Error() string {","\treturn fmt.Sprintf(\"invalid resource key %q: %v\", e.Key, e.Original)","}","","func (e *InvalidResourceKeyError) Unwrap() error {","\treturn e.Original","}","","// InvalidRequestError is an error received when a","// resource request is badly formed for some reason: either the","// parameters don't match the resolver's expectations or there is some","// other structural issue.","type InvalidRequestError struct {","\tResolutionRequestKey string","\tMessage              string","}","","var _ error = \u0026InvalidRequestError{}","","func (e *InvalidRequestError) Error() string {","\treturn fmt.Sprintf(\"invalid resource request %q: %s\", e.ResolutionRequestKey, e.Message)","}","","// GetResourceError is an error received during what should","// otherwise have been a successful resource request.","type GetResourceError struct {","\tResolverName string","\tKey          string","\tOriginal     error","}","","var _ error = \u0026GetResourceError{}","","func (e *GetResourceError) Error() string {","\treturn fmt.Sprintf(\"error getting %q %q: %v\", e.ResolverName, e.Key, e.Original)","}","","func (e *GetResourceError) Unwrap() error {","\treturn e.Original","}","","// UpdatingRequestError is an error during any part of the update","// process for a ResolutionRequest, e.g. when attempting to patch the","// ResolutionRequest with resolved data.","type UpdatingRequestError struct {","\tResolutionRequestKey string","\tOriginal             error","}","","var _ error = \u0026UpdatingRequestError{}","","func (e *UpdatingRequestError) Error() string {","\treturn fmt.Sprintf(\"error updating resource request %q with data: %v\", e.ResolutionRequestKey, e.Original)","}","","func (e *UpdatingRequestError) Unwrap() error {","\treturn e.Original","}","","// ReasonError extracts the reason and underlying error","// embedded in a given error or returns some sane defaults","// if the error isn't a common.Error.","func ReasonError(err error) (string, error) {","\treason := ReasonResolutionFailed","\tresolutionError := err","","\tvar e *Error","\tif errors.As(err, \u0026e) {","\t\treason = e.Reason","\t\tresolutionError = e.Unwrap()","\t}","","\treturn reason, resolutionError","}","","// IsErrTransient returns true if an error returned by GetTask/GetStepAction is retryable.","func IsErrTransient(err error) bool {","\tswitch {","\tcase apierrors.IsConflict(err), apierrors.IsServerTimeout(err), apierrors.IsTimeout(err), apierrors.IsTooManyRequests(err), errors.Is(err, apiserver.ErrCouldntValidateObjectRetryable):","\t\treturn true","\tdefault:","\t\treturn slices.ContainsFunc([]string{errEtcdLeaderChange, context.DeadlineExceeded.Error()}, func(s string) bool {","\t\t\treturn strings.Contains(err.Error(), s)","\t\t})","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,2,2,2,0,0,0,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,1,1,1,0,0,0,0,1,1,1,1,1,1,1,1,1,0,1,0,0,0,1,1,1,1,1,1,1,1,0,0]},{"id":241,"path":"pkg/resolution/resolver/bundle/bundle.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package bundle","","import (","\t\"archive/tar\"","\t\"context\"","\t\"errors\"","\t\"fmt\"","\t\"io\"","\t\"strings\"","","\t\"github.com/google/go-containerregistry/pkg/authn\"","\t\"github.com/google/go-containerregistry/pkg/name\"","\tv1 \"github.com/google/go-containerregistry/pkg/v1\"","\t\"github.com/google/go-containerregistry/pkg/v1/remote\"","\tpipelinev1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"",")","","const (","\t// MaximumBundleObjects defines the maximum number of objects in a bundle","\tMaximumBundleObjects = 20",")","","// RequestOptions are the options used to request a resource from","// a remote bundle.","type RequestOptions struct {","\tServiceAccount  string","\tImagePullSecret string","\tBundle          string","\tEntryName       string","\tKind            string","\tCache           string","}","","// ResolvedResource wraps the content of a matched entry in a bundle.","type ResolvedResource struct {","\tdata        []byte","\tannotations map[string]string","\tsource      *pipelinev1.RefSource","}","","var _ framework.ResolvedResource = \u0026ResolvedResource{}","","// Data returns the bytes of the resource fetched from the bundle.","func (br *ResolvedResource) Data() []byte {","\treturn br.data","}","","// Annotations returns the annotations from the bundle that are relevant","// to resolution.","func (br *ResolvedResource) Annotations() map[string]string {","\treturn br.annotations","}","","// RefSource is the source reference of the remote data that records where the remote","// file came from including the url, digest and the entrypoint.","func (br *ResolvedResource) RefSource() *pipelinev1.RefSource {","\treturn br.source","}","","// GetEntry accepts a keychain and options for the request and returns","// either a successfully resolved bundle entry or an error.","func GetEntry(ctx context.Context, keychain authn.Keychain, opts RequestOptions) (*ResolvedResource, error) {","\turi, img, err := retrieveImage(ctx, keychain, opts.Bundle)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"cannot retrieve the oci image: %w\", err)","\t}","","\th, err := img.Digest()","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"cannot get the oci digest: %w\", err)","\t}","","\tmanifest, err := img.Manifest()","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"could not parse image manifest: %w\", err)","\t}","","\tif err := checkImageCompliance(manifest); err != nil {","\t\treturn nil, fmt.Errorf(\"invalid tekton bundle %s, error: %w\", opts.Bundle, err)","\t}","","\tlayers, err := img.Layers()","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"could not read image layers: %w\", err)","\t}","","\tlayerMap := map[string]v1.Layer{}","\tfor _, l := range layers {","\t\tdigest, err := l.Digest()","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed to find digest for layer: %w\", err)","\t\t}","\t\tlayerMap[digest.String()] = l","\t}","","\tfor idx, l := range manifest.Layers {","\t\tlKind := l.Annotations[BundleAnnotationKind]","\t\tlName := l.Annotations[BundleAnnotationName]","","\t\tif strings.ToLower(opts.Kind) == strings.ToLower(lKind) \u0026\u0026 opts.EntryName == lName {","\t\t\tobj, err := readTarLayer(layerMap[l.Digest.String()])","\t\t\tif err != nil {","\t\t\t\t// This could still be a raw layer so try to read it as that instead.","\t\t\t\tobj, _ = readRawLayer(layers[idx])","\t\t\t}","\t\t\treturn \u0026ResolvedResource{","\t\t\t\tdata: obj,","\t\t\t\tannotations: map[string]string{","\t\t\t\t\tResolverAnnotationKind:       lKind,","\t\t\t\t\tResolverAnnotationName:       lName,","\t\t\t\t\tResolverAnnotationAPIVersion: l.Annotations[BundleAnnotationAPIVersion],","\t\t\t\t},","\t\t\t\tsource: \u0026pipelinev1.RefSource{","\t\t\t\t\tURI: uri,","\t\t\t\t\tDigest: map[string]string{","\t\t\t\t\t\th.Algorithm: h.Hex,","\t\t\t\t\t},","\t\t\t\t\tEntryPoint: opts.EntryName,","\t\t\t\t},","\t\t\t}, nil","\t\t}","\t}","\treturn nil, fmt.Errorf(\"could not find object in image with kind: %s and name: %s\", opts.Kind, opts.EntryName)","}","","// retrieveImage will fetch the image's url, contents and manifest.","func retrieveImage(ctx context.Context, keychain authn.Keychain, ref string) (string, v1.Image, error) {","\timgRef, err := name.ParseReference(ref)","\tif err != nil {","\t\treturn \"\", nil, fmt.Errorf(\"%s is an unparseable image reference: %w\", ref, err)","\t}","\tcustomRetryBackoff, err := GetBundleResolverBackoff(ctx)","\tif err == nil {","\t\timg, err := remote.Image(imgRef, remote.WithAuthFromKeychain(keychain), remote.WithContext(ctx),","\t\t\tremote.WithRetryBackoff(customRetryBackoff))","","\t\treturn imgRef.Context().Name(), img, err","\t} else {","\t\timg, err := remote.Image(imgRef, remote.WithAuthFromKeychain(keychain), remote.WithContext(ctx))","","\t\treturn imgRef.Context().Name(), img, err","\t}","}","","// checkImageCompliance will perform common checks to ensure the Tekton Bundle is compliant to our spec.","func checkImageCompliance(manifest *v1.Manifest) error {","\t// Check the manifest's layers to ensure there are a maximum of 10.","\tif len(manifest.Layers) \u003e MaximumBundleObjects {","\t\treturn fmt.Errorf(\"contained more than the maximum %d allow objects\", MaximumBundleObjects)","\t}","","\t// Ensure each layer complies to the spec.","\tfor i, l := range manifest.Layers {","\t\tif _, ok := l.Annotations[BundleAnnotationAPIVersion]; !ok {","\t\t\treturn fmt.Errorf(\"the layer %v does not contain a %s annotation\", i, BundleAnnotationAPIVersion)","\t\t}","","\t\tif _, ok := l.Annotations[BundleAnnotationName]; !ok {","\t\t\treturn fmt.Errorf(\"the layer %v does not contain a %s annotation\", i, BundleAnnotationName)","\t\t}","","\t\tkind, ok := l.Annotations[BundleAnnotationKind]","\t\tif !ok {","\t\t\treturn fmt.Errorf(\"the layer %v does not contain a %s annotation\", i, BundleAnnotationKind)","\t\t}","\t\tif strings.TrimSuffix(strings.ToLower(kind), \"s\") != kind {","\t\t\treturn fmt.Errorf(\"the layer %v the annotation %s must be lowercased and singular, found %s\", i, BundleAnnotationKind, kind)","\t\t}","\t}","","\treturn nil","}","","// Utility function to read out the contents of an image layer, assumed to be a tarball, as bytes.","func readTarLayer(layer v1.Layer) ([]byte, error) {","\trc, err := layer.Uncompressed()","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"failed to read image layer: %w\", err)","\t}","\tdefer func() {","\t\t_ = rc.Close()","\t}()","","\t// If the user bundled this up as a tar file then we need to untar it.","\ttreader := tar.NewReader(rc)","\theader, err := treader.Next()","\tif err != nil {","\t\treturn nil, errors.New(\"layer is not a tarball\")","\t}","","\tcontents := make([]byte, header.Size)","\tif _, err := io.ReadFull(treader, contents); err != nil \u0026\u0026 err != io.EOF {","\t\t// We only allow 1 resource per layer so this tar bundle should have one and only one file.","\t\treturn nil, fmt.Errorf(\"failed to read tar bundle: %w\", err)","\t}","","\treturn contents, nil","}","","// Utility function to read out the contents of an image layer, assumed to be raw bytes, as bytes.","func readRawLayer(layer v1.Layer) ([]byte, error) {","\trc, err := layer.Uncompressed()","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"failed to read image layer: %w\", err)","\t}","\tdefer func() {","\t\t_ = rc.Close()","\t}()","","\tcontents, err := io.ReadAll(rc)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"could not read contents of image layer: %w\", err)","\t}","","\treturn contents, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,2,2,2,0,0,0,2,2,2,0,0,0,2,2,2,1,1,0,2,2,1,1,0,2,2,1,1,0,2,2,2,0,2,2,1,1,0,2,2,2,2,1,1,2,0,0,2,2,2,2,2,2,2,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,1,0,0,0,2,2,2,1,1,2,2,2,2,2,2,2,1,1,1,1,0,0,0,2,2,2,2,2,0,0,2,2,2,2,0,2,2,2,0,2,2,2,2,2,2,2,0,0,2,0,0,0,2,2,2,1,1,2,2,2,0,0,2,2,2,1,1,0,2,2,1,1,1,0,2,0,0,0,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,0]},{"id":242,"path":"pkg/resolution/resolver/bundle/config.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package bundle","","import (","\t\"context\"","\t\"fmt\"","\t\"strconv\"","\t\"time\"","","\t\"github.com/google/go-containerregistry/pkg/v1/remote\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"",")","","const (","\t// ConfigServiceAccount is the configuration field name for controlling","\t// the Service Account name to use for bundle requests.","\tConfigServiceAccount = \"default-service-account\"","\t// ConfigKind is the configuration field name for controlling","\t// what the layer name in the bundle image is.","\tConfigKind = \"default-kind\"","\t// ConfigTimeoutKey is the configuration field name for controlling","\t// the maximum duration of a resolution request for a file from registry.","\tConfigTimeoutKey = \"fetch-timeout\"","\t// ConfigBackoffDuration is the configuration field name for controlling","\t// the initial duration of a backoff when a bundle resolution fails","\tConfigBackoffDuration  = \"backoff-duration\"","\tDefaultBackoffDuration = 2.0 * time.Second","\t// ConfigBackoffFactor is the configuration field name for controlling","\t// the factor by which successive backoffs will increase when a bundle","\t// resolution fails","\tConfigBackoffFactor  = \"backoff-factor\"","\tDefaultBackoffFactor = 2.0","\t// ConfigBackoffJitter is the configuration field name for controlling","\t// the randomness applied to backoff durations when a bundle resolution fails","\tConfigBackoffJitter  = \"backoff-jitter\"","\tDefaultBackoffJitter = 0.1","\t// ConfigBackoffSteps is the configuration field name for controlling","\t// the number of attempted backoffs to retry when a bundle resolution fails","\tConfigBackoffSteps  = \"backoff-steps\"","\tDefaultBackoffSteps = 2","\t// ConfigBackoffCap is the configuration field name for controlling","\t// the maximum duration to try when backing off","\tConfigBackoffCap  = \"backoff-cap\"","\tDefaultBackoffCap = 10 * time.Second",")","","// GetBundleResolverBackoff returns a remote.Backoff to","// be passed when resolving remote images. This can be configured with the","// backoff-duration, backoff-factor, backoff-jitter, backoff-steps, and backoff-cap","// fields in the bundle-resolver-config ConfigMap.","func GetBundleResolverBackoff(ctx context.Context) (remote.Backoff, error) {","\tconf := framework.GetResolverConfigFromContext(ctx)","","\tcustomRetryBackoff := remote.Backoff{","\t\tDuration: DefaultBackoffDuration,","\t\tFactor:   DefaultBackoffFactor,","\t\tJitter:   DefaultBackoffJitter,","\t\tSteps:    DefaultBackoffSteps,","\t\tCap:      DefaultBackoffCap,","\t}","\tif v, ok := conf[ConfigBackoffDuration]; ok {","\t\tvar err error","\t\tduration, err := time.ParseDuration(v)","\t\tif err != nil {","\t\t\treturn customRetryBackoff, fmt.Errorf(\"error parsing backoff duration value %s: %w\", v, err)","\t\t}","\t\tcustomRetryBackoff.Duration = duration","\t}","\tif v, ok := conf[ConfigBackoffFactor]; ok {","\t\tvar err error","\t\tfactor, err := strconv.ParseFloat(v, 64)","\t\tif err != nil {","\t\t\treturn customRetryBackoff, fmt.Errorf(\"error parsing backoff factor value %s: %w\", v, err)","\t\t}","\t\tcustomRetryBackoff.Factor = factor","\t}","\tif v, ok := conf[ConfigBackoffJitter]; ok {","\t\tvar err error","\t\tjitter, err := strconv.ParseFloat(v, 64)","\t\tif err != nil {","\t\t\treturn customRetryBackoff, fmt.Errorf(\"error parsing backoff jitter value %s: %w\", v, err)","\t\t}","\t\tcustomRetryBackoff.Jitter = jitter","\t}","\tif v, ok := conf[ConfigBackoffSteps]; ok {","\t\tvar err error","\t\tsteps, err := strconv.Atoi(v)","\t\tif err != nil {","\t\t\treturn customRetryBackoff, fmt.Errorf(\"error parsing backoff steps value %s: %w\", v, err)","\t\t}","\t\tcustomRetryBackoff.Steps = steps","\t}","\tif v, ok := conf[ConfigBackoffCap]; ok {","\t\tvar err error","\t\tcap, err := time.ParseDuration(v)","\t\tif err != nil {","\t\t\treturn customRetryBackoff, fmt.Errorf(\"error parsing backoff steps value %s: %w\", v, err)","\t\t}","\t\tcustomRetryBackoff.Cap = cap","\t}","","\treturn customRetryBackoff, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,0,2,2,2,2,1,1,2,0,2,2,2,2,1,1,2,0,2,2,2,2,1,1,2,0,2,2,2,2,1,1,2,0,0,2,0]},{"id":243,"path":"pkg/resolution/resolver/bundle/params.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package bundle","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","","\t\"github.com/google/go-containerregistry/pkg/name\"","\tpipelinev1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/resource\"",")","","// ParamServiceAccount is the parameter defining what service","// account name to use for bundle requests.","const ParamServiceAccount = \"serviceAccount\"","","// ParamImagePullSecret is the parameter defining what secret","// name to use for bundle requests.","const ParamImagePullSecret = \"secret\"","","// ParamBundle is the parameter defining what the bundle image url is.","const ParamBundle = \"bundle\"","","// ParamName is the parameter defining what the layer name in the bundle","// image is.","const ParamName = resource.ParamName","","// ParamKind is the parameter defining what the layer kind in the bundle","// image is.","const ParamKind = \"kind\"","","// paramCache is the parameter defining whether to use cache for bundle requests.","const paramCache = \"cache\"","","// OptionsFromParams parses the params from a resolution request and","// converts them into options to pass as part of a bundle request.","func OptionsFromParams(ctx context.Context, params []pipelinev1.Param) (RequestOptions, error) {","\topts := RequestOptions{}","\tconf := framework.GetResolverConfigFromContext(ctx)","","\tparamsMap := make(map[string]pipelinev1.ParamValue)","\tfor _, p := range params {","\t\tparamsMap[p.Name] = p.Value","\t}","","\tsaVal, ok := paramsMap[ParamServiceAccount]","\tsa := \"\"","\tif !ok || saVal.StringVal == \"\" {","\t\tif saString, ok := conf[ConfigServiceAccount]; ok {","\t\t\tsa = saString","\t\t} else {","\t\t\treturn opts, errors.New(\"default Service Account was not set during installation of the bundle resolver\")","\t\t}","\t} else {","\t\tsa = saVal.StringVal","\t}","","\tbundleVal, ok := paramsMap[ParamBundle]","\tif !ok || bundleVal.StringVal == \"\" {","\t\treturn opts, fmt.Errorf(\"parameter %q required\", ParamBundle)","\t}","\tif _, err := name.ParseReference(bundleVal.StringVal); err != nil {","\t\treturn opts, fmt.Errorf(\"invalid bundle reference: %w\", err)","\t}","","\tnameVal, ok := paramsMap[ParamName]","\tif !ok || nameVal.StringVal == \"\" {","\t\treturn opts, fmt.Errorf(\"parameter %q required\", ParamName)","\t}","","\tkindVal, ok := paramsMap[ParamKind]","\tkind := \"\"","\tif !ok || kindVal.StringVal == \"\" {","\t\tif kindString, ok := conf[ConfigKind]; ok {","\t\t\tkind = kindString","\t\t} else {","\t\t\treturn opts, errors.New(\"default resource Kind was not set during installation of the bundle resolver\")","\t\t}","\t} else {","\t\tkind = kindVal.StringVal","\t}","","\topts.ServiceAccount = sa","\topts.ImagePullSecret = paramsMap[ParamImagePullSecret].StringVal","\topts.Bundle = bundleVal.StringVal","\topts.EntryName = nameVal.StringVal","\topts.Kind = kind","","\t// Use default cache mode since validation happens centrally in framework","\tif cacheVal, ok := paramsMap[paramCache]; ok \u0026\u0026 cacheVal.StringVal != \"\" {","\t\topts.Cache = cacheVal.StringVal","\t} else {","\t\topts.Cache = \"auto\"","\t}","","\treturn opts, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,0,2,2,1,1,2,1,1,0,2,2,1,1,0,2,2,2,2,2,2,1,1,2,2,2,0,2,2,2,2,2,2,2,2,1,2,2,2,0,2,0]},{"id":244,"path":"pkg/resolution/resolver/bundle/resolver.go","lines":["/*"," Copyright 2022 The Tekton Authors",""," Licensed under the Apache License, Version 2.0 (the \"License\");"," you may not use this file except in compliance with the License."," You may obtain a copy of the License at","","     http://www.apache.org/licenses/LICENSE-2.0",""," Unless required by applicable law or agreed to in writing, software"," distributed under the License is distributed on an \"AS IS\" BASIS,"," WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied."," See the License for the specific language governing permissions and"," limitations under the License.","*/","","package bundle","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","\t\"time\"","","\t\"github.com/google/go-containerregistry/pkg/authn/k8schain\"","\tresolverconfig \"github.com/tektoncd/pipeline/pkg/apis/config/resolver\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\tcommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"","\t\"k8s.io/client-go/kubernetes\"","\t\"knative.dev/pkg/client/injection/kube/client\"",")","","const (","\tdisabledError = \"cannot handle resolution request, enable-bundles-resolver feature flag not true\"","","\t// LabelValueBundleResolverType is the value to use for the","\t// resolution.tekton.dev/type label on resource requests","\tLabelValueBundleResolverType string = \"bundles\"","","\t// BundleResolverName is the name that the bundle resolver should be associated with.","\tBundleResolverName = \"bundleresolver\"","","\t// ConfigMapName is the bundle resolver's config map","\tConfigMapName = \"bundleresolver-config\"",")","","var _ framework.ConfigWatcher = \u0026Resolver{}","","// GetConfigName returns the name of the git resolver's configmap.","func (r *Resolver) GetConfigName(context.Context) string {","\treturn ConfigMapName","}","","var _ framework.TimedResolution = \u0026Resolver{}","","// Resolver implements a framework.Resolver that can fetch files from OCI bundles.","//","// Deprecated: Use [github.com/tektoncd/pipeline/pkg/remoteresolution/resolver/bundle.Resolver] instead.","type Resolver struct {","\tkubeClientSet kubernetes.Interface","}","","// Initialize sets up any dependencies needed by the Resolver. None atm.","func (r *Resolver) Initialize(ctx context.Context) error {","\tr.kubeClientSet = client.Get(ctx)","\treturn nil","}","","// GetName returns a string name to refer to this Resolver by.","func (r *Resolver) GetName(context.Context) string {","\treturn BundleResolverName","}","","// GetSelector returns a map of labels to match requests to this Resolver.","func (r *Resolver) GetSelector(context.Context) map[string]string {","\treturn map[string]string{","\t\tcommon.LabelKeyResolverType: LabelValueBundleResolverType,","\t}","}","","// ValidateParams ensures parameters from a request are as expected.","func (r *Resolver) ValidateParams(ctx context.Context, params []v1.Param) error {","\treturn ValidateParams(ctx, params)","}","","// Resolve uses the given params to resolve the requested file or resource.","func (r *Resolver) Resolve(ctx context.Context, params []v1.Param) (framework.ResolvedResource, error) {","\treturn ResolveRequest(ctx, r.kubeClientSet, \u0026v1beta1.ResolutionRequestSpec{Params: params})","}","","// Resolve uses the given params to resolve the requested file or resource.","func ResolveRequest(ctx context.Context, kubeClientSet kubernetes.Interface, req *v1beta1.ResolutionRequestSpec) (framework.ResolvedResource, error) {","\tif isDisabled(ctx) {","\t\treturn nil, errors.New(disabledError)","\t}","\topts, err := OptionsFromParams(ctx, req.Params)","\tif err != nil {","\t\treturn nil, err","\t}","\tvar imagePullSecrets []string","\tif opts.ImagePullSecret != \"\" {","\t\timagePullSecrets = append(imagePullSecrets, opts.ImagePullSecret)","\t}","\tnamespace := common.RequestNamespace(ctx)","\tkc, err := k8schain.New(ctx, kubeClientSet, k8schain.Options{","\t\tNamespace:          namespace,","\t\tServiceAccountName: opts.ServiceAccount,","\t\tImagePullSecrets:   imagePullSecrets,","\t})","\tif err != nil {","\t\treturn nil, err","\t}","\treturn GetEntry(ctx, kc, opts)","}","","func ValidateParams(ctx context.Context, params []v1.Param) error {","\tif isDisabled(ctx) {","\t\treturn errors.New(disabledError)","\t}","\tif _, err := OptionsFromParams(ctx, params); err != nil {","\t\treturn err","\t}","\treturn nil","}","","func isDisabled(ctx context.Context) bool {","\tcfg := resolverconfig.FromContextOrDefaults(ctx)","\treturn !cfg.FeatureFlags.EnableBundleResolver","}","","// GetResolutionTimeout returns a time.Duration for the amount of time a","// single bundle fetch may take. This can be configured with the","// fetch-timeout field in the bundle-resolver-config ConfigMap.","func (r *Resolver) GetResolutionTimeout(ctx context.Context, defaultTimeout time.Duration, params map[string]string) (time.Duration, error) {","\tconf := framework.GetResolverConfigFromContext(ctx)","","\ttimeout := defaultTimeout","\tif v, ok := conf[ConfigTimeoutKey]; ok {","\t\tvar err error","\t\ttimeout, err = time.ParseDuration(v)","\t\tif err != nil {","\t\t\treturn time.Duration(0), fmt.Errorf(\"error parsing bundle timeout value %s: %w\", v, err)","\t\t}","\t}","","\treturn timeout, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,1,1,0,0,2,0]},{"id":245,"path":"pkg/resolution/resolver/cluster/resolver.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package cluster","","import (","\t\"context\"","\t\"encoding/hex\"","\t\"errors\"","\t\"fmt\"","\t\"slices\"","\t\"strings\"","","\tresolverconfig \"github.com/tektoncd/pipeline/pkg/apis/config/resolver\"","\tpipelinev1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tpipelinev1beta1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\tclientset \"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"","\tpipelineclient \"github.com/tektoncd/pipeline/pkg/client/injection/client\"","\tcommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"knative.dev/pkg/logging\"","\t\"sigs.k8s.io/yaml\"",")","","const (","\tdisabledError = \"cannot handle resolution request, enable-cluster-resolver feature flag not true\"","","\t// LabelValueClusterResolverType is the value to use for the","\t// resolution.tekton.dev/type label on resource requests","\tLabelValueClusterResolverType string = \"cluster\"","","\t// ClusterResolverName is the name that the cluster resolver should be","\t// associated with","\tClusterResolverName string = \"Cluster\"","","\tConfigMapName = \"cluster-resolver-config\"",")","","var supportedKinds = []string{\"task\", \"pipeline\", \"stepaction\"}","","var _ framework.Resolver = (*Resolver)(nil)","var _ framework.ConfigWatcher = (*Resolver)(nil)","","// Resolver implements a framework.Resolver that can fetch resources from other namespaces.","//","// Deprecated: Use [github.com/tektoncd/pipeline/pkg/remoteresolution/resolver/cluster.Resolver] instead.","type Resolver struct {","\tpipelineClientSet clientset.Interface","}","","// Initialize performs any setup required by the cluster resolver.","func (r *Resolver) Initialize(ctx context.Context) error {","\tr.pipelineClientSet = pipelineclient.Get(ctx)","\treturn nil","}","","// GetName returns the string name that the cluster resolver should be","// associated with.","func (r *Resolver) GetName(_ context.Context) string {","\treturn ClusterResolverName","}","","// GetSelector returns the labels that resource requests are required to have for","// the cluster resolver to process them.","func (r *Resolver) GetSelector(_ context.Context) map[string]string {","\treturn map[string]string{","\t\tcommon.LabelKeyResolverType: LabelValueClusterResolverType,","\t}","}","","// GetConfigName returns the name of the cluster resolver's configmap.","func (r *Resolver) GetConfigName(context.Context) string {","\treturn ConfigMapName","}","","// ValidateParams returns an error if the given parameter map is not","// valid for a resource request targeting the cluster resolver.","func (r *Resolver) ValidateParams(ctx context.Context, params []pipelinev1.Param) error {","\treturn ValidateParams(ctx, params)","}","","// Resolve performs the work of fetching a resource from a namespace with the given","// parameters.","func (r *Resolver) Resolve(ctx context.Context, origParams []pipelinev1.Param) (framework.ResolvedResource, error) {","\treturn ResolveFromParams(ctx, origParams, r.pipelineClientSet)","}","","func ResolveFromParams(ctx context.Context, origParams []pipelinev1.Param, pipelineClientSet clientset.Interface) (framework.ResolvedResource, error) {","\tif isDisabled(ctx) {","\t\treturn nil, errors.New(disabledError)","\t}","","\tlogger := logging.FromContext(ctx)","","\tparams, err := populateParamsWithDefaults(ctx, origParams)","\tif err != nil {","\t\tlogger.Infof(\"cluster resolver parameter(s) invalid: %v\", err)","\t\treturn nil, err","\t}","","\tvar data []byte","\tvar spec []byte","\tvar sha256Checksum []byte","\tvar uid string","\tgroupVersion := pipelinev1.SchemeGroupVersion.String()","","\tswitch params[KindParam] {","\tcase \"stepaction\":","\t\tstepaction, err := pipelineClientSet.TektonV1beta1().StepActions(params[NamespaceParam]).Get(ctx, params[NameParam], metav1.GetOptions{})","\t\tif err != nil {","\t\t\tlogger.Infof(\"failed to load stepaction %s from namespace %s: %v\", params[NameParam], params[NamespaceParam], err)","\t\t\treturn nil, err","\t\t}","\t\tuid, data, sha256Checksum, spec, err = fetchStepaction(ctx, pipelinev1beta1.SchemeGroupVersion.String(), stepaction, params)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\tcase \"task\":","\t\ttask, err := pipelineClientSet.TektonV1().Tasks(params[NamespaceParam]).Get(ctx, params[NameParam], metav1.GetOptions{})","\t\tif err != nil {","\t\t\tlogger.Infof(\"failed to load task %s from namespace %s: %v\", params[NameParam], params[NamespaceParam], err)","\t\t\treturn nil, err","\t\t}","\t\tuid, data, sha256Checksum, spec, err = fetchTask(ctx, groupVersion, task, params)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\tcase \"pipeline\":","\t\tpipeline, err := pipelineClientSet.TektonV1().Pipelines(params[NamespaceParam]).Get(ctx, params[NameParam], metav1.GetOptions{})","\t\tif err != nil {","\t\t\tlogger.Infof(\"failed to load pipeline %s from namespace %s: %v\", params[NameParam], params[NamespaceParam], err)","\t\t\treturn nil, err","\t\t}","\t\tuid, data, sha256Checksum, spec, err = fetchPipeline(ctx, groupVersion, pipeline, params)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\tdefault:","\t\tlogger.Infof(\"unknown or invalid resource kind %s\", params[KindParam])","\t\treturn nil, fmt.Errorf(\"unknown or invalid resource kind %s\", params[KindParam])","\t}","","\treturn \u0026ResolvedClusterResource{","\t\tContent:    data,","\t\tSpec:       spec,","\t\tName:       params[NameParam],","\t\tNamespace:  params[NamespaceParam],","\t\tIdentifier: fmt.Sprintf(\"/apis/%s/namespaces/%s/%s/%s@%s\", groupVersion, params[NamespaceParam], params[KindParam], params[NameParam], uid),","\t\tChecksum:   sha256Checksum,","\t}, nil","}","","// ResolvedClusterResource implements framework.ResolvedResource and returns","// the resolved file []byte data and an annotation map for any metadata.","type ResolvedClusterResource struct {","\t// Content is the actual resolved resource data.","\tContent []byte","\t// Spec is the data in the resolved task/pipeline CRD spec.","\tSpec []byte","\t// Name is the resolved resource name in the cluster","\tName string","\t// Namespace is the namespace in the cluster under which the resolved resource was created.","\tNamespace string","\t// Identifier is the unique identifier for the resource in the cluster.","\t// It is in the format of \u003cresource uri\u003e@\u003cuid\u003e.","\t// Resource URI is the namespace-scoped uri i.e. /apis/GROUP/VERSION/namespaces/NAMESPACE/RESOURCETYPE/NAME.","\t// https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-uris","\tIdentifier string","\t// Sha256 Checksum of the cluster resource","\tChecksum []byte","}","","var _ framework.ResolvedResource = \u0026ResolvedClusterResource{}","","// Data returns the bytes of the file resolved from git.","func (r *ResolvedClusterResource) Data() []byte {","\treturn r.Content","}","","// Annotations returns the metadata that accompanies the resource fetched from the cluster.","func (r *ResolvedClusterResource) Annotations() map[string]string {","\treturn map[string]string{","\t\tResourceNameAnnotation:      r.Name,","\t\tResourceNamespaceAnnotation: r.Namespace,","\t}","}","","// RefSource is the source reference of the remote data that records where the remote","// file came from including the url, digest and the entrypoint.","func (r ResolvedClusterResource) RefSource() *pipelinev1.RefSource {","\treturn \u0026pipelinev1.RefSource{","\t\tURI: r.Identifier,","\t\tDigest: map[string]string{","\t\t\t\"sha256\": hex.EncodeToString(r.Checksum),","\t\t},","\t}","}","","func populateParamsWithDefaults(ctx context.Context, origParams []pipelinev1.Param) (map[string]string, error) {","\tconf := framework.GetResolverConfigFromContext(ctx)","","\tparamsMap := make(map[string]pipelinev1.ParamValue)","\tfor _, p := range origParams {","\t\tparamsMap[p.Name] = p.Value","\t}","","\tparams := make(map[string]string)","","\tvar missingParams []string","","\tif pKind, ok := paramsMap[KindParam]; !ok || pKind.StringVal == \"\" {","\t\tif kindVal, ok := conf[DefaultKindKey]; !ok {","\t\t\tmissingParams = append(missingParams, KindParam)","\t\t} else {","\t\t\tparams[KindParam] = kindVal","\t\t}","\t} else {","\t\tparams[KindParam] = pKind.StringVal","\t}","\tif kindVal, ok := params[KindParam]; ok \u0026\u0026 !isSupportedKind(kindVal) {","\t\treturn nil, fmt.Errorf(\"unknown or unsupported resource kind '%s'\", kindVal)","\t}","","\tif pName, ok := paramsMap[NameParam]; !ok || pName.StringVal == \"\" {","\t\tmissingParams = append(missingParams, NameParam)","\t} else {","\t\tparams[NameParam] = pName.StringVal","\t}","","\tif pNS, ok := paramsMap[NamespaceParam]; !ok || pNS.StringVal == \"\" {","\t\tif nsVal, ok := conf[DefaultNamespaceKey]; !ok {","\t\t\tmissingParams = append(missingParams, NamespaceParam)","\t\t} else {","\t\t\tparams[NamespaceParam] = nsVal","\t\t}","\t} else {","\t\tparams[NamespaceParam] = pNS.StringVal","\t}","","\tif len(missingParams) \u003e 0 {","\t\treturn nil, fmt.Errorf(\"missing required cluster resolver params: %s\", strings.Join(missingParams, \", \"))","\t}","","\tif conf[BlockedNamespacesKey] != \"\" \u0026\u0026 isInCommaSeparatedList(params[NamespaceParam], conf[BlockedNamespacesKey]) {","\t\treturn nil, fmt.Errorf(\"access to specified namespace %s is blocked\", params[NamespaceParam])","\t}","","\tif conf[AllowedNamespacesKey] != \"\" \u0026\u0026 isInCommaSeparatedList(params[NamespaceParam], conf[AllowedNamespacesKey]) {","\t\treturn params, nil","\t}","","\tif conf[BlockedNamespacesKey] != \"\" \u0026\u0026 conf[BlockedNamespacesKey] == \"*\" {","\t\treturn nil, errors.New(\"only explicit allowed access to namespaces is allowed\")","\t}","","\tif conf[AllowedNamespacesKey] != \"\" \u0026\u0026 !isInCommaSeparatedList(params[NamespaceParam], conf[AllowedNamespacesKey]) {","\t\treturn nil, fmt.Errorf(\"access to specified namespace %s is not allowed\", params[NamespaceParam])","\t}","","\treturn params, nil","}","","func isInCommaSeparatedList(checkVal string, commaList string) bool {","\tfor _, s := range strings.Split(commaList, \",\") {","\t\tif s == checkVal {","\t\t\treturn true","\t\t}","\t}","\treturn false","}","","func isDisabled(ctx context.Context) bool {","\tcfg := resolverconfig.FromContextOrDefaults(ctx)","\treturn !cfg.FeatureFlags.EnableClusterResolver","}","","func ValidateParams(ctx context.Context, params []pipelinev1.Param) error {","\tif isDisabled(ctx) {","\t\treturn errors.New(disabledError)","\t}","","\t_, err := populateParamsWithDefaults(ctx, params)","\treturn err","}","","func fetchStepaction(ctx context.Context, groupVersion string, stepaction *pipelinev1beta1.StepAction, params map[string]string) (string, []byte, []byte, []byte, error) {","\tlogger := logging.FromContext(ctx)","\tuid := string(stepaction.UID)","\tstepaction.Kind = \"StepAction\"","\tstepaction.APIVersion = groupVersion","\tdata, err := yaml.Marshal(stepaction)","\tif err != nil {","\t\tlogger.Infof(\"failed to marshal stepaction %s from namespace %s: %v\", params[NameParam], params[NamespaceParam], err)","\t\treturn \"\", nil, nil, nil, err","\t}","\tsha256Checksum, err := stepaction.Checksum()","\tif err != nil {","\t\treturn \"\", nil, nil, nil, err","\t}","","\tspec, err := yaml.Marshal(stepaction.Spec)","\tif err != nil {","\t\tlogger.Infof(\"failed to marshal the spec of the task %s from namespace %s: %v\", params[NameParam], params[NamespaceParam], err)","\t\treturn \"\", nil, nil, nil, err","\t}","\treturn uid, data, sha256Checksum, spec, nil","}","","func fetchTask(ctx context.Context, groupVersion string, task *pipelinev1.Task, params map[string]string) (string, []byte, []byte, []byte, error) {","\tlogger := logging.FromContext(ctx)","\tuid := string(task.UID)","\ttask.Kind = \"Task\"","\ttask.APIVersion = groupVersion","\tdata, err := yaml.Marshal(task)","\tif err != nil {","\t\tlogger.Infof(\"failed to marshal task %s from namespace %s: %v\", params[NameParam], params[NamespaceParam], err)","\t\treturn \"\", nil, nil, nil, err","\t}","\tsha256Checksum, err := task.Checksum()","\tif err != nil {","\t\treturn \"\", nil, nil, nil, err","\t}","","\tspec, err := yaml.Marshal(task.Spec)","\tif err != nil {","\t\tlogger.Infof(\"failed to marshal the spec of the task %s from namespace %s: %v\", params[NameParam], params[NamespaceParam], err)","\t\treturn \"\", nil, nil, nil, err","\t}","\treturn uid, data, sha256Checksum, spec, nil","}","","func fetchPipeline(ctx context.Context, groupVersion string, pipeline *pipelinev1.Pipeline, params map[string]string) (string, []byte, []byte, []byte, error) {","\tlogger := logging.FromContext(ctx)","\tuid := string(pipeline.UID)","\tpipeline.Kind = \"Pipeline\"","\tpipeline.APIVersion = groupVersion","\tdata, err := yaml.Marshal(pipeline)","\tif err != nil {","\t\tlogger.Infof(\"failed to marshal pipeline %s from namespace %s: %v\", params[NameParam], params[NamespaceParam], err)","\t\treturn \"\", nil, nil, nil, err","\t}","","\tsha256Checksum, err := pipeline.Checksum()","\tif err != nil {","\t\treturn \"\", nil, nil, nil, err","\t}","","\tspec, err := yaml.Marshal(pipeline.Spec)","\tif err != nil {","\t\tlogger.Infof(\"failed to marshal the spec of the pipeline %s from namespace %s: %v\", params[NameParam], params[NamespaceParam], err)","\t\treturn \"\", nil, nil, nil, err","\t}","\treturn uid, data, sha256Checksum, spec, nil","}","","func isSupportedKind(kindValue string) bool {","\treturn slices.Contains[[]string, string](supportedKinds, kindValue)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,0,0,2,2,2,0,0,0,2,2,2,2,2,0,0,2,2,2,0,0,0,2,2,2,0,0,0,2,2,2,0,2,2,1,1,0,2,2,2,2,1,1,1,0,2,2,2,2,2,2,2,2,2,2,1,1,1,2,2,1,1,2,2,2,2,2,2,2,2,1,1,2,2,2,1,1,1,2,2,1,1,1,1,1,0,0,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,0,2,2,2,0,2,2,2,0,2,2,2,0,2,0,0,2,2,2,2,2,0,2,0,0,2,2,2,2,0,2,2,2,2,0,2,2,0,0,2,2,2,2,2,2,2,1,1,1,2,2,1,1,0,2,2,1,1,1,2,0,0,2,2,2,2,2,2,2,1,1,1,2,2,1,1,0,2,2,1,1,1,2,0,0,2,2,2,2,2,2,2,1,1,1,0,2,2,1,1,0,2,2,1,1,1,2,0,0,2,2,2]},{"id":246,"path":"pkg/resolution/resolver/framework/configstore.go","lines":["/*"," Copyright 2022 The Tekton Authors",""," Licensed under the Apache License, Version 2.0 (the \"License\");"," you may not use this file except in compliance with the License."," You may obtain a copy of the License at","","     http://www.apache.org/licenses/LICENSE-2.0",""," Unless required by applicable law or agreed to in writing, software"," distributed under the License is distributed on an \"AS IS\" BASIS,"," WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied."," See the License for the specific language governing permissions and"," limitations under the License.","*/","","package framework","","import (","\t\"context\"","","\tresolverconfig \"github.com/tektoncd/pipeline/pkg/apis/config/resolver\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"knative.dev/pkg/configmap\"",")","","// resolverConfigKey is the context key associated with configuration","// for one specific resolver, and is only used if that resolver","// implements the optional framework.ConfigWatcher interface.","var resolverConfigKey = struct{}{}","","// DataFromConfigMap returns a copy of the contents of a configmap or an","// empty map if the configmap doesn't have any data.","func DataFromConfigMap(config *corev1.ConfigMap) (map[string]string, error) {","\tresolverConfig := map[string]string{}","\tif config == nil {","\t\treturn resolverConfig, nil","\t}","\tfor key, value := range config.Data {","\t\tresolverConfig[key] = value","\t}","\treturn resolverConfig, nil","}","","// ConfigStore wraps a knative untyped store and provides helper methods","// for working with a resolver's configuration data.","type ConfigStore struct {","\t*resolverconfig.Store","\tresolverConfigName string","\tuntyped            *configmap.UntypedStore","}","","// NewConfigStore creates a new untyped store for the resolver's configuration and a config.Store for general Pipeline configuration.","func NewConfigStore(resolverConfigName string, logger configmap.Logger) *ConfigStore {","\treturn \u0026ConfigStore{","\t\tStore:              resolverconfig.NewStore(logger),","\t\tresolverConfigName: resolverConfigName,","\t\tuntyped: configmap.NewUntypedStore(","\t\t\t\"resolver-config\",","\t\t\tlogger,","\t\t\tconfigmap.Constructors{","\t\t\t\tresolverConfigName: DataFromConfigMap,","\t\t\t},","\t\t),","\t}","}","","// WatchConfigs uses the provided configmap.Watcher","// to setup watches for the config names provided in the","// Constructors map","func (store *ConfigStore) WatchConfigs(w configmap.Watcher) {","\tstore.untyped.WatchConfigs(w)","\tstore.Store.WatchConfigs(w)","}","","// GetResolverConfig returns a copy of the resolver's current","// configuration or an empty map if the stored config is nil or invalid.","func (store *ConfigStore) GetResolverConfig() map[string]string {","\tresolverConfig := map[string]string{}","\tuntypedConf := store.untyped.UntypedLoad(store.resolverConfigName)","\tif conf, ok := untypedConf.(map[string]string); ok {","\t\tfor key, val := range conf {","\t\t\tresolverConfig[key] = val","\t\t}","\t}","\treturn resolverConfig","}","","// ToContext returns a new context with the resolver's configuration","// data stored in it.","func (store *ConfigStore) ToContext(ctx context.Context) context.Context {","\tconf := store.GetResolverConfig()","\treturn InjectResolverConfigToContext(store.Store.ToContext(ctx), conf)","}","","// InjectResolverConfigToContext returns a new context with a","// map stored in it for a resolvers config.","func InjectResolverConfigToContext(ctx context.Context, conf map[string]string) context.Context {","\treturn context.WithValue(ctx, resolverConfigKey, conf)","}","","// GetResolverConfigFromContext returns any resolver-specific","// configuration that has been stored or an empty map if none exists.","func GetResolverConfigFromContext(ctx context.Context) map[string]string {","\tconf := map[string]string{}","\tstoredConfig := ctx.Value(resolverConfigKey)","\tif resolverConfig, ok := storedConfig.(map[string]string); ok {","\t\tconf = resolverConfig","\t}","\treturn conf","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,1,1,1,1,0,0,0,2,2,2,2,1,1,1,0,2,0,0,0,0,1,1,1,1,0,0,0,1,1,1,0,0,0,1,1,1,1,1,1,1,0]},{"id":247,"path":"pkg/resolution/resolver/framework/controller.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package framework","","import (","\t\"context\"","\t\"fmt\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\trrclient \"github.com/tektoncd/pipeline/pkg/client/resolution/injection/client\"","\trrinformer \"github.com/tektoncd/pipeline/pkg/client/resolution/injection/informers/resolution/v1beta1/resolutionrequest\"","\trrlister \"github.com/tektoncd/pipeline/pkg/client/resolution/listers/resolution/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/common\"","\t\"k8s.io/apimachinery/pkg/labels\"","\t\"k8s.io/apimachinery/pkg/types\"","\t\"k8s.io/client-go/tools/cache\"","\t\"k8s.io/utils/clock\"","\tkubeclient \"knative.dev/pkg/client/injection/kube/client\"","\t\"knative.dev/pkg/configmap\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/logging\"","\t\"knative.dev/pkg/reconciler\"",")","","// ReconcilerModifier is a func that can access and modify a reconciler","// in the moments before a resolver is started. It allows for","// things like injecting a test clock.","type ReconcilerModifier = func(reconciler *Reconciler)","","// NewController returns a knative controller for a Tekton Resolver.","// This sets up a lot of the boilerplate that individual resolvers","// shouldn't need to be concerned with since it's common to all of them.","func NewController(ctx context.Context, resolver Resolver, modifiers ...ReconcilerModifier) func(context.Context, configmap.Watcher) *controller.Impl {","\tif err := ValidateResolver(ctx, resolver.GetSelector(ctx)); err != nil {","\t\tpanic(err.Error())","\t}","\treturn func(ctx context.Context, cmw configmap.Watcher) *controller.Impl {","\t\tlogger := logging.FromContext(ctx)","\t\tkubeclientset := kubeclient.Get(ctx)","\t\trrclientset := rrclient.Get(ctx)","\t\trrInformer := rrinformer.Get(ctx)","","\t\tif err := resolver.Initialize(ctx); err != nil {","\t\t\tpanic(err.Error())","\t\t}","","\t\tr := \u0026Reconciler{","\t\t\tLeaderAwareFuncs:           LeaderAwareFuncs(rrInformer.Lister()),","\t\t\tkubeClientSet:              kubeclientset,","\t\t\tresolutionRequestLister:    rrInformer.Lister(),","\t\t\tresolutionRequestClientSet: rrclientset,","\t\t\tresolver:                   resolver,","\t\t}","","\t\twatchConfigChanges(ctx, r, cmw)","","\t\t// TODO(sbwsg): Do better sanitize.","\t\tresolverName := resolver.GetName(ctx)","\t\tresolverName = strings.ReplaceAll(resolverName, \"/\", \"\")","\t\tresolverName = strings.ReplaceAll(resolverName, \" \", \"\")","","\t\tapplyModifiersAndDefaults(ctx, r, modifiers)","","\t\timpl := controller.NewContext(ctx, r, controller.ControllerOptions{","\t\t\tWorkQueueName: \"TektonResolverFramework.\" + resolverName,","\t\t\tLogger:        logger,","\t\t})","","\t\t_, err := rrInformer.Informer().AddEventHandler(cache.FilteringResourceEventHandler{","\t\t\tFilterFunc: FilterResolutionRequestsBySelector(resolver.GetSelector(ctx)),","\t\t\tHandler: cache.ResourceEventHandlerFuncs{","\t\t\t\tAddFunc: impl.Enqueue,","\t\t\t\tUpdateFunc: func(oldObj, newObj interface{}) {","\t\t\t\t\timpl.Enqueue(newObj)","\t\t\t\t},","\t\t\t\t// TODO(sbwsg): should we deliver delete events","\t\t\t\t// to the resolver?","\t\t\t\t// DeleteFunc: impl.Enqueue,","\t\t\t},","\t\t})","\t\tif err != nil {","\t\t\tlogging.FromContext(ctx).Panicf(\"Couldn't register ResolutionRequest informer event handler: %w\", err)","\t\t}","","\t\treturn impl","\t}","}","","// watchConfigChanges binds a framework.Resolver to updates on its","// configmap, using knative's configmap helpers. This is only done if","// the resolver implements the framework.ConfigWatcher interface.","func watchConfigChanges(ctx context.Context, reconciler *Reconciler, cmw configmap.Watcher) {","\tif configWatcher, ok := reconciler.resolver.(ConfigWatcher); ok {","\t\tlogger := logging.FromContext(ctx)","\t\tresolverConfigName := configWatcher.GetConfigName(ctx)","\t\tif resolverConfigName == \"\" {","\t\t\tpanic(\"resolver returned empty config name\")","\t\t}","\t\treconciler.configStore = NewConfigStore(resolverConfigName, logger)","\t\treconciler.configStore.WatchConfigs(cmw)","\t}","}","","// applyModifiersAndDefaults applies the given modifiers to","// a reconciler and, after doing so, sets any default values for things","// that weren't set by a modifier.","func applyModifiersAndDefaults(ctx context.Context, r *Reconciler, modifiers []ReconcilerModifier) {","\tfor _, mod := range modifiers {","\t\tmod(r)","\t}","","\tif r.Clock == nil {","\t\tr.Clock = clock.RealClock{}","\t}","}","","func FilterResolutionRequestsBySelector(selector map[string]string) func(obj interface{}) bool {","\treturn func(obj interface{}) bool {","\t\trr, ok := obj.(*v1beta1.ResolutionRequest)","\t\tif !ok {","\t\t\treturn false","\t\t}","\t\tif len(rr.ObjectMeta.Labels) == 0 {","\t\t\treturn false","\t\t}","\t\tfor key, val := range selector {","\t\t\tlookup, has := rr.ObjectMeta.Labels[key]","\t\t\tif !has {","\t\t\t\treturn false","\t\t\t}","\t\t\tif lookup != val {","\t\t\t\treturn false","\t\t\t}","\t\t}","\t\treturn true","\t}","}","","// TODO(sbwsg): I don't really understand the LeaderAwareness types beyond the","// fact that the controller crashes if they're missing. It looks","// like this is bucketing based on labels. Should we use the filter","// selector from above in the call to lister.List here?","func LeaderAwareFuncs(lister rrlister.ResolutionRequestLister) reconciler.LeaderAwareFuncs {","\treturn reconciler.LeaderAwareFuncs{","\t\tPromoteFunc: func(bkt reconciler.Bucket, enq func(reconciler.Bucket, types.NamespacedName)) error {","\t\t\tall, err := lister.List(labels.Everything())","\t\t\tif err != nil {","\t\t\t\treturn err","\t\t\t}","\t\t\tfor _, elt := range all {","\t\t\t\tenq(bkt, types.NamespacedName{","\t\t\t\t\tNamespace: elt.GetNamespace(),","\t\t\t\t\tName:      elt.GetName(),","\t\t\t\t})","\t\t\t}","\t\t\treturn nil","\t\t},","\t}","}","","// ErrMissingTypeSelector is returned when a resolver does not return","// a selector with a type label from its GetSelector method.","var ErrMissingTypeSelector = fmt.Errorf(\"invalid resolver: minimum selector must include %q\", common.LabelKeyResolverType)","","func ValidateResolver(ctx context.Context, sel map[string]string) error {","\tif sel == nil {","\t\treturn ErrMissingTypeSelector","\t}","\tif sel[common.LabelKeyResolverType] == \"\" {","\t\treturn ErrMissingTypeSelector","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,0,2,2,2,2,2,2,2,1,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,0,0,0,0,2,1,1,0,2,0,0,0,0,0,0,2,2,1,1,1,1,0,1,1,0,0,0,0,0,0,2,2,2,2,0,2,1,1,0,0,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,0,0,0,0,0,2,2,2,2,2,1,1,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,2,2,1,1,2,1,1,2,0]},{"id":248,"path":"pkg/resolution/resolver/framework/fakeresolver.go","lines":["/*"," Copyright 2022 The Tekton Authors",""," Licensed under the Apache License, Version 2.0 (the \"License\");"," you may not use this file except in compliance with the License."," You may obtain a copy of the License at","","     http://www.apache.org/licenses/LICENSE-2.0",""," Unless required by applicable law or agreed to in writing, software"," distributed under the License is distributed on an \"AS IS\" BASIS,"," WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied."," See the License for the specific language governing permissions and"," limitations under the License.","*/","","package framework","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","\t\"strings\"","\t\"time\"","","\tpipelinev1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tresolutioncommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"",")","","const (","\t// LabelValueFakeResolverType is the value to use for the","\t// resolution.tekton.dev/type label on resource requests","\tLabelValueFakeResolverType string = \"fake\"","","\t// FakeResolverName is the name that the fake resolver should be","\t// associated with","\tFakeResolverName string = \"Fake\"","","\t// FakeParamName is the name used for the fake resolver's single parameter.","\tFakeParamName string = \"fake-key\"",")","","var _ Resolver = \u0026FakeResolver{}","","// FakeResolvedResource is a framework.ResolvedResource implementation for use with the fake resolver.","// If it's the value in the FakeResolver's ForParam map for the key given as the fake param value, the FakeResolver will","// first check if it's got a value for ErrorWith. If so, that string will be returned as an error. Then, if WaitFor is","// greater than zero, the FakeResolver will wait that long before returning. And finally, the FakeResolvedResource will","// be returned.","type FakeResolvedResource struct {","\tContent       string","\tAnnotationMap map[string]string","\tContentSource *pipelinev1.RefSource","\tErrorWith     string","\tWaitFor       time.Duration","}","","// Data returns the FakeResolvedResource's Content field as bytes.","func (f *FakeResolvedResource) Data() []byte {","\treturn []byte(f.Content)","}","","// Annotations returns the FakeResolvedResource's AnnotationMap field.","func (f *FakeResolvedResource) Annotations() map[string]string {","\treturn f.AnnotationMap","}","","// RefSource is the source reference of the remote data that records where the remote","// file came from including the url, digest and the entrypoint.","func (f *FakeResolvedResource) RefSource() *pipelinev1.RefSource {","\treturn f.ContentSource","}","","// FakeResolver implements a framework.Resolver that can fetch pre-configured strings based on a parameter value, or return","// resolution attempts with a configured error.","type FakeResolver struct {","\tForParam map[string]*FakeResolvedResource","\tTimeout  time.Duration","}","","// Initialize performs any setup required by the fake resolver.","func (r *FakeResolver) Initialize(ctx context.Context) error {","\tif r.ForParam == nil {","\t\tr.ForParam = make(map[string]*FakeResolvedResource)","\t}","\treturn nil","}","","// GetName returns the string name that the fake resolver should be","// associated with.","func (r *FakeResolver) GetName(_ context.Context) string {","\treturn FakeResolverName","}","","// GetSelector returns the labels that resource requests are required to have for","// the fake resolver to process them.","func (r *FakeResolver) GetSelector(_ context.Context) map[string]string {","\treturn map[string]string{","\t\tresolutioncommon.LabelKeyResolverType: LabelValueFakeResolverType,","\t}","}","","// ValidateParams returns an error if the given parameter map is not","// valid for a resource request targeting the fake resolver.","func (r *FakeResolver) ValidateParams(_ context.Context, params []pipelinev1.Param) error {","\treturn ValidateParams(params)","}","","func ValidateParams(params []pipelinev1.Param) error {","\tparamsMap := make(map[string]pipelinev1.ParamValue)","\tfor _, p := range params {","\t\tparamsMap[p.Name] = p.Value","\t}","","\trequired := []string{","\t\tFakeParamName,","\t}","\tmissing := []string{}","\tif params == nil {","\t\tmissing = required","\t} else {","\t\tfor _, p := range required {","\t\t\tv, has := paramsMap[p]","\t\t\tif !has || v.StringVal == \"\" {","\t\t\t\tmissing = append(missing, p)","\t\t\t}","\t\t}","\t}","\tif len(missing) \u003e 0 {","\t\treturn fmt.Errorf(\"missing %v\", strings.Join(missing, \", \"))","\t}","","\treturn nil","}","","// Resolve performs the work of fetching a file from the fake resolver given a map of","// parameters.","func (r *FakeResolver) Resolve(_ context.Context, params []pipelinev1.Param) (ResolvedResource, error) {","\treturn Resolve(params, r.ForParam)","}","","func Resolve(params []pipelinev1.Param, forParam map[string]*FakeResolvedResource) (ResolvedResource, error) {","\tparamsMap := make(map[string]pipelinev1.ParamValue)","\tfor _, p := range params {","\t\tparamsMap[p.Name] = p.Value","\t}","","\tparamValue := paramsMap[FakeParamName].StringVal","","\tfrr, ok := forParam[paramValue]","\tif !ok {","\t\treturn nil, fmt.Errorf(\"couldn't find resource for param value %s\", paramValue)","\t}","","\tif frr.ErrorWith != \"\" {","\t\treturn nil, errors.New(frr.ErrorWith)","\t}","","\tif frr.WaitFor.Seconds() \u003e 0 {","\t\ttime.Sleep(frr.WaitFor)","\t}","","\treturn frr, nil","}","","var _ TimedResolution = \u0026FakeResolver{}","","// GetResolutionTimeout returns the configured timeout for the reconciler, or the default time.Duration if not configured.","func (r *FakeResolver) GetResolutionTimeout(ctx context.Context, defaultTimeout time.Duration, params map[string]string) (time.Duration, error) {","\treturn GetResolutionTimeout(r.Timeout, defaultTimeout), nil","}","","// GetResolutionTimeout returns the input timeout if set to something greater than 0 or the default time.Duration if not configured.","func GetResolutionTimeout(timeout, defaultTimeout time.Duration) time.Duration {","\tif timeout \u003e 0 {","\t\treturn timeout","\t}","\treturn defaultTimeout","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,2,2,2,0,0,0,2,2,2,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,0,0,2,2,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,1,2,2,2,2,1,1,0,0,2,1,1,0,2,0,0,0,0,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,0,2,2,2,0,2,0,0,0,0,0,2,2,2,0,0,2,2,2,2,2,0]},{"id":249,"path":"pkg/resolution/resolver/framework/reconciler.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package framework","","import (","\t\"context\"","\t\"encoding/base64\"","\t\"encoding/json\"","\t\"errors\"","\t\"fmt\"","\t\"time\"","","\tpipelinev1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tpipelinev1beta1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\trrclient \"github.com/tektoncd/pipeline/pkg/client/resolution/clientset/versioned\"","\trrv1beta1 \"github.com/tektoncd/pipeline/pkg/client/resolution/listers/resolution/v1beta1\"","\tresolutioncommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/types\"","\t\"k8s.io/client-go/kubernetes\"","\t\"k8s.io/client-go/tools/cache\"","\t\"k8s.io/utils/clock\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/logging\"","\t\"knative.dev/pkg/reconciler\"",")","","// Reconciler handles ResolutionRequest objects, performs functionality","// common to all resolvers and delegates resolver-specific actions","// to its embedded type-specific Resolver object.","//","// Deprecated: Use [github.com/tektoncd/pipeline/pkg/remoteresolution/resolver/framework.Reconciler] instead.","type Reconciler struct {","\t// Implements reconciler.LeaderAware","\treconciler.LeaderAwareFuncs","","\t// Clock is used by the reconciler to track the passage of time","\t// and can be overridden for tests.","\tClock clock.PassiveClock","","\tresolver                   Resolver","\tkubeClientSet              kubernetes.Interface","\tresolutionRequestLister    rrv1beta1.ResolutionRequestLister","\tresolutionRequestClientSet rrclient.Interface","","\tconfigStore *ConfigStore","}","","var _ reconciler.LeaderAware = \u0026Reconciler{}","","// defaultMaximumResolutionDuration is the maximum amount of time","// resolution may take.","","// defaultMaximumResolutionDuration is the max time that a call to","// Resolve() may take. It can be overridden by a resolver implementing","// the framework.TimedResolution interface.","const defaultMaximumResolutionDuration = time.Minute","","// Reconcile receives the string key of a ResolutionRequest object, looks","// it up, checks it for common errors, and then delegates","// resolver-specific functionality to the reconciler's embedded","// type-specific resolver. Any errors that occur during validation or","// resolution are handled by updating or failing the ResolutionRequest.","func (r *Reconciler) Reconcile(ctx context.Context, key string) error {","\tnamespace, name, err := cache.SplitMetaNamespaceKey(key)","\tif err != nil {","\t\terr = \u0026resolutioncommon.InvalidResourceKeyError{Key: key, Original: err}","\t\treturn controller.NewPermanentError(err)","\t}","","\trr, err := r.resolutionRequestLister.ResolutionRequests(namespace).Get(name)","\tif err != nil {","\t\terr := \u0026resolutioncommon.GetResourceError{ResolverName: \"resolutionrequest\", Key: key, Original: err}","\t\treturn controller.NewPermanentError(err)","\t}","","\tif rr.IsDone() {","\t\treturn nil","\t}","","\t// Inject request-scoped information into the context, such as","\t// the namespace that the request originates from and the","\t// configuration from the configmap this resolver is watching.","\tctx = resolutioncommon.InjectRequestNamespace(ctx, namespace)","\tctx = resolutioncommon.InjectRequestName(ctx, name)","\tif r.configStore != nil {","\t\tctx = r.configStore.ToContext(ctx)","\t}","","\treturn r.resolve(ctx, key, rr)","}","","func (r *Reconciler) resolve(ctx context.Context, key string, rr *v1beta1.ResolutionRequest) error {","\terrChan := make(chan error)","\tresourceChan := make(chan ResolvedResource)","","\tparamsMap := make(map[string]string)","\tfor _, p := range rr.Spec.Params {","\t\tparamsMap[p.Name] = p.Value.StringVal","\t}","","\ttimeoutDuration := defaultMaximumResolutionDuration","\tif timed, ok := r.resolver.(TimedResolution); ok {","\t\tvar err error","\t\ttimeoutDuration, err = timed.GetResolutionTimeout(ctx, defaultMaximumResolutionDuration, paramsMap)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t}","","\t// A new context is created for resolution so that timeouts can","\t// be enforced without affecting other uses of ctx (e.g. sending","\t// Updates to ResolutionRequest objects).","\tresolutionCtx, cancelFn := context.WithTimeout(ctx, timeoutDuration)","\tdefer cancelFn()","","\tgo func() {","\t\tvalidationError := r.resolver.ValidateParams(resolutionCtx, rr.Spec.Params)","\t\tif validationError != nil {","\t\t\terrChan \u003c- \u0026resolutioncommon.InvalidRequestError{","\t\t\t\tResolutionRequestKey: key,","\t\t\t\tMessage:              validationError.Error(),","\t\t\t}","\t\t\treturn","\t\t}","\t\tresource, resolveErr := r.resolver.Resolve(resolutionCtx, rr.Spec.Params)","\t\tif resolveErr != nil {","\t\t\terrChan \u003c- \u0026resolutioncommon.GetResourceError{","\t\t\t\tResolverName: r.resolver.GetName(resolutionCtx),","\t\t\t\tKey:          key,","\t\t\t\tOriginal:     resolveErr,","\t\t\t}","\t\t\treturn","\t\t}","\t\tresourceChan \u003c- resource","\t}()","","\tselect {","\tcase err := \u003c-errChan:","\t\tif err != nil {","\t\t\treturn r.OnError(ctx, rr, err)","\t\t}","\tcase \u003c-resolutionCtx.Done():","\t\tif err := resolutionCtx.Err(); err != nil {","\t\t\treturn r.OnError(ctx, rr, err)","\t\t}","\tcase resource := \u003c-resourceChan:","\t\treturn r.writeResolvedData(ctx, rr, resource)","\t}","","\treturn errors.New(\"unknown error\")","}","","// OnError is used to handle any situation where a ResolutionRequest has","// reached a terminal situation that cannot be recovered from.","func (r *Reconciler) OnError(ctx context.Context, rr *v1beta1.ResolutionRequest, err error) error {","\tif rr == nil {","\t\treturn controller.NewPermanentError(err)","\t}","\tif err != nil {","\t\t_ = r.MarkFailed(ctx, rr, err)","\t\treturn controller.NewPermanentError(err)","\t}","\treturn nil","}","","// MarkFailed updates a ResolutionRequest as having failed. It returns","// errors that occur during the update process or nil if the update","// appeared to succeed.","func (r *Reconciler) MarkFailed(ctx context.Context, rr *v1beta1.ResolutionRequest, resolutionErr error) error {","\tkey := fmt.Sprintf(\"%s/%s\", rr.Namespace, rr.Name)","\treason, resolutionErr := resolutioncommon.ReasonError(resolutionErr)","\tlatestGeneration, err := r.resolutionRequestClientSet.ResolutionV1beta1().ResolutionRequests(rr.Namespace).Get(ctx, rr.Name, metav1.GetOptions{})","\tif err != nil {","\t\tlogging.FromContext(ctx).Warnf(\"error getting latest generation of resolutionrequest %q: %v\", key, err)","\t\treturn err","\t}","\tif latestGeneration.IsDone() {","\t\treturn nil","\t}","\tlatestGeneration.Status.MarkFailed(reason, resolutionErr.Error())","\t_, err = r.resolutionRequestClientSet.ResolutionV1beta1().ResolutionRequests(rr.Namespace).UpdateStatus(ctx, latestGeneration, metav1.UpdateOptions{})","\tif err != nil {","\t\tlogging.FromContext(ctx).Warnf(\"error marking resolutionrequest %q as failed: %v\", key, err)","\t\treturn err","\t}","\treturn nil","}","","// statusDataPatch is the json structure that will be PATCHed into","// a ResolutionRequest with its data and annotations once successfully","// resolved.","type statusDataPatch struct {","\tAnnotations map[string]string             `json:\"annotations\"`","\tData        string                        `json:\"data\"`","\tSource      *pipelinev1beta1.ConfigSource `json:\"source\"`","\tRefSource   *pipelinev1.RefSource         `json:\"refSource\"`","}","","func (r *Reconciler) writeResolvedData(ctx context.Context, rr *v1beta1.ResolutionRequest, resource ResolvedResource) error {","\tencodedData := base64.StdEncoding.Strict().EncodeToString(resource.Data())","\tpatchBytes, err := json.Marshal(map[string]statusDataPatch{","\t\t\"status\": {","\t\t\tData:        encodedData,","\t\t\tAnnotations: resource.Annotations(),","\t\t\tRefSource:   resource.RefSource(),","\t\t\tSource:      (*pipelinev1beta1.ConfigSource)(resource.RefSource()),","\t\t},","\t})","\tif err != nil {","\t\treturn r.OnError(ctx, rr, \u0026resolutioncommon.UpdatingRequestError{","\t\t\tResolutionRequestKey: fmt.Sprintf(\"%s/%s\", rr.Namespace, rr.Name),","\t\t\tOriginal:             fmt.Errorf(\"error serializing resource request patch: %w\", err),","\t\t})","\t}","\t_, err = r.resolutionRequestClientSet.ResolutionV1beta1().ResolutionRequests(rr.Namespace).Patch(ctx, rr.Name, types.MergePatchType, patchBytes, metav1.PatchOptions{}, \"status\")","\tif err != nil {","\t\treturn r.OnError(ctx, rr, \u0026resolutioncommon.UpdatingRequestError{","\t\t\tResolutionRequestKey: fmt.Sprintf(\"%s/%s\", rr.Namespace, rr.Name),","\t\t\tOriginal:             err,","\t\t})","\t}","","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,1,1,1,0,2,2,1,1,1,0,2,1,1,0,0,0,0,2,2,2,1,1,0,2,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,1,1,0,0,0,0,0,2,2,2,2,2,2,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,1,0,0,0,0,2,2,1,1,2,2,2,2,1,0,0,0,0,0,2,2,2,2,2,1,1,1,2,1,1,2,2,2,1,1,1,2,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,2,2,1,1,1,1,1,0,2,0]},{"id":250,"path":"pkg/resolution/resolver/framework/testing/fakecontroller.go","lines":["/*"," Copyright 2022 The Tekton Authors",""," Licensed under the Apache License, Version 2.0 (the \"License\");"," you may not use this file except in compliance with the License."," You may obtain a copy of the License at","","     http://www.apache.org/licenses/LICENSE-2.0",""," Unless required by applicable law or agreed to in writing, software"," distributed under the License is distributed on an \"AS IS\" BASIS,"," WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied."," See the License for the specific language governing permissions and"," limitations under the License.","*/","","package testing","","import (","\t\"context\"","\t\"encoding/base64\"","\t\"strings\"","\t\"testing\"","\t\"time\"","","\t\"github.com/google/go-cmp/cmp\"","\t\"github.com/google/go-cmp/cmp/cmpopts\"","\tresolverconfig \"github.com/tektoncd/pipeline/pkg/apis/config/resolver\"","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"","\t\"github.com/tektoncd/pipeline/test\"","\t\"github.com/tektoncd/pipeline/test/diff\"","\t\"github.com/tektoncd/pipeline/test/names\"","\tcorev1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/types\"","\t\"k8s.io/client-go/tools/record\"","\ttestclock \"k8s.io/utils/clock/testing\"","\t\"knative.dev/pkg/apis\"","\tcminformer \"knative.dev/pkg/configmap/informer\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/logging\"","\tpkgreconciler \"knative.dev/pkg/reconciler\"","\t\"knative.dev/pkg/system\"",")","","var (","\tnow                      = time.Date(2022, time.January, 1, 0, 0, 0, 0, time.UTC)","\ttestClock                = testclock.NewFakePassiveClock(now)","\tignoreLastTransitionTime = cmpopts.IgnoreFields(apis.Condition{}, \"LastTransitionTime.Inner.Time\")",")","","// ResolverReconcileTestModifier is a function thaat will be invoked after the test assets and controller have been created","type ResolverReconcileTestModifier = func(resolver framework.Resolver, testAssets test.Assets)","","// RunResolverReconcileTest takes data to seed clients and informers, a Resolver, a ResolutionRequest, and the expected","// ResolutionRequestStatus and error, both of which can be nil. It instantiates a controller for that resolver and","// reconciles the given request. It then checks for the expected error, if any, and compares the resulting status with","// the expected status.","func RunResolverReconcileTest(ctx context.Context, t *testing.T, d test.Data, resolver framework.Resolver, request *v1beta1.ResolutionRequest,","\texpectedStatus *v1beta1.ResolutionRequestStatus, expectedErr error, resolverModifiers ...ResolverReconcileTestModifier) {","\tt.Helper()","","\ttestAssets, cancel := GetResolverFrameworkController(ctx, t, d, resolver, setClockOnReconciler)","\tdefer cancel()","","\tfor _, rm := range resolverModifiers {","\t\trm(resolver, testAssets)","\t}","","\terr := testAssets.Controller.Reconciler.Reconcile(testAssets.Ctx, getRequestName(request))","\tif expectedErr != nil {","\t\tif err == nil {","\t\t\tt.Fatalf(\"expected to get error: `%v`, but got nothing\", expectedErr)","\t\t}","\t\tif expectedErr.Error() != err.Error() {","\t\t\tt.Fatalf(\"expected to get error `%v`, but got `%v`\", expectedErr, err)","\t\t}","\t} else if err != nil {","\t\tif ok, _ := controller.IsRequeueKey(err); !ok {","\t\t\tt.Fatalf(\"did not expect an error, but got `%v`\", err)","\t\t}","\t}","","\tc := testAssets.Clients.ResolutionRequests.ResolutionV1beta1()","\treconciledRR, err := c.ResolutionRequests(request.Namespace).Get(testAssets.Ctx, request.Name, metav1.GetOptions{})","\tif err != nil {","\t\tt.Fatalf(\"getting updated ResolutionRequest: %v\", err)","\t}","\tif expectedStatus != nil {","\t\tif d := cmp.Diff(*expectedStatus, reconciledRR.Status, ignoreLastTransitionTime); d != \"\" {","\t\t\tt.Errorf(\"ResolutionRequest status doesn't match %s\", diff.PrintWantGot(d))","\t\t\tif expectedStatus.Data != \"\" \u0026\u0026 expectedStatus.Data != reconciledRR.Status.Data {","\t\t\t\tdecodedExpectedData, err := base64.StdEncoding.Strict().DecodeString(expectedStatus.Data)","\t\t\t\tif err != nil {","\t\t\t\t\tt.Errorf(\"couldn't decode expected data: %v\", err)","\t\t\t\t\treturn","\t\t\t\t}","\t\t\t\tdecodedGotData, err := base64.StdEncoding.Strict().DecodeString(reconciledRR.Status.Data)","\t\t\t\tif err != nil {","\t\t\t\t\tt.Errorf(\"couldn't decode reconciled data: %v\", err)","\t\t\t\t\treturn","\t\t\t\t}","\t\t\t\tif d := cmp.Diff(decodedExpectedData, decodedGotData); d != \"\" {","\t\t\t\t\tt.Errorf(\"decoded data did not match expected: %s\", diff.PrintWantGot(d))","\t\t\t\t}","\t\t\t}","\t\t}","\t}","}","","// GetResolverFrameworkController returns an instance of the resolver framework controller/reconciler using the given resolver,","// seeded with d, where d represents the state of the system (existing resources) needed for the test.","func GetResolverFrameworkController(ctx context.Context, t *testing.T, d test.Data, resolver framework.Resolver, modifiers ...framework.ReconcilerModifier) (test.Assets, func()) {","\tt.Helper()","\tnames.TestingSeed()","\treturn initializeResolverFrameworkControllerAssets(ctx, t, d, resolver, modifiers...)","}","","func initializeResolverFrameworkControllerAssets(ctx context.Context, t *testing.T, d test.Data, resolver framework.Resolver, modifiers ...framework.ReconcilerModifier) (test.Assets, func()) {","\tt.Helper()","\tctx, cancel := context.WithCancel(ctx)","\tensureConfigurationConfigMapsExist(\u0026d)","\tc, informers := test.SeedTestData(t, ctx, d)","\tconfigMapWatcher := cminformer.NewInformedWatcher(c.Kube, resolverconfig.ResolversNamespace(system.Namespace()))","\tctl := framework.NewController(ctx, resolver, modifiers...)(ctx, configMapWatcher)","\tif err := configMapWatcher.Start(ctx.Done()); err != nil {","\t\tt.Fatalf(\"error starting configmap watcher: %v\", err)","\t}","","\tif la, ok := ctl.Reconciler.(pkgreconciler.LeaderAware); ok {","\t\t_ = la.Promote(pkgreconciler.UniversalBucket(), func(pkgreconciler.Bucket, types.NamespacedName) {})","\t}","","\treturn test.Assets{","\t\tLogger:     logging.FromContext(ctx),","\t\tController: ctl,","\t\tClients:    c,","\t\tInformers:  informers,","\t\tRecorder:   controller.GetEventRecorder(ctx).(*record.FakeRecorder),","\t\tCtx:        ctx,","\t}, cancel","}","","func getRequestName(rr *v1beta1.ResolutionRequest) string {","\treturn strings.Join([]string{rr.Namespace, rr.Name}, \"/\")","}","","func setClockOnReconciler(r *framework.Reconciler) {","\tif r.Clock == nil {","\t\tr.Clock = testClock","\t}","}","","func ensureConfigurationConfigMapsExist(d *test.Data) {","\tvar featureFlagsExists bool","\tvar resolverCacheConfigExists bool","\tfor _, cm := range d.ConfigMaps {","\t\tif cm.Name == resolverconfig.GetFeatureFlagsConfigName() {","\t\t\tfeatureFlagsExists = true","\t\t}","\t\tif cm.Name == \"resolver-cache-config\" {","\t\t\tresolverCacheConfigExists = true","\t\t}","\t}","\tif !featureFlagsExists {","\t\td.ConfigMaps = append(d.ConfigMaps, \u0026corev1.ConfigMap{","\t\t\tObjectMeta: metav1.ObjectMeta{","\t\t\t\tName:      resolverconfig.GetFeatureFlagsConfigName(),","\t\t\t\tNamespace: resolverconfig.ResolversNamespace(system.Namespace()),","\t\t\t},","\t\t\tData: map[string]string{},","\t\t})","\t}","\tif !resolverCacheConfigExists {","\t\td.ConfigMaps = append(d.ConfigMaps, \u0026corev1.ConfigMap{","\t\t\tObjectMeta: metav1.ObjectMeta{","\t\t\t\tName:      \"resolver-cache-config\",","\t\t\t\tNamespace: resolverconfig.ResolversNamespace(system.Namespace()),","\t\t\t},","\t\t\tData: map[string]string{},","\t\t})","\t}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0,1,1,0,0,1,1,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0]},{"id":251,"path":"pkg/resolution/resolver/framework/testing/featureflag.go","lines":["/*"," Copyright 2022 The Tekton Authors",""," Licensed under the Apache License, Version 2.0 (the \"License\");"," you may not use this file except in compliance with the License."," You may obtain a copy of the License at","","     http://www.apache.org/licenses/LICENSE-2.0",""," Unless required by applicable law or agreed to in writing, software"," distributed under the License is distributed on an \"AS IS\" BASIS,"," WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied."," See the License for the specific language governing permissions and"," limitations under the License.","","*/","","package testing","","import (","\t\"context\"","","\tresolverconfig \"github.com/tektoncd/pipeline/pkg/apis/config/resolver\"",")","","// ContextWithGitResolverDisabled returns a context containing a Config with the enable-git-resolver feature flag disabled.","func ContextWithGitResolverDisabled(ctx context.Context) context.Context {","\treturn contextWithResolverDisabled(ctx, \"enable-git-resolver\")","}","","// ContextWithHubResolverDisabled returns a context containing a Config with the enable-hub-resolver feature flag disabled.","func ContextWithHubResolverDisabled(ctx context.Context) context.Context {","\treturn contextWithResolverDisabled(ctx, \"enable-hub-resolver\")","}","","// ContextWithBundlesResolverDisabled returns a context containing a Config with the enable-bundles-resolver feature flag disabled.","func ContextWithBundlesResolverDisabled(ctx context.Context) context.Context {","\treturn contextWithResolverDisabled(ctx, \"enable-bundles-resolver\")","}","","// ContextWithClusterResolverDisabled returns a context containing a Config with the enable-cluster-resolver feature flag disabled.","func ContextWithClusterResolverDisabled(ctx context.Context) context.Context {","\treturn contextWithResolverDisabled(ctx, \"enable-cluster-resolver\")","}","","// ContextWithHttpResolverDisabled returns a context containing a Config with the enable-http-resolver feature flag disabled.","func ContextWithHttpResolverDisabled(ctx context.Context) context.Context {","\treturn contextWithResolverDisabled(ctx, \"enable-http-resolver\")","}","","func contextWithResolverDisabled(ctx context.Context, resolverFlag string) context.Context {","\tfeatureFlags, _ := resolverconfig.NewFeatureFlagsFromMap(map[string]string{","\t\tresolverFlag: \"false\",","\t})","\tcfg := \u0026resolverconfig.Config{","\t\tFeatureFlags: featureFlags,","\t}","\treturn resolverconfig.ToContext(ctx, cfg)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,1,1,1,1,1,1,1,1,1]},{"id":252,"path":"pkg/resolution/resolver/git/config.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package git","","import (","\t\"context\"","\t\"fmt\"","\t\"reflect\"","\t\"strings\"","","\t\"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"",")","","const (","\t// DefaultTimeoutKey is the configuration field name for controlling","\t// the maximum duration of a resolution request for a file from git.","\tDefaultTimeoutKey = \"fetch-timeout\"","","\t// DefaultURLKey is the configuration field name for controlling","\t// the git url to fetch the remote resource from.","\tDefaultURLKey = \"default-url\"","","\t// DefaultRevisionKey is the configuration field name for controlling","\t// the revision to fetch the remote resource from.","\tDefaultRevisionKey = \"default-revision\"","","\t// DefaultOrgKey is the configuration field name for setting a default organization when using the SCM API.","\tDefaultOrgKey = \"default-org\"","","\t// ServerURLKey is the config map key for the SCM provider URL","\tServerURLKey = \"server-url\"","\t// SCMTypeKey is the config map key for the SCM provider type","\tSCMTypeKey = \"scm-type\"","\t// APISecretNameKey is the config map key for the token secret's name","\tAPISecretNameKey = \"api-token-secret-name\"","\t// APISecretKeyKey is the config map key for the containing the token within the token secret","\tAPISecretKeyKey = \"api-token-secret-key\"","\t// APISecretNamespaceKey is the config map key for the token secret's namespace","\tAPISecretNamespaceKey = \"api-token-secret-namespace\"",")","","type GitResolverConfig map[string]ScmConfig","","type ScmConfig struct {","\tTimeout            string `json:\"fetch-timeout\"`","\tURL                string `json:\"default-url\"`","\tRevision           string `json:\"default-revision\"`","\tOrg                string `json:\"default-org\"`","\tServerURL          string `json:\"server-url\"`","\tSCMType            string `json:\"scm-type\"`","\tGitToken           string `json:\"git-token\"`","\tAPISecretName      string `json:\"api-token-secret-name\"`","\tAPISecretKey       string `json:\"api-token-secret-key\"`","\tAPISecretNamespace string `json:\"api-token-secret-namespace\"`","}","","func GetGitResolverConfig(ctx context.Context) (GitResolverConfig, error) {","\tvar scmConfig interface{} = \u0026ScmConfig{}","\tstructType := reflect.TypeOf(scmConfig).Elem()","\tgitResolverConfig := map[string]ScmConfig{}","\tconf := framework.GetResolverConfigFromContext(ctx)","\tfor key, value := range conf {","\t\tvar configIdentifier, configKey string","\t\tsplittedKeyName := strings.Split(key, \".\")","\t\tswitch len(splittedKeyName) {","\t\tcase 2:","\t\t\tconfigKey = splittedKeyName[1]","\t\t\tconfigIdentifier = splittedKeyName[0]","\t\tcase 1:","\t\t\tconfigKey = key","\t\t\tconfigIdentifier = \"default\"","\t\tdefault:","\t\t\treturn nil, fmt.Errorf(\"key %s passed in git resolver configmap is invalid\", key)","\t\t}","\t\t_, ok := gitResolverConfig[configIdentifier]","\t\tif !ok {","\t\t\tgitResolverConfig[configIdentifier] = ScmConfig{}","\t\t}","\t\tfor i := range structType.NumField() {","\t\t\tfield := structType.Field(i)","\t\t\tfieldName := field.Name","\t\t\tjsonTag := field.Tag.Get(\"json\")","\t\t\tif configKey == jsonTag {","\t\t\t\ttokenDetails := gitResolverConfig[configIdentifier]","\t\t\t\tvar scm interface{} = \u0026tokenDetails","\t\t\t\tstructValue := reflect.ValueOf(scm).Elem()","\t\t\t\tstructValue.FieldByName(fieldName).SetString(value)","\t\t\t\tgitResolverConfig[configIdentifier] = structValue.Interface().(ScmConfig)","\t\t\t}","\t\t}","\t}","\treturn gitResolverConfig, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0]},{"id":253,"path":"pkg/resolution/resolver/git/repository.go","lines":["/*","Copyright 2025 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package git","","import (","\t\"context\"","\t\"encoding/base64\"","\t\"errors\"","\t\"fmt\"","\t\"os\"","\t\"os/exec\"","\t\"path/filepath\"","\t\"strings\"",")","","type cmdExecutor = func(context.Context, string, ...string) *exec.Cmd","","type remote struct {","\turl         string","\tusername    string","\tpassword    string","\tcmdExecutor cmdExecutor","}","","func (r remote) clone(ctx context.Context) (*repository, func(), error) {","\turlParts := strings.Split(r.url, \"/\")","\trepoName := urlParts[len(urlParts)-1]","\ttmpDir, err := os.MkdirTemp(\"\", repoName+\"-*\")","\tif err != nil {","\t\treturn nil, func() {}, err","\t}","\tcleanupFunc := func() {","\t\tos.RemoveAll(tmpDir)","\t}","","\trepo := \u0026repository{","\t\turl:       r.url,","\t\tusername:  r.username,","\t\tpassword:  r.password,","\t\tdirectory: tmpDir,","\t\texecutor:  r.cmdExecutor,","\t}","","\t_, err = repo.execGit(ctx, \"clone\", repo.url, tmpDir, \"--depth=1\", \"--no-checkout\")","\tif err != nil {","\t\tif strings.Contains(err.Error(), \"could not read Username\") {","\t\t\terr = errors.New(\"clone error: authentication required\")","\t\t}","\t\treturn nil, cleanupFunc, err","\t}","\treturn repo, cleanupFunc, nil","}","","type repository struct {","\turl       string","\tusername  string","\tpassword  string","\tdirectory string","\texecutor  cmdExecutor","}","","func (repo *repository) currentRevision(ctx context.Context) (string, error) {","\trevisionSha, err := repo.execGit(ctx, \"rev-list\", \"-n1\", \"HEAD\")","\tif err != nil {","\t\treturn \"\", err","\t}","\treturn strings.TrimSpace(string(revisionSha)), nil","}","","func (repo *repository) checkout(ctx context.Context, revision string) error {","\t_, err := repo.execGit(ctx, \"fetch\", \"origin\", revision, \"--depth=1\")","\tif err != nil {","\t\treturn err","\t}","","\t_, err = repo.execGit(ctx, \"checkout\", \"FETCH_HEAD\")","\tif err != nil {","\t\treturn err","\t}","","\treturn nil","}","","func (repo *repository) execGit(ctx context.Context, subCmd string, args ...string) ([]byte, error) {","\tif repo.executor == nil {","\t\trepo.executor = exec.CommandContext","\t}","","\targs = append([]string{subCmd}, args...)","","\t// We need to configure which directory contains the cloned repository since `cd`ing","\t// into the repository directory is not concurrency-safe","\tconfigArgs := []string{\"-C\", repo.directory}","","\tenv := []string{\"GIT_TERMINAL_PROMPT=false\"}","\t// NOTE: Since this is only HTTP basic auth, authentication is only supported for http","\t// cloning, while unauthenticated cloning is supported for any other protocol supported","\t// by git which doesn't require authentication.","\tif repo.username != \"\" \u0026\u0026 repo.password != \"\" {","\t\ttoken := base64.URLEncoding.EncodeToString([]byte(repo.username + \":\" + repo.password))","\t\tenv = append(","\t\t\tenv,","\t\t\t\"GIT_AUTH_HEADER=Authorization: Basic \"+token,","\t\t)","\t\tconfigArgs = append(configArgs, \"--config-env\", \"http.extraHeader=GIT_AUTH_HEADER\")","\t}","","\tcmd := repo.executor(ctx, \"git\", append(configArgs, args...)...)","\tcmd.Env = append(cmd.Environ(), env...)","","\tout, err := cmd.Output()","\tif err != nil {","\t\tmsg := string(out)","\t\tvar exitErr *exec.ExitError","\t\tif errors.As(err, \u0026exitErr) {","\t\t\tmsg = string(exitErr.Stderr)","\t\t}","\t\terr = fmt.Errorf(\"git %s error: %s: %w\", subCmd, strings.TrimSpace(msg), err)","\t}","\treturn out, err","}","","func (repo *repository) getFileContent(path string) ([]byte, error) {","\tif _, err := os.Stat(repo.directory); errors.Is(err, os.ErrNotExist) {","\t\treturn nil, fmt.Errorf(\"repository clone no longer exists, used after cleaned? %w\", err)","\t}","\tfileContents, err := os.ReadFile(filepath.Join(repo.directory, path))","\tif err != nil {","\t\tif errors.Is(err, os.ErrNotExist) {","\t\t\treturn nil, errors.New(\"file does not exist\")","\t\t}","\t\treturn nil, err","\t}","\treturn fileContents, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,1,0,2,2,2,0,2,2,2,2,2,2,2,2,2,2,1,1,1,1,0,2,0,0,0,0,0,0,0,0,0,0,2,2,2,1,1,2,0,0,2,2,2,2,2,0,2,2,1,1,0,2,0,0,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,1,1,2,2,2,2,2,1,0,2,0]},{"id":254,"path":"pkg/resolution/resolver/git/resolver.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package git","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","\t\"os\"","\t\"regexp\"","\t\"strings\"","\t\"time\"","","\t\"github.com/jenkins-x/go-scm/scm\"","\t\"github.com/jenkins-x/go-scm/scm/factory\"","\tresolverconfig \"github.com/tektoncd/pipeline/pkg/apis/config/resolver\"","\tpipelinev1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tcommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"","\t\"go.uber.org/zap\"","\tapierrors \"k8s.io/apimachinery/pkg/api/errors\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/util/cache\"","\t\"k8s.io/client-go/kubernetes\"","\tkubeclient \"knative.dev/pkg/client/injection/kube/client\"","\t\"knative.dev/pkg/logging\"",")","","const (","\tdisabledError = \"cannot handle resolution request, enable-git-resolver feature flag not true\"","","\t// labelValueGitResolverType is the value to use for the","\t// resolution.tekton.dev/type label on resource requests","\tlabelValueGitResolverType string = \"git\"","","\t// gitResolverName is the name that the git resolver should be","\t// associated with","\tgitResolverName string = \"Git\"","","\t// yamlContentType is the content type to use when returning yaml","\tyamlContentType string = \"application/x-yaml\"","","\t// ConfigMapName is the git resolver's config map","\tConfigMapName = \"git-resolver-config\"","","\t// cacheSize is the size of the LRU secrets cache","\tcacheSize = 1024","\t// ttl is the time to live for a cache entry","\tttl = 5 * time.Minute",")","","var _ framework.Resolver = \u0026Resolver{}","","// Resolver implements a framework.Resolver that can fetch files from git.","//","// Deprecated: Use [github.com/tektoncd/pipeline/pkg/remoteresolution/resolver/git.Resolver] instead.","type Resolver struct {","\tkubeClient kubernetes.Interface","\tlogger     *zap.SugaredLogger","\tcache      *cache.LRUExpireCache","\tttl        time.Duration","","\t// Used in testing","\tclientFunc func(string, string, string, ...factory.ClientOptionFunc) (*scm.Client, error)","}","","// Initialize performs any setup required by the gitresolver.","func (r *Resolver) Initialize(ctx context.Context) error {","\tr.kubeClient = kubeclient.Get(ctx)","\tr.logger = logging.FromContext(ctx)","\tr.cache = cache.NewLRUExpireCache(cacheSize)","\tr.ttl = ttl","\tif r.clientFunc == nil {","\t\tr.clientFunc = factory.NewClient","\t}","\treturn nil","}","","// GetName returns the string name that the gitresolver should be","// associated with.","func (r *Resolver) GetName(_ context.Context) string {","\treturn gitResolverName","}","","// GetSelector returns the labels that resource requests are required to have for","// the gitresolver to process them.","func (r *Resolver) GetSelector(_ context.Context) map[string]string {","\treturn map[string]string{","\t\tcommon.LabelKeyResolverType: labelValueGitResolverType,","\t}","}","","// ValidateParams returns an error if the given parameter map is not","// valid for a resource request targeting the gitresolver.","func (r *Resolver) ValidateParams(ctx context.Context, params []pipelinev1.Param) error {","\treturn ValidateParams(ctx, params)","}","","// Resolve performs the work of fetching a file from git given a map of","// parameters.","func (r *Resolver) Resolve(ctx context.Context, origParams []pipelinev1.Param) (framework.ResolvedResource, error) {","\tif IsDisabled(ctx) {","\t\treturn nil, errors.New(disabledError)","\t}","","\tparams, err := PopulateDefaultParams(ctx, origParams)","\tif err != nil {","\t\treturn nil, err","\t}","","\tg := \u0026GitResolver{","\t\tParams:     params,","\t\tLogger:     r.logger,","\t\tCache:      r.cache,","\t\tTTL:        r.ttl,","\t\tKubeClient: r.kubeClient,","\t}","","\tif params[UrlParam] != \"\" {","\t\treturn g.ResolveGitClone(ctx)","\t}","","\treturn g.ResolveAPIGit(ctx, r.clientFunc)","}","","func ValidateParams(ctx context.Context, params []pipelinev1.Param) error {","\tif IsDisabled(ctx) {","\t\treturn errors.New(disabledError)","\t}","","\tif _, err := PopulateDefaultParams(ctx, params); err != nil {","\t\treturn err","\t}","\treturn nil","}","","// validateRepoURL validates if the given URL is a valid git, http, https URL or","// starting with a / (a local repository).","func validateRepoURL(url string) bool {","\t// Explanation:","\tpattern := `^(/|[^@]+@[^:]+|(git|https?)://)`","\tre := regexp.MustCompile(pattern)","\treturn re.MatchString(url)","}","","type GitResolver struct {","\tKubeClient kubernetes.Interface","\tLogger     *zap.SugaredLogger","\tCache      *cache.LRUExpireCache","\tTTL        time.Duration","\tParams     map[string]string","","\t// Function variables for mocking in tests","\tResolveGitCloneFunc func(ctx context.Context) (framework.ResolvedResource, error)","\tResolveAPIGitFunc   func(ctx context.Context, clientFunc func(string, string, string, ...factory.ClientOptionFunc) (*scm.Client, error)) (framework.ResolvedResource, error)","}","","// ResolveGitClone resolves a git resource using git clone.","func (g *GitResolver) ResolveGitClone(ctx context.Context) (framework.ResolvedResource, error) {","\tif g.ResolveGitCloneFunc != nil {","\t\treturn g.ResolveGitCloneFunc(ctx)","\t}","\tconf, err := GetScmConfigForParamConfigKey(ctx, g.Params)","\tif err != nil {","\t\treturn nil, err","\t}","\trepoURL := g.Params[UrlParam]","\tif repoURL == \"\" {","\t\turlString := conf.URL","\t\tif urlString == \"\" {","\t\t\treturn nil, errors.New(\"default Git Repo Url was not set during installation of the git resolver\")","\t\t}","\t}","\trevision := g.Params[RevisionParam]","\tif revision == \"\" {","\t\trevisionString := conf.Revision","\t\tif revisionString == \"\" {","\t\t\treturn nil, errors.New(\"default Git Revision was not set during installation of the git resolver\")","\t\t}","\t}","","\tvar username string","\tvar password string","","\tsecretRef := \u0026secretCacheKey{","\t\tname: g.Params[GitTokenParam],","\t\tkey:  g.Params[GitTokenKeyParam],","\t}","\tif secretRef.name != \"\" {","\t\tif secretRef.key == \"\" {","\t\t\tsecretRef.key = DefaultTokenKeyParam","\t\t}","\t\tsecretRef.ns = common.RequestNamespace(ctx)","\t} else {","\t\tsecretRef = nil","\t}","","\tif secretRef != nil {","\t\tgitToken, err := g.getAPIToken(ctx, secretRef, GitTokenKeyParam)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tusername = \"git\"","\t\tpassword = string(gitToken)","\t}","","\tpath := g.Params[PathParam]","","\trepo, cleanupFunc, err := remote{url: repoURL, username: username, password: password}.clone(ctx)","\tdefer cleanupFunc()","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"error resolving repository: %w\", err)","\t}","","\terr = repo.checkout(ctx, revision)","\tif err != nil {","\t\treturn nil, err","\t}","","\tfullRevision, err := repo.currentRevision(ctx)","\tif err != nil {","\t\treturn nil, err","\t}","","\tfileContents, err := repo.getFileContent(path)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"error opening file %q: %w\", path, err)","\t}","","\treturn \u0026resolvedGitResource{","\t\tRevision: fullRevision,","\t\tContent:  fileContents,","\t\tURL:      repo.url,","\t\tPath:     path,","\t}, nil","}","","// ResolveAPIGit resolves a git resource using the SCM API.","func (g *GitResolver) ResolveAPIGit(ctx context.Context, clientFunc func(string, string, string, ...factory.ClientOptionFunc) (*scm.Client, error)) (framework.ResolvedResource, error) {","\tif g.ResolveAPIGitFunc != nil {","\t\treturn g.ResolveAPIGitFunc(ctx, clientFunc)","\t}","\t// If we got here, the \"repo\" param was specified, so use the API approach","\tscmType, serverURL, err := getSCMTypeAndServerURL(ctx, g.Params)","\tif err != nil {","\t\treturn nil, err","\t}","\tsecretRef := \u0026secretCacheKey{","\t\tname: g.Params[TokenParam],","\t\tkey:  g.Params[TokenKeyParam],","\t}","\tif secretRef.name != \"\" {","\t\tif secretRef.key == \"\" {","\t\t\tsecretRef.key = DefaultTokenKeyParam","\t\t}","\t\tsecretRef.ns = common.RequestNamespace(ctx)","\t} else {","\t\tsecretRef = nil","\t}","\tapiToken, err := g.getAPIToken(ctx, secretRef, APISecretNameKey)","\tif err != nil {","\t\treturn nil, err","\t}","\tscmClient, err := clientFunc(scmType, serverURL, string(apiToken))","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"failed to create SCM client: %w\", err)","\t}","","\torgRepo := fmt.Sprintf(\"%s/%s\", g.Params[OrgParam], g.Params[RepoParam])","\tpath := g.Params[PathParam]","\tref := g.Params[RevisionParam]","","\t// fetch the actual content from a file in the repo","\tcontent, _, err := scmClient.Contents.Find(ctx, orgRepo, path, ref)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"couldn't fetch resource content: %w\", err)","\t}","\tif content == nil || len(content.Data) == 0 {","\t\treturn nil, fmt.Errorf(\"no content for resource in %s %s\", orgRepo, path)","\t}","","\t// find the actual git commit sha by the ref","\tcommit, _, err := scmClient.Git.FindCommit(ctx, orgRepo, ref)","\tif err != nil || commit == nil {","\t\treturn nil, fmt.Errorf(\"couldn't fetch the commit sha for the ref %s in the repo: %w\", ref, err)","\t}","","\t// fetch the repository URL","\trepo, _, err := scmClient.Repositories.Find(ctx, orgRepo)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"couldn't fetch repository: %w\", err)","\t}","","\treturn \u0026resolvedGitResource{","\t\tContent:  content.Data,","\t\tRevision: commit.Sha,","\t\tOrg:      g.Params[OrgParam],","\t\tRepo:     g.Params[RepoParam],","\t\tPath:     content.Path,","\t\tURL:      repo.Clone,","\t}, nil","}","","var _ framework.ConfigWatcher = \u0026Resolver{}","","// GetConfigName returns the name of the git resolver's configmap.","func (r *Resolver) GetConfigName(context.Context) string {","\treturn ConfigMapName","}","","var _ framework.TimedResolution = \u0026Resolver{}","","// GetResolutionTimeout returns a time.Duration for the amount of time a","// single git fetch may take. This can be configured with the","// fetch-timeout field in the git-resolver-config configmap.","func (r *Resolver) GetResolutionTimeout(ctx context.Context, defaultTimeout time.Duration, params map[string]string) (time.Duration, error) {","\tconf, err := GetScmConfigForParamConfigKey(ctx, params)","\tif err != nil {","\t\treturn time.Duration(0), err","\t}","\tif timeoutString := conf.Timeout; timeoutString != \"\" {","\t\ttimeout, err := time.ParseDuration(timeoutString)","\t\tif err != nil {","\t\t\treturn time.Duration(0), err","\t\t}","\t\treturn timeout, nil","\t}","\treturn defaultTimeout, nil","}","","func PopulateDefaultParams(ctx context.Context, params []pipelinev1.Param) (map[string]string, error) {","\tparamsMap := make(map[string]string)","\tfor _, p := range params {","\t\tparamsMap[p.Name] = p.Value.StringVal","\t}","","\tconf, err := GetScmConfigForParamConfigKey(ctx, paramsMap)","\tif err != nil {","\t\treturn nil, err","\t}","","\tvar missingParams []string","","\tif _, ok := paramsMap[RevisionParam]; !ok {","\t\tdefaultRevision := conf.Revision","\t\tif defaultRevision != \"\" {","\t\t\tparamsMap[RevisionParam] = defaultRevision","\t\t} else {","\t\t\tmissingParams = append(missingParams, RevisionParam)","\t\t}","\t}","\tif _, ok := paramsMap[PathParam]; !ok {","\t\tmissingParams = append(missingParams, PathParam)","\t}","","\tif paramsMap[UrlParam] != \"\" \u0026\u0026 paramsMap[RepoParam] != \"\" {","\t\treturn nil, fmt.Errorf(\"cannot specify both '%s' and '%s'\", UrlParam, RepoParam)","\t}","","\tif paramsMap[UrlParam] == \"\" \u0026\u0026 paramsMap[RepoParam] == \"\" {","\t\turlString := conf.URL","\t\tif urlString != \"\" {","\t\t\tparamsMap[UrlParam] = urlString","\t\t} else {","\t\t\treturn nil, fmt.Errorf(\"must specify one of '%s' or '%s'\", UrlParam, RepoParam)","\t\t}","\t}","","\tif paramsMap[RepoParam] != \"\" {","\t\tif _, ok := paramsMap[OrgParam]; !ok {","\t\t\tdefaultOrg := conf.Org","\t\t\tif defaultOrg != \"\" {","\t\t\t\tparamsMap[OrgParam] = defaultOrg","\t\t\t} else {","\t\t\t\treturn nil, fmt.Errorf(\"'%s' is required when '%s' is specified\", OrgParam, RepoParam)","\t\t\t}","\t\t}","\t}","\tif len(missingParams) \u003e 0 {","\t\treturn nil, fmt.Errorf(\"missing required git resolver params: %s\", strings.Join(missingParams, \", \"))","\t}","","\t// validate the url params if we are not using the SCM API","\tif paramsMap[RepoParam] == \"\" \u0026\u0026 paramsMap[OrgParam] == \"\" \u0026\u0026 !validateRepoURL(paramsMap[UrlParam]) {","\t\treturn nil, fmt.Errorf(\"invalid git repository url: %s\", paramsMap[UrlParam])","\t}","","\t// TODO(sbwsg): validate pathInRepo is valid relative pathInRepo","\treturn paramsMap, nil","}","","// supports the SPDX format which is recommended by in-toto","// ref: https://spdx.dev/spdx-specification-21-web-version/#h.49x2ik5","// ref: https://github.com/in-toto/attestation/blob/main/spec/field_types.md","func spdxGit(url string) string {","\treturn \"git+\" + url","}","","// resolvedGitResource implements framework.ResolvedResource and returns","// the resolved file []byte data and an annotation map for any metadata.","type resolvedGitResource struct {","\tRevision string","\tContent  []byte","\tOrg      string","\tRepo     string","\tPath     string","\tURL      string","}","","var _ framework.ResolvedResource = \u0026resolvedGitResource{}","","// Data returns the bytes of the file resolved from git.","func (r *resolvedGitResource) Data() []byte {","\treturn r.Content","}","","// Annotations returns the metadata that accompanies the file fetched","// from git.","func (r *resolvedGitResource) Annotations() map[string]string {","\tm := map[string]string{","\t\tAnnotationKeyRevision:           r.Revision,","\t\tAnnotationKeyPath:               r.Path,","\t\tAnnotationKeyURL:                r.URL,","\t\tcommon.AnnotationKeyContentType: yamlContentType,","\t}","","\tif r.Org != \"\" {","\t\tm[AnnotationKeyOrg] = r.Org","\t}","\tif r.Repo != \"\" {","\t\tm[AnnotationKeyRepo] = r.Repo","\t}","","\treturn m","}","","// RefSource is the source reference of the remote data that records where the remote","// file came from including the url, digest and the entrypoint.","func (r *resolvedGitResource) RefSource() *pipelinev1.RefSource {","\treturn \u0026pipelinev1.RefSource{","\t\tURI: spdxGit(r.URL),","\t\tDigest: map[string]string{","\t\t\t\"sha1\": r.Revision,","\t\t},","\t\tEntryPoint: r.Path,","\t}","}","","type secretCacheKey struct {","\tns   string","\tname string","\tkey  string","}","","func (g *GitResolver) getAPIToken(ctx context.Context, apiSecret *secretCacheKey, key string) ([]byte, error) {","\tconf, err := GetScmConfigForParamConfigKey(ctx, g.Params)","\tif err != nil {","\t\treturn nil, err","\t}","","\tok := false","","\t// NOTE(chmouel): only cache secrets when user hasn't passed params in their resolver configuration","\tcacheSecret := false","\tif apiSecret == nil {","\t\tcacheSecret = true","\t\tapiSecret = \u0026secretCacheKey{}","\t}","","\tif apiSecret.name == \"\" {","\t\tapiSecret.name = conf.APISecretName","\t\tif apiSecret.name == \"\" {","\t\t\terr := fmt.Errorf(\"cannot get API token, required when specifying '%s' param, '%s' not specified in config\", RepoParam, key)","\t\t\tg.Logger.Info(err)","\t\t\treturn nil, err","\t\t}","\t}","\tif apiSecret.key == \"\" {","\t\tapiSecret.key = conf.APISecretKey","\t\tif apiSecret.key == \"\" {","\t\t\terr := fmt.Errorf(\"cannot get API token, required when specifying '%s' param, '%s' not specified in config\", RepoParam, APISecretKeyKey)","\t\t\tg.Logger.Info(err)","\t\t\treturn nil, err","\t\t}","\t}","\tif apiSecret.ns == \"\" {","\t\tapiSecret.ns = conf.APISecretNamespace","\t\tif apiSecret.ns == \"\" {","\t\t\tapiSecret.ns = os.Getenv(\"SYSTEM_NAMESPACE\")","\t\t}","\t}","","\tif cacheSecret {","\t\tval, ok := g.Cache.Get(apiSecret)","\t\tif ok {","\t\t\treturn val.([]byte), nil","\t\t}","\t}","","\tsecret, err := g.KubeClient.CoreV1().Secrets(apiSecret.ns).Get(ctx, apiSecret.name, metav1.GetOptions{})","\tif err != nil {","\t\tif apierrors.IsNotFound(err) {","\t\t\tnotFoundErr := fmt.Errorf(\"cannot get API token, secret %s not found in namespace %s\", apiSecret.name, apiSecret.ns)","\t\t\tg.Logger.Info(notFoundErr)","\t\t\treturn nil, notFoundErr","\t\t}","\t\twrappedErr := fmt.Errorf(\"error reading API token from secret %s in namespace %s: %w\", apiSecret.name, apiSecret.ns, err)","\t\tg.Logger.Info(wrappedErr)","\t\treturn nil, wrappedErr","\t}","","\tsecretVal, ok := secret.Data[apiSecret.key]","\tif !ok {","\t\terr := fmt.Errorf(\"cannot get API token, key %s not found in secret %s in namespace %s\", apiSecret.key, apiSecret.name, apiSecret.ns)","\t\tg.Logger.Info(err)","\t\treturn nil, err","\t}","\tif cacheSecret {","\t\tg.Cache.Add(apiSecret, secretVal, ttl)","\t}","\treturn secretVal, nil","}","","func getSCMTypeAndServerURL(ctx context.Context, params map[string]string) (string, string, error) {","\tconf, err := GetScmConfigForParamConfigKey(ctx, params)","\tif err != nil {","\t\treturn \"\", \"\", err","\t}","","\tvar scmType, serverURL string","\tif key, ok := params[ScmTypeParam]; ok {","\t\tscmType = key","\t}","\tif scmType == \"\" {","\t\tscmType = conf.SCMType","\t}","\tif key, ok := params[ServerURLParam]; ok {","\t\tserverURL = key","\t}","\tif serverURL == \"\" {","\t\tserverURL = conf.ServerURL","\t}","\treturn scmType, serverURL, nil","}","","func IsDisabled(ctx context.Context) bool {","\tcfg := resolverconfig.FromContextOrDefaults(ctx)","\treturn !cfg.FeatureFlags.EnableGitResolver","}","","func GetScmConfigForParamConfigKey(ctx context.Context, params map[string]string) (ScmConfig, error) {","\tgitResolverConfig, err := GetGitResolverConfig(ctx)","\tif err != nil {","\t\treturn ScmConfig{}, err","\t}","\tif configKeyToUse, ok := params[ConfigKeyParam]; ok {","\t\tif config, exist := gitResolverConfig[configKeyToUse]; exist {","\t\t\treturn config, nil","\t\t}","\t\treturn ScmConfig{}, fmt.Errorf(\"no git resolver configuration found for configKey %s\", configKeyToUse)","\t}","\treturn gitResolverConfig[\"default\"], nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,1,1,2,0,0,0,0,2,2,2,0,0,0,2,2,2,2,2,0,0,0,2,2,2,0,0,0,2,2,2,2,0,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,0,2,2,2,2,0,0,0,0,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,2,2,1,1,2,2,1,1,1,1,0,2,2,1,1,1,1,0,0,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,1,1,0,2,2,2,2,0,2,2,1,1,0,2,2,2,2,0,2,2,2,2,2,2,0,0,0,2,2,1,1,0,2,2,1,1,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,1,1,0,0,2,2,1,1,0,0,2,2,1,1,0,2,2,2,2,2,2,2,2,0,0,0,0,0,2,2,2,0,0,0,0,0,0,2,2,2,1,1,2,2,2,1,1,2,0,2,0,0,2,2,2,2,2,0,2,2,1,1,0,2,2,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,0,2,2,2,1,2,2,2,0,0,2,2,2,2,1,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,0,0,0,0,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,2,2,2,1,1,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,1,1,0,0,2,2,2,1,1,0,0,2,2,2,2,2,2,2,1,1,1,0,0,2,2,1,1,1,1,2,2,2,2,0,0,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,0,2,0]},{"id":255,"path":"pkg/resolution/resolver/http/resolver.go","lines":["/*","Copyright 2023 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package http","","import (","\t\"context\"","\t\"crypto/sha256\"","\t\"crypto/sha512\"","\t\"crypto/subtle\"","\t\"encoding/base64\"","\t\"encoding/hex\"","\t\"errors\"","\t\"fmt\"","\t\"io\"","\t\"net/http\"","\t\"net/url\"","\t\"strings\"","\t\"time\"","","\tresolverconfig \"github.com/tektoncd/pipeline/pkg/apis/config/resolver\"","\tpipelinev1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tcommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"","\t\"go.uber.org/zap\"","\tapierrors \"k8s.io/apimachinery/pkg/api/errors\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/client-go/kubernetes\"","\tkubeclient \"knative.dev/pkg/client/injection/kube/client\"","\t\"knative.dev/pkg/logging\"",")","","const (","\t// LabelValueHttpResolverType is the value to use for the","\t// resolution.tekton.dev/type label on resource requests","\tLabelValueHttpResolverType string = \"http\"","","\tdisabledError = \"cannot handle resolution request, enable-http-resolver feature flag not true\"","","\t// httpResolverName The name of the resolver","\thttpResolverName = \"Http\"","","\t// configMapName is the http resolver's config map","\tconfigMapName = \"http-resolver-config\"","","\t// default Timeout value when fetching http resources in seconds","\tdefaultHttpTimeoutValue = \"1m\"","","\t// default key in the HTTP password secret","\tdefaultBasicAuthSecretKey = \"password\"","","\t// digestParam is the parameter name for the digest of the content","\tdigestParam = \"digest\"","","\t// sha512Algo is the prefix name for the sha512sum value","\tsha512Algo = \"sha512\"","","\t// sha256Algo is the prefix name for the sha256sum value","\tsha256Algo = \"sha256\"",")","","// Resolver implements a framework.Resolver that can fetch files from an HTTP URL","//","// Deprecated: Use [github.com/tektoncd/pipeline/pkg/remoteresolution/resolver/http.Resolver] instead.","type Resolver struct {","\tkubeClient kubernetes.Interface","\tlogger     *zap.SugaredLogger","}","","func (r *Resolver) Initialize(ctx context.Context) error {","\tr.kubeClient = kubeclient.Get(ctx)","\tr.logger = logging.FromContext(ctx)","\treturn nil","}","","// GetName returns a string name to refer to this resolver by.","func (r *Resolver) GetName(context.Context) string {","\treturn httpResolverName","}","","// GetConfigName returns the name of the http resolver's configmap.","func (r *Resolver) GetConfigName(context.Context) string {","\treturn configMapName","}","","// GetSelector returns a map of labels to match requests to this resolver.","func (r *Resolver) GetSelector(context.Context) map[string]string {","\treturn map[string]string{","\t\tcommon.LabelKeyResolverType: LabelValueHttpResolverType,","\t}","}","","// ValidateParams ensures parameters from a request are as expected.","func (r *Resolver) ValidateParams(ctx context.Context, params []pipelinev1.Param) error {","\treturn ValidateParams(ctx, params)","}","","// Resolve uses the given params to resolve the requested file or resource.","func (r *Resolver) Resolve(ctx context.Context, oParams []pipelinev1.Param) (framework.ResolvedResource, error) {","\tif IsDisabled(ctx) {","\t\treturn nil, errors.New(disabledError)","\t}","","\tparams, err := PopulateDefaultParams(ctx, oParams)","\tif err != nil {","\t\treturn nil, err","\t}","","\treturn FetchHttpResource(ctx, params, r.kubeClient, r.logger)","}","","func IsDisabled(ctx context.Context) bool {","\tcfg := resolverconfig.FromContextOrDefaults(ctx)","\treturn !cfg.FeatureFlags.EnableHttpResolver","}","","// resolvedHttpResource wraps the data we want to return to Pipelines","type resolvedHttpResource struct {","\tURL     string","\tContent []byte","}","","var _ framework.ResolvedResource = \u0026resolvedHttpResource{}","","// Data returns the bytes of our hard-coded Pipeline","func (rr *resolvedHttpResource) Data() []byte {","\treturn rr.Content","}","","// Annotations returns any metadata needed alongside the data. None atm.","func (*resolvedHttpResource) Annotations() map[string]string {","\treturn nil","}","","// RefSource is the source reference of the remote data that records where the remote","// file came from including the url, digest and the entrypoint.","func (rr *resolvedHttpResource) RefSource() *pipelinev1.RefSource {","\th := sha256.New()","\th.Write(rr.Content)","\tsha256CheckSum := hex.EncodeToString(h.Sum(nil))","","\treturn \u0026pipelinev1.RefSource{","\t\tURI: rr.URL,","\t\tDigest: map[string]string{","\t\t\t\"sha256\": sha256CheckSum,","\t\t},","\t}","}","","func PopulateDefaultParams(ctx context.Context, params []pipelinev1.Param) (map[string]string, error) {","\tparamsMap := make(map[string]string)","\tfor _, p := range params {","\t\tparamsMap[p.Name] = p.Value.StringVal","\t}","","\tvar missingParams []string","","\tif _, ok := paramsMap[UrlParam]; !ok {","\t\tmissingParams = append(missingParams, UrlParam)","\t} else {","\t\tu, err := url.ParseRequestURI(paramsMap[UrlParam])","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"cannot parse url %s: %w\", paramsMap[UrlParam], err)","\t\t}","\t\tif u.Scheme != \"http\" \u0026\u0026 u.Scheme != \"https\" {","\t\t\treturn nil, fmt.Errorf(\"url %s is not a valid http(s) url\", paramsMap[UrlParam])","\t\t}","\t}","","\tif username, ok := paramsMap[HttpBasicAuthUsername]; ok {","\t\tif _, ok := paramsMap[HttpBasicAuthSecret]; !ok {","\t\t\treturn nil, fmt.Errorf(\"missing required param %s when using %s\", HttpBasicAuthSecret, HttpBasicAuthUsername)","\t\t}","\t\tif username == \"\" {","\t\t\treturn nil, fmt.Errorf(\"value %s cannot be empty\", HttpBasicAuthUsername)","\t\t}","\t}","","\tif secret, ok := paramsMap[HttpBasicAuthSecret]; ok {","\t\tif _, ok := paramsMap[HttpBasicAuthUsername]; !ok {","\t\t\treturn nil, fmt.Errorf(\"missing required param %s when using %s\", HttpBasicAuthUsername, HttpBasicAuthSecret)","\t\t}","\t\tif secret == \"\" {","\t\t\treturn nil, fmt.Errorf(\"value %s cannot be empty\", HttpBasicAuthSecret)","\t\t}","\t}","","\tif len(missingParams) \u003e 0 {","\t\treturn nil, fmt.Errorf(\"missing required http resolver params: %s\", strings.Join(missingParams, \", \"))","\t}","","\treturn paramsMap, nil","}","","func makeHttpClient(ctx context.Context) (*http.Client, error) {","\tconf := framework.GetResolverConfigFromContext(ctx)","\ttimeout, _ := time.ParseDuration(defaultHttpTimeoutValue)","\tif v, ok := conf[TimeoutKey]; ok {","\t\tvar err error","\t\ttimeout, err = time.ParseDuration(v)","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"error parsing timeout value %s: %w\", v, err)","\t\t}","\t}","\treturn \u0026http.Client{","\t\tTimeout: timeout,","\t}, nil","}","","// compareSHA compares two hexadecimal SHA strings in constant time.","func compareSHA(expectedSHA string, computedSHA []byte) error {","\texpectedBytes, err := hex.DecodeString(expectedSHA)","\tif err != nil {","\t\treturn fmt.Errorf(\"error decoding expected SHA string: %w\", err)","\t}","","\tmatch := subtle.ConstantTimeCompare(expectedBytes, computedSHA)","\tif match != 1 {","\t\treturn fmt.Errorf(\"SHA mismatch, expected %s, got %s\", expectedSHA, hex.EncodeToString(computedSHA))","\t}","","\treturn nil","}","","func validateDigest(digest string, body []byte, logger *zap.SugaredLogger) error {","\tdigestValues := strings.SplitN(digest, \":\", 2)","\tif len(digestValues) != 2 {","\t\treturn fmt.Errorf(\"invalid digest format: %s\", digest)","\t}","\tdigestAlgo := digestValues[0]","\tif digestAlgo != sha512Algo \u0026\u0026 digestAlgo != sha256Algo {","\t\treturn fmt.Errorf(\"invalid digest algorithm: %s\", digestAlgo)","\t}","","\tdigestValue := digestValues[1]","","\tlogger.Infof(\"Validating %s with value %s to the content\", digestAlgo, digestValue)","\tswitch digestAlgo {","\tcase sha512Algo:","\t\tsha512Hash := sha512.Sum512(body)","\t\tif len(digestValue) != 128 {","\t\t\treturn fmt.Errorf(\"invalid sha512 digest value, expected length: 128, got: %d\", len(digestValue))","\t\t}","\t\treturn compareSHA(digestValue, sha512Hash[:])","\tcase sha256Algo:","\t\tsha256Hash := sha256.Sum256(body)","\t\tif len(digestValue) != 64 {","\t\t\treturn fmt.Errorf(\"invalid sha256 digest value, expected length: 64, got: %d\", len(digestValue))","\t\t}","\t\treturn compareSHA(digestValue, sha256Hash[:])","\t}","","\treturn nil","}","","func FetchHttpResource(ctx context.Context, params map[string]string, kubeclient kubernetes.Interface, logger *zap.SugaredLogger) (framework.ResolvedResource, error) {","\tvar targetURL string","\tvar ok bool","","\thttpClient, err := makeHttpClient(ctx)","\tif err != nil {","\t\treturn nil, err","\t}","","\tif targetURL, ok = params[UrlParam]; !ok {","\t\treturn nil, fmt.Errorf(\"missing required params: %s\", UrlParam)","\t}","","\treq, err := http.NewRequestWithContext(ctx, http.MethodGet, targetURL, nil)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"constructing request: %w\", err)","\t}","","\t// NOTE(chmouel): We already made sure that username and secret was specified by the user","\tif secret, ok := params[HttpBasicAuthSecret]; ok \u0026\u0026 secret != \"\" {","\t\tif encodedSecret, err := getBasicAuthSecret(ctx, params, kubeclient, logger); err != nil {","\t\t\treturn nil, err","\t\t} else {","\t\t\treq.Header.Set(\"Authorization\", encodedSecret)","\t\t}","\t}","","\tresp, err := httpClient.Do(req)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"error fetching URL: %w\", err)","\t}","\tif resp.StatusCode != http.StatusOK {","\t\treturn nil, fmt.Errorf(\"requested URL '%s' is not found\", targetURL)","\t}","\tdefer func() {","\t\t_ = resp.Body.Close()","\t}()","\tbody, err := io.ReadAll(resp.Body)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"error reading response body: %w\", err)","\t}","","\tdigest, ok := params[digestParam]","\tif ok {","\t\terr = validateDigest(digest, body, logger)","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"error validating digest: %w\", err)","\t\t}","\t}","","\treturn \u0026resolvedHttpResource{","\t\tContent: body,","\t\tURL:     targetURL,","\t}, nil","}","","func getBasicAuthSecret(ctx context.Context, params map[string]string, kubeclient kubernetes.Interface, logger *zap.SugaredLogger) (string, error) {","\tsecretName := params[HttpBasicAuthSecret]","\tuserName := params[HttpBasicAuthUsername]","\ttokenSecretKey := defaultBasicAuthSecretKey","\tif v, ok := params[HttpBasicAuthSecretKey]; ok {","\t\tif v != \"\" {","\t\t\ttokenSecretKey = v","\t\t}","\t}","\tsecretNS := common.RequestNamespace(ctx)","\tsecret, err := kubeclient.CoreV1().Secrets(secretNS).Get(ctx, secretName, metav1.GetOptions{})","\tif err != nil {","\t\tif apierrors.IsNotFound(err) {","\t\t\tnotFoundErr := fmt.Errorf(\"cannot get API token, secret %s not found in namespace %s\", secretName, secretNS)","\t\t\tlogger.Info(notFoundErr)","\t\t\treturn \"\", notFoundErr","\t\t}","\t\twrappedErr := fmt.Errorf(\"error reading API token from secret %s in namespace %s: %w\", secretName, secretNS, err)","\t\tlogger.Info(wrappedErr)","\t\treturn \"\", wrappedErr","\t}","\tsecretVal, ok := secret.Data[tokenSecretKey]","\tif !ok {","\t\terr := fmt.Errorf(\"cannot get API token, key %s not found in secret %s in namespace %s\", tokenSecretKey, secretName, secretNS)","\t\tlogger.Info(err)","\t\treturn \"\", err","\t}","\treturn \"Basic \" + base64.StdEncoding.EncodeToString(","\t\t[]byte(fmt.Sprintf(\"%s:%s\", userName, secretVal))), nil","}","","func ValidateParams(ctx context.Context, params []pipelinev1.Param) error {","\tif IsDisabled(ctx) {","\t\treturn errors.New(disabledError)","\t}","\t_, err := PopulateDefaultParams(ctx, params)","\tif err != nil {","\t\treturn err","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,2,2,0,0,2,2,2,0,0,2,2,2,2,0,2,2,2,2,0,2,0,0,2,2,2,2,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,0,0,0,2,2,2,2,2,0,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,1,0,0,2,2,2,2,2,2,1,1,0,2,1,1,0,2,2,1,1,0,0,2,2,2,2,2,2,0,0,2,2,1,1,2,2,2,2,2,2,2,2,1,1,0,2,2,1,1,1,1,0,0,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,1,1,1,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,0]},{"id":256,"path":"pkg/resolution/resolver/hub/resolver.go","lines":["/*","Copyright 2022 The Tekton Authors","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","    http://www.apache.org/licenses/LICENSE-2.0","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package hub","","import (","\t\"context\"","\t\"crypto/sha256\"","\t\"encoding/hex\"","\t\"encoding/json\"","\t\"errors\"","\t\"fmt\"","\t\"io\"","\t\"net/http\"","\t\"slices\"","\t\"strings\"","","\tgoversion \"github.com/hashicorp/go-version\"","\tresolverconfig \"github.com/tektoncd/pipeline/pkg/apis/config/resolver\"","\tpipelinev1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tcommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\t\"github.com/tektoncd/pipeline/pkg/resolution/resolver/framework\"",")","","const (","\t// LabelValueHubResolverType is the value to use for the","\t// resolution.tekton.dev/type label on resource requests","\tLabelValueHubResolverType string = \"hub\"","","\t// ArtifactHubType is the value to use setting the type field to artifact","\tArtifactHubType string = \"artifact\"","","\t// TektonHubType is the value to use setting the type field to tekton","\tTektonHubType string = \"tekton\"","","\tdisabledError = \"cannot handle resolution request, enable-hub-resolver feature flag not true\"",")","","var supportedKinds = []string{\"task\", \"pipeline\", \"stepaction\"}","","// Resolver implements a framework.Resolver that can fetch files from OCI bundles.","//","// Deprecated: Use [github.com/tektoncd/pipeline/pkg/remoteresolution/resolver/hub.Resolver] instead.","type Resolver struct {","\t// TektonHubURL is the URL for hub resolver with type tekton","\tTektonHubURL string","\t// ArtifactHubURL is the URL for hub resolver with type artifact","\tArtifactHubURL string","}","","// Initialize sets up any dependencies needed by the resolver. None atm.","func (r *Resolver) Initialize(context.Context) error {","\treturn nil","}","","// GetName returns a string name to refer to this resolver by.","func (r *Resolver) GetName(context.Context) string {","\treturn \"Hub\"","}","","// GetConfigName returns the name of the bundle resolver's configmap.","func (r *Resolver) GetConfigName(context.Context) string {","\treturn \"hubresolver-config\"","}","","// GetSelector returns a map of labels to match requests to this resolver.","func (r *Resolver) GetSelector(context.Context) map[string]string {","\treturn map[string]string{","\t\tcommon.LabelKeyResolverType: LabelValueHubResolverType,","\t}","}","","// ValidateParams ensures parameters from a request are as expected.","func (r *Resolver) ValidateParams(ctx context.Context, params []pipelinev1.Param) error {","\treturn ValidateParams(ctx, params, r.TektonHubURL)","}","","func ValidateParams(ctx context.Context, params []pipelinev1.Param, tektonHubUrl string) error {","\tif isDisabled(ctx) {","\t\treturn errors.New(disabledError)","\t}","","\tparamsMap, err := populateDefaultParams(ctx, params)","\tif err != nil {","\t\treturn fmt.Errorf(\"failed to populate default params: %w\", err)","\t}","\tif err := validateParams(ctx, paramsMap, tektonHubUrl); err != nil {","\t\treturn fmt.Errorf(\"failed to validate params: %w\", err)","\t}","","\treturn nil","}","","type tektonHubDataResponse struct {","\tYAML string `json:\"yaml\"`","}","","type tektonHubResponse struct {","\tData tektonHubDataResponse `json:\"data\"`","}","","type artifactHubDataResponse struct {","\tYAML string `json:\"manifestRaw\"`","}","","type artifactHubResponse struct {","\tData artifactHubDataResponse `json:\"data\"`","}","","// Resolve uses the given params to resolve the requested file or resource.","func (r *Resolver) Resolve(ctx context.Context, params []pipelinev1.Param) (framework.ResolvedResource, error) {","\treturn Resolve(ctx, params, r.TektonHubURL, r.ArtifactHubURL)","}","","func Resolve(ctx context.Context, params []pipelinev1.Param, tektonHubURL, artifactHubURL string) (framework.ResolvedResource, error) {","\tif isDisabled(ctx) {","\t\treturn nil, errors.New(disabledError)","\t}","","\tparamsMap, err := populateDefaultParams(ctx, params)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"failed to populate default params: %w\", err)","\t}","\tif err := validateParams(ctx, paramsMap, tektonHubURL); err != nil {","\t\treturn nil, fmt.Errorf(\"failed to validate params: %w\", err)","\t}","","\tif constraint, err := goversion.NewConstraint(paramsMap[ParamVersion]); err == nil {","\t\tchosen, err := resolveVersionConstraint(ctx, paramsMap, constraint, artifactHubURL, tektonHubURL)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\tparamsMap[ParamVersion] = chosen.String()","\t}","","\tresVer, err := resolveVersion(paramsMap[ParamVersion], paramsMap[ParamType])","\tif err != nil {","\t\treturn nil, err","\t}","\tparamsMap[ParamVersion] = resVer","","\t// call hub API","\tswitch paramsMap[ParamType] {","\tcase ArtifactHubType:","\t\turl := fmt.Sprintf(fmt.Sprintf(\"%s/%s\", artifactHubURL, ArtifactHubYamlEndpoint),","\t\t\tparamsMap[ParamKind], paramsMap[ParamCatalog], paramsMap[ParamName], paramsMap[ParamVersion])","\t\tresp := artifactHubResponse{}","\t\tif err := fetchHubResource(ctx, url, \u0026resp); err != nil {","\t\t\treturn nil, fmt.Errorf(\"fail to fetch Artifact Hub resource: %w\", err)","\t\t}","\t\treturn \u0026ResolvedHubResource{","\t\t\tURL:     url,","\t\t\tContent: []byte(resp.Data.YAML),","\t\t}, nil","\tcase TektonHubType:","\t\turl := fmt.Sprintf(fmt.Sprintf(\"%s/%s\", tektonHubURL, TektonHubYamlEndpoint),","\t\t\tparamsMap[ParamCatalog], paramsMap[ParamKind], paramsMap[ParamName], paramsMap[ParamVersion])","\t\tresp := tektonHubResponse{}","\t\tif err := fetchHubResource(ctx, url, \u0026resp); err != nil {","\t\t\treturn nil, fmt.Errorf(\"fail to fetch Tekton Hub resource: %w\", err)","\t\t}","\t\treturn \u0026ResolvedHubResource{","\t\t\tURL:     url,","\t\t\tContent: []byte(resp.Data.YAML),","\t\t}, nil","\t}","","\treturn nil, fmt.Errorf(\"hub resolver type: %s is not supported\", paramsMap[ParamType])","}","","// ResolvedHubResource wraps the data we want to return to Pipelines","type ResolvedHubResource struct {","\tURL     string","\tContent []byte","}","","var _ framework.ResolvedResource = \u0026ResolvedHubResource{}","","// Data returns the bytes of our hard-coded Pipeline","func (rr *ResolvedHubResource) Data() []byte {","\treturn rr.Content","}","","// Annotations returns any metadata needed alongside the data. None atm.","func (*ResolvedHubResource) Annotations() map[string]string {","\treturn nil","}","","// RefSource is the source reference of the remote data that records where the remote","// file came from including the url, digest and the entrypoint.","func (rr *ResolvedHubResource) RefSource() *pipelinev1.RefSource {","\th := sha256.New()","\th.Write(rr.Content)","\tsha256CheckSum := hex.EncodeToString(h.Sum(nil))","","\treturn \u0026pipelinev1.RefSource{","\t\tURI: rr.URL,","\t\tDigest: map[string]string{","\t\t\t\"sha256\": sha256CheckSum,","\t\t},","\t}","}","","func isDisabled(ctx context.Context) bool {","\tcfg := resolverconfig.FromContextOrDefaults(ctx)","\treturn !cfg.FeatureFlags.EnableHubResolver","}","","func fetchHubResource(ctx context.Context, apiEndpoint string, v interface{}) error {","\t// #nosec G107 -- URL cannot be constant in this case.","\treq, err := http.NewRequestWithContext(ctx, http.MethodGet, apiEndpoint, nil)","\tif err != nil {","\t\treturn fmt.Errorf(\"constructing request: %w\", err)","\t}","","\tresp, err := http.DefaultClient.Do(req)","\tif err != nil {","\t\treturn fmt.Errorf(\"requesting resource from Hub: %w\", err)","\t}","\tif resp.StatusCode != http.StatusOK {","\t\treturn fmt.Errorf(\"requested resource '%s' not found on hub\", apiEndpoint)","\t}","\tdefer func() {","\t\t_ = resp.Body.Close()","\t}()","\tbody, err := io.ReadAll(resp.Body)","\tif err != nil {","\t\treturn fmt.Errorf(\"error reading response body: %w\", err)","\t}","","\terr = json.Unmarshal(body, v)","\tif err != nil {","\t\treturn fmt.Errorf(\"error unmarshalling json response: %w\", err)","\t}","\treturn nil","}","","func resolveCatalogName(paramsMap, conf map[string]string) (string, error) {","\tvar configTHCatalog, configAHTaskCatalog, configAHPipelineCatalog string","\tvar ok bool","","\tif configTHCatalog, ok = conf[ConfigTektonHubCatalog]; !ok {","\t\treturn \"\", errors.New(\"default Tekton Hub catalog was not set during installation of the hub resolver\")","\t}","\tif configAHTaskCatalog, ok = conf[ConfigArtifactHubTaskCatalog]; !ok {","\t\treturn \"\", errors.New(\"default Artifact Hub task catalog was not set during installation of the hub resolver\")","\t}","\tif configAHPipelineCatalog, ok = conf[ConfigArtifactHubPipelineCatalog]; !ok {","\t\treturn \"\", errors.New(\"default Artifact Hub pipeline catalog was not set during installation of the hub resolver\")","\t}","\tif _, ok := paramsMap[ParamCatalog]; !ok {","\t\tswitch paramsMap[ParamType] {","\t\tcase ArtifactHubType:","\t\t\tswitch paramsMap[ParamKind] {","\t\t\tcase \"task\":","\t\t\t\treturn configAHTaskCatalog, nil","\t\t\tcase \"pipeline\":","\t\t\t\treturn configAHPipelineCatalog, nil","\t\t\tdefault:","\t\t\t\treturn \"\", fmt.Errorf(\"failed to resolve catalog name with kind: %s\", paramsMap[ParamKind])","\t\t\t}","\t\tcase TektonHubType:","\t\t\treturn configTHCatalog, nil","\t\tdefault:","\t\t\treturn \"\", fmt.Errorf(\"failed to resolve catalog name with type: %s\", paramsMap[ParamType])","\t\t}","\t}","","\treturn paramsMap[ParamCatalog], nil","}","","type artifactHubavailableVersionsResults struct {","\tVersion    string `json:\"version\"`","\tPrerelease bool   `json:\"prerelease\"`","}","","type artifactHubListResult struct {","\tAvailableVersions []artifactHubavailableVersionsResults `json:\"available_versions\"`","\tVersion           string                                `json:\"version\"`","}","","type tektonHubListResultVersion struct {","\tVersion string `json:\"version\"`","}","","type tektonHubListDataResult struct {","\tVersions []tektonHubListResultVersion `json:\"versions\"`","}","","type tektonHubListResult struct {","\tData tektonHubListDataResult `json:\"data\"`","}","","// the Artifact Hub follows the semVer (i.e. \u003cmajor-version\u003e.\u003cminor-version\u003e.0)","// the Tekton Hub follows the simplified semVer (i.e. \u003cmajor-version\u003e.\u003cminor-version\u003e)","// for resolution request with \"artifact\" type, we append \".0\" suffix if the input version is simplified semVer","// for resolution request with \"tekton\" type, we only use \u003cmajor-version\u003e.\u003cminor-version\u003e part of the input if it is semVer","func resolveVersion(version, hubType string) (string, error) {","\tsemVer := strings.Split(version, \".\")","\tresVer := version","","\tif hubType == ArtifactHubType \u0026\u0026 len(semVer) == 2 {","\t\tresVer = version + \".0\"","\t} else if hubType == TektonHubType \u0026\u0026 len(semVer) \u003e 2 {","\t\tresVer = strings.Join(semVer[0:2], \".\")","\t}","","\treturn resVer, nil","}","","func populateDefaultParams(ctx context.Context, params []pipelinev1.Param) (map[string]string, error) {","\tconf := framework.GetResolverConfigFromContext(ctx)","\tparamsMap := make(map[string]string)","\tfor _, p := range params {","\t\tparamsMap[p.Name] = p.Value.StringVal","\t}","","\t// type","\tif _, ok := paramsMap[ParamType]; !ok {","\t\tif typeString, ok := conf[ConfigType]; ok {","\t\t\tparamsMap[ParamType] = typeString","\t\t} else {","\t\t\treturn nil, errors.New(\"default type was not set during installation of the hub resolver\")","\t\t}","\t}","","\t// kind","\tif _, ok := paramsMap[ParamKind]; !ok {","\t\tif kindString, ok := conf[ConfigKind]; ok {","\t\t\tparamsMap[ParamKind] = kindString","\t\t} else {","\t\t\treturn nil, errors.New(\"default resource kind was not set during installation of the hub resolver\")","\t\t}","\t}","","\t// catalog","\tresCatName, err := resolveCatalogName(paramsMap, conf)","\tif err != nil {","\t\treturn nil, err","\t}","\tparamsMap[ParamCatalog] = resCatName","","\treturn paramsMap, nil","}","","func validateParams(ctx context.Context, paramsMap map[string]string, tektonHubURL string) error {","\tvar missingParams []string","\tif _, ok := paramsMap[ParamName]; !ok {","\t\tmissingParams = append(missingParams, ParamName)","\t}","\tif _, ok := paramsMap[ParamVersion]; !ok {","\t\tmissingParams = append(missingParams, ParamVersion)","\t}","\tif kind, ok := paramsMap[ParamKind]; ok {","\t\tif !isSupportedKind(kind) {","\t\t\treturn fmt.Errorf(\"kind param must be one of: %s\", strings.Join(supportedKinds, \", \"))","\t\t}","\t}","\tif hubType, ok := paramsMap[ParamType]; ok {","\t\tif hubType != ArtifactHubType \u0026\u0026 hubType != TektonHubType {","\t\t\treturn fmt.Errorf(\"type param must be %s or %s\", ArtifactHubType, TektonHubType)","\t\t}","","\t\tif hubType == TektonHubType \u0026\u0026 tektonHubURL == \"\" {","\t\t\treturn errors.New(\"please configure TEKTON_HUB_API env variable to use tekton type\")","\t\t}","\t}","","\tif len(missingParams) \u003e 0 {","\t\treturn fmt.Errorf(\"missing required hub resolver params: %s\", strings.Join(missingParams, \", \"))","\t}","","\treturn nil","}","","func resolveVersionConstraint(ctx context.Context, paramsMap map[string]string, constraint goversion.Constraints, artifactHubURL, tektonHubURL string) (*goversion.Version, error) {","\tvar ret *goversion.Version","\tif paramsMap[ParamType] == ArtifactHubType {","\t\tallVersionsURL := fmt.Sprintf(\"%s/%s\", artifactHubURL, fmt.Sprintf(","\t\t\tArtifactHubListTasksEndpoint,","\t\t\tparamsMap[ParamKind], paramsMap[ParamCatalog], paramsMap[ParamName]))","\t\tresp := artifactHubListResult{}","\t\tif err := fetchHubResource(ctx, allVersionsURL, \u0026resp); err != nil {","\t\t\treturn nil, fmt.Errorf(\"fail to fetch Artifact Hub resource: %w\", err)","\t\t}","\t\tfor _, vers := range resp.AvailableVersions {","\t\t\tif vers.Prerelease {","\t\t\t\tcontinue","\t\t\t}","\t\t\tcheckV, err := goversion.NewVersion(vers.Version)","\t\t\tif err != nil {","\t\t\t\treturn nil, fmt.Errorf(\"fail to parse version %s from %s: %w\", ArtifactHubType, vers.Version, err)","\t\t\t}","\t\t\tif checkV == nil {","\t\t\t\tcontinue","\t\t\t}","\t\t\tif constraint.Check(checkV) {","\t\t\t\tif ret != nil \u0026\u0026 ret.GreaterThan(checkV) {","\t\t\t\t\tcontinue","\t\t\t\t}","\t\t\t\t// TODO(chmouel): log constraint result in controller","\t\t\t\tret = checkV","\t\t\t}","\t\t}","\t} else if paramsMap[ParamType] == TektonHubType {","\t\tallVersionsURL := fmt.Sprintf(\"%s/%s\", tektonHubURL,","\t\t\tfmt.Sprintf(TektonHubListTasksEndpoint,","\t\t\t\tparamsMap[ParamCatalog], paramsMap[ParamKind], paramsMap[ParamName]))","\t\tresp := tektonHubListResult{}","\t\tif err := fetchHubResource(ctx, allVersionsURL, \u0026resp); err != nil {","\t\t\treturn nil, fmt.Errorf(\"fail to fetch Tekton Hub resource: %w\", err)","\t\t}","\t\tfor _, vers := range resp.Data.Versions {","\t\t\tcheckV, err := goversion.NewVersion(vers.Version)","\t\t\tif err != nil {","\t\t\t\treturn nil, fmt.Errorf(\"fail to parse version %s from %s: %w\", TektonHubType, vers, err)","\t\t\t}","\t\t\tif checkV == nil {","\t\t\t\tcontinue","\t\t\t}","\t\t\tif constraint.Check(checkV) {","\t\t\t\tif ret != nil \u0026\u0026 ret.GreaterThan(checkV) {","\t\t\t\t\tcontinue","\t\t\t\t}","\t\t\t\t// TODO(chmouel): log constraint result in controller","\t\t\t\tret = checkV","\t\t\t}","\t\t}","\t}","\tif ret == nil {","\t\treturn nil, fmt.Errorf(\"no version found for constraint %s\", paramsMap[ParamVersion])","\t}","\treturn ret, nil","}","","func isSupportedKind(kindValue string) bool {","\treturn slices.Contains[[]string, string](supportedKinds, kindValue)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,1,0,0,1,1,1,0,0,2,2,2,2,2,0,0,2,2,2,0,2,2,2,2,0,2,2,2,2,2,2,2,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,2,2,2,2,0,2,2,1,1,2,1,1,0,2,2,2,2,2,2,0,0,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,1,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,2,2,2,2,0,2,2,2,2,1,1,0,2,2,1,1,2,1,1,2,2,2,2,2,1,1,0,2,2,2,2,2,0,0,2,2,2,2,2,1,1,2,1,1,2,1,1,2,2,2,2,2,2,2,2,2,2,0,2,2,1,1,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,0,0,2,2,2,2,1,1,0,0,0,2,1,1,1,1,1,0,0,0,2,2,2,2,2,2,2,0,0,2,2,2,1,1,2,1,1,2,2,2,2,0,2,2,2,2,0,2,2,2,0,0,2,1,1,0,2,0,0,2,2,2,2,2,2,2,2,1,1,2,2,1,0,2,2,1,1,2,1,0,2,2,1,0,0,2,0,0,2,2,2,2,2,2,1,1,2,2,2,1,1,2,1,0,2,2,1,0,0,2,0,0,0,2,2,2,2,0,0,2,2,2]},{"id":257,"path":"pkg/resolution/resource/crd_resource.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resource","","import (","\t\"context\"","\t\"encoding/base64\"","\t\"errors\"","\t\"fmt\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\trrclient \"github.com/tektoncd/pipeline/pkg/client/resolution/clientset/versioned\"","\trrlisters \"github.com/tektoncd/pipeline/pkg/client/resolution/listers/resolution/v1beta1\"","\tcommon \"github.com/tektoncd/pipeline/pkg/resolution/common\"","\tapierrors \"k8s.io/apimachinery/pkg/api/errors\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"knative.dev/pkg/apis\"",")","","// CRDRequester implements the Requester interface using","// ResolutionRequest CRDs.","//","// Deprecated: Use [github.com/tektoncd/pipeline/pkg/remoteresolution/resource.CRDRequester] instead.","type CRDRequester struct {","\tclientset rrclient.Interface","\tlister    rrlisters.ResolutionRequestLister","}","","// NewCRDRequester returns an implementation of Requester that uses","// ResolutionRequest CRD objects to mediate between the caller who wants a","// resource (e.g. Tekton Pipelines) and the responder who can fetch","// it (e.g. the gitresolver)","//","// Deprecated: Use [github.com/tektoncd/pipeline/pkg/remoteresolution/resource.NewCRDRequester] instead.","func NewCRDRequester(clientset rrclient.Interface, lister rrlisters.ResolutionRequestLister) *CRDRequester {","\treturn \u0026CRDRequester{clientset, lister}","}","","var _ Requester = \u0026CRDRequester{}","","// Submit constructs a ResolutionRequest object and submits it to the","// kubernetes cluster, returning any errors experienced while doing so.","// If ResolutionRequest is succeeded then it returns the resolved data.","func (r *CRDRequester) Submit(ctx context.Context, resolver ResolverName, req Request) (ResolvedResource, error) {","\trr, _ := r.lister.ResolutionRequests(req.Namespace()).Get(req.Name())","\tif rr == nil {","\t\tif err := r.createResolutionRequest(ctx, resolver, req); err != nil \u0026\u0026","\t\t\t// When the request reconciles frequently, the creation may fail","\t\t\t// because the list informer cache is not updated.","\t\t\t// If the request already exists then we can assume that is in progress.","\t\t\t// The next reconcile will handle it based on the actual situation.","\t\t\t!apierrors.IsAlreadyExists(err) {","\t\t\treturn nil, err","\t\t}","\t\treturn nil, common.ErrRequestInProgress","\t}","","\tif rr.Status.GetCondition(apis.ConditionSucceeded).IsUnknown() {","\t\t// TODO(sbwsg): This should be where an existing","\t\t// resource is given an additional owner reference so","\t\t// that it doesn't get deleted until the caller is done","\t\t// with it. Use appendOwnerReference and then submit","\t\t// update to ResolutionRequest.","\t\treturn nil, common.ErrRequestInProgress","\t}","","\tif rr.Status.GetCondition(apis.ConditionSucceeded).IsTrue() {","\t\treturn CrdIntoResource(rr), nil","\t}","","\tmessage := rr.Status.GetCondition(apis.ConditionSucceeded).GetMessage()","\terr := common.NewError(common.ReasonResolutionFailed, errors.New(message))","\treturn nil, err","}","","func (r *CRDRequester) createResolutionRequest(ctx context.Context, resolver ResolverName, req Request) error {","\tvar owner metav1.OwnerReference","\tif ownedReq, ok := req.(OwnedRequest); ok {","\t\towner = ownedReq.OwnerRef()","\t}","\trr := CreateResolutionRequest(ctx, resolver, req.Name(), req.Namespace(), req.Params(), owner)","\t_, err := r.clientset.ResolutionV1beta1().ResolutionRequests(rr.Namespace).Create(ctx, rr, metav1.CreateOptions{})","\treturn err","}","","func CreateResolutionRequest(ctx context.Context, resolver common.ResolverName, name, namespace string, params []v1.Param, ownerRef metav1.OwnerReference) *v1beta1.ResolutionRequest {","\trr := \u0026v1beta1.ResolutionRequest{","\t\tTypeMeta: metav1.TypeMeta{","\t\t\tAPIVersion: \"resolution.tekton.dev/v1beta1\",","\t\t\tKind:       \"ResolutionRequest\",","\t\t},","\t\tObjectMeta: metav1.ObjectMeta{","\t\t\tName:      name,","\t\t\tNamespace: namespace,","\t\t\tLabels: map[string]string{","\t\t\t\tcommon.LabelKeyResolverType: string(resolver),","\t\t\t},","\t\t},","\t\tSpec: v1beta1.ResolutionRequestSpec{","\t\t\tParams: params,","\t\t},","\t}","\tappendOwnerReference(rr, ownerRef)","\treturn rr","}","","func appendOwnerReference(rr *v1beta1.ResolutionRequest, ownerRef metav1.OwnerReference) {","\tisOwner := false","\tfor _, ref := range rr.ObjectMeta.OwnerReferences {","\t\tif ownerRefsAreEqual(ref, ownerRef) {","\t\t\tisOwner = true","\t\t}","\t}","\tif !isOwner {","\t\trr.ObjectMeta.OwnerReferences = append(rr.ObjectMeta.OwnerReferences, ownerRef)","\t}","}","","func ownerRefsAreEqual(a, b metav1.OwnerReference) bool {","\t// pointers values cannot be directly compared.","\tif (a.Controller == nil \u0026\u0026 b.Controller != nil) ||","\t\t(a.Controller != nil \u0026\u0026 b.Controller == nil) ||","\t\t(*a.Controller != *b.Controller) {","\t\treturn false","\t}","\treturn a.APIVersion == b.APIVersion \u0026\u0026 a.Kind == b.Kind \u0026\u0026 a.Name == b.Name \u0026\u0026 a.UID == b.UID","}","","// ReadOnlyResolutionRequest is an opaque wrapper around ResolutionRequest","// that provides the methods needed to read data from it using the","// Resource interface without exposing the underlying API","// object.","type ReadOnlyResolutionRequest struct {","\treq *v1beta1.ResolutionRequest","}","","var _ common.ResolvedResource = ReadOnlyResolutionRequest{}","","func CrdIntoResource(rr *v1beta1.ResolutionRequest) ReadOnlyResolutionRequest {","\treturn ReadOnlyResolutionRequest{req: rr}","}","","func (r ReadOnlyResolutionRequest) Annotations() map[string]string {","\tstatus := r.req.GetStatus()","\tif status != nil \u0026\u0026 status.Annotations != nil {","\t\tannotationsCopy := map[string]string{}","\t\tfor key, val := range status.Annotations {","\t\t\tannotationsCopy[key] = val","\t\t}","\t\treturn annotationsCopy","\t}","\treturn nil","}","","func (r ReadOnlyResolutionRequest) Data() ([]byte, error) {","\tencodedData := r.req.Status.ResolutionRequestStatusFields.Data","\tdecodedBytes, err := base64.StdEncoding.Strict().DecodeString(encodedData)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"error decoding data from base64: %w\", err)","\t}","\treturn decodedBytes, nil","}","","func (r ReadOnlyResolutionRequest) RefSource() *v1.RefSource {","\treturn r.req.Status.RefSource","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,1,1,2,0,0,2,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,0,0,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,1,1,1,0,2,2,2,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,2,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,1,1,2,0,0,2,2,2]},{"id":258,"path":"pkg/resolution/resource/name.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resource","","import (","\t\"fmt\"","\t\"hash\"","\t\"hash/fnv\"","\t\"sort\"","\t\"strings\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/resolution/v1beta1\"","\t\"k8s.io/apimachinery/pkg/util/validation\"","\t\"knative.dev/pkg/kmeta\"",")","","const (","\t// ParamName is a param that explicitly assigns a name to the remote object","\tParamName = \"name\"","","\t// ParamURL is a param that hold the URL used for accesing the remote object","\tParamURL = \"url\"",")","","//","","const maxLength = validation.DNS1123LabelMaxLength","","// GenerateDeterministicName makes a best-effort attempt to create a","// unique but reproducible name for use in a Request. The returned value","// will have the format {prefix}-{hash} where {prefix} is","// given and {hash} is nameHasher(base) + nameHasher(param1) +","// nameHasher(param2) + ...","func GenerateDeterministicName(prefix, base string, params v1.Params) (string, error) {","\treturn GenerateDeterministicNameFromSpec(prefix, base, \u0026v1beta1.ResolutionRequestSpec{Params: params})","}","","// GetNameAndNamespace determines the name and namespace for a resource request.","// It prioritizes explicit values, falling back to the owning object and \"default\" namespace.","// If needed, it generates a deterministic name to prevent duplicate requests within a context.","func GetNameAndNamespace(resolverName string, owner kmeta.OwnerRefable, name string, namespace string, req *v1beta1.ResolutionRequestSpec) (string, string, error) {","\tif name == \"\" {","\t\tname = owner.GetObjectMeta().GetName()","\t\tnamespace = owner.GetObjectMeta().GetNamespace()","\t}","\tif namespace == \"\" {","\t\tnamespace = \"default\"","\t}","\t// Generating a deterministic name for the resource request","\t// prevents multiple requests being issued for the same","\t// pipelinerun's pipelineRef or taskrun's taskRef.","\tremoteResourceBaseName := namespace + \"/\" + name","\tname, err := GenerateDeterministicNameFromSpec(resolverName, remoteResourceBaseName, req)","\tif err != nil {","\t\treturn \"\", \"\", fmt.Errorf(\"error generating name for taskrun %s/%s: %w\", namespace, name, err)","\t}","\treturn name, namespace, nil","}","","// nameHasher returns the hash.Hash to use when generating names.","func nameHasher() hash.Hash {","\treturn fnv.New128a()","}","","// GenerateDeterministicNameFromSpec makes a best-effort attempt to create a","// unique but reproducible name for use in a Request. The returned value","// will have the format {prefix}-{hash} where {prefix} is","// given and {hash} is nameHasher(base) + nameHasher(param1) +","// nameHasher(param2) + ...","func GenerateDeterministicNameFromSpec(prefix, base string, resolutionSpec *v1beta1.ResolutionRequestSpec) (string, error) {","\thasher := nameHasher()","\tif _, err := hasher.Write([]byte(base)); err != nil {","\t\treturn \"\", err","\t}","","\tif resolutionSpec == nil {","\t\treturn fmt.Sprintf(\"%s-%x\", prefix, hasher.Sum(nil)), nil","\t}","\tparams := resolutionSpec.Params","\tsortedParams := make(v1.Params, len(params))","\tfor i := range params {","\t\tsortedParams[i] = *params[i].DeepCopy()","\t}","\tsort.SliceStable(sortedParams, func(i, j int) bool {","\t\treturn sortedParams[i].Name \u003c sortedParams[j].Name","\t})","\tfor _, p := range sortedParams {","\t\tif _, err := hasher.Write([]byte(p.Name)); err != nil {","\t\t\treturn \"\", err","\t\t}","\t\tswitch p.Value.Type {","\t\tcase v1.ParamTypeString:","\t\t\tif _, err := hasher.Write([]byte(p.Value.StringVal)); err != nil {","\t\t\t\treturn \"\", err","\t\t\t}","\t\tcase v1.ParamTypeArray, v1.ParamTypeObject:","\t\t\tasJSON, err := p.Value.MarshalJSON()","\t\t\tif err != nil {","\t\t\t\treturn \"\", err","\t\t\t}","\t\t\tif _, err := hasher.Write(asJSON); err != nil {","\t\t\t\treturn \"\", err","\t\t\t}","\t\t}","\t}","\tif len(resolutionSpec.URL) \u003e 0 {","\t\tif _, err := hasher.Write([]byte(resolutionSpec.URL)); err != nil {","\t\t\treturn \"\", err","\t\t}","\t}","\tname := fmt.Sprintf(\"%s-%x\", prefix, hasher.Sum(nil))","\tif maxLength \u003e len(name) {","\t\treturn name, nil","\t}","\treturn name[:strings.LastIndex(name[:maxLength], \" \")], nil","}","","// GenerateErrorLogString makes a best effort attempt to get the name of the task","// when a resolver error occurred.  The TaskRef name does not have to be set, where","// the specific resolver gets the name from the parameters.","func GenerateErrorLogString(resolverType string, params v1.Params) string {","\tparamString := fmt.Sprintf(\"resolver type %s\\n\", resolverType)","\tfor _, p := range params {","\t\tif p.Name == ParamName {","\t\t\tname := p.Value.StringVal","\t\t\tif p.Value.Type != v1.ParamTypeString {","\t\t\t\tasJSON, err := p.Value.MarshalJSON()","\t\t\t\tif err != nil {","\t\t\t\t\tparamString += fmt.Sprintf(\"name could not be marshalled: %s\\n\", err.Error())","\t\t\t\t\tcontinue","\t\t\t\t}","\t\t\t\tname = string(asJSON)","\t\t\t}","\t\t\tparamString += fmt.Sprintf(\"name = %s\\n\", name)","\t\t}","\t\tif p.Name == ParamURL {","\t\t\tparamString += fmt.Sprintf(\"url = %s\\n\", p.Value.StringVal)","\t\t}","\t}","\treturn paramString","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,0,0,0,2,2,2,0,0,0,0,0,0,2,2,2,1,1,0,2,1,1,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,1,1,2,2,2,1,1,2,1,1,0,0,2,2,1,1,0,2,2,2,2,1,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,0,2,0,2,2,2,0,2,0]},{"id":259,"path":"pkg/resolution/resource/request.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package resource","","import v1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","","var _ Request = \u0026BasicRequest{}","","// BasicRequest holds the fields needed to submit a new resource request.","//","// Deprecated: Use [github.com/tektoncd/pipeline/pkg/remoteresolution/resource.BasicRequest] instead.","type BasicRequest struct {","\tname      string","\tnamespace string","\tparams    v1.Params","}","","// NewRequest returns an instance of a BasicRequest with the given name,","// namespace and params.","//","// Deprecated: Use [github.com/tektoncd/pipeline/pkg/remoteresolution/resource.NewRequest] instead.","func NewRequest(name, namespace string, params v1.Params) Request {","\treturn \u0026BasicRequest{name, namespace, params}","}","","// Name returns the name attached to the request","func (req *BasicRequest) Name() string {","\treturn req.name","}","","// Namespace returns the namespace that the request is associated with","func (req *BasicRequest) Namespace() string {","\treturn req.namespace","}","","// Params are the map of parameters associated with this request","func (req *BasicRequest) Params() v1.Params {","\treturn req.params","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2]},{"id":260,"path":"pkg/result/result.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package result","","import (","\t\"encoding/json\"","\t\"errors\"","\t\"fmt\"",")","","const (","\t// TaskRunResultType default task run result value","\tTaskRunResultType ResultType = 1","\t// reserved: 2","\t// was RunResultType","","\t// InternalTektonResultType default internal tekton result value","\tInternalTektonResultType = 3","\t// UnknownResultType default unknown result type value","\tUnknownResultType = 10","\t// StepResultType default step result value","\tStepResultType ResultType = 4","","\t// StepArtifactsResultType default step artifacts result value","\tStepArtifactsResultType ResultType = 5","","\t// TaskRunArtifactsResultType default taskRun artifacts result value","\tTaskRunArtifactsResultType ResultType = 6",")","","// RunResult is used to write key/value pairs to TaskRun pod termination messages.","// The key/value pairs may come from the entrypoint binary, or represent a TaskRunResult.","// If they represent a TaskRunResult, the key is the name of the result and the value is the","// JSON-serialized value of the result.","type RunResult struct {","\tKey   string `json:\"key\"`","\tValue string `json:\"value\"`","\t// ResourceName may be used in tests, but it is not populated in termination messages.","\t// It is preserved here for backwards compatibility and will not be ported to v1.","\tResourceName string     `json:\"resourceName,omitempty\"`","\tResultType   ResultType `json:\"type,omitempty\"`","}","","// ResultType used to find out whether a RunResult is from a task result or not","// Note that ResultsType is another type which is used to define the data type","// (e.g. string, array, etc) we used for Results","//","//nolint:revive // revive complains about stutter of `result.ResultType`.","type ResultType int","","// UnmarshalJSON unmarshals either an int or a string into a ResultType. String","// ResultTypes were removed because they made JSON messages bigger, which in","// turn limited the amount of space in termination messages for task results. String","// support is maintained for backwards compatibility - the Pipelines controller could","// be stopped midway through TaskRun execution, updated with support for int in place","// of string, and then fail the running TaskRun because it doesn't know how to interpret","// the string value that the TaskRun's entrypoint will emit when it completes.","func (r *ResultType) UnmarshalJSON(data []byte) error {","\tvar asInt int","\tvar intErr error","","\tif err := json.Unmarshal(data, \u0026asInt); err != nil {","\t\tintErr = err","\t} else {","\t\t*r = ResultType(asInt)","\t\treturn nil","\t}","","\tvar asString string","","\tif err := json.Unmarshal(data, \u0026asString); err != nil {","\t\treturn fmt.Errorf(\"unsupported value type, neither int nor string: %w\", errors.Join(intErr, err))","\t}","","\tswitch asString {","\tcase \"StepResult\":","\t\t*r = StepResultType","\tcase \"TaskRunResult\":","\t\t*r = TaskRunResultType","\tcase \"InternalTektonResult\":","\t\t*r = InternalTektonResultType","\tcase \"StepArtifactsResult\":","\t\t*r = StepArtifactsResultType","\tcase \"TaskRunArtifactsResult\":","\t\t*r = TaskRunArtifactsResultType","\tdefault:","\t\t*r = UnknownResultType","\t}","","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,1,1,0,0,2,0]},{"id":261,"path":"pkg/spire/config/config.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package config","","import (","\t\"errors\"","\t\"fmt\"","\t\"sort\"","\t\"strings\"",")","","// SpireConfig holds the images reference for a number of container images used","// across tektoncd pipelines.","// +k8s:deepcopy-gen=true","type SpireConfig struct {","\t// The trust domain corresponds to the trust root of a SPIFFE identity provider.","\tTrustDomain string","\t// Path to the spire agent socket defined by the CSI driver","\tSocketPath string","\t// Spire server address","\tServerAddr string","\t// Prefix to attach to the node name when registering it with the spire server","\tNodeAliasPrefix string","","\t// MockSpire only to be used for testing the controller, will not exhibit","\t// all characteristics of spire since it is only being used in the context","\t// of process memory.","\tMockSpire bool","}","","// Validate returns an error if any image is not set.","func (c SpireConfig) Validate() error {","\tvar unset []string","\tfor _, f := range []struct {","\t\tv, name string","\t}{","\t\t{c.TrustDomain, \"spire-trust-domain\"},","\t\t{c.SocketPath, \"spire-socket-path\"},","\t\t{c.ServerAddr, \"spire-server-addr\"},","\t\t{c.NodeAliasPrefix, \"spire-node-alias-prefix\"},","\t} {","\t\tif f.v == \"\" {","\t\t\tunset = append(unset, f.name)","\t\t}","\t}","\tif len(unset) \u003e 0 {","\t\tsort.Strings(unset)","\t\treturn fmt.Errorf(\"found unset spire configuration flags: %s\", unset)","\t}","","\tif !strings.HasPrefix(c.NodeAliasPrefix, \"/\") {","\t\treturn errors.New(\"Spire node alias should start with a /\")","\t}","","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,0,1,0]},{"id":262,"path":"pkg/spire/controller.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package spire","","import (","\t\"context\"","\t\"fmt\"","\t\"time\"","","\t\"github.com/pkg/errors\"","\t\"github.com/spiffe/go-spiffe/v2/spiffetls/tlsconfig\"","\t\"github.com/spiffe/go-spiffe/v2/svid/x509svid\"","\t\"github.com/spiffe/go-spiffe/v2/workloadapi\"","\tentryv1 \"github.com/spiffe/spire-api-sdk/proto/spire/api/server/entry/v1\"","\tspiffetypes \"github.com/spiffe/spire-api-sdk/proto/spire/api/types\"","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\tspireconfig \"github.com/tektoncd/pipeline/pkg/spire/config\"","\t\"go.uber.org/zap\"","\t\"google.golang.org/grpc\"","\t\"google.golang.org/grpc/codes\"","\t\"google.golang.org/grpc/credentials\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/client-go/rest\"","\t\"knative.dev/pkg/injection\"","\t\"knative.dev/pkg/logging\"",")","","func init() {","\tinjection.Default.RegisterClient(withControllerClient)","}","","// controllerKey is a way to associate the ControllerAPIClient from inside the context.Context","type controllerKey struct{}","","// OnStore stores the changed spire config into the SpireClientApi","func OnStore(ctx context.Context, logger *zap.SugaredLogger) func(name string, value interface{}) {","\treturn func(name string, value interface{}) {","\t\tif name == config.GetSpireConfigName() {","\t\t\tcfg, ok := value.(*spireconfig.SpireConfig)","\t\t\tif !ok {","\t\t\t\tlogger.Error(\"Failed to do type assertion for extracting SPIRE config\")","\t\t\t\treturn","\t\t\t}","\t\t\tcontrollerAPIClient := GetControllerAPIClient(ctx)","\t\t\tcontrollerAPIClient.Close()","\t\t\tcontrollerAPIClient.SetConfig(*cfg)","\t\t}","\t}","}","","// GetControllerAPIClient extracts the ControllerAPIClient from the context.","func GetControllerAPIClient(ctx context.Context) ControllerAPIClient {","\tuntyped := ctx.Value(controllerKey{})","\tif untyped == nil {","\t\tlogging.FromContext(ctx).Errorf(\"Unable to fetch client from context.\")","\t\treturn nil","\t}","\treturn untyped.(ControllerAPIClient)","}","","func withControllerClient(ctx context.Context, cfg *rest.Config) context.Context {","\treturn context.WithValue(ctx, controllerKey{}, \u0026spireControllerAPIClient{})","}","","type spireControllerAPIClient struct {","\tconfig       *spireconfig.SpireConfig","\tserverConn   *grpc.ClientConn","\tworkloadConn *workloadapi.X509Source","\tentryClient  entryv1.EntryClient","\tworkloadAPI  *workloadapi.Client","}","","var _ ControllerAPIClient = (*spireControllerAPIClient)(nil)","","func (sc *spireControllerAPIClient) setupClient(ctx context.Context) error {","\tif sc.config == nil {","\t\treturn errors.New(\"config has not been set yet\")","\t}","\tif sc.entryClient == nil || sc.workloadConn == nil || sc.workloadAPI == nil || sc.serverConn == nil {","\t\treturn sc.dial(ctx)","\t}","\treturn nil","}","","func (sc *spireControllerAPIClient) dial(ctx context.Context) error {","\tif sc.workloadConn == nil {","\t\t// Create X509Source - https://github.com/spiffe/go-spiffe/blob/main/v2/workloadapi/client.go","\t\tsource, err := workloadapi.NewX509Source(ctx, workloadapi.WithClientOptions(workloadapi.WithAddr(sc.config.SocketPath)))","\t\tif err != nil {","\t\t\treturn fmt.Errorf(\"unable to create X509Source for SPIFFE client: %w\", err)","\t\t}","\t\tsc.workloadConn = source","\t}","","\tif sc.workloadAPI == nil {","\t\t// spire workloadapi client for controller - https://github.com/spiffe/go-spiffe/blob/main/v2/workloadapi/client.go","\t\tclient, err := workloadapi.New(ctx, workloadapi.WithAddr(sc.config.SocketPath))","\t\tif err != nil {","\t\t\treturn fmt.Errorf(\"spire workload API not initialized due to error: %w\", err)","\t\t}","\t\tsc.workloadAPI = client","\t}","","\tif sc.serverConn == nil {","\t\t// Create connection to spire server","\t\ttlsConfig := tlsconfig.MTLSClientConfig(sc.workloadConn, sc.workloadConn, tlsconfig.AuthorizeAny())","\t\tconn, err := grpc.DialContext(ctx, sc.config.ServerAddr, grpc.WithTransportCredentials(credentials.NewTLS(tlsConfig)))","\t\tif err != nil {","\t\t\tsc.workloadConn.Close()","\t\t\tsc.workloadConn = nil","\t\t\treturn fmt.Errorf(\"unable to dial SPIRE server: %w\", err)","\t\t}","\t\tsc.serverConn = conn","\t}","","\tif sc.entryClient == nil {","\t\tsc.entryClient = entryv1.NewEntryClient(sc.serverConn)","\t}","","\treturn nil","}","","// SetConfig sets the spire configuration for ControllerAPIClient","func (sc *spireControllerAPIClient) SetConfig(c spireconfig.SpireConfig) {","\tsc.config = \u0026c","}","","func (sc *spireControllerAPIClient) fetchControllerSVID(ctx context.Context) (*x509svid.SVID, error) {","\txsvid, err := sc.workloadAPI.FetchX509SVID(ctx)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"failed to fetch controller SVID: %w\", err)","\t}","\treturn xsvid, nil","}","","func (sc *spireControllerAPIClient) nodeEntry(nodeName string) *spiffetypes.Entry {","\tselectors := []*spiffetypes.Selector{","\t\t{","\t\t\tType:  \"k8s_psat\",","\t\t\tValue: \"agent_ns:spire\",","\t\t},","\t\t{","\t\t\tType:  \"k8s_psat\",","\t\t\tValue: \"agent_node_name:\" + nodeName,","\t\t},","\t}","","\treturn \u0026spiffetypes.Entry{","\t\tSpiffeId: \u0026spiffetypes.SPIFFEID{","\t\t\tTrustDomain: sc.config.TrustDomain,","\t\t\tPath:        fmt.Sprintf(\"%v%v\", sc.config.NodeAliasPrefix, nodeName),","\t\t},","\t\tParentId: \u0026spiffetypes.SPIFFEID{","\t\t\tTrustDomain: sc.config.TrustDomain,","\t\t\tPath:        \"/spire/server\",","\t\t},","\t\tSelectors: selectors,","\t}","}","","func (sc *spireControllerAPIClient) workloadEntry(tr *v1beta1.TaskRun, pod *corev1.Pod, expiry int64) *spiffetypes.Entry {","\t// Note: We can potentially add attestation on the container images as well since","\t// the information is available here.","\tselectors := []*spiffetypes.Selector{","\t\t{","\t\t\tType:  \"k8s\",","\t\t\tValue: \"pod-uid:\" + string(pod.UID),","\t\t},","\t\t{","\t\t\tType:  \"k8s\",","\t\t\tValue: \"pod-name:\" + pod.Name,","\t\t},","\t}","","\treturn \u0026spiffetypes.Entry{","\t\tSpiffeId: \u0026spiffetypes.SPIFFEID{","\t\t\tTrustDomain: sc.config.TrustDomain,","\t\t\tPath:        fmt.Sprintf(\"/ns/%v/taskrun/%v\", tr.Namespace, tr.Name),","\t\t},","\t\tParentId: \u0026spiffetypes.SPIFFEID{","\t\t\tTrustDomain: sc.config.TrustDomain,","\t\t\tPath:        fmt.Sprintf(\"%v%v\", sc.config.NodeAliasPrefix, pod.Spec.NodeName),","\t\t},","\t\tSelectors: selectors,","\t\tExpiresAt: expiry,","\t}","}","","// ttl is the TTL for the SPIRE entry in seconds, not the SVID TTL","func (sc *spireControllerAPIClient) CreateEntries(ctx context.Context, tr *v1beta1.TaskRun, pod *corev1.Pod, ttl time.Duration) error {","\terr := sc.setupClient(ctx)","\tif err != nil {","\t\treturn err","\t}","","\texpiryTime := time.Now().Unix() + int64(ttl)","\tentries := []*spiffetypes.Entry{","\t\tsc.nodeEntry(pod.Spec.NodeName),","\t\tsc.workloadEntry(tr, pod, expiryTime),","\t}","","\treq := entryv1.BatchCreateEntryRequest{","\t\tEntries: entries,","\t}","","\tresp, err := sc.entryClient.BatchCreateEntry(ctx, \u0026req)","\tif err != nil {","\t\treturn err","\t}","","\tif len(resp.GetResults()) != len(entries) {","\t\treturn fmt.Errorf(\"batch create entry failed, malformed response expected %v result\", len(entries))","\t}","","\tvar errPaths []string","\tvar errCodes []int32","","\tfor _, r := range resp.GetResults() {","\t\tstatusCode := r.GetStatus().GetCode()","\t\tif statusCode \u003c 0 {","\t\t\treturn fmt.Errorf(\"statusCode overflows uint32: %d\", statusCode)","\t\t}","\t\tcode := codes.Code(statusCode)","","\t\tif code != codes.AlreadyExists \u0026\u0026 code != codes.OK {","\t\t\terrPaths = append(errPaths, r.GetEntry().GetSpiffeId().GetPath())","\t\t\terrCodes = append(errCodes, statusCode)","\t\t}","\t}","","\tif len(errPaths) != 0 {","\t\treturn fmt.Errorf(\"batch create entry failed for entries %+v with codes %+v\", errPaths, errCodes)","\t}","\treturn nil","}","","func (sc *spireControllerAPIClient) getEntries(ctx context.Context, tr *v1beta1.TaskRun, pod *corev1.Pod) ([]*spiffetypes.Entry, error) {","\treq := \u0026entryv1.ListEntriesRequest{","\t\tFilter: \u0026entryv1.ListEntriesRequest_Filter{","\t\t\tBySpiffeId: \u0026spiffetypes.SPIFFEID{","\t\t\t\tTrustDomain: sc.config.TrustDomain,","\t\t\t\tPath:        fmt.Sprintf(\"/ns/%v/taskrun/%v\", tr.Namespace, tr.Name),","\t\t\t},","\t\t},","\t}","","\tentries := []*spiffetypes.Entry{}","\tfor {","\t\tresp, err := sc.entryClient.ListEntries(ctx, req)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","","\t\tentries = append(entries, resp.GetEntries()...)","","\t\tif resp.GetNextPageToken() == \"\" {","\t\t\tbreak","\t\t}","","\t\treq.PageToken = resp.GetNextPageToken()","\t}","","\treturn entries, nil","}","","func (sc *spireControllerAPIClient) DeleteEntry(ctx context.Context, tr *v1beta1.TaskRun, pod *corev1.Pod) error {","\tentries, err := sc.getEntries(ctx, tr, pod)","\tif err != nil {","\t\treturn err","\t}","","\tvar ids []string","\tfor _, e := range entries {","\t\tids = append(ids, e.GetId())","\t}","","\treq := \u0026entryv1.BatchDeleteEntryRequest{","\t\tIds: ids,","\t}","\tresp, err := sc.entryClient.BatchDeleteEntry(ctx, req)","\tif err != nil {","\t\treturn err","\t}","","\tvar errIds []string","\tvar errCodes []int32","","\tfor _, r := range resp.GetResults() {","\t\tstatusCode := r.GetStatus().GetCode()","\t\tif statusCode \u003c 0 {","\t\t\treturn fmt.Errorf(\"statusCode overflows uint32: %d\", statusCode)","\t\t}","\t\tcode := codes.Code(statusCode)","","\t\tif code != codes.NotFound \u0026\u0026 code != codes.OK {","\t\t\terrIds = append(errIds, r.GetId())","\t\t\terrCodes = append(errCodes, statusCode)","\t\t}","\t}","","\tif len(errIds) != 0 {","\t\treturn fmt.Errorf(\"batch delete entry failed for ids %+v with codes %+v\", errIds, errCodes)","\t}","","\treturn nil","}","","func (sc *spireControllerAPIClient) Close() error {","\tvar err error","\tif sc.serverConn != nil {","\t\terr = sc.serverConn.Close()","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tsc.serverConn = nil","\t}","\tif sc.workloadAPI != nil {","\t\terr = sc.workloadAPI.Close()","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tsc.workloadAPI = nil","\t}","\tif sc.workloadConn != nil {","\t\terr = sc.workloadConn.Close()","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tsc.workloadConn = nil","\t}","\tsc.entryClient = nil","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,0,2,2,2,2,2,1,1,1,2,2,2,0,0,0,0,0,2,2,2,1,1,1,2,0,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,2,2,1,1,2,2,2,2,0,0,2,2,2,2,2,1,1,2,0,0,2,2,2,2,1,1,2,0,0,2,2,2,2,2,1,1,1,1,2,0,0,2,2,2,0,2,0,0,0,2,2,2,0,2,2,2,1,1,2,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,0,1,0,0,1,0,0,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,1,0,0,2,2,2,2,2,1,1,2,0,2,2,2,1,1,2,0,2,2,2,1,1,2,0,2,2,0]},{"id":263,"path":"pkg/spire/entrypointer.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package spire","","import (","\t\"context\"","\t\"time\"","","\t\"github.com/pkg/errors\"","\t\"github.com/spiffe/go-spiffe/v2/svid/x509svid\"","\t\"github.com/spiffe/go-spiffe/v2/workloadapi\"","\tspireconfig \"github.com/tektoncd/pipeline/pkg/spire/config\"",")","","// NewEntrypointerAPIClient creates the EntrypointerAPIClient","func NewEntrypointerAPIClient(c *spireconfig.SpireConfig) EntrypointerAPIClient {","\treturn \u0026spireEntrypointerAPIClient{","\t\tconfig: c,","\t}","}","","type spireEntrypointerAPIClient struct {","\tconfig *spireconfig.SpireConfig","\tclient *workloadapi.Client","}","","func (w *spireEntrypointerAPIClient) setupClient(ctx context.Context) error {","\tif w.config == nil {","\t\treturn errors.New(\"config has not been set yet\")","\t}","\tif w.client == nil {","\t\treturn w.dial(ctx)","\t}","\treturn nil","}","","func (w *spireEntrypointerAPIClient) dial(ctx context.Context) error {","\t// spire workloadapi client for entrypoint - https://github.com/spiffe/go-spiffe/blob/main/v2/workloadapi/client.go","\tclient, err := workloadapi.New(ctx, workloadapi.WithAddr(w.config.SocketPath))","\tif err != nil {","\t\treturn errors.Wrap(err, \"spire workload API not initialized due to error\")","\t}","\tw.client = client","\treturn nil","}","","// package-level timeout and backoff enable shortened timeout for unit tests","var (","\ttimeout = 20 * time.Second","\tbackoff = 2 * time.Second",")","","func (w *spireEntrypointerAPIClient) getWorkloadSVID(ctx context.Context) (*x509svid.SVID, error) {","\t// Should this be using exponential backoff? IDK enough about the underlying","\t// implementation to know if exponential backoff is in fact justified, so","\t// when I modified this code to use a ticker I didn't change the backoff","\t// logic.","\tticker := time.NewTicker(backoff)","\tdefer ticker.Stop()","","\tctx, cancel := context.WithTimeout(ctx, timeout)","\tdefer cancel()","","\tfor {","\t\tvar xsvid *x509svid.SVID","\t\tvar err error","\t\tif xsvid, err = w.client.FetchX509SVID(ctx); err == nil { // No err -- return immediately on success","\t\t\treturn xsvid, nil","\t\t}","\t\tselect {","\t\tcase \u003c-ticker.C:","\t\t\t// do nothing; loop will try again","\t\tcase \u003c-ctx.Done():","\t\t\t// ctx timed out or was cancelled","\t\t\treturn nil, errors.Wrap(ctx.Err(), errors.Wrap(err, \"failed to fetch SVID\").Error())","\t\t}","\t}","}","","func (w *spireEntrypointerAPIClient) Close() error {","\tif w.client != nil {","\t\treturn w.client.Close()","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,0,0,0,0,2,2,1,1,2,2,2,2,0,0,2,2,2,2,1,1,2,2,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,0,0,0,0,2,2,2,2,1,0]},{"id":264,"path":"pkg/spire/sign.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package spire","","import (","\t\"context\"","\t\"crypto\"","\t\"crypto/rand\"","\t\"crypto/sha256\"","\t\"encoding/base64\"","\t\"encoding/pem\"","\t\"errors\"","\t\"strings\"","","\t\"github.com/spiffe/go-spiffe/v2/svid/x509svid\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/result\"",")","","// Signs the TaskRun results with the TaskRun spire SVID and appends the results to RunResult","func (w *spireEntrypointerAPIClient) Sign(ctx context.Context, results []result.RunResult) ([]result.RunResult, error) {","\terr := w.setupClient(ctx)","\tif err != nil {","\t\treturn nil, err","\t}","","\txsvid, err := w.getWorkloadSVID(ctx)","\tif err != nil {","\t\treturn nil, err","\t}","","\tif len(xsvid.Certificates) == 0 {","\t\treturn nil, errors.New(\"returned workload svid does not have certificates\")","\t}","","\toutput := []result.RunResult{}","\tp := pem.EncodeToMemory(\u0026pem.Block{","\t\tBytes: xsvid.Certificates[0].Raw,","\t\tType:  \"CERTIFICATE\",","\t})","\toutput = append(output, result.RunResult{","\t\tKey:        KeySVID,","\t\tValue:      string(p),","\t\tResultType: result.TaskRunResultType,","\t})","","\tfor _, r := range results {","\t\tif r.ResultType == result.TaskRunResultType {","\t\t\tresultValue, err := getResultValue(r)","\t\t\tif err != nil {","\t\t\t\treturn nil, err","\t\t\t}","\t\t\ts, err := signWithKey(xsvid, resultValue)","\t\t\tif err != nil {","\t\t\t\treturn nil, err","\t\t\t}","\t\t\toutput = append(output, result.RunResult{","\t\t\t\tKey:        r.Key + KeySignatureSuffix,","\t\t\t\tValue:      base64.StdEncoding.EncodeToString(s),","\t\t\t\tResultType: result.TaskRunResultType,","\t\t\t})","\t\t}","\t}","\t// get complete manifest of keys such that it can be verified","\tmanifest := getManifest(results)","\toutput = append(output, result.RunResult{","\t\tKey:        KeyResultManifest,","\t\tValue:      manifest,","\t\tResultType: result.TaskRunResultType,","\t})","\tmanifestSig, err := signWithKey(xsvid, manifest)","\tif err != nil {","\t\treturn nil, err","\t}","\toutput = append(output, result.RunResult{","\t\tKey:        KeyResultManifest + KeySignatureSuffix,","\t\tValue:      base64.StdEncoding.EncodeToString(manifestSig),","\t\tResultType: result.TaskRunResultType,","\t})","","\treturn output, nil","}","","func signWithKey(xsvid *x509svid.SVID, value string) ([]byte, error) {","\tdgst := sha256.Sum256([]byte(value))","\ts, err := xsvid.PrivateKey.Sign(rand.Reader, dgst[:], crypto.SHA256)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn s, nil","}","","func getManifest(results []result.RunResult) string {","\tkeys := []string{}","\tfor _, r := range results {","\t\tif strings.HasSuffix(r.Key, KeySignatureSuffix) || r.Key == KeySVID || r.ResultType != result.TaskRunResultType {","\t\t\tcontinue","\t\t}","\t\tkeys = append(keys, r.Key)","\t}","\treturn strings.Join(keys, \",\")","}","","// AppendStatusInternalAnnotation creates the status annotations which are used by the controller to verify the status hash","func (sc *spireControllerAPIClient) AppendStatusInternalAnnotation(ctx context.Context, tr *v1beta1.TaskRun) error {","\terr := sc.setupClient(ctx)","\tif err != nil {","\t\treturn err","\t}","","\t// Add status hash","\tcurrentHash, err := hashTaskrunStatusInternal(tr)","\tif err != nil {","\t\treturn err","\t}","","\t// Sign with controller private key","\txsvid, err := sc.fetchControllerSVID(ctx)","\tif err != nil {","\t\treturn err","\t}","","\tsig, err := signWithKey(xsvid, currentHash)","\tif err != nil {","\t\treturn err","\t}","","\tif len(xsvid.Certificates) == 0 {","\t\treturn errors.New(\"returned controller svid does not have certificates\")","\t}","\t// Store Controller SVID","\tp := pem.EncodeToMemory(\u0026pem.Block{","\t\tBytes: xsvid.Certificates[0].Raw,","\t\tType:  \"CERTIFICATE\",","\t})","\tif tr.Status.Annotations == nil {","\t\ttr.Status.Annotations = map[string]string{}","\t}","\ttr.Status.Annotations[controllerSvidAnnotation] = string(p)","\ttr.Status.Annotations[TaskRunStatusHashAnnotation] = currentHash","\ttr.Status.Annotations[taskRunStatusHashSigAnnotation] = base64.StdEncoding.EncodeToString(sig)","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,1,1,0,2,2,2,2,0,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,1,1,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,2,0,0,2,2,2,2,1,1,2,0,0,2,2,2,2,2,0,2,0,2,0,0,0,2,2,2,1,1,0,0,2,2,1,1,0,0,2,2,1,1,0,2,2,1,1,0,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,0]},{"id":265,"path":"pkg/spire/spire_mock.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package spire","","import (","\t\"context\"","\t\"crypto/sha256\"","\t\"fmt\"","\t\"strings\"","\t\"time\"","","\t\"github.com/pkg/errors\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/result\"","\tspireconfig \"github.com/tektoncd/pipeline/pkg/spire/config\"","\t\"go.uber.org/zap\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/client-go/rest\"","\t\"knative.dev/pkg/injection\"",")","","func init() {","\tinjection.Fake.RegisterClient(withFakeControllerClient)","}","","func withFakeControllerClient(ctx context.Context, cfg *rest.Config) context.Context {","\treturn context.WithValue(ctx, controllerKey{}, \u0026spireControllerAPIClient{})","}","","// MockClient is a client used for mocking the this package for unit testing","// other tekton components that use the spire entrypointer or controller client.","//","// The MockClient implements both SpireControllerApiClient and SpireEntrypointerApiClient","// and in addition to that provides the helper functions to define and query internal state.","type MockClient struct {","\t// Entries is a dictionary of entries that mock the SPIRE server datastore (for function Sign only)","\tEntries map[string]bool","","\t// SignIdentities represents the list of identities to use to sign (providing context of a caller to Sign)","\t// when Sign is called, the identity is dequeued from the slice. A signature will only be provided if the","\t// corresponding entry is in Entries. This only takes effect if SignOverride is nil.","\tSignIdentities []string","","\t// VerifyAlwaysReturns defines whether to always verify successfully or to always fail verification if non-nil.","\t// This only take effect on Verify functions:","\t// - VerifyStatusInternalAnnotationOverride","\t// - VerifyTaskRunResultsOverride","\tVerifyAlwaysReturns *bool","","\t// VerifyStatusInternalAnnotationOverride contains the function to overwrite a call to VerifyStatusInternalAnnotation","\tVerifyStatusInternalAnnotationOverride func(ctx context.Context, tr *v1beta1.TaskRun, logger *zap.SugaredLogger) error","","\t// VerifyTaskRunResultsOverride contains the function to overwrite a call to VerifyTaskRunResults","\tVerifyTaskRunResultsOverride func(ctx context.Context, prs []result.RunResult, tr *v1beta1.TaskRun) error","","\t// AppendStatusInternalAnnotationOverride  contains the function to overwrite a call to AppendStatusInternalAnnotation","\tAppendStatusInternalAnnotationOverride func(ctx context.Context, tr *v1beta1.TaskRun) error","","\t// CheckSpireVerifiedFlagOverride contains the function to overwrite a call to CheckSpireVerifiedFlag","\tCheckSpireVerifiedFlagOverride func(tr *v1beta1.TaskRun) bool","","\t// SignOverride contains the function to overwrite a call to Sign","\tSignOverride func(ctx context.Context, results []result.RunResult) ([]result.RunResult, error)","}","","var _ ControllerAPIClient = (*MockClient)(nil)","var _ EntrypointerAPIClient = (*MockClient)(nil)","","const controllerSvid = \"CONTROLLER_SVID_DATA\"","","func (*MockClient) mockSign(content, signedBy string) string {","\treturn fmt.Sprintf(\"signed-by-%s:%x\", signedBy, sha256.Sum256([]byte(content)))","}","","func (sc *MockClient) mockVerify(content, sig, signedBy string) bool {","\treturn sig == sc.mockSign(content, signedBy)","}","","// GetIdentity get the taskrun namespace and taskrun name that is used for signing and verifying in mocked spire","func (*MockClient) GetIdentity(tr *v1beta1.TaskRun) string {","\treturn fmt.Sprintf(\"/ns/%v/taskrun/%v\", tr.Namespace, tr.Name)","}","","// AppendStatusInternalAnnotation creates the status annotations which are used by the controller to verify the status hash","func (sc *MockClient) AppendStatusInternalAnnotation(ctx context.Context, tr *v1beta1.TaskRun) error {","\tif sc.AppendStatusInternalAnnotationOverride != nil {","\t\treturn sc.AppendStatusInternalAnnotationOverride(ctx, tr)","\t}","\t// Add status hash","\tcurrentHash, err := hashTaskrunStatusInternal(tr)","\tif err != nil {","\t\treturn err","\t}","","\tif tr.Status.Annotations == nil {","\t\ttr.Status.Annotations = map[string]string{}","\t}","\ttr.Status.Annotations[controllerSvidAnnotation] = controllerSvid","\ttr.Status.Annotations[TaskRunStatusHashAnnotation] = currentHash","\ttr.Status.Annotations[taskRunStatusHashSigAnnotation] = sc.mockSign(currentHash, \"controller\")","\treturn nil","}","","// CheckSpireVerifiedFlag checks if the verified status annotation is set which would result in spire verification failed","func (sc *MockClient) CheckSpireVerifiedFlag(tr *v1beta1.TaskRun) bool {","\tif sc.CheckSpireVerifiedFlagOverride != nil {","\t\treturn sc.CheckSpireVerifiedFlagOverride(tr)","\t}","","\t_, ok := tr.Status.Annotations[VerifiedAnnotation]","\treturn !ok","}","","// CreateEntries adds entries to the dictionary of entries that mock the SPIRE server datastore","func (sc *MockClient) CreateEntries(ctx context.Context, tr *v1beta1.TaskRun, pod *corev1.Pod, ttl time.Duration) error {","\tid := fmt.Sprintf(\"/ns/%v/taskrun/%v\", tr.Namespace, tr.Name)","\tif sc.Entries == nil {","\t\tsc.Entries = map[string]bool{}","\t}","\tsc.Entries[id] = true","\treturn nil","}","","// DeleteEntry removes the entry from the dictionary of entries that mock the SPIRE server datastore","func (sc *MockClient) DeleteEntry(ctx context.Context, tr *v1beta1.TaskRun, pod *corev1.Pod) error {","\tid := fmt.Sprintf(\"/ns/%v/taskrun/%v\", tr.Namespace, tr.Name)","\tif sc.Entries != nil {","\t\tdelete(sc.Entries, id)","\t}","\treturn nil","}","","// VerifyStatusInternalAnnotation checks that the internal status annotations are valid by the mocked spire client","func (sc *MockClient) VerifyStatusInternalAnnotation(ctx context.Context, tr *v1beta1.TaskRun, logger *zap.SugaredLogger) error {","\tif sc.VerifyStatusInternalAnnotationOverride != nil {","\t\treturn sc.VerifyStatusInternalAnnotationOverride(ctx, tr, logger)","\t}","","\tif sc.VerifyAlwaysReturns != nil {","\t\tif *sc.VerifyAlwaysReturns {","\t\t\treturn nil","\t\t}","\t\treturn errors.New(\"failed to verify from mock VerifyAlwaysReturns\")","\t}","","\tif !sc.CheckSpireVerifiedFlag(tr) {","\t\treturn errors.New(\"annotation tekton.dev/not-verified = yes failed spire verification\")","\t}","","\tannotations := tr.Status.Annotations","","\t// Verify annotations are there","\tif annotations[controllerSvidAnnotation] != controllerSvid {","\t\treturn errors.New(\"svid annotation missing\")","\t}","","\t// Check signature","\tcurrentHash, err := hashTaskrunStatusInternal(tr)","\tif err != nil {","\t\treturn err","\t}","\tif !sc.mockVerify(currentHash, annotations[taskRunStatusHashSigAnnotation], \"controller\") {","\t\treturn errors.New(\"signature was not able to be verified\")","\t}","","\t// check current status hash vs annotation status hash by controller","\treturn CheckStatusInternalAnnotation(tr)","}","","// VerifyTaskRunResults checks that all the TaskRun results are valid by the mocked spire client","func (sc *MockClient) VerifyTaskRunResults(ctx context.Context, prs []result.RunResult, tr *v1beta1.TaskRun) error {","\tif sc.VerifyTaskRunResultsOverride != nil {","\t\treturn sc.VerifyTaskRunResultsOverride(ctx, prs, tr)","\t}","","\tif sc.VerifyAlwaysReturns != nil {","\t\tif *sc.VerifyAlwaysReturns {","\t\t\treturn nil","\t\t}","\t\treturn errors.New(\"failed to verify from mock VerifyAlwaysReturns\")","\t}","","\tresultMap := map[string]result.RunResult{}","\tfor _, r := range prs {","\t\tif r.ResultType == result.TaskRunResultType {","\t\t\tresultMap[r.Key] = r","\t\t}","\t}","","\tvar identity string","\t// Get SVID identity","\tfor k, p := range resultMap {","\t\tif k == KeySVID {","\t\t\tidentity = p.Value","\t\t\tbreak","\t\t}","\t}","","\t// Verify manifest","\tif err := verifyManifest(resultMap); err != nil {","\t\treturn err","\t}","","\tif identity != sc.GetIdentity(tr) {","\t\treturn errors.New(\"mock identity did not match\")","\t}","","\tfor key, r := range resultMap {","\t\tif strings.HasSuffix(key, KeySignatureSuffix) {","\t\t\tcontinue","\t\t}","\t\tif key == KeySVID {","\t\t\tcontinue","\t\t}","","\t\tsigEntry, ok := resultMap[key+KeySignatureSuffix]","\t\tsigValue, err := getResultValue(sigEntry)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tresultValue, err := getResultValue(r)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tif !ok || !sc.mockVerify(resultValue, sigValue, identity) {","\t\t\treturn errors.Errorf(\"failed to verify field: %v\", key)","\t\t}","\t}","","\treturn nil","}","","// Sign signs and appends signatures to the RunResult based on the mocked spire client","func (sc *MockClient) Sign(ctx context.Context, results []result.RunResult) ([]result.RunResult, error) {","\tif sc.SignOverride != nil {","\t\treturn sc.SignOverride(ctx, results)","\t}","","\tif len(sc.SignIdentities) == 0 {","\t\treturn nil, errors.New(\"signIdentities empty, please provide identities to sign with the MockClient.GetIdentity function\")","\t}","","\tidentity := sc.SignIdentities[0]","\tsc.SignIdentities = sc.SignIdentities[1:]","","\tif !sc.Entries[identity] {","\t\treturn nil, errors.Errorf(\"entry doesn't exist for identity: %v\", identity)","\t}","","\toutput := []result.RunResult{}","\toutput = append(output, result.RunResult{","\t\tKey:        KeySVID,","\t\tValue:      identity,","\t\tResultType: result.TaskRunResultType,","\t})","","\tfor _, r := range results {","\t\tif r.ResultType == result.TaskRunResultType {","\t\t\tresultValue, err := getResultValue(r)","\t\t\tif err != nil {","\t\t\t\treturn nil, err","\t\t\t}","\t\t\ts := sc.mockSign(resultValue, identity)","\t\t\toutput = append(output, result.RunResult{","\t\t\t\tKey:        r.Key + KeySignatureSuffix,","\t\t\t\tValue:      s,","\t\t\t\tResultType: result.TaskRunResultType,","\t\t\t})","\t\t}","\t}","\t// get complete manifest of keys such that it can be verified","\tmanifest := getManifest(results)","\toutput = append(output, result.RunResult{","\t\tKey:        KeyResultManifest,","\t\tValue:      manifest,","\t\tResultType: result.TaskRunResultType,","\t})","\tmanifestSig := sc.mockSign(manifest, identity)","\toutput = append(output, result.RunResult{","\t\tKey:        KeyResultManifest + KeySignatureSuffix,","\t\tValue:      manifestSig,","\t\tResultType: result.TaskRunResultType,","\t})","","\treturn output, nil","}","","// Close mock closing the spire client connection","func (*MockClient) Close() error { return nil }","","// SetConfig sets the spire configuration for MockClient","func (*MockClient) SetConfig(spireconfig.SpireConfig) {}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,2,2,2,0,0,2,2,2,0,0,2,2,1,1,0,2,2,1,1,0,2,2,2,2,2,2,2,0,0,0,2,2,1,1,0,2,2,0,0,0,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,0,0,0,2,2,1,1,0,2,1,1,1,1,0,0,2,1,1,0,2,2,2,2,2,2,0,0,2,2,1,1,2,2,2,0,0,2,0,0,0,2,2,1,1,0,2,1,1,1,1,0,0,2,2,2,2,2,0,0,2,2,2,2,2,2,0,0,0,0,2,2,2,0,2,2,2,0,2,2,2,0,2,2,0,0,2,2,2,1,1,2,2,1,1,2,2,2,0,0,2,0,0,0,2,2,1,1,0,2,1,1,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,1,0,0,0]},{"id":266,"path":"pkg/spire/verify.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package spire","","import (","\t\"context\"","\t\"crypto\"","\t\"crypto/ecdsa\"","\t\"crypto/ed25519\"","\t\"crypto/rsa\"","\t\"crypto/sha256\"","\t\"crypto/x509\"","\t\"encoding/base64\"","\t\"encoding/json\"","\t\"encoding/pem\"","\t\"fmt\"","\t\"sort\"","\t\"strings\"","","\t\"github.com/pkg/errors\"","\t\"github.com/spiffe/go-spiffe/v2/workloadapi\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/result\"","\t\"go.uber.org/zap\"",")","","// VerifyTaskRunResults ensures that the TaskRun results are valid and have not been tampered with","func (sc *spireControllerAPIClient) VerifyTaskRunResults(ctx context.Context, prs []result.RunResult, tr *v1beta1.TaskRun) error {","\terr := sc.setupClient(ctx)","\tif err != nil {","\t\treturn err","\t}","","\tresultMap := map[string]result.RunResult{}","\tfor _, r := range prs {","\t\tif r.ResultType == result.TaskRunResultType {","\t\t\tresultMap[r.Key] = r","\t\t}","\t}","","\tcert, err := getSVID(resultMap)","\tif err != nil {","\t\treturn err","\t}","","\ttrust, err := getTrustBundle(ctx, sc.workloadAPI)","\tif err != nil {","\t\treturn err","\t}","","\tif err := verifyManifest(resultMap); err != nil {","\t\treturn err","\t}","","\tif err := verifyCertURI(cert, tr, sc.config.TrustDomain); err != nil {","\t\treturn err","\t}","","\tif err := verifyCertificateTrust(cert, trust); err != nil {","\t\treturn err","\t}","","\tfor key := range resultMap {","\t\tif strings.HasSuffix(key, KeySignatureSuffix) {","\t\t\tcontinue","\t\t}","\t\tif key == KeySVID {","\t\t\tcontinue","\t\t}","\t\tif err := verifyResult(cert.PublicKey, key, resultMap); err != nil {","\t\t\treturn err","\t\t}","\t}","","\treturn nil","}","","// VerifyStatusInternalAnnotation run multuple verification steps to ensure that the spire status annotations are valid","func (sc *spireControllerAPIClient) VerifyStatusInternalAnnotation(ctx context.Context, tr *v1beta1.TaskRun, logger *zap.SugaredLogger) error {","\terr := sc.setupClient(ctx)","\tif err != nil {","\t\treturn err","\t}","","\tif !sc.CheckSpireVerifiedFlag(tr) {","\t\treturn errors.New(\"annotation tekton.dev/not-verified = yes failed spire verification\")","\t}","","\tannotations := tr.Status.Annotations","","\t// get trust bundle from spire server","\ttrust, err := getTrustBundle(ctx, sc.workloadAPI)","\tif err != nil {","\t\treturn err","\t}","","\t// verify controller SVID","\tsvid, ok := annotations[controllerSvidAnnotation]","\tif !ok {","\t\treturn errors.New(\"No SVID found\")","\t}","\tblock, _ := pem.Decode([]byte(svid))","\tif block == nil {","\t\treturn fmt.Errorf(\"invalid SVID: %w\", err)","\t}","\tcert, err := x509.ParseCertificate(block.Bytes)","\tif err != nil {","\t\treturn fmt.Errorf(\"invalid SVID: %w\", err)","\t}","","\t// verify certificate root of trust","\tif err := verifyCertificateTrust(cert, trust); err != nil {","\t\treturn err","\t}","\tlogger.Infof(\"Successfully verified certificate %s against SPIRE\", svid)","","\tif err := verifyAnnotation(cert.PublicKey, annotations); err != nil {","\t\treturn err","\t}","\tlogger.Info(\"Successfully verified signature\")","","\t// CheckStatusInternalAnnotation check current status hash vs annotation status hash by controller","\tif err := CheckStatusInternalAnnotation(tr); err != nil {","\t\treturn err","\t}","\tlogger.Info(\"Successfully verified status annotation hash matches the current taskrun status\")","","\treturn nil","}","","// CheckSpireVerifiedFlag checks if the verified status annotation is set which would result in spire verification failed","func (sc *spireControllerAPIClient) CheckSpireVerifiedFlag(tr *v1beta1.TaskRun) bool {","\tif _, ok := tr.Status.Annotations[VerifiedAnnotation]; !ok {","\t\treturn true","\t}","\treturn false","}","","func hashTaskrunStatusInternal(tr *v1beta1.TaskRun) (string, error) {","\ts, err := json.Marshal(tr.Status.TaskRunStatusFields)","\tif err != nil {","\t\treturn \"\", err","\t}","\treturn fmt.Sprintf(\"%x\", sha256.Sum256(s)), nil","}","","// CheckStatusInternalAnnotation ensures that the internal status annotation hash and current status hash match","func CheckStatusInternalAnnotation(tr *v1beta1.TaskRun) error {","\t// get stored hash of status","\tannotations := tr.Status.Annotations","\thash, ok := annotations[TaskRunStatusHashAnnotation]","\tif !ok {","\t\treturn fmt.Errorf(\"no annotation status hash found for %s\", TaskRunStatusHashAnnotation)","\t}","\t// get current hash of status","\tcurrent, err := hashTaskrunStatusInternal(tr)","\tif err != nil {","\t\treturn err","\t}","\tif hash != current {","\t\treturn fmt.Errorf(\"current status hash and stored annotation hash does not match! Annotation Hash: %s, Current Status Hash: %s\", hash, current)","\t}","","\treturn nil","}","","func getSVID(resultMap map[string]result.RunResult) (*x509.Certificate, error) {","\tsvid, ok := resultMap[KeySVID]","\tif !ok {","\t\treturn nil, errors.New(\"no SVID found\")","\t}","\tsvidValue, err := getResultValue(svid)","\tif err != nil {","\t\treturn nil, err","\t}","\tblock, _ := pem.Decode([]byte(svidValue))","\tif block == nil {","\t\treturn nil, fmt.Errorf(\"invalid SVID: %w\", err)","\t}","\tcert, err := x509.ParseCertificate(block.Bytes)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"invalid SVID: %w\", err)","\t}","\treturn cert, nil","}","","func getTrustBundle(ctx context.Context, client *workloadapi.Client) (*x509.CertPool, error) {","\tx509set, err := client.FetchX509Bundles(ctx)","\tif err != nil {","\t\treturn nil, err","\t}","\tx509Bundle := x509set.Bundles()","\tif err != nil {","\t\treturn nil, err","\t}","\tif len(x509Bundle) \u003e 0 {","\t\ttrustPool := x509.NewCertPool()","\t\tfor _, bundle := range x509Bundle {","\t\t\tfor _, c := range bundle.X509Authorities() {","\t\t\t\ttrustPool.AddCert(c)","\t\t\t}","\t\t\treturn trustPool, nil","\t\t}","\t}","\treturn nil, errors.Wrap(err, \"trust domain bundle empty\")","}","","func getFullPath(tr *v1beta1.TaskRun) string {","\t// URI:spiffe://example.org/ns/default/taskrun/cache-image-pipelinerun-r4r22-fetch-from-git","\treturn fmt.Sprintf(\"/ns/%s/taskrun/%s\", tr.Namespace, tr.Name)","}","","func verifyCertURI(cert *x509.Certificate, tr *v1beta1.TaskRun, trustDomain string) error {","\tpath := getFullPath(tr)","\tswitch {","\tcase len(cert.URIs) == 0:","\t\treturn fmt.Errorf(\"cert uri missing for taskrun: %s\", tr.Name)","\tcase len(cert.URIs) \u003e 1:","\t\treturn fmt.Errorf(\"cert contains more than one URI for taskrun: %s\", tr.Name)","\tcase len(cert.URIs) == 1:","\t\tif cert.URIs[0].Host != trustDomain {","\t\t\treturn fmt.Errorf(\"cert uri: %s does not match trust domain: %s\", cert.URIs[0].Host, trustDomain)","\t\t}","\t\tif cert.URIs[0].Path != path {","\t\t\treturn fmt.Errorf(\"cert uri: %s does not match taskrun: %s\", cert.URIs[0].Path, path)","\t\t}","\t}","\treturn nil","}","","func verifyCertificateTrust(cert *x509.Certificate, rootCertPool *x509.CertPool) error {","\tverifyOptions := x509.VerifyOptions{","\t\tRoots: rootCertPool,","\t}","\tchains, err := cert.Verify(verifyOptions)","\tif len(chains) == 0 || err != nil {","\t\treturn errors.New(\"cert cannot be verified by provided roots\")","\t}","\treturn nil","}","","func verifyManifest(results map[string]result.RunResult) error {","\tmanifest, ok := results[KeyResultManifest]","\tif !ok {","\t\treturn errors.New(\"no manifest found in results\")","\t}","\tmanifestValue, err := getResultValue(manifest)","\tif err != nil {","\t\treturn err","\t}","\ts := strings.Split(manifestValue, \",\")","\tfor _, key := range s {","\t\t_, found := results[key]","\t\tif key != \"\" \u0026\u0026 !found {","\t\t\treturn fmt.Errorf(\"no result found for %s but is part of the manifest %s\", key, manifestValue)","\t\t}","\t}","\treturn nil","}","","func verifyAnnotation(pub interface{}, annotations map[string]string) error {","\tsignature, ok := annotations[taskRunStatusHashSigAnnotation]","\tif !ok {","\t\treturn fmt.Errorf(\"no signature found for %s\", taskRunStatusHashSigAnnotation)","\t}","\thash, ok := annotations[TaskRunStatusHashAnnotation]","\tif !ok {","\t\treturn fmt.Errorf(\"no annotation status hash found for %s\", TaskRunStatusHashAnnotation)","\t}","\treturn verifySignature(pub, signature, hash)","}","","func verifyResult(pub crypto.PublicKey, key string, results map[string]result.RunResult) error {","\tsignature, ok := results[key+KeySignatureSuffix]","\tif !ok {","\t\treturn fmt.Errorf(\"no signature found for %s\", key)","\t}","\tsigValue, err := getResultValue(signature)","\tif err != nil {","\t\treturn err","\t}","\tresultValue, err := getResultValue(results[key])","\tif err != nil {","\t\treturn err","\t}","\treturn verifySignature(pub, sigValue, resultValue)","}","","func verifySignature(pub crypto.PublicKey, signature string, value string) error {","\tb, err := base64.StdEncoding.DecodeString(signature)","\tif err != nil {","\t\treturn fmt.Errorf(\"invalid signature: %w\", err)","\t}","\th := sha256.Sum256([]byte(value))","\t// Check val against sig","\tswitch t := pub.(type) {","\tcase *ecdsa.PublicKey:","\t\tif !ecdsa.VerifyASN1(t, h[:], b) {","\t\t\treturn errors.New(\"invalid signature\")","\t\t}","\t\treturn nil","\tcase *rsa.PublicKey:","\t\treturn rsa.VerifyPKCS1v15(t, crypto.SHA256, h[:], b)","\tcase ed25519.PublicKey:","\t\tif !ed25519.Verify(t, []byte(value), b) {","\t\t\treturn errors.New(\"invalid signature\")","\t\t}","\t\treturn nil","\tdefault:","\t\treturn fmt.Errorf(\"unsupported key type: %s\", t)","\t}","}","","func getResultValue(result result.RunResult) (string, error) {","\taos := v1beta1.ArrayOrString{}","\terr := aos.UnmarshalJSON([]byte(result.Value))","\tvalList := []string{}","\tif err != nil {","\t\treturn \"\", fmt.Errorf(\"unmarshal error for key: %s\", result.Key)","\t}","\tswitch aos.Type {","\tcase v1beta1.ParamTypeString:","\t\treturn aos.StringVal, nil","\tcase v1beta1.ParamTypeArray:","\t\tvalList = append(valList, aos.ArrayVal...)","\t\treturn strings.Join(valList, \",\"), nil","\tcase v1beta1.ParamTypeObject:","\t\tkeys := make([]string, 0, len(aos.ObjectVal))","\t\tfor k := range aos.ObjectVal {","\t\t\tkeys = append(keys, k)","\t\t}","\t\tsort.Strings(keys)","\t\tfor _, k := range keys {","\t\t\tvalList = append(valList, k)","\t\t\tvalList = append(valList, aos.ObjectVal[k])","\t\t}","\t\treturn strings.Join(valList, \",\"), nil","\t}","\treturn \"\", fmt.Errorf(\"invalid result type for key: %s\", result.Key)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,1,1,0,2,2,2,2,2,0,0,2,2,2,2,0,2,2,1,1,0,2,2,2,0,2,2,2,0,2,1,1,0,2,2,2,0,2,2,0,2,2,2,0,0,2,0,0,0,2,2,2,1,1,0,2,2,2,0,2,2,2,2,2,1,1,0,0,2,2,2,2,2,2,2,2,2,2,1,1,0,0,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,0,0,2,2,2,1,1,2,0,0,0,2,2,2,2,2,1,1,0,2,2,1,1,2,2,2,0,2,0,0,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,1,1,2,0,0,2,2,2,1,1,2,2,1,1,2,2,2,2,2,2,2,0,0,1,0,0,2,2,2,2,0,2,2,2,1,1,1,1,2,2,1,1,2,2,2,0,2,0,0,2,2,2,2,2,2,1,1,2,0,0,2,2,2,2,2,2,2,1,1,2,2,2,2,2,2,0,2,0,0,2,2,2,1,1,2,2,1,1,2,0,0,2,2,2,2,2,2,2,1,1,2,2,1,1,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,0,0,0,2,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,1,0]},{"id":267,"path":"pkg/status/status.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package status","","import (","\t\"context\"","\t\"fmt\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/client/clientset/versioned\"","\t\"k8s.io/apimachinery/pkg/api/errors\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"",")","","// GetTaskRunStatusForPipelineTask takes a child reference and returns the actual TaskRunStatus","// for the PipelineTask. It returns an error if the child reference's kind isn't TaskRun.","func GetTaskRunStatusForPipelineTask(ctx context.Context, client versioned.Interface, ns string, childRef v1.ChildStatusReference) (*v1.TaskRunStatus, error) {","\tif childRef.Kind != \"TaskRun\" {","\t\treturn nil, fmt.Errorf(\"could not fetch status for PipelineTask %s: should have kind TaskRun, but is %s\", childRef.PipelineTaskName, childRef.Kind)","\t}","","\ttr, err := client.TektonV1().TaskRuns(ns).Get(ctx, childRef.Name, metav1.GetOptions{})","\tif err != nil \u0026\u0026 !errors.IsNotFound(err) {","\t\treturn nil, err","\t}","\tif tr == nil {","\t\treturn nil, nil //nolint:nilnil // would be more ergonomic to return a sentinel error","\t}","","\treturn \u0026tr.Status, nil","}","","// GetCustomRunStatusForPipelineTask takes a child reference and returns the actual CustomRunStatus for the","// PipelineTask. It returns an error if the child reference's kind isn't CustomRun.","func GetCustomRunStatusForPipelineTask(ctx context.Context, client versioned.Interface, ns string, childRef v1.ChildStatusReference) (*v1beta1.CustomRunStatus, error) {","\tvar runStatus *v1beta1.CustomRunStatus","","\tswitch childRef.Kind {","\tcase \"CustomRun\":","\t\tr, err := client.TektonV1beta1().CustomRuns(ns).Get(ctx, childRef.Name, metav1.GetOptions{})","\t\tif err != nil \u0026\u0026 !errors.IsNotFound(err) {","\t\t\treturn nil, err","\t\t}","\t\tif r == nil {","\t\t\treturn nil, nil //nolint:nilnil // would be more ergonomic to return a sentinel error","\t\t}","\t\trunStatus = \u0026r.Status","\tdefault:","\t\treturn nil, fmt.Errorf(\"could not fetch status for PipelineTask %s: should have kind CustomRun, but is %s\", childRef.PipelineTaskName, childRef.Kind)","\t}","","\treturn runStatus, nil","}","","// GetPipelineTaskStatuses returns populated TaskRun and Run status maps for a PipelineRun from its ChildReferences.","// If the PipelineRun has no ChildReferences, nothing will be populated.","func GetPipelineTaskStatuses(ctx context.Context, client versioned.Interface, ns string, pr *v1.PipelineRun) (map[string]*v1.PipelineRunTaskRunStatus,","\tmap[string]*v1.PipelineRunRunStatus, error) {","\t// If the PipelineRun is nil, just return","\tif pr == nil {","\t\treturn nil, nil, nil","\t}","","\t// If there are no child references or either TaskRuns or Runs is non-zero, return the existing TaskRuns and Runs maps","\tif len(pr.Status.ChildReferences) == 0 {","\t\treturn nil, nil, nil","\t}","","\ttrStatuses := make(map[string]*v1.PipelineRunTaskRunStatus)","\trunStatuses := make(map[string]*v1.PipelineRunRunStatus)","","\tfor _, cr := range pr.Status.ChildReferences {","\t\tswitch cr.Kind {","\t\tcase \"TaskRun\":","\t\t\ttr, err := client.TektonV1().TaskRuns(ns).Get(ctx, cr.Name, metav1.GetOptions{})","\t\t\tif err != nil \u0026\u0026 !errors.IsNotFound(err) {","\t\t\t\treturn nil, nil, err","\t\t\t}","","\t\t\ttrStatuses[cr.Name] = \u0026v1.PipelineRunTaskRunStatus{","\t\t\t\tPipelineTaskName: cr.PipelineTaskName,","\t\t\t\tWhenExpressions:  cr.WhenExpressions,","\t\t\t}","","\t\t\tif tr != nil {","\t\t\t\ttrStatuses[cr.Name].Status = \u0026tr.Status","\t\t\t}","\t\tcase \"CustomRun\":","\t\t\tr, err := client.TektonV1beta1().CustomRuns(ns).Get(ctx, cr.Name, metav1.GetOptions{})","\t\t\tif err != nil \u0026\u0026 !errors.IsNotFound(err) {","\t\t\t\treturn nil, nil, err","\t\t\t}","","\t\t\trunStatuses[cr.Name] = \u0026v1.PipelineRunRunStatus{","\t\t\t\tPipelineTaskName: cr.PipelineTaskName,","\t\t\t\tWhenExpressions:  cr.WhenExpressions,","\t\t\t}","","\t\t\tif r != nil {","\t\t\t\trunStatuses[cr.Name].Status = \u0026r.Status","\t\t\t}","\t\tdefault:","\t\t\t// Don't do anything for unknown types.","\t\t}","\t}","","\treturn trStatuses, runStatuses, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,2,2,1,1,2,1,1,0,2,0,0,0,0,2,2,2,2,2,2,2,1,1,2,1,1,2,2,2,0,0,2,0,0,0,0,0,2,2,2,2,2,0,0,2,1,1,0,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,2,0,0,0,0,0,2,0]},{"id":268,"path":"pkg/substitution/replacements.go","lines":["/*","Copyright 2025 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package substitution","","import (","\t\"fmt\"","\t\"strings\"",")","","// ApplyReplacements returns a string with references to parameters replaced,","// based on the mapping provided in replacements.","// For example, if the input string is \"foo: $(params.foo)\", and replacements maps \"params.foo\" to \"bar\",","// the output would be \"foo: bar\".","func ApplyReplacements(in string, replacements map[string]string) string {","\treplacementsList := []string{}","\tfor k, v := range replacements {","\t\treplacementsList = append(replacementsList, fmt.Sprintf(\"$(%s)\", k), v)","\t}","\t// strings.Replacer does all replacements in one pass, preventing multiple replacements","\t// See #2093 for an explanation on why we need to do this.","\treplacer := strings.NewReplacer(replacementsList...)","\treturn replacer.Replace(in)","}","","// ApplyArrayReplacements takes an input string, and output an array of strings related to possible arrayReplacements. If there aren't any","// areas where the input can be split up via arrayReplacements, then just return an array with a single element,","// which is ApplyReplacements(in, replacements).","func ApplyArrayReplacements(in string, stringReplacements map[string]string, arrayReplacements map[string][]string) []string {","\tfor k, v := range arrayReplacements {","\t\tstringToReplace := fmt.Sprintf(\"$(%s)\", k)","","\t\t// If the input string matches a replacement's key (without padding characters), return the corresponding array.","\t\t// Note that the webhook should prevent all instances where this could evaluate to false.","\t\tif (strings.Count(in, stringToReplace) == 1) \u0026\u0026 len(in) == len(stringToReplace) {","\t\t\treturn v","\t\t}","","\t\t// same replace logic for star array expressions","\t\tstarStringtoReplace := fmt.Sprintf(\"$(%s[*])\", k)","\t\tif (strings.Count(in, starStringtoReplace) == 1) \u0026\u0026 len(in) == len(starStringtoReplace) {","\t\t\treturn v","\t\t}","\t}","","\t// Otherwise return a size-1 array containing the input string with standard stringReplacements applied.","\treturn []string{ApplyReplacements(in, stringReplacements)}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,0,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,0,0,2,0]},{"id":269,"path":"pkg/substitution/substitution.go","lines":["//go:build !disable_tls","","/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package substitution","","import (","\t\"fmt\"","\t\"regexp\"","\t\"strconv\"","\t\"strings\"","","\t\"k8s.io/apimachinery/pkg/util/sets\"","\t\"knative.dev/pkg/apis\"",")","","const (","\tparameterSubstitution = `.*?(\\[\\*\\])?`","","\t// braceMatchingRegex is a regex for parameter references including dot notation, bracket notation with single and double quotes.","\tbraceMatchingRegex = \"(\\\\$(\\\\(%s(\\\\.(?P\u003cvar1\u003e%s)|\\\\[\\\"(?P\u003cvar2\u003e%s)\\\"\\\\]|\\\\['(?P\u003cvar3\u003e%s)'\\\\])\\\\)))\"","\t// arrayIndexing will match all `[int]` and `[*]` for parseExpression","\tarrayIndexing = `\\[([0-9])*\\*?\\]`","\t// paramIndex will match all `$(params.paramName[int])` expressions","\tparamIndexing = `\\$\\(params(\\.[_a-zA-Z0-9.-]+|\\[\\'[_a-zA-Z0-9.-\\/]+\\'\\]|\\[\\\"[_a-zA-Z0-9.-\\/]+\\\"\\])\\[[0-9]+\\]\\)`","\t// intIndex will match all `[int]` expressions","\tintIndex = `\\[[0-9]+\\]`",")","","// arrayIndexingRegex is used to match `[int]` and `[*]`","var arrayIndexingRegex = regexp.MustCompile(arrayIndexing)","","// paramIndexingRegex will match all `$(params.paramName[int])` expressions","var paramIndexingRegex = regexp.MustCompile(paramIndexing)","","// intIndexRegex will match all `[int]` for param expression","var intIndexRegex = regexp.MustCompile(intIndex)","","// ValidateNoReferencesToUnknownVariables returns an error if the input string contains references to unknown variables","// Inputs:","// - value: a string containing a reference to a variable that can be substituted, e.g. \"echo $(params.foo)\"","// - prefix: the prefix of the substitutable variable, e.g. \"params\" or \"context.pipeline\"","// - vars: names of known variables","func ValidateNoReferencesToUnknownVariables(value, prefix string, vars sets.String) *apis.FieldError {","\treturn validateNoReferencesToUnknownVariables(value, prefix, vars, false)","}","","// ValidateNoReferencesToUnknownVariablesWithDetail same as ValidateNoReferencesToUnknownVariables","// but with more prefix detailed error message","func ValidateNoReferencesToUnknownVariablesWithDetail(value, prefix string, vars sets.String) *apis.FieldError {","\treturn validateNoReferencesToUnknownVariables(value, prefix, vars, true)","}","","func validateNoReferencesToUnknownVariables(value, prefix string, vars sets.String, withDetail bool) *apis.FieldError {","\tif vs, present, errString := ExtractVariablesFromString(value, prefix); present {","\t\tif errString != \"\" {","\t\t\treturn \u0026apis.FieldError{","\t\t\t\tMessage: errString,","\t\t\t\tPaths:   []string{\"\"},","\t\t\t}","\t\t}","\t\tfor _, v := range vs {","\t\t\tv = TrimArrayIndex(v)","\t\t\tif !vars.Has(v) {","\t\t\t\tvar msg string","\t\t\t\tif withDetail {","\t\t\t\t\tmsg = fmt.Sprintf(\"non-existent variable `%s` in %q\", v, value)","\t\t\t\t} else {","\t\t\t\t\tmsg = fmt.Sprintf(\"non-existent variable in %q\", value)","\t\t\t\t}","\t\t\t\treturn \u0026apis.FieldError{","\t\t\t\t\tMessage: msg,","\t\t\t\t\t// Empty path is required to make the `ViaField`, â€¦ work","\t\t\t\t\tPaths: []string{\"\"},","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn nil","}","","// ValidateNoReferencesToProhibitedVariables returns an error if the input string contains any references to any variables in vars,","// except for array indexing references.","//","// Inputs:","// - value: a string containing a reference to a variable that can be substituted, e.g. \"echo $(params.foo)\"","// - prefix: the prefix of the substitutable variable, e.g. \"params\" or \"context.pipeline\"","// - vars: names of known variables","func ValidateNoReferencesToProhibitedVariables(value, prefix string, vars sets.String) *apis.FieldError {","\tif vs, present, errString := ExtractVariablesFromString(value, prefix); present {","\t\tif errString != \"\" {","\t\t\treturn \u0026apis.FieldError{","\t\t\t\tMessage: errString,","\t\t\t\tPaths:   []string{\"\"},","\t\t\t}","\t\t}","\t\tfor _, v := range vs {","\t\t\tv = strings.TrimSuffix(v, \"[*]\")","\t\t\tif vars.Has(v) {","\t\t\t\treturn \u0026apis.FieldError{","\t\t\t\t\tMessage: fmt.Sprintf(\"variable type invalid in %q\", value),","\t\t\t\t\t// Empty path is required to make the `ViaField`, â€¦ work","\t\t\t\t\tPaths: []string{\"\"},","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn nil","}","","// ValidateNoReferencesToEntireProhibitedVariables returns an error if the input string contains any whole array/object references","// to any variables in vars. References to array indexes or object keys are permitted.","//","// Inputs:","// - value: a string containing a reference to a variable that can be substituted, e.g. \"echo $(params.foo)\"","// - prefix: the prefix of the substitutable variable, e.g. \"params\" or \"context.pipeline\"","// - vars: names of known variables","func ValidateNoReferencesToEntireProhibitedVariables(value, prefix string, vars sets.String) *apis.FieldError {","\tpaths := []string{\"\"} // Empty path is required to make the `ViaField`, â€¦ work","\tvs, err := extractEntireVariablesFromString(value, prefix)","\tif err != nil {","\t\treturn \u0026apis.FieldError{","\t\t\tMessage: fmt.Sprintf(\"extractEntireVariablesFromString failed : %v\", err),","\t\t\tPaths:   paths,","\t\t}","\t}","","\tfor _, v := range vs {","\t\tv = strings.TrimSuffix(v, \"[*]\")","\t\tif vars.Has(v) {","\t\t\treturn \u0026apis.FieldError{","\t\t\t\tMessage: fmt.Sprintf(\"variable type invalid in %q\", value),","\t\t\t\tPaths:   paths,","\t\t\t}","\t\t}","\t}","","\treturn nil","}","","// ValidateVariableReferenceIsIsolated returns an error if the input string contains characters in addition to references to known parameters.","// For example, if \"foo\" is a known parameter, a value of \"foo: $(params.foo)\" returns an error, but a value of \"$(params.foo)\" does not.","// Inputs:","// - value: a string containing a reference to a variable that can be substituted, e.g. \"echo $(params.foo)\"","// - prefix: the prefix of the substitutable variable, e.g. \"params\" or \"context.pipeline\"","// - vars: names of known variables","func ValidateVariableReferenceIsIsolated(value, prefix string, vars sets.String) *apis.FieldError {","\tpaths := []string{\"\"} // Empty path is required to make the `ViaField`, â€¦ work","\tif vs, present, errString := ExtractVariablesFromString(value, prefix); present {","\t\tif errString != \"\" {","\t\t\treturn \u0026apis.FieldError{","\t\t\t\tMessage: errString,","\t\t\t\tPaths:   paths,","\t\t\t}","\t\t}","\t\tfirstMatch, err := extractExpressionFromString(value, prefix)","\t\tif err != nil {","\t\t\treturn \u0026apis.FieldError{","\t\t\t\tMessage: err.Error(),","\t\t\t\tPaths:   paths,","\t\t\t}","\t\t}","\t\tfor _, v := range vs {","\t\t\tv = strings.TrimSuffix(v, \"[*]\")","\t\t\tif vars.Has(v) {","\t\t\t\tif len(value) != len(firstMatch) {","\t\t\t\t\treturn \u0026apis.FieldError{","\t\t\t\t\t\tMessage: fmt.Sprintf(\"variable is not properly isolated in %q\", value),","\t\t\t\t\t\tPaths:   paths,","\t\t\t\t\t}","\t\t\t\t}","\t\t\t}","\t\t}","\t}","\treturn nil","}","","// ValidateWholeArrayOrObjectRefInStringVariable validates if a single string field uses references to the whole array/object appropriately","// valid example: \"$(params.myObject[*])\"","// invalid example: \"$(params.name-not-exist[*])\"","func ValidateWholeArrayOrObjectRefInStringVariable(name, value, prefix string, vars sets.String) (isIsolated bool, errs *apis.FieldError) {","\tnameSubstitution := `[_a-zA-Z0-9.-]+\\[\\*\\]`","","\t// a regex to check if the stringValue is an isolated reference to the whole array/object param without extra string literal.","\tisolatedVariablePattern := fmt.Sprintf(fmt.Sprintf(\"^%s$\", braceMatchingRegex), prefix, nameSubstitution, nameSubstitution, nameSubstitution)","\tisolatedVariableRegex, err := regexp.Compile(isolatedVariablePattern)","\tif err != nil {","\t\treturn false, \u0026apis.FieldError{","\t\t\tMessage: fmt.Sprint(\"Fail to parse the regex: \", err),","\t\t\tPaths:   []string{fmt.Sprintf(\"%s.%s\", prefix, name)},","\t\t}","\t}","","\tif isolatedVariableRegex.MatchString(value) {","\t\treturn true, ValidateNoReferencesToUnknownVariables(value, prefix, vars).ViaFieldKey(prefix, name)","\t}","","\treturn false, nil","}","","// extract a the first full string expressions found (e.g \"$(input.params.foo)\").","// Returns \"\" if nothing is found.","func extractExpressionFromString(s, prefix string) (string, error) {","\tpattern := fmt.Sprintf(braceMatchingRegex, prefix, parameterSubstitution, parameterSubstitution, parameterSubstitution)","\tre, err := regexp.Compile(pattern)","\tif err != nil {","\t\treturn \"\", err","\t}","\tmatch := re.FindStringSubmatch(s)","\tif match == nil {","\t\treturn \"\", nil","\t}","\treturn match[0], nil","}","","// ExtractVariablesFromString extracts variables from an input string s with the given prefix via regex matching.","// It returns a slice of strings which contains the extracted variables, a bool flag to indicate if matches were found","// and the error string if the referencing of parameters is invalid.","// If the string does not contain the input prefix then the output will contain a slice of strings with length 0.","func ExtractVariablesFromString(s, prefix string) ([]string, bool, string) {","\tpattern := fmt.Sprintf(braceMatchingRegex, prefix, parameterSubstitution, parameterSubstitution, parameterSubstitution)","\tre, err := regexp.Compile(pattern)","\tif err != nil {","\t\treturn nil, false, \"\"","\t}","\tmatches := re.FindAllStringSubmatch(s, -1)","\terrString := \"\"","\t// Input string does not contain the prefix and therefore not matches are found.","\tif len(matches) == 0 {","\t\treturn []string{}, false, \"\"","\t}","\tvars := make([]string, len(matches))","\tfor i, match := range matches {","\t\tgroups := matchGroups(match, re)","\t\tfor j, v := range []string{\"var1\", \"var2\", \"var3\"} {","\t\t\tval := groups[v]","\t\t\t// If using the dot notation, the number of dot-separated components is restricted up to 2.","\t\t\t// Valid Examples:","\t\t\t//  - extract \"aString\" from \u003cprefix\u003e.aString","\t\t\t//  - extract \"anObject\" from \u003cprefix\u003e.anObject.key","\t\t\t// Invalid Examples:","\t\t\t//  - \u003cprefix\u003e.foo.bar.baz....","\t\t\tif j == 0 \u0026\u0026 strings.Contains(val, \".\") {","\t\t\t\tif len(strings.Split(val, \".\")) \u003e 2 {","\t\t\t\t\terrString = fmt.Sprintf(`Invalid referencing of parameters in \"%s\"! Only two dot-separated components after the prefix \"%s\" are allowed.`, s, prefix)","\t\t\t\t\treturn vars, true, errString","\t\t\t\t}","\t\t\t\tvars[i] = strings.SplitN(val, \".\", 2)[0]","\t\t\t\tbreak","\t\t\t}","\t\t\tif val != \"\" {","\t\t\t\tvars[i] = val","\t\t\t\tbreak","\t\t\t}","\t\t}","\t}","\treturn vars, true, errString","}","","// extractEntireVariablesFromString returns any references to entire array or object params in s with the given prefix","func extractEntireVariablesFromString(s, prefix string) ([]string, error) {","\tpattern := fmt.Sprintf(braceMatchingRegex, prefix, parameterSubstitution, parameterSubstitution, parameterSubstitution)","\tre, err := regexp.Compile(pattern)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"failed to parse regex pattern: %w\", err)","\t}","","\tmatches := re.FindAllStringSubmatch(s, -1)","\tif len(matches) == 0 {","\t\treturn []string{}, nil","\t}","\tvars := make([]string, len(matches))","\tfor i, match := range matches {","\t\tgroups := matchGroups(match, re)","\t\t// foo -\u003e foo","\t\t// foo.bar -\u003e foo.bar","\t\t// foo.bar.baz -\u003e foo.bar.baz","\t\tfor _, v := range []string{\"var1\", \"var2\", \"var3\"} {","\t\t\tval := groups[v]","\t\t\tif val != \"\" {","\t\t\t\tvars[i] = val","\t\t\t\tbreak","\t\t\t}","\t\t}","\t}","\treturn vars, nil","}","","func matchGroups(matches []string, pattern *regexp.Regexp) map[string]string {","\tgroups := make(map[string]string)","\tfor i, name := range pattern.SubexpNames()[1:] {","\t\tgroups[name] = matches[i+1]","\t}","\treturn groups","}","","// TrimArrayIndex replaces all `[i]` and `[*]` to \"\".","func TrimArrayIndex(s string) string {","\treturn arrayIndexingRegex.ReplaceAllString(s, \"\")","}","","// ExtractArrayIndexingParamsExpressions will find all  `$(params.paramName[int])` expressions","func ExtractArrayIndexingParamsExpressions(s string) []string {","\treturn paramIndexingRegex.FindAllString(s, -1)","}","","func ExtractVariableExpressions(s, prefix string) ([]string, error) {","\tpattern := fmt.Sprintf(braceMatchingRegex, prefix, parameterSubstitution, parameterSubstitution, parameterSubstitution)","\tre, err := regexp.Compile(pattern)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"failed to parse regex pattern: %w\", err)","\t}","","\tmatches := re.FindAllString(s, -1)","\tif len(matches) == 0 {","\t\treturn []string{}, nil","\t}","\treturn matches, nil","}","","// ExtractIndexString will find the leftmost match of `[int]`","func ExtractIndexString(s string) string {","\treturn intIndexRegex.FindString(s)","}","","// ExtractIndex will extract int from `[int]`","func ExtractIndex(s string) (int, error) {","\treturn strconv.Atoi(strings.TrimSuffix(strings.TrimPrefix(s, \"[\"), \"]\"))","}","","// StripStarVarSubExpression strips \"$(target[*])\"\" to get \"target\"","func StripStarVarSubExpression(s string) string {","\treturn strings.TrimSuffix(strings.TrimSuffix(strings.TrimPrefix(s, \"$(\"), \")\"), \"[*]\")","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,0,0,0,0,0,0,2,2,2,1,1,1,1,1,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,0,0,2,0,0,0,0,0,0,0,0,2,2,2,2,1,1,1,1,1,2,2,1,1,1,1,1,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,0,0,0,0,2,2,2,2,1,1,2,2,1,1,2,0,0,0,0,0,0,2,2,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,0,0,0,2,0,0,0,2,2,2,2,2,2,0,2,2,1,1,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,2,2,2,2,2,2,0,0,0,2,2,2,0,0,2,2,2,0,2,2,2,2,1,1,0,2,2,2,2,2,0,0,0,2,2,2,0,0,2,2,2,0,0,2,2,2]},{"id":270,"path":"pkg/taskrunmetrics/fake/fake.go","lines":["/*","Copyright 2021 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package fake","","import (","\t\"context\"","","\t_ \"github.com/tektoncd/pipeline/pkg/client/injection/informers/pipeline/v1/taskrun/fake\" // Make sure the fake taskrun informer is setup","\t\"github.com/tektoncd/pipeline/pkg/taskrunmetrics\"","\t\"k8s.io/client-go/rest\"","\t\"knative.dev/pkg/injection\"",")","","func init() {","\tinjection.Fake.RegisterClient(func(ctx context.Context, _ *rest.Config) context.Context { return taskrunmetrics.WithClient(ctx) })","\tinjection.Fake.RegisterInformer(taskrunmetrics.WithInformer)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0]},{"id":271,"path":"pkg/taskrunmetrics/injection.go","lines":["/*","Copyright 2021 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package taskrunmetrics","","import (","\t\"context\"","","\ttaskruninformer \"github.com/tektoncd/pipeline/pkg/client/injection/informers/pipeline/v1/taskrun\"","\tlisters \"github.com/tektoncd/pipeline/pkg/client/listers/pipeline/v1\"","\t\"k8s.io/client-go/rest\"","\t\"knative.dev/pkg/controller\"","\t\"knative.dev/pkg/injection\"","\t\"knative.dev/pkg/logging\"",")","","func init() {","\tinjection.Default.RegisterClient(func(ctx context.Context, _ *rest.Config) context.Context { return WithClient(ctx) })","\tinjection.Default.RegisterInformer(WithInformer)","}","","// RecorderKey is used for associating the Recorder inside the context.Context.","type RecorderKey struct{}","","// WithClient adds a metrics recorder to the given context","func WithClient(ctx context.Context) context.Context {","\trec, err := NewRecorder(ctx)","\tif err != nil {","\t\tlogging.FromContext(ctx).Errorf(\"Failed to create taskrun metrics recorder %v\", err)","\t}","\treturn context.WithValue(ctx, RecorderKey{}, rec)","}","","// Get extracts the taskrunmetrics.Recorder from the context.","func Get(ctx context.Context) *Recorder {","\tuntyped := ctx.Value(RecorderKey{})","\tif untyped == nil {","\t\tlogging.FromContext(ctx).Panic(\"Unable to fetch *taskrunmetrics.Recorder from context.\")","\t}","\treturn untyped.(*Recorder)","}","","// InformerKey is used for associating the Informer inside the context.Context.","type InformerKey struct{}","","// WithInformer returns the given context, and a configured informer","func WithInformer(ctx context.Context) (context.Context, controller.Informer) {","\treturn ctx, \u0026recorderInformer{","\t\tctx:     ctx,","\t\tmetrics: Get(ctx),","\t\tlister:  taskruninformer.Get(ctx).Lister(),","\t}","}","","type recorderInformer struct {","\tctx     context.Context","\tmetrics *Recorder","\tlister  listers.TaskRunLister","}","","var _ controller.Informer = (*recorderInformer)(nil)","","// Run starts the recorder informer in a goroutine","func (ri *recorderInformer) Run(stopCh \u003c-chan struct{}) {","\t// Turn the stopCh into a context for reporting metrics.","\tctx, cancel := context.WithCancel(ri.ctx)","\tgo func() {","\t\t\u003c-stopCh","\t\tcancel()","\t}()","","\tgo ri.metrics.ReportRunningTaskRuns(ctx, ri.lister)","}","","// HasSynced returns whether the informer has synced, which in this case will always be true.","func (ri *recorderInformer) HasSynced() bool {","\treturn true","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,0,0,0,0,1,1,1,1,1,1,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,1,0,0,0,1,1,1]},{"id":272,"path":"pkg/taskrunmetrics/metrics.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package taskrunmetrics","","import (","\t\"context\"","\t\"encoding/hex\"","\t\"fmt\"","\t\"sync\"","\t\"time\"","","\t\"github.com/pkg/errors\"","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tlisters \"github.com/tektoncd/pipeline/pkg/client/listers/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/pod\"","\t\"go.opencensus.io/stats\"","\t\"go.opencensus.io/stats/view\"","\t\"go.opencensus.io/tag\"","\t\"go.uber.org/zap\"","\t\"golang.org/x/crypto/blake2b\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/api/equality\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/apimachinery/pkg/labels\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/logging\"","\t\"knative.dev/pkg/metrics\"",")","","const anonymous = \"anonymous\"","","var (","\tpipelinerunTag = tag.MustNewKey(\"pipelinerun\")","\tpipelineTag    = tag.MustNewKey(\"pipeline\")","\ttaskrunTag     = tag.MustNewKey(\"taskrun\")","\ttaskTag        = tag.MustNewKey(\"task\")","\tnamespaceTag   = tag.MustNewKey(\"namespace\")","\tstatusTag      = tag.MustNewKey(\"status\")","\treasonTag      = tag.MustNewKey(\"reason\")","\tpodTag         = tag.MustNewKey(\"pod\")","","\ttrDurationView                             *view.View","\tprTRDurationView                           *view.View","\ttrTotalView                                *view.View","\trunningTRsView                             *view.View","\trunningTRsThrottledByQuotaView             *view.View","\trunningTRsThrottledByNodeView              *view.View","\trunningTRsWaitingOnTaskResolutionCountView *view.View","\tpodLatencyView                             *view.View","","\ttrDuration = stats.Float64(","\t\t\"taskrun_duration_seconds\",","\t\t\"The taskrun's execution time in seconds\",","\t\tstats.UnitDimensionless)","","\tprTRDuration = stats.Float64(","\t\t\"pipelinerun_taskrun_duration_seconds\",","\t\t\"The pipelinerun's taskrun execution time in seconds\",","\t\tstats.UnitDimensionless)","","\ttrTotal = stats.Float64(\"taskrun_total\",","\t\t\"Number of taskruns\",","\t\tstats.UnitDimensionless)","","\trunningTRs = stats.Float64(\"running_taskruns\",","\t\t\"Number of taskruns executing currently\",","\t\tstats.UnitDimensionless)","","\trunningTRsWaitingOnTaskResolutionCount = stats.Float64(\"running_taskruns_waiting_on_task_resolution_count\",","\t\t\"Number of taskruns executing currently that are waiting on resolution requests for their task references.\",","\t\tstats.UnitDimensionless)","","\trunningTRsThrottledByQuota = stats.Float64(\"running_taskruns_throttled_by_quota\",","\t\t\"Number of taskruns executing currently, but whose underlying Pods or Containers are suspended by k8s because of defined ResourceQuotas.  Such suspensions can occur as part of initial scheduling of the Pod, or scheduling of any of the subsequent Container(s) in the Pod after the first Container is started\",","\t\tstats.UnitDimensionless)","","\trunningTRsThrottledByNode = stats.Float64(\"running_taskruns_throttled_by_node\",","\t\t\"Number of taskruns executing currently, but whose underlying Pods or Containers are suspended by k8s because of Node level constraints. Such suspensions can occur as part of initial scheduling of the Pod, or scheduling of any of the subsequent Container(s) in the Pod after the first Container is started\",","\t\tstats.UnitDimensionless)","","\tpodLatency = stats.Float64(\"taskruns_pod_latency_milliseconds\",","\t\t\"scheduling latency for the taskruns pods\",","\t\tstats.UnitMilliseconds)",")","","// Recorder is used to actually record TaskRun metrics","type Recorder struct {","\tmutex       sync.Mutex","\tinitialized bool","\tcfg         *config.Metrics","","\tReportingPeriod time.Duration","","\tinsertTaskTag func(task,","\t\ttaskrun string) []tag.Mutator","","\tinsertPipelineTag func(pipeline,","\t\tpipelinerun string) []tag.Mutator","","\thash string","}","","// We cannot register the view multiple times, so NewRecorder lazily","// initializes this singleton and returns the same recorder across any","// subsequent invocations.","var (","\tonce           sync.Once","\tr              *Recorder","\terrRegistering error",")","","// NewRecorder creates a new metrics recorder instance","// to log the TaskRun related metrics","func NewRecorder(ctx context.Context) (*Recorder, error) {","\tonce.Do(func() {","\t\tcfg := config.FromContextOrDefaults(ctx)","\t\tr = \u0026Recorder{","\t\t\tinitialized: true,","\t\t\tcfg:         cfg.Metrics,","","\t\t\t// Default to reporting metrics every 30s.","\t\t\tReportingPeriod: 30 * time.Second,","\t\t}","","\t\terrRegistering = viewRegister(cfg.Metrics)","\t\tif errRegistering != nil {","\t\t\tr.initialized = false","\t\t\treturn","\t\t}","\t})","","\treturn r, errRegistering","}","","func viewRegister(cfg *config.Metrics) error {","\tr.mutex.Lock()","\tdefer r.mutex.Unlock()","","\tvar prunTag []tag.Key","\tswitch cfg.PipelinerunLevel {","\tcase config.PipelinerunLevelAtPipelinerun:","\t\tprunTag = []tag.Key{pipelineTag, pipelinerunTag}","\t\tr.insertPipelineTag = pipelinerunInsertTag","\tcase config.PipelinerunLevelAtPipeline:","\t\tprunTag = []tag.Key{pipelineTag}","\t\tr.insertPipelineTag = pipelineInsertTag","\tcase config.PipelinerunLevelAtNS:","\t\tprunTag = []tag.Key{}","\t\tr.insertPipelineTag = nilInsertTag","\tdefault:","\t\treturn errors.New(\"invalid config for PipelinerunLevel: \" + cfg.PipelinerunLevel)","\t}","","\tvar trunTag []tag.Key","\tswitch cfg.TaskrunLevel {","\tcase config.TaskrunLevelAtTaskrun:","\t\ttrunTag = []tag.Key{taskTag, taskrunTag}","\t\tr.insertTaskTag = taskrunInsertTag","\tcase config.TaskrunLevelAtTask:","\t\ttrunTag = []tag.Key{taskTag}","\t\tr.insertTaskTag = taskInsertTag","\tcase config.PipelinerunLevelAtNS:","\t\ttrunTag = []tag.Key{}","\t\tr.insertTaskTag = nilInsertTag","\tdefault:","\t\treturn errors.New(\"invalid config for TaskrunLevel: \" + cfg.TaskrunLevel)","\t}","","\tdistribution := view.Distribution(10, 30, 60, 300, 900, 1800, 3600, 5400, 10800, 21600, 43200, 86400)","","\tif cfg.TaskrunLevel == config.TaskrunLevelAtTaskrun ||","\t\tcfg.PipelinerunLevel == config.PipelinerunLevelAtPipelinerun {","\t\tdistribution = view.LastValue()","\t} else {","\t\tswitch cfg.DurationTaskrunType {","\t\tcase config.DurationTaskrunTypeHistogram:","\t\tcase config.DurationTaskrunTypeLastValue:","\t\t\tdistribution = view.LastValue()","\t\tdefault:","\t\t\treturn errors.New(\"invalid config for DurationTaskrunType: \" + cfg.DurationTaskrunType)","\t\t}","\t}","","\tif cfg.CountWithReason {","\t\ttrunTag = append(trunTag, reasonTag)","\t}","","\ttrDurationView = \u0026view.View{","\t\tDescription: trDuration.Description(),","\t\tMeasure:     trDuration,","\t\tAggregation: distribution,","\t\tTagKeys:     append([]tag.Key{statusTag, namespaceTag}, trunTag...),","\t}","\tprTRDurationView = \u0026view.View{","\t\tDescription: prTRDuration.Description(),","\t\tMeasure:     prTRDuration,","\t\tAggregation: distribution,","\t\tTagKeys:     append([]tag.Key{statusTag, namespaceTag}, append(trunTag, prunTag...)...),","\t}","","\ttrTotalView = \u0026view.View{","\t\tDescription: trTotal.Description(),","\t\tMeasure:     trTotal,","\t\tAggregation: view.Count(),","\t\tTagKeys:     []tag.Key{statusTag},","\t}","","\trunningTRsView = \u0026view.View{","\t\tDescription: runningTRs.Description(),","\t\tMeasure:     runningTRs,","\t\tAggregation: view.LastValue(),","\t}","\trunningTRsWaitingOnTaskResolutionCountView = \u0026view.View{","\t\tDescription: runningTRsWaitingOnTaskResolutionCount.Description(),","\t\tMeasure:     runningTRsWaitingOnTaskResolutionCount,","\t\tAggregation: view.LastValue(),","\t}","","\tthrottleViewTags := []tag.Key{}","\tif cfg.ThrottleWithNamespace {","\t\tthrottleViewTags = append(throttleViewTags, namespaceTag)","\t}","\trunningTRsThrottledByQuotaView = \u0026view.View{","\t\tDescription: runningTRsThrottledByQuota.Description(),","\t\tMeasure:     runningTRsThrottledByQuota,","\t\tAggregation: view.LastValue(),","\t\tTagKeys:     throttleViewTags,","\t}","\trunningTRsThrottledByNodeView = \u0026view.View{","\t\tDescription: runningTRsThrottledByNode.Description(),","\t\tMeasure:     runningTRsThrottledByNode,","\t\tAggregation: view.LastValue(),","\t\tTagKeys:     throttleViewTags,","\t}","\tpodLatencyView = \u0026view.View{","\t\tDescription: podLatency.Description(),","\t\tMeasure:     podLatency,","\t\tAggregation: view.LastValue(),","\t\tTagKeys:     append([]tag.Key{namespaceTag, podTag}, trunTag...),","\t}","\treturn view.Register(","\t\ttrDurationView,","\t\tprTRDurationView,","\t\ttrTotalView,","\t\trunningTRsView,","\t\trunningTRsWaitingOnTaskResolutionCountView,","\t\trunningTRsThrottledByQuotaView,","\t\trunningTRsThrottledByNodeView,","\t\tpodLatencyView,","\t)","}","","func viewUnregister() {","\tview.Unregister(","\t\ttrDurationView,","\t\tprTRDurationView,","\t\ttrTotalView,","\t\trunningTRsView,","\t\trunningTRsWaitingOnTaskResolutionCountView,","\t\trunningTRsThrottledByQuotaView,","\t\trunningTRsThrottledByNodeView,","\t\tpodLatencyView,","\t)","}","","// OnStore returns a function that checks if metrics are configured for a config.Store, and registers it if so","func OnStore(logger *zap.SugaredLogger, r *Recorder) func(name string, value interface{}) {","\treturn func(name string, value interface{}) {","\t\tif name == config.GetMetricsConfigName() {","\t\t\tcfg, ok := value.(*config.Metrics)","\t\t\tif !ok {","\t\t\t\tlogger.Error(\"Failed to do type insertion for extracting metrics config\")","\t\t\t\treturn","\t\t\t}","\t\t\tupdated := r.updateConfig(cfg)","\t\t\tif !updated {","\t\t\t\treturn","\t\t\t}","\t\t\t// Update metrics according to the configuration","\t\t\tviewUnregister()","\t\t\terr := viewRegister(cfg)","\t\t\tif err != nil {","\t\t\t\tlogger.Errorf(\"Failed to register View %v \", err)","\t\t\t\treturn","\t\t\t}","\t\t}","\t}","}","","func pipelinerunInsertTag(pipeline, pipelinerun string) []tag.Mutator {","\treturn []tag.Mutator{","\t\ttag.Insert(pipelineTag, pipeline),","\t\ttag.Insert(pipelinerunTag, pipelinerun),","\t}","}","","func pipelineInsertTag(pipeline, pipelinerun string) []tag.Mutator {","\treturn []tag.Mutator{tag.Insert(pipelineTag, pipeline)}","}","","func taskrunInsertTag(task, taskrun string) []tag.Mutator {","\treturn []tag.Mutator{","\t\ttag.Insert(taskTag, task),","\t\ttag.Insert(taskrunTag, taskrun),","\t}","}","","func taskInsertTag(task, taskrun string) []tag.Mutator {","\treturn []tag.Mutator{tag.Insert(taskTag, task)}","}","","func nilInsertTag(task, taskrun string) []tag.Mutator {","\treturn []tag.Mutator{}","}","","func getTaskTagName(tr *v1.TaskRun) string {","\ttaskName := anonymous","\tswitch {","\tcase tr.Spec.TaskRef != nil \u0026\u0026 len(tr.Spec.TaskRef.Name) \u003e 0:","\t\ttaskName = tr.Spec.TaskRef.Name","\tcase tr.Spec.TaskSpec != nil:","\t\tpipelineTaskTable, hasPipelineTaskTable := tr.Labels[pipeline.PipelineTaskLabelKey]","\t\tif hasPipelineTaskTable \u0026\u0026 len(pipelineTaskTable) \u003e 0 {","\t\t\ttaskName = pipelineTaskTable","\t\t}","\tdefault:","\t\tif len(tr.Labels) \u003e 0 {","\t\t\ttaskLabel, hasTaskLabel := tr.Labels[pipeline.TaskLabelKey]","\t\t\tif hasTaskLabel \u0026\u0026 len(taskLabel) \u003e 0 {","\t\t\t\ttaskName = taskLabel","\t\t\t}","\t\t}","\t}","","\treturn taskName","}","","func (r *Recorder) updateConfig(cfg *config.Metrics) bool {","\tr.mutex.Lock()","\tdefer r.mutex.Unlock()","","\tvar hash string","\tif cfg != nil {","\t\ts := fmt.Sprintf(\"%v\", *cfg)","\t\tsum := blake2b.Sum256([]byte(s))","\t\thash = hex.EncodeToString(sum[:])","\t}","","\tif r.hash == hash {","\t\treturn false","\t}","","\tr.cfg = cfg","\tr.hash = hash","","\treturn true","}","","// DurationAndCount logs the duration of TaskRun execution and","// count for number of TaskRuns succeed or failed","// returns an error if its failed to log the metrics","func (r *Recorder) DurationAndCount(ctx context.Context, tr *v1.TaskRun, beforeCondition *apis.Condition) error {","\tif !r.initialized {","\t\treturn fmt.Errorf(\"ignoring the metrics recording for %s , failed to initialize the metrics recorder\", tr.Name)","\t}","","\tafterCondition := tr.Status.GetCondition(apis.ConditionSucceeded)","\tif equality.Semantic.DeepEqual(beforeCondition, afterCondition) {","\t\treturn nil","\t}","","\tr.mutex.Lock()","\tdefer r.mutex.Unlock()","","\tduration := time.Since(tr.Status.StartTime.Time)","\tif tr.Status.CompletionTime != nil {","\t\tduration = tr.Status.CompletionTime.Sub(tr.Status.StartTime.Time)","\t}","","\ttaskName := getTaskTagName(tr)","","\tcond := tr.Status.GetCondition(apis.ConditionSucceeded)","\tstatus := \"success\"","\tif cond.Status == corev1.ConditionFalse {","\t\tstatus = \"failed\"","\t}","\treason := cond.Reason","","\tdurationStat := trDuration","\ttags := []tag.Mutator{tag.Insert(namespaceTag, tr.Namespace), tag.Insert(statusTag, status), tag.Insert(reasonTag, reason)}","\tif ok, pipeline, pipelinerun := IsPartOfPipeline(tr); ok {","\t\tdurationStat = prTRDuration","\t\ttags = append(tags, r.insertPipelineTag(pipeline, pipelinerun)...)","\t}","\ttags = append(tags, r.insertTaskTag(taskName, tr.Name)...)","","\tctx, err := tag.New(ctx, tags...)","\tif err != nil {","\t\treturn err","\t}","","\tmetrics.Record(ctx, durationStat.M(duration.Seconds()))","\tmetrics.Record(ctx, trTotal.M(1))","","\treturn nil","}","","// RunningTaskRuns logs the number of TaskRuns running right now","// returns an error if its failed to log the metrics","func (r *Recorder) RunningTaskRuns(ctx context.Context, lister listers.TaskRunLister) error {","\tr.mutex.Lock()","\tdefer r.mutex.Unlock()","","\tif !r.initialized {","\t\treturn errors.New(\"ignoring the metrics recording, failed to initialize the metrics recorder\")","\t}","","\ttrs, err := lister.List(labels.Everything())","\tif err != nil {","\t\treturn err","\t}","","\taddNamespaceLabelToQuotaThrottleMetric := r.cfg != nil \u0026\u0026 r.cfg.ThrottleWithNamespace","","\tvar runningTrs int","\ttrsThrottledByQuota := map[string]int{}","\ttrsThrottledByNode := map[string]int{}","\tvar trsWaitResolvingTaskRef int","\tfor _, pr := range trs {","\t\t// initialize metrics with namespace tag to zero if unset; will then update as needed below","\t\t_, ok := trsThrottledByQuota[pr.Namespace]","\t\tif !ok {","\t\t\ttrsThrottledByQuota[pr.Namespace] = 0","\t\t}","\t\t_, ok = trsThrottledByNode[pr.Namespace]","\t\tif !ok {","\t\t\ttrsThrottledByNode[pr.Namespace] = 0","\t\t}","","\t\tif pr.IsDone() {","\t\t\tcontinue","\t\t}","\t\trunningTrs++","","\t\tsucceedCondition := pr.Status.GetCondition(apis.ConditionSucceeded)","\t\tif succeedCondition != nil \u0026\u0026 succeedCondition.Status == corev1.ConditionUnknown {","\t\t\tswitch succeedCondition.Reason {","\t\t\tcase pod.ReasonExceededResourceQuota:","\t\t\t\tcnt := trsThrottledByQuota[pr.Namespace]","\t\t\t\tcnt++","\t\t\t\ttrsThrottledByQuota[pr.Namespace] = cnt","\t\t\tcase pod.ReasonExceededNodeResources:","\t\t\t\tcnt := trsThrottledByNode[pr.Namespace]","\t\t\t\tcnt++","\t\t\t\ttrsThrottledByNode[pr.Namespace] = cnt","\t\t\tcase v1.TaskRunReasonResolvingTaskRef:","\t\t\t\ttrsWaitResolvingTaskRef++","\t\t\t}","\t\t}","\t}","","\tctx, err = tag.New(ctx)","\tif err != nil {","\t\treturn err","\t}","\tmetrics.Record(ctx, runningTRs.M(float64(runningTrs)))","\tmetrics.Record(ctx, runningTRsWaitingOnTaskResolutionCount.M(float64(trsWaitResolvingTaskRef)))","","\tfor ns, cnt := range trsThrottledByQuota {","\t\tvar mutators []tag.Mutator","\t\tif addNamespaceLabelToQuotaThrottleMetric {","\t\t\tmutators = []tag.Mutator{tag.Insert(namespaceTag, ns)}","\t\t}","\t\tctx, err := tag.New(ctx, mutators...)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tmetrics.Record(ctx, runningTRsThrottledByQuota.M(float64(cnt)))","\t}","\tfor ns, cnt := range trsThrottledByNode {","\t\tvar mutators []tag.Mutator","\t\tif addNamespaceLabelToQuotaThrottleMetric {","\t\t\tmutators = []tag.Mutator{tag.Insert(namespaceTag, ns)}","\t\t}","\t\tctx, err := tag.New(ctx, mutators...)","\t\tif err != nil {","\t\t\treturn err","\t\t}","\t\tmetrics.Record(ctx, runningTRsThrottledByNode.M(float64(cnt)))","\t}","\treturn nil","}","","// ReportRunningTaskRuns invokes RunningTaskRuns on our configured PeriodSeconds","// until the context is cancelled.","func (r *Recorder) ReportRunningTaskRuns(ctx context.Context, lister listers.TaskRunLister) {","\tlogger := logging.FromContext(ctx)","\tfor {","\t\tdelay := time.NewTimer(r.ReportingPeriod)","\t\tselect {","\t\tcase \u003c-ctx.Done():","\t\t\t// When the context is cancelled, stop reporting.","\t\t\tif !delay.Stop() {","\t\t\t\t\u003c-delay.C","\t\t\t}","\t\t\treturn","","\t\tcase \u003c-delay.C:","\t\t\t// Every 30s surface a metric for the number of running tasks, as well as those running tasks that are currently throttled by k8s,","\t\t\t// and those running tasks waiting on task reference resolution","\t\t\tif err := r.RunningTaskRuns(ctx, lister); err != nil {","\t\t\t\tlogger.Warnf(\"Failed to log the metrics : %v\", err)","\t\t\t}","\t\t}","\t}","}","","// RecordPodLatency logs the duration required to schedule the pod for TaskRun","// returns an error if its failed to log the metrics","func (r *Recorder) RecordPodLatency(ctx context.Context, pod *corev1.Pod, tr *v1.TaskRun) error {","\tr.mutex.Lock()","\tdefer r.mutex.Unlock()","","\tif !r.initialized {","\t\treturn errors.New(\"ignoring the metrics recording for pod , failed to initialize the metrics recorder\")","\t}","","\tscheduledTime := getScheduledTime(pod)","\tif scheduledTime.IsZero() {","\t\treturn errors.New(\"pod has never got scheduled\")","\t}","","\tlatency := scheduledTime.Sub(pod.CreationTimestamp.Time)","\ttaskName := getTaskTagName(tr)","","\tctx, err := tag.New(","\t\tctx,","\t\tappend([]tag.Mutator{","\t\t\ttag.Insert(namespaceTag, tr.Namespace),","\t\t\ttag.Insert(podTag, pod.Name),","\t\t},","\t\t\tr.insertTaskTag(taskName, tr.Name)...)...)","\tif err != nil {","\t\treturn err","\t}","","\tmetrics.Record(ctx, podLatency.M(float64(latency.Milliseconds())))","","\treturn nil","}","","// IsPartOfPipeline return true if TaskRun is a part of a Pipeline.","// It also return the name of Pipeline and PipelineRun","func IsPartOfPipeline(tr *v1.TaskRun) (bool, string, string) {","\tpipelineLabel, hasPipelineLabel := tr.Labels[pipeline.PipelineLabelKey]","\tpipelineRunLabel, hasPipelineRunLabel := tr.Labels[pipeline.PipelineRunLabelKey]","","\tif hasPipelineLabel \u0026\u0026 hasPipelineRunLabel {","\t\treturn true, pipelineLabel, pipelineRunLabel","\t}","","\treturn false, \"\", \"\"","}","","func getScheduledTime(pod *corev1.Pod) metav1.Time {","\tfor _, c := range pod.Status.Conditions {","\t\tif c.Type == corev1.PodScheduled {","\t\t\treturn c.LastTransitionTime","\t\t}","\t}","","\treturn metav1.Time{}","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,0,0,2,0,0,2,2,2,2,2,2,2,2,2,1,1,1,2,2,2,2,2,0,0,2,2,2,2,2,1,1,1,2,2,2,1,1,0,0,2,2,2,2,2,2,2,0,2,2,1,1,0,0,0,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,0,1,1,1,0,2,2,2,2,2,2,0,1,1,1,0,1,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,2,0,0,0,0,0,2,2,2,2,0,2,2,2,2,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,0,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,1,1,2,2,2,2,2,2,2,2,2,2,1,1,2,0,2,2,2,2,2,2,2,1,1,2,0,2,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,0,0,0,0,0,2,2,2,2,2,2,2,0,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,1,1,0,2,2,2,0,0,0,0,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,0,0,2,0]},{"id":273,"path":"pkg/termination/parse.go","lines":["//go:build !disable_tls","","/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package termination","","import (","\t\"encoding/json\"","\t\"fmt\"","\t\"sort\"","","\t\"github.com/tektoncd/pipeline/pkg/result\"","\t\"go.uber.org/zap\"",")","","// ParseMessage parses a termination message as results.","//","// If more than one item has the same key, only the latest is returned. Items","// are sorted by their key.","func ParseMessage(logger *zap.SugaredLogger, msg string) ([]result.RunResult, error) {","\tif msg == \"\" {","\t\treturn nil, nil","\t}","","\tvar r []result.RunResult","\tif err := json.Unmarshal([]byte(msg), \u0026r); err != nil {","\t\treturn nil, fmt.Errorf(\"parsing message json: %w, msg: %s\", err, msg)","\t}","","\twriteIndex := 0","\tfor _, rr := range r {","\t\tif rr != (result.RunResult{}) {","\t\t\t// Erase incorrect result","\t\t\tr[writeIndex] = rr","\t\t\twriteIndex++","\t\t} else {","\t\t\tlogger.Errorf(\"termination message contains non taskrun or pipelineresource result keys\")","\t\t}","\t}","\tr = r[:writeIndex]","","\t// Remove duplicates (last one wins) and sort by key.","\tm := map[string]result.RunResult{}","\tfor _, rr := range r {","\t\tm[rr.Key] = rr","\t}","\tr2 := make([]result.RunResult, 0, len(m))","\tfor _, v := range m {","\t\tr2 = append(r2, v)","\t}","\tsort.Slice(r2, func(i, j int) bool { return r2[i].Key \u003c r2[j].Key })","","\treturn r2, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,0,2,2,2,2,0,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0]},{"id":274,"path":"pkg/termination/write.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package termination","","import (","\t\"encoding/json\"","\t\"os\"","","\t\"github.com/tektoncd/pipeline/pkg/result\"",")","","const (","\t// MaxContainerTerminationMessageLength is the upper bound any one container may write to","\t// its termination message path. Contents above this length will cause a failure.","\tMaxContainerTerminationMessageLength = 1024 * 4",")","","// WriteMessage writes the results to the termination message path.","func WriteMessage(path string, pro []result.RunResult) error {","\t// if the file at path exists, concatenate the new values otherwise create it","\t// file at path already exists","\tfileContents, err := os.ReadFile(path)","\tif err == nil {","\t\tvar existingEntries []result.RunResult","\t\tif err := json.Unmarshal(fileContents, \u0026existingEntries); err == nil {","\t\t\t// append new entries to existing entries","\t\t\tpro = append(existingEntries, pro...)","\t\t}","\t} else if !os.IsNotExist(err) {","\t\treturn err","\t}","\tjsonOutput, err := json.Marshal(pro)","\tif err != nil {","\t\treturn err","\t}","","\tif len(jsonOutput) \u003e MaxContainerTerminationMessageLength {","\t\treturn errTooLong","\t}","","\tf, err := os.OpenFile(path, os.O_WRONLY|os.O_CREATE, 0666)","\tif err != nil {","\t\treturn err","\t}","\tdefer f.Close()","","\tif _, err = f.Write(jsonOutput); err != nil {","\t\treturn err","\t}","\treturn f.Sync()","}","","// MessageLengthError indicate the length of termination message of container is beyond 4096 which is the max length read by kubenates","type MessageLengthError string","","const (","\terrTooLong MessageLengthError = \"Termination message is above max allowed size 4096, caused by large task result.\"",")","","func (e MessageLengthError) Error() string {","\treturn string(e)","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,1,1,1,2,2,1,1,0,2,2,2,0,2,2,1,1,2,2,2,1,1,2,0,0,0,0,0,0,0,0,0,1,1,1]},{"id":275,"path":"pkg/tracing/tracing.go","lines":["/*","Copyright 2023 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package tracing","","import (","\t\"context\"","\t\"encoding/base64\"","\t\"fmt\"","\t\"net/url\"","","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\t\"go.opentelemetry.io/otel\"","\t\"go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracehttp\"","\t\"go.opentelemetry.io/otel/propagation\"","\t\"go.opentelemetry.io/otel/sdk/resource\"","\ttracesdk \"go.opentelemetry.io/otel/sdk/trace\"","\tsemconv \"go.opentelemetry.io/otel/semconv/v1.12.0\"","\t\"go.opentelemetry.io/otel/trace\"","\t\"go.opentelemetry.io/otel/trace/embedded\"","\t\"go.opentelemetry.io/otel/trace/noop\"","\t\"go.uber.org/zap\"","\tcorev1 \"k8s.io/api/core/v1\"","\tlisterv1 \"k8s.io/client-go/listers/core/v1\"","\t\"knative.dev/pkg/system\"",")","","type tracerProvider struct {","\tembedded.TracerProvider","","\tservice  string","\tprovider trace.TracerProvider","\tcfg      *config.Tracing","\tusername string","\tpassword string","\tlogger   *zap.SugaredLogger","}","","func init() {","\totel.SetTextMapPropagator(propagation.TraceContext{})","}","","// New returns a new instance of tracerProvider for the given service","func New(service string, logger *zap.SugaredLogger) *tracerProvider {","\treturn \u0026tracerProvider{","\t\tservice:  service,","\t\tprovider: noop.NewTracerProvider(),","\t\tlogger:   logger,","\t}","}","","// OnStore configures tracerProvider dynamically","func (t *tracerProvider) OnStore(lister listerv1.SecretLister) func(name string, value interface{}) {","\treturn func(name string, value interface{}) {","\t\tif name != config.GetTracingConfigName() {","\t\t\treturn","\t\t}","","\t\tcfg, ok := value.(*config.Tracing)","\t\tif !ok {","\t\t\tt.logger.Error(\"tracing configmap is in invalid format. value: %v\", value)","\t\t\treturn","\t\t}","","\t\tif cfg.Equals(t.cfg) {","\t\t\tt.logger.Info(\"tracing config unchanged\", cfg, t.cfg)","\t\t\treturn","\t\t}","\t\tt.cfg = cfg","","\t\tif lister != nil \u0026\u0026 cfg.CredentialsSecret != \"\" {","\t\t\tsec, err := lister.Secrets(system.Namespace()).Get(cfg.CredentialsSecret)","\t\t\tif err != nil {","\t\t\t\tt.logger.Errorf(\"unable to initialize tracing with error : %v\", err.Error())","\t\t\t\treturn","\t\t\t}","\t\t\tcreds := sec.Data","\t\t\tt.username = string(creds[\"username\"])","\t\t\tt.password = string(creds[\"password\"])","\t\t} else {","\t\t\tt.username = \"\"","\t\t\tt.password = \"\"","\t\t}","","\t\tt.reinitialize()","\t}","}","","func (t *tracerProvider) Tracer(name string, options ...trace.TracerOption) trace.Tracer {","\treturn t.provider.Tracer(name, options...)","}","","// Handler is called by the informer when the secret is updated","func (t *tracerProvider) Handler(obj interface{}) {","\tsecret, ok := obj.(*corev1.Secret)","\tif !ok {","\t\tt.logger.Error(\"Failed to do type assertion for Secret\")","\t\treturn","\t}","\tt.OnSecret(secret)","}","","func (t *tracerProvider) OnSecret(secret *corev1.Secret) {","\tif secret.Name != t.cfg.CredentialsSecret {","\t\treturn","\t}","","\tcreds := secret.Data","\tusername := string(creds[\"username\"])","\tpassword := string(creds[\"password\"])","","\tif t.username == username \u0026\u0026 t.password == password {","\t\t// No change in credentials, no need to reinitialize","\t\treturn","\t}","\tt.username = username","\tt.password = password","","\tt.logger.Debugf(\"tracing credentials updated, reinitializing tracingprovider with secret: %v\", secret.Name)","","\tt.reinitialize()","}","","func (t *tracerProvider) reinitialize() {","\ttp, err := createTracerProvider(t.service, t.cfg, t.username, t.password)","\tif err != nil {","\t\tt.logger.Errorf(\"unable to initialize tracing with error : %v\", err.Error())","\t\treturn","\t}","\tt.logger.Info(\"initialized Tracer Provider\")","\tif p, ok := t.provider.(*tracesdk.TracerProvider); ok {","\t\tif err := p.Shutdown(context.Background()); err != nil {","\t\t\tt.logger.Errorf(\"unable to shutdown tracingprovider with error : %v\", err.Error())","\t\t}","\t}","\tt.provider = tp","}","","func createTracerProvider(service string, cfg *config.Tracing, user, pass string) (trace.TracerProvider, error) {","\tif !cfg.Enabled {","\t\treturn noop.NewTracerProvider(), nil","\t}","\tu, err := url.Parse(cfg.Endpoint)","\tif err != nil {","\t\treturn nil, err","\t}","","\topts := []otlptracehttp.Option{","\t\totlptracehttp.WithEndpoint(u.Host),","\t\totlptracehttp.WithURLPath(u.Path),","\t}","","\tif u.Scheme == \"http\" {","\t\topts = append(opts, otlptracehttp.WithInsecure())","\t}","","\tif user != \"\" \u0026\u0026 pass != \"\" {","\t\tcreds := fmt.Sprintf(\"%s:%s\", user, pass)","\t\tenc := base64.StdEncoding.EncodeToString([]byte(creds))","\t\to := otlptracehttp.WithHeaders(map[string]string{","\t\t\t\"Authorization\": \"Basic \" + enc,","\t\t})","\t\topts = append(opts, o)","\t}","","\tctx := context.Background()","\texp, err := otlptracehttp.New(ctx, opts...)","\tif err != nil {","\t\treturn nil, err","\t}","\t// Initialize tracerProvider with the jaeger exporter","\ttp := tracesdk.NewTracerProvider(","\t\ttracesdk.WithBatcher(exp),","\t\t// Record information about the service in a Resource.","\t\ttracesdk.WithResource(resource.NewWithAttributes(","\t\t\tsemconv.SchemaURL,","\t\t\tsemconv.ServiceNameKey.String(service),","\t\t)),","\t)","\treturn tp, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,1,1,0,2,2,1,1,1,0,2,1,1,1,2,2,2,2,2,1,1,1,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,0,0,2,2,2,1,1,1,2,0,0,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,1,1,1,2,2,2,1,1,0,2,0,0,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,2,0,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,0]},{"id":276,"path":"pkg/trustedresources/verifier/verifier.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package verifier","","import (","\t\"context\"","\t\"crypto\"","\t\"fmt\"","\t\"os\"","\t\"path/filepath\"","\t\"strings\"","","\t\"github.com/sigstore/sigstore/pkg/cryptoutils\"","\t\"github.com/sigstore/sigstore/pkg/signature\"","\t\"github.com/sigstore/sigstore/pkg/signature/kms\"","","\t// TODO(#5976): consider move these registration to cmd/controller/main.go","\t_ \"github.com/sigstore/sigstore/pkg/signature/kms/aws\"        // imported to execute init function to register aws kms","\t_ \"github.com/sigstore/sigstore/pkg/signature/kms/azure\"      // imported to execute init function to register azure kms","\t_ \"github.com/sigstore/sigstore/pkg/signature/kms/gcp\"        // imported to execute init function to register gcp kms","\t_ \"github.com/sigstore/sigstore/pkg/signature/kms/hashivault\" // imported to execute init function to register hashivault kms","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1alpha1\"","\tv1 \"k8s.io/api/core/v1\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/client-go/kubernetes\"",")","","const (","\t// keyReference is the prefix of secret reference","\tkeyReference = \"k8s://\"",")","","// FromPolicy get all verifiers from VerificationPolicy.","// For each policy, loop the Authorities of the VerificationPolicy to fetch public key","// from either inline Data or from a SecretRef.","func FromPolicy(ctx context.Context, k8s kubernetes.Interface, policy *v1alpha1.VerificationPolicy) ([]signature.Verifier, error) {","\tverifiers := []signature.Verifier{}","\tfor _, a := range policy.Spec.Authorities {","\t\talgorithm, err := matchHashAlgorithm(a.Key.HashAlgorithm)","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"authority %q contains an invalid hash algorithm: %w\", a.Name, err)","\t\t}","","\t\tswitch {","\t\tcase a.Key.Data != \"\":","\t\t\tv, err := fromData([]byte(a.Key.Data), algorithm)","\t\t\tif err != nil {","\t\t\t\treturn nil, fmt.Errorf(\"failed to get verifier from data: %w\", err)","\t\t\t}","\t\t\tverifiers = append(verifiers, v)","\t\tcase a.Key.SecretRef != nil:","\t\t\tv, err := fromSecret(ctx, fmt.Sprintf(\"%s%s/%s\", keyReference, a.Key.SecretRef.Namespace, a.Key.SecretRef.Name), algorithm, k8s)","\t\t\tif err != nil {","\t\t\t\treturn nil, fmt.Errorf(\"failed to get verifier from secret: %w\", err)","\t\t\t}","\t\t\tverifiers = append(verifiers, v)","\t\tcase a.Key.KMS != \"\":","\t\t\tv, err := kms.Get(ctx, a.Key.KMS, algorithm)","\t\t\tif err != nil {","\t\t\t\treturn nil, fmt.Errorf(\"failed to get verifier from kms: %w\", err)","\t\t\t}","\t\t\tverifiers = append(verifiers, v)","\t\tdefault:","\t\t\treturn nil, ErrEmptyKey","\t\t}","\t}","\tif len(verifiers) == 0 {","\t\treturn verifiers, ErrEmptyPublicKeys","\t}","\treturn verifiers, nil","}","","// fromKeyRef parses the given keyRef, loads the key and returns an appropriate","// verifier using the provided hash algorithm","func fromKeyRef(ctx context.Context, keyRef string, hashAlgorithm crypto.Hash, k8s kubernetes.Interface) (signature.Verifier, error) {","\tvar raw []byte","\tif strings.HasPrefix(keyRef, keyReference) {","\t\tv, err := fromSecret(ctx, keyRef, hashAlgorithm, k8s)","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed to get verifier from secret: %w\", err)","\t\t}","\t\treturn v, nil","\t}","\traw, err := os.ReadFile(filepath.Clean(keyRef))","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"%w: %v\", ErrFailedLoadKeyFile, err) //nolint:errorlint","\t}","\tv, err := fromData(raw, hashAlgorithm)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"failed to get verifier from data: %w\", err)","\t}","\treturn v, nil","}","","// fromSecret fetches the public key from SecretRef and returns the verifier","// hashAlgorithm is provided to determine the hash algorithm of the key","func fromSecret(ctx context.Context, secretRef string, hashAlgorithm crypto.Hash, k8s kubernetes.Interface) (signature.Verifier, error) {","\tif strings.HasPrefix(secretRef, keyReference) {","\t\ts, err := getKeyPairSecret(ctx, secretRef, k8s)","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed to get secret: %w\", err)","\t\t}","\t\t// only 1 public key should be in the secret","\t\tif len(s.Data) == 0 {","\t\t\treturn nil, fmt.Errorf(\"secret %q contains no data %w\", secretRef, ErrEmptySecretData)","\t\t}","\t\tif len(s.Data) \u003e 1 {","\t\t\treturn nil, fmt.Errorf(\"secret %q contains multiple data entries, only one is supported. %w\", secretRef, ErrMultipleSecretData)","\t\t}","\t\tfor _, raw := range s.Data {","\t\t\tv, err := fromData(raw, hashAlgorithm)","\t\t\tif err != nil {","\t\t\t\treturn nil, fmt.Errorf(\"failed to get verifier from secret data: %w\", err)","\t\t\t}","\t\t\treturn v, nil","\t\t}","\t}","\treturn nil, fmt.Errorf(\"%w: secretRef %v is invalid\", ErrK8sSpecificationInvalid, secretRef)","}","","// fromData fetches the public key from raw data and returns the verifier","func fromData(raw []byte, hashAlgorithm crypto.Hash) (signature.Verifier, error) {","\tpubKey, err := cryptoutils.UnmarshalPEMToPublicKey(raw)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"%w: %v\", ErrDecodeKey, err) //nolint:errorlint","\t}","\tv, err := signature.LoadVerifier(pubKey, hashAlgorithm)","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"%w: %v\", ErrLoadVerifier, err) //nolint:errorlint","\t}","\treturn v, nil","}","","// getKeyPairSecret fetches the secret from a k8sRef","// TODO(#5884): use a secret lister to fetch secrets","func getKeyPairSecret(ctx context.Context, k8sRef string, k8s kubernetes.Interface) (*v1.Secret, error) {","\tsplit := strings.Split(strings.TrimPrefix(k8sRef, keyReference), \"/\")","\tif len(split) != 2 {","\t\treturn nil, ErrK8sSpecificationInvalid","\t}","\tnamespace, name := split[0], split[1]","","\ts, err := k8s.CoreV1().Secrets(namespace).Get(ctx, name, metav1.GetOptions{})","\tif err != nil {","\t\treturn nil, fmt.Errorf(\"%w: %v\", ErrSecretNotFound, err) //nolint:errorlint","\t}","","\treturn s, nil","}","","// matchHashAlgorithm returns a crypto.Hash code using an algorithm name as input parameter","func matchHashAlgorithm(algorithmName v1alpha1.HashAlgorithm) (crypto.Hash, error) {","\tnormalizedAlgo := strings.ToLower(string(algorithmName))","\talgo, exists := v1alpha1.SupportedSignatureAlgorithms[v1alpha1.HashAlgorithm(normalizedAlgo)]","\tif !exists {","\t\treturn crypto.SHA256, fmt.Errorf(\"%w: %s\", ErrAlgorithmInvalid, algorithmName)","\t}","\treturn algo, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,0]},{"id":277,"path":"pkg/trustedresources/verify.go","lines":["/*","Copyright 2022 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package trustedresources","","import (","\t\"bytes\"","\t\"context\"","\t\"encoding/base64\"","\t\"errors\"","\t\"fmt\"","\t\"regexp\"","","\t\"github.com/sigstore/sigstore/pkg/signature\"","\t\"github.com/tektoncd/pipeline/pkg/apis/config\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1alpha1\"","\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1beta1\"","\t\"github.com/tektoncd/pipeline/pkg/trustedresources/verifier\"","\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"","\t\"k8s.io/client-go/kubernetes\"","\t\"knative.dev/pkg/apis\"","\t\"knative.dev/pkg/logging\"",")","","const (","\t// SignatureAnnotation is the key of signature in annotation map","\tSignatureAnnotation = \"tekton.dev/signature\"","\t// ConditionTrustedResourcesVerified specifies that the resources pass trusted resources verification or not.","\tConditionTrustedResourcesVerified apis.ConditionType = \"TrustedResourcesVerified\"",")","","const (","\tVerificationSkip = iota","\tVerificationPass","\tVerificationWarn","\tVerificationError",")","","type Hashable interface {","\tChecksum() ([]byte, error)","}","","// VerificationResultType indicates different cases of a verification result","type VerificationResultType int","","// VerificationResult contains the type and message about the result of verification","type VerificationResult struct {","\t// VerificationResultType has 4 types which is corresponding to 4 cases:","\t// 0 (VerificationSkip): The verification was skipped. Err is nil in this case.","\t// 1 (VerificationPass): The verification passed. Err is nil in this case.","\t// 2 (VerificationWarn): A warning is logged. It could be no matching policies and feature flag \"no-match-policy\" is \"warn\", or only Warn mode verification policies fail.","\t// 3 (VerificationError): The verification failed, it could be the signature doesn't match the public key, no matching policies and \"no-match-policy\" is set to \"fail\" or there are errors during verification.","\tVerificationResultType VerificationResultType","\t// Err contains the error message when there is a warning logged or error returned.","\tErr error","}","","// VerifyResource verifies the signature and public key against resource (v1beta1 and v1 task and pipeline).","// VerificationResult is returned with different types for different cases:","// 1) Return VerificationResult with VerificationSkip type, when no policies are found and no-match-policy is set to ignore","// 2) Return VerificationResult with VerificationPass type when verification passed;","// 3) Return VerificationResult with VerificationWarn type, when no matching policies and feature flag \"no-match-policy\" is \"warn\", or only Warn mode verification policies fail. Err field is filled with the warning;","// 4) Return VerificationResult with VerificationError type when no policies are found and no-match-policy is set to fail, the resource fails to pass matched enforce verification policy, or there are errors during verification. Err is filled with the err.","// refSource contains the source information of the resource.","func VerifyResource(ctx context.Context, resource metav1.Object, k8s kubernetes.Interface, refSource *v1.RefSource, verificationpolicies []*v1alpha1.VerificationPolicy) VerificationResult {","\tvar refSourceURI string","\tif refSource != nil {","\t\trefSourceURI = refSource.URI","\t}","","\tmatchedPolicies, err := getMatchedPolicies(resource.GetName(), refSourceURI, verificationpolicies)","\tif err != nil {","\t\tif errors.Is(err, ErrNoMatchedPolicies) {","\t\t\tswitch config.GetVerificationNoMatchPolicy(ctx) {","\t\t\tcase config.IgnoreNoMatchPolicy:","\t\t\t\treturn VerificationResult{VerificationResultType: VerificationSkip}","\t\t\tcase config.WarnNoMatchPolicy:","\t\t\t\tlogger := logging.FromContext(ctx)","\t\t\t\twarning := fmt.Errorf(\"failed to get matched policies: %w\", err)","\t\t\t\tlogger.Warnf(warning.Error())","\t\t\t\treturn VerificationResult{VerificationResultType: VerificationWarn, Err: warning}","\t\t\t}","\t\t}","\t\treturn VerificationResult{VerificationResultType: VerificationError, Err: fmt.Errorf(\"failed to get matched policies: %w\", err)}","\t}","\tsignature, err := extractSignature(resource)","\tif err != nil {","\t\treturn VerificationResult{VerificationResultType: VerificationError, Err: err}","\t}","\treturn verifyResource(ctx, resource, k8s, signature, matchedPolicies)","}","","// VerifyTask is the deprecated, this is to keep backward compatibility","func VerifyTask(ctx context.Context, taskObj *v1beta1.Task, k8s kubernetes.Interface, refSource *v1.RefSource, verificationpolicies []*v1alpha1.VerificationPolicy) VerificationResult {","\treturn VerifyResource(ctx, taskObj, k8s, refSource, verificationpolicies)","}","","// VerifyPipeline is the deprecated, this is to keep backward compatibility","func VerifyPipeline(ctx context.Context, pipelineObj *v1beta1.Pipeline, k8s kubernetes.Interface, refSource *v1.RefSource, verificationpolicies []*v1alpha1.VerificationPolicy) VerificationResult {","\treturn VerifyResource(ctx, pipelineObj, k8s, refSource, verificationpolicies)","}","","// getMatchedPolicies filters out the policies by checking if the resource url (source) is matching any of the `patterns` in the `resources` list.","func getMatchedPolicies(resourceName string, source string, policies []*v1alpha1.VerificationPolicy) ([]*v1alpha1.VerificationPolicy, error) {","\tmatchedPolicies := []*v1alpha1.VerificationPolicy{}","\tfor _, p := range policies {","\t\tfor _, r := range p.Spec.Resources {","\t\t\tmatching, err := regexp.MatchString(r.Pattern, source)","\t\t\tif err != nil {","\t\t\t\t// FixMe: changing %v to %w breaks integration tests.","\t\t\t\treturn matchedPolicies, fmt.Errorf(\"%v: %w\", err, ErrRegexMatch) //nolint:errorlint","\t\t\t}","\t\t\tif matching {","\t\t\t\tmatchedPolicies = append(matchedPolicies, p)","\t\t\t\tbreak","\t\t\t}","\t\t}","\t}","\tif len(matchedPolicies) == 0 {","\t\treturn matchedPolicies, fmt.Errorf(\"%w: no matching policies are found for resource: %s against source: %s\", ErrNoMatchedPolicies, resourceName, source)","\t}","\treturn matchedPolicies, nil","}","","// verifyResource verifies resource which implements metav1.Object by provided signature and public keys from verification policies.","// For matched policies, `verifyResourceâ€œ will adopt the following rules to do verification:","//  1. If multiple policies match, the resource must satisfy all the \"enforce\" policies to pass verification. The matching \"enforce\" policies are evaluated using AND logic.","//     Alternatively, if the resource only matches policies in \"warn\" mode, it will still pass verification and only log a warning if these policies are not satisfied.","//  2. To pass one policy, the resource can pass any public keys in the policy. We use OR logic on public keys of one policy.","//","// TODO(#6683): return all failed policies in error.","func verifyResource(ctx context.Context, resource metav1.Object, k8s kubernetes.Interface, signature []byte, matchedPolicies []*v1alpha1.VerificationPolicy) VerificationResult {","\tlogger := logging.FromContext(ctx)","\tvar warnPolicies []*v1alpha1.VerificationPolicy","\tvar enforcePolicies []*v1alpha1.VerificationPolicy","\tfor _, p := range matchedPolicies {","\t\tif p.Spec.Mode == v1alpha1.ModeWarn {","\t\t\twarnPolicies = append(warnPolicies, p)","\t\t} else {","\t\t\tenforcePolicies = append(enforcePolicies, p)","\t\t}","\t}","","\t// get the checksum of the resource","\tchecksumBytes, err := getChecksum(resource)","\tif err != nil {","\t\treturn VerificationResult{VerificationResultType: VerificationError, Err: err}","\t}","","\t// first evaluate all enforce policies. Return VerificationError type of VerificationResult if any policy fails.","\tfor _, p := range enforcePolicies {","\t\tverifiers, err := verifier.FromPolicy(ctx, k8s, p)","\t\tif err != nil {","\t\t\treturn VerificationResult{VerificationResultType: VerificationError, Err: fmt.Errorf(\"failed to get verifiers from policy: %w\", err)}","\t\t}","\t\tpassVerification := doesAnyVerifierPass(ctx, checksumBytes, signature, verifiers)","\t\tif !passVerification {","\t\t\treturn VerificationResult{VerificationResultType: VerificationError, Err: fmt.Errorf(\"%w: resource %s in namespace %s fails verification\", ErrResourceVerificationFailed, resource.GetName(), resource.GetNamespace())}","\t\t}","\t}","","\t// then evaluate all warn policies. Return VerificationWarn type of VerificationResult if any warn policies fails.","\tfor _, p := range warnPolicies {","\t\tverifiers, err := verifier.FromPolicy(ctx, k8s, p)","\t\tif err != nil {","\t\t\twarn := fmt.Errorf(\"failed to get verifiers for resource %s from namespace %s: %w\", resource.GetName(), resource.GetNamespace(), err)","\t\t\tlogger.Warnf(warn.Error())","\t\t\treturn VerificationResult{VerificationResultType: VerificationWarn, Err: warn}","\t\t}","\t\tpassVerification := doesAnyVerifierPass(ctx, checksumBytes, signature, verifiers)","\t\tif !passVerification {","\t\t\twarn := fmt.Errorf(\"%w: resource %s in namespace %s fails verification\", ErrResourceVerificationFailed, resource.GetName(), resource.GetNamespace())","\t\t\tlogger.Warnf(warn.Error())","\t\t\treturn VerificationResult{VerificationResultType: VerificationWarn, Err: warn}","\t\t}","\t}","","\treturn VerificationResult{VerificationResultType: VerificationPass}","}","","// doesAnyVerifierPass loop over verifiers to verify the checksum and the signature, return true if any verifier pass verification.","func doesAnyVerifierPass(ctx context.Context, checksumBytes []byte, signature []byte, verifiers []signature.Verifier) bool {","\tlogger := logging.FromContext(ctx)","\tpassVerification := false","\tfor _, verifier := range verifiers {","\t\tif err := verifier.VerifySignature(bytes.NewReader(signature), bytes.NewReader(checksumBytes)); err == nil {","\t\t\t// if one of the verifier passes verification, then this policy passes verification","\t\t\tpassVerification = true","\t\t\tbreak","\t\t} else {","\t\t\t// FixMe: changing %v to %w breaks integration tests.","\t\t\twarn := fmt.Errorf(\"%w:%v\", ErrResourceVerificationFailed, err.Error())","\t\t\tlogger.Warnf(warn.Error())","\t\t}","\t}","\treturn passVerification","}","","// extractSignature extracts the signature if it is present in the metadata.","// Returns a non-nil error if the signature cannot be decoded.","func extractSignature(in metav1.Object) ([]byte, error) {","\t// signature should be contained in annotation","\tsig, ok := in.GetAnnotations()[SignatureAnnotation]","\tif !ok {","\t\treturn nil, nil","\t}","\t// extract signature","\tsignature, err := base64.StdEncoding.DecodeString(sig)","\tif err != nil {","\t\treturn nil, err","\t}","\treturn signature, nil","}","","// getChecksum gets the sha256 checksum of the resource.","// Returns a non-nil error if the checksum cannot be computed or the resource is of unknown type.","func getChecksum(resource metav1.Object) ([]byte, error) {","\th, ok := resource.(Hashable)","\tif !ok {","\t\treturn nil, fmt.Errorf(\"%w: resource %T is not a Hashable type\", ErrResourceNotSupported, resource)","\t}","\tchecksumBytes, err := h.Checksum()","\tif err != nil {","\t\treturn nil, err","\t}","\treturn checksumBytes, nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,2,2,1,1,2,0,0,0,1,1,1,0,0,1,1,1,0,0,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,1,1,0,0,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,0,2,2,1,1,2,0,0,0,0,2,2,2,1,1,2,2,1,1,2,0]},{"id":278,"path":"pkg/workspace/apply.go","lines":["/*","Copyright 2020 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package workspace","","import (","\t\"context\"","\t\"fmt\"","","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\tpkgnames \"github.com/tektoncd/pipeline/pkg/names\"","\t\"github.com/tektoncd/pipeline/pkg/substitution\"","\tcorev1 \"k8s.io/api/core/v1\"","\t\"k8s.io/apimachinery/pkg/util/sets\"",")","","const (","\tvolumeNameBase      = \"ws\"","\tdefaultRandomLength = 5",")","","// nameVolumeMap is a map from a workspace's name to its Volume.","type nameVolumeMap map[string]corev1.Volume","","// setVolumeSource assigns a volume to a workspace's name.","func (nvm nameVolumeMap) setVolumeSource(workspaceName string, volumeName string, source corev1.VolumeSource) {","\tnvm[workspaceName] = corev1.Volume{","\t\tName:         volumeName,","\t\tVolumeSource: source,","\t}","}","","// generateVolumeName generates a unique name for a volume based on the workspace name.","func generateVolumeName(name string) string {","\treturn pkgnames.GenerateHashedName(volumeNameBase, name, defaultRandomLength)","}","","// CreateVolumes will return a dictionary where the keys are the names of the workspaces bound in","// wb and the value is a newly-created Volume to use. If the same Volume is bound twice, the","// resulting volumes will both have the same name to prevent the same Volume from being attached","// to a pod twice. The names of the returned volumes will be a short hash string starting \"ws-\".","func CreateVolumes(wb []v1.WorkspaceBinding) map[string]corev1.Volume {","\tpvcs := map[string]corev1.Volume{}","\tv := make(nameVolumeMap, len(wb))","\t// Track the names we've used so far to avoid collisions","\tusedNames := make(map[string]struct{}, len(wb))","","\tfor _, w := range wb {","\t\tname := generateVolumeName(w.Name)","","\t\t// If we've already generated this name, try appending extra characters until we find a unique name","\t\tfor _, exists := usedNames[name]; exists; _, exists = usedNames[name] {","\t\t\tname = generateVolumeName(name + \"$\")","\t\t}","\t\t// Track the name we've used","\t\tusedNames[name] = struct{}{}","","\t\tswitch {","\t\tcase w.PersistentVolumeClaim != nil:","\t\t\t// If it's a PVC, we need to check if we've encountered it before so we avoid mounting it twice","\t\t\tif vv, ok := pvcs[w.PersistentVolumeClaim.ClaimName]; ok {","\t\t\t\tv[w.Name] = vv","\t\t\t} else {","\t\t\t\tpvc := *w.PersistentVolumeClaim","\t\t\t\tv.setVolumeSource(w.Name, name, corev1.VolumeSource{PersistentVolumeClaim: \u0026pvc})","\t\t\t\tpvcs[pvc.ClaimName] = v[w.Name]","\t\t\t}","\t\tcase w.EmptyDir != nil:","\t\t\ted := *w.EmptyDir","\t\t\tv.setVolumeSource(w.Name, name, corev1.VolumeSource{EmptyDir: \u0026ed})","\t\tcase w.ConfigMap != nil:","\t\t\tcm := *w.ConfigMap","\t\t\tv.setVolumeSource(w.Name, name, corev1.VolumeSource{ConfigMap: \u0026cm})","\t\tcase w.Secret != nil:","\t\t\ts := *w.Secret","\t\t\tv.setVolumeSource(w.Name, name, corev1.VolumeSource{Secret: \u0026s})","\t\tcase w.Projected != nil:","\t\t\ts := *w.Projected","\t\t\tv.setVolumeSource(w.Name, name, corev1.VolumeSource{Projected: \u0026s})","\t\tcase w.CSI != nil:","\t\t\tcsi := *w.CSI","\t\t\tv.setVolumeSource(w.Name, name, corev1.VolumeSource{CSI: \u0026csi})","\t\t}","\t}","\treturn v","}","","func getDeclaredWorkspace(name string, w []v1.WorkspaceDeclaration) (*v1.WorkspaceDeclaration, error) {","\tfor _, workspace := range w {","\t\tif workspace.Name == name {","\t\t\treturn \u0026workspace, nil","\t\t}","\t}","\t// Trusting validation to ensure","\treturn nil, fmt.Errorf(\"even though validation should have caught it, bound workspace %s did not exist in declared workspaces\", name)","}","","// Apply will update the StepTemplate, Sidecars and Volumes declaration in ts so that the workspaces","// specified through wb combined with the declared workspaces in ts will be available for","// all Step and Sidecar containers in the resulting pod.","func Apply(ctx context.Context, ts v1.TaskSpec, wb []v1.WorkspaceBinding, v map[string]corev1.Volume) (*v1.TaskSpec, error) {","\t// If there are no bound workspaces, we don't need to do anything","\tif len(wb) == 0 {","\t\treturn \u0026ts, nil","\t}","","\taddedVolumes := sets.NewString()","","\t// Initialize StepTemplate if it hasn't been already","\tif ts.StepTemplate == nil {","\t\tts.StepTemplate = \u0026v1.StepTemplate{}","\t}","","\tisolatedWorkspaces := sets.NewString()","","\tfor _, step := range ts.Steps {","\t\tfor _, workspaceUsage := range step.Workspaces {","\t\t\tisolatedWorkspaces.Insert(workspaceUsage.Name)","\t\t}","\t}","\tfor _, sidecar := range ts.Sidecars {","\t\tfor _, workspaceUsage := range sidecar.Workspaces {","\t\t\tisolatedWorkspaces.Insert(workspaceUsage.Name)","\t\t}","\t}","","\tfor i := range wb {","\t\t// Propagate missing Workspaces","\t\taddWorkspace := true","\t\tfor _, ws := range ts.Workspaces {","\t\t\tif ws.Name == wb[i].Name {","\t\t\t\taddWorkspace = false","\t\t\t\tbreak","\t\t\t}","\t\t}","\t\tif addWorkspace {","\t\t\tts.Workspaces = append(ts.Workspaces, v1.WorkspaceDeclaration{Name: wb[i].Name})","\t\t}","\t\tw, err := getDeclaredWorkspace(wb[i].Name, ts.Workspaces)","\t\tif err != nil {","\t\t\treturn nil, err","\t\t}","\t\t// Get the volume we should be using for this binding","\t\tvv := v[wb[i].Name]","","\t\tvolumeMount := corev1.VolumeMount{","\t\t\tName:      vv.Name,","\t\t\tMountPath: w.GetMountPath(),","\t\t\tSubPath:   wb[i].SubPath,","\t\t\tReadOnly:  w.ReadOnly,","\t\t}","","\t\tif isolatedWorkspaces.Has(w.Name) {","\t\t\tmountAsIsolatedWorkspace(ts, w.Name, volumeMount)","\t\t} else {","\t\t\tmountAsSharedWorkspace(ts, volumeMount)","\t\t}","","\t\t// Only add this volume if it hasn't already been added","\t\tif !addedVolumes.Has(vv.Name) {","\t\t\tts.Volumes = append(ts.Volumes, vv)","\t\t\taddedVolumes.Insert(vv.Name)","\t\t}","\t}","\treturn \u0026ts, nil","}","","// mountAsSharedWorkspace takes a volumeMount and adds it to all the steps and sidecars in","// a TaskSpec.","func mountAsSharedWorkspace(ts v1.TaskSpec, volumeMount corev1.VolumeMount) {","\tts.StepTemplate.VolumeMounts = append(ts.StepTemplate.VolumeMounts, volumeMount)","","\tfor i := range ts.Sidecars {","\t\tAddSidecarVolumeMount(\u0026ts.Sidecars[i], volumeMount)","\t}","}","","// mountAsIsolatedWorkspace takes a volumeMount and adds it only to the steps and sidecars","// that have requested access to it.","func mountAsIsolatedWorkspace(ts v1.TaskSpec, workspaceName string, volumeMount corev1.VolumeMount) {","\tfor i := range ts.Steps {","\t\tstep := \u0026ts.Steps[i]","\t\tfor _, workspaceUsage := range step.Workspaces {","\t\t\tif workspaceUsage.Name == workspaceName {","\t\t\t\tvm := volumeMount","\t\t\t\tif workspaceUsage.MountPath != \"\" {","\t\t\t\t\tvm.MountPath = workspaceUsage.MountPath","\t\t\t\t}","\t\t\t\tstep.VolumeMounts = append(step.VolumeMounts, vm)","\t\t\t\tbreak","\t\t\t}","\t\t}","\t}","\tfor i := range ts.Sidecars {","\t\tsidecar := \u0026ts.Sidecars[i]","\t\tfor _, workspaceUsage := range sidecar.Workspaces {","\t\t\tif workspaceUsage.Name == workspaceName {","\t\t\t\tvm := volumeMount","\t\t\t\tif workspaceUsage.MountPath != \"\" {","\t\t\t\t\tvm.MountPath = workspaceUsage.MountPath","\t\t\t\t}","\t\t\t\tsidecar.VolumeMounts = append(sidecar.VolumeMounts, vm)","\t\t\t\tbreak","\t\t\t}","\t\t}","\t}","}","","// AddSidecarVolumeMount is a helper to add a volumeMount to the sidecar unless its","// MountPath would conflict with another of the sidecar's existing volume mounts.","func AddSidecarVolumeMount(sidecar *v1.Sidecar, volumeMount corev1.VolumeMount) {","\tfor j := range sidecar.VolumeMounts {","\t\tif sidecar.VolumeMounts[j].MountPath == volumeMount.MountPath {","\t\t\treturn","\t\t}","\t}","\tsidecar.VolumeMounts = append(sidecar.VolumeMounts, volumeMount)","}","","func findWorkspaceSubstitutionLocationsInSidecars(sidecars []v1.Sidecar) sets.String {","\tlocationsToCheck := sets.NewString()","\tfor _, sidecar := range sidecars {","\t\tlocationsToCheck.Insert(sidecar.Script)","","\t\tfor i := range sidecar.Args {","\t\t\tlocationsToCheck.Insert(sidecar.Args[i])","\t\t}","","\t\tfor i := range sidecar.Command {","\t\t\tlocationsToCheck.Insert(sidecar.Command[i])","\t\t}","\t\tlocationsToCheck.Insert(sidecar.WorkingDir)","\t\tfor _, e := range sidecar.Env {","\t\t\tlocationsToCheck.Insert(e.Value)","\t\t}","\t}","\treturn locationsToCheck","}","","func findWorkspaceSubstitutionLocationsInSteps(steps []v1.Step) sets.String {","\tlocationsToCheck := sets.NewString()","\tfor _, step := range steps {","\t\tlocationsToCheck.Insert(step.Script)","","\t\tfor i := range step.Args {","\t\t\tlocationsToCheck.Insert(step.Args[i])","\t\t}","","\t\tfor i := range step.Command {","\t\t\tlocationsToCheck.Insert(step.Command[i])","\t\t}","","\t\tlocationsToCheck.Insert(step.WorkingDir)","\t\tfor _, e := range step.Env {","\t\t\tlocationsToCheck.Insert(e.Value)","\t\t}","\t\tfor _, p := range step.Params {","\t\t\tlocationsToCheck.Insert(p.Value.ArrayVal...)","\t\t\tfor k := range p.Value.ObjectVal {","\t\t\t\tlocationsToCheck.Insert(p.Value.ObjectVal[k])","\t\t\t}","\t\t\tlocationsToCheck.Insert(p.Value.StringVal)","\t\t}","\t}","\treturn locationsToCheck","}","","func findWorkspaceSubstitutionLocationsInStepTemplate(stepTemplate *v1.StepTemplate) sets.String {","\tlocationsToCheck := sets.NewString()","","\tif stepTemplate != nil {","\t\tfor i := range stepTemplate.Args {","\t\t\tlocationsToCheck.Insert(stepTemplate.Args[i])","\t\t}","\t\tfor i := range stepTemplate.Command {","\t\t\tlocationsToCheck.Insert(stepTemplate.Command[i])","\t\t}","","\t\tlocationsToCheck.Insert(stepTemplate.WorkingDir)","\t\tfor _, e := range stepTemplate.Env {","\t\t\tlocationsToCheck.Insert(e.Value)","\t\t}","\t}","\treturn locationsToCheck","}","","// FindWorkspacesUsedByTask returns a set of all the workspaces that the TaskSpec uses.","func FindWorkspacesUsedByTask(ts v1.TaskSpec) (sets.String, error) {","\tlocationsToCheck := sets.NewString()","\tlocationsToCheck.Insert(findWorkspaceSubstitutionLocationsInSteps(ts.Steps).List()...)","\tlocationsToCheck.Insert(findWorkspaceSubstitutionLocationsInSidecars(ts.Sidecars).List()...)","\tlocationsToCheck.Insert(findWorkspaceSubstitutionLocationsInStepTemplate(ts.StepTemplate).List()...)","\tworkspacesUsedInSteps := sets.NewString()","\tfor item := range locationsToCheck {","\t\tworkspacesUsed, _, errString := substitution.ExtractVariablesFromString(item, \"workspaces\")","\t\tif errString != \"\" {","\t\t\treturn workspacesUsedInSteps, fmt.Errorf(\"Error while extracting workspace: %s\", errString)","\t\t}","\t\tworkspacesUsedInSteps.Insert(workspacesUsed...)","\t}","\treturn workspacesUsedInSteps, nil","}","","// ReplaceWorkspaceBindingsVars returns a new slice of WorkspaceBinding with references to parameters replaced,","// based on the mapping provided in replacements.","func ReplaceWorkspaceBindingsVars(wbs []v1.WorkspaceBinding, replacements map[string]string) []v1.WorkspaceBinding {","\tfor i := range wbs {","\t\treplaceWorkspaceBindingVars(\u0026wbs[i], replacements)","\t}","\treturn wbs","}","","// replaceWorkspaceBindingVars returns a new WorkspaceBinding with references to parameters replaced,","// based on the mapping provided in replacements.","func replaceWorkspaceBindingVars(wb *v1.WorkspaceBinding, replacements map[string]string) *v1.WorkspaceBinding {","\twb.SubPath = substitution.ApplyReplacements(wb.SubPath, replacements)","\tif wb.PersistentVolumeClaim != nil {","\t\twb.PersistentVolumeClaim = applyPersistentVolumeClaimVolumeSource(wb.PersistentVolumeClaim, replacements)","\t}","\tif wb.ConfigMap != nil {","\t\twb.ConfigMap = applyConfigMapVolumeSource(wb.ConfigMap, replacements)","\t}","\tif wb.Secret != nil {","\t\twb.Secret = applySecretVolumeSource(wb.Secret, replacements)","\t}","\tif wb.Projected != nil {","\t\tfor j, source := range wb.Projected.Sources {","\t\t\tif source.ConfigMap != nil {","\t\t\t\twb.Projected.Sources[j].ConfigMap = applyConfigMapProjection(wb.Projected.Sources[j].ConfigMap, replacements)","\t\t\t}","\t\t\tif source.Secret != nil {","\t\t\t\twb.Projected.Sources[j].Secret = applySecretProjection(wb.Projected.Sources[j].Secret, replacements)","\t\t\t}","\t\t}","\t}","\tif wb.CSI != nil {","\t\twb.CSI = applyCSIVolumeSource(wb.CSI, replacements)","\t}","\treturn wb","}","","func applyPersistentVolumeClaimVolumeSource(pvc *corev1.PersistentVolumeClaimVolumeSource,","\treplacements map[string]string) *corev1.PersistentVolumeClaimVolumeSource {","\tpvc.ClaimName = substitution.ApplyReplacements(pvc.ClaimName, replacements)","\treturn pvc","}","","func applyConfigMapVolumeSource(cm *corev1.ConfigMapVolumeSource, replacements map[string]string) *corev1.ConfigMapVolumeSource {","\tcm.Name = substitution.ApplyReplacements(cm.Name, replacements)","\tcm.Items = applyKeyToPathItems(cm.Items, replacements)","\treturn cm","}","","func applySecretVolumeSource(s *corev1.SecretVolumeSource, replacements map[string]string) *corev1.SecretVolumeSource {","\ts.SecretName = substitution.ApplyReplacements(s.SecretName, replacements)","\ts.Items = applyKeyToPathItems(s.Items, replacements)","\treturn s","}","","func applyConfigMapProjection(cm *corev1.ConfigMapProjection, replacements map[string]string) *corev1.ConfigMapProjection {","\tcm.Name = substitution.ApplyReplacements(cm.Name, replacements)","\tcm.Items = applyKeyToPathItems(cm.Items, replacements)","\treturn cm","}","","func applySecretProjection(s *corev1.SecretProjection, replacements map[string]string) *corev1.SecretProjection {","\ts.Name = substitution.ApplyReplacements(s.Name, replacements)","\ts.Items = applyKeyToPathItems(s.Items, replacements)","\treturn s","}","","func applyCSIVolumeSource(csi *corev1.CSIVolumeSource, replacements map[string]string) *corev1.CSIVolumeSource {","\tcsi.Driver = substitution.ApplyReplacements(csi.Driver, replacements)","\tif csi.NodePublishSecretRef != nil {","\t\tcsi.NodePublishSecretRef.Name = substitution.ApplyReplacements(csi.NodePublishSecretRef.Name, replacements)","\t}","\treturn csi","}","","func applyKeyToPathItems(items []corev1.KeyToPath, replacements map[string]string) []corev1.KeyToPath {","\tfor i := range items {","\t\titem := \u0026items[i]","\t\titem.Key = substitution.ApplyReplacements(item.Key, replacements)","\t\titem.Path = substitution.ApplyReplacements(item.Path, replacements)","\t}","\treturn items","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,0,0,2,2,2,0,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,0,0,2,2,2,2,2,0,0,1,0,0,0,0,0,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,2,2,0,2,2,2,2,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,1,1,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,2,0,0,0,0,2,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,0,0,0,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,0,2,0,0,2,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,2,2,2,2,1,1,2,0,0,2,0,0,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,0,2,0,0,0,2,2,2,2,2,2,2,2,2,1,1,2,0,2,0,0,0,0,2,2,2,2,2,0,0,0,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0,0,0,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,0,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,0]},{"id":279,"path":"pkg/workspace/validate.go","lines":["/*","Copyright 2019 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","package workspace","","import (","\t\"context\"","\t\"errors\"","\t\"fmt\"","","\tpipelineErrors \"github.com/tektoncd/pipeline/pkg/apis/pipeline/errors\"","\tv1 \"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1\"","\t\"k8s.io/apimachinery/pkg/util/sets\"",")","","// ValidateBindings will return an error if the bound workspaces in binds don't satisfy the declared","// workspaces in decls.","func ValidateBindings(ctx context.Context, decls []v1.WorkspaceDeclaration, binds []v1.WorkspaceBinding) error {","\t// This will also be validated at webhook time but in case the webhook isn't invoked for some","\t// reason we'll invoke the same validation here.","\tfor _, b := range binds {","\t\tif err := b.Validate(ctx); err != nil {","\t\t\treturn pipelineErrors.WrapUserError(fmt.Errorf(\"binding %q is invalid: %w\", b.Name, err))","\t\t}","\t}","","\tdeclNames := sets.NewString()","\tbindNames := sets.NewString()","\tfor _, decl := range decls {","\t\tdeclNames.Insert(decl.Name)","\t}","\tfor _, bind := range binds {","\t\tbindNames.Insert(bind.Name)","\t}","","\tfor _, decl := range decls {","\t\tif decl.Optional {","\t\t\tcontinue","\t\t}","\t\tif !bindNames.Has(decl.Name) {","\t\t\treturn pipelineErrors.WrapUserError(fmt.Errorf(\"declared workspace %q is required but has not been bound\", decl.Name))","\t\t}","\t}","\tfor _, bind := range binds {","\t\tif !declNames.Has(bind.Name) {","\t\t\treturn pipelineErrors.WrapUserError(fmt.Errorf(\"workspace binding %q does not match any declared workspace\", bind.Name))","\t\t}","\t}","","\treturn nil","}","","// ValidateOnlyOnePVCIsUsed checks that a list of WorkspaceBinding uses only one","// persistent volume claim.","//","// This is only useful to validate that WorkspaceBindings in TaskRuns are compatible","// with affinity rules enforced by the AffinityAssistant.","func ValidateOnlyOnePVCIsUsed(wb []v1.WorkspaceBinding) error {","\tworkspaceVolumes := make(map[string]bool)","\tfor _, w := range wb {","\t\tif w.PersistentVolumeClaim != nil {","\t\t\tworkspaceVolumes[w.PersistentVolumeClaim.ClaimName] = true","\t\t}","\t\tif w.VolumeClaimTemplate != nil {","\t\t\tworkspaceVolumes[w.Name] = true","\t\t}","\t}","","\tif len(workspaceVolumes) \u003e 1 {","\t\treturn pipelineErrors.WrapUserError(errors.New(\"more than one PersistentVolumeClaim is bound\"))","\t}","\treturn nil","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,2,2,0,0,2,2,2,2,2,2,2,2,0,2,2,2,0,2,2,2,0,2,2,2,2,0,0,2,0,0,0,0,0,0,0,2,2,2,2,2,2,2,2,2,0,0,2,2,2,2,0]},{"id":280,"path":"tekton/release_names.go","lines":["/*","Copyright 2025 The Tekton Authors","","Licensed under the Apache License, Version 2.0 (the \"License\");","you may not use this file except in compliance with the License.","You may obtain a copy of the License at","","    http://www.apache.org/licenses/LICENSE-2.0","","Unless required by applicable law or agreed to in writing, software","distributed under the License is distributed on an \"AS IS\" BASIS,","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.","See the License for the specific language governing permissions and","limitations under the License.","*/","","/*","This utility can be used to generate a new release name in the format:","\t\u003ccat breed\u003e \u003crobot name\u003e","","to be used for a Tekton Pipelines release.","It looks for cat breeds from CatAPIURL and it parses robot names out","of Wikipedia WikiURL. It filters names that have been used already,","based on the GitHub API GitHubReleasesURL","","To use, run:","\tgo run release_names.go","","","Example output:","\t{","\t\t\"release_name\": \"California Spangled Clank\",","\t\t\"cat_breed_url\": \"https://en.wikipedia.org/wiki/California_Spangled\",","\t\t\"robot_url\": \"https://en.wikipedia.org/wiki/Clank\"","\t}","*/","","package main","","import (","\t\"context\"","\t\"crypto/rand\"","\t\"encoding/json\"","\t\"errors\"","\t\"fmt\"","\t\"io\"","\t\"math/big\"","\t\"net/http\"","\t\"regexp\"","\t\"strings\"",")","","// API Endpoints","const (","\tCatAPIURL         = \"https://api.thecatapi.com/v1/breeds\"","\tRobotWikiURL      = \"https://en.wikipedia.org/wiki/List_of_fictional_robots_and_androids\"","\tWikiURL           = \"https://en.wikipedia.org/wiki/\"","\tGitHubReleasesURL = \"https://api.github.com/repos/tektoncd/pipeline/releases\"",")","","// Structs to hold API responses","type CatBreed struct {","\tName string `json:\"name\"`","}","","type Release struct {","\tName string `json:\"name\"`","}","","func httpGet(url string) (*http.Response, error) {","\treq, err := http.NewRequestWithContext(context.Background(), http.MethodGet, url, nil)","\tif err != nil {","\t\treturn nil, err","\t}","","\treq.Header.Set(\"User-Agent\", \"golang-tekton-bot/0.1\")","","\treturn http.DefaultClient.Do(req)","}","","// Fetch cat breeds and organize them by first letter","func getCatBreeds() (map[string][]string, error) {","\tresp, err := httpGet(CatAPIURL)","\tif err != nil {","\t\treturn nil, err","\t}","\tdefer resp.Body.Close()","","\tvar breeds []CatBreed","\tif err := json.NewDecoder(resp.Body).Decode(\u0026breeds); err != nil {","\t\treturn nil, err","\t}","","\tcatDict := make(map[string][]string)","\tfor _, breed := range breeds {","\t\tfirstLetter := strings.ToUpper(string(breed.Name[0]))","\t\tcatDict[firstLetter] = append(catDict[firstLetter], breed.Name)","\t}","","\treturn catDict, nil","}","","// Scrape Wikipedia for robot names","func getRobotNames() (map[string][]string, error) {","\tresp, err := httpGet(RobotWikiURL)","\tif err != nil {","\t\treturn nil, err","\t}","\tdefer resp.Body.Close()","","\tbodyBytes, err := io.ReadAll(resp.Body)","\tif err != nil {","\t\treturn nil, err","\t}","","\trobotDict := make(map[string][]string)","","\t// Regex to extract robot names from \u003cli\u003e\u003cb\u003eRobot Name\u003c/b\u003e","\tre := regexp.MustCompile(`\u003cli\u003e\\s*\u003cb\u003e\\s*\u003ca[^\u003e]*\u003e([^\u003c]+)\u003c/a\u003e\\s*\u003c/b\u003e`)","\tmatches := re.FindAllStringSubmatch(string(bodyBytes), -1)","","\tfor _, match := range matches {","\t\tif len(match) \u003e 1 {","\t\t\tname := strings.TrimSpace(match[1])","\t\t\tfirstLetter := strings.ToUpper(string(name[0]))","\t\t\trobotDict[firstLetter] = append(robotDict[firstLetter], name)","\t\t}","\t}","","\treturn robotDict, nil","}","","// Fetch past releases from GitHub","func getPastReleases() (map[string]bool, error) {","\tpastReleases := make(map[string]bool)","\tpage := 1","\tperPage := 100","","\t// Loop until we get an page smaller than perPage (or empty)","\tfor {","\t\turl := fmt.Sprintf(\"%s?per_page=%d\u0026page=%d\", GitHubReleasesURL, perPage, page)","\t\tresp, err := httpGet(url)","\t\tif err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed to fetch releases page %d: %w\", page, err)","\t\t}","\t\tdefer resp.Body.Close()","","\t\tvar pageReleases []Release","\t\tif err := json.NewDecoder(resp.Body).Decode(\u0026pageReleases); err != nil {","\t\t\treturn nil, fmt.Errorf(\"failed to fetch releases page %d: %w\", page, err)","\t\t}","","\t\t// If we got an empty page, we've reached the end","\t\tif len(pageReleases) == 0 {","\t\t\tbreak","\t\t}","","\t\tpastReleases := make(map[string]bool)","\t\tfor _, release := range pageReleases {","\t\t\tpastReleases[release.Name] = true","\t\t}","","\t\t// If we got fewer than the requested number, we've reached the end","\t\tif len(pageReleases) \u003c perPage {","\t\t\tbreak","\t\t}","","\t\tpage++","\t}","","\treturn pastReleases, nil","}","","func randomElement(array []string) (string, error) {","\tn, err := rand.Int(rand.Reader, big.NewInt(int64(len(array))))","\tif err != nil {","\t\treturn \"\", err","\t}","\treturn array[n.Int64()], nil","}","","// Generate a unique release name","func generateUniqueTuple() (string, string, error) {","\tcatBreeds, err := getCatBreeds()","\tif err != nil {","\t\treturn \"\", \"\", err","\t}","","\trobotNames, err := getRobotNames()","\tif err != nil {","\t\treturn \"\", \"\", err","\t}","","\tpastReleases, err := getPastReleases()","\tif err != nil {","\t\treturn \"\", \"\", err","\t}","","\t// Find common letters","\tcommonLetters := []string{}","\tfor letter := range catBreeds {","\t\tif _, exists := robotNames[letter]; exists {","\t\t\tcommonLetters = append(commonLetters, letter)","\t\t}","\t}","","\tif len(commonLetters) == 0 {","\t\treturn \"\", \"\", errors.New(\"no matching names found\")","\t}","","\tmaxAttempts := 10","\tfor range maxAttempts {","\t\tchosenLetter, err := randomElement(commonLetters)","\t\tif err != nil {","\t\t\treturn \"\", \"\", err","\t\t}","","\t\tcat, err := randomElement(catBreeds[chosenLetter])","\t\tif err != nil {","\t\t\treturn \"\", \"\", err","\t\t}","","\t\trobot, err := randomElement(robotNames[chosenLetter])","\t\tif err != nil {","\t\t\treturn \"\", \"\", err","\t\t}","","\t\tnewName := cat + \" \" + robot","\t\tif !pastReleases[newName] {","\t\t\treturn cat, robot, nil","\t\t}","\t}","","\treturn \"\", \"\", errors.New(\"could not generate a unique name after multiple attempts\")","}","","func printJsonError(err error) {","\tfmt.Println(`{\"error\": \"` + err.Error() + `\"}`) //nolint:forbidigo","}","","func main() {","\tcat, robot, err := generateUniqueTuple()","\tif err != nil {","\t\tprintJsonError(err)","\t\treturn","\t}","","\toutput := map[string]string{","\t\t\"release_name\":  cat + \" \" + robot,","\t\t\"cat_breed_url\": WikiURL + strings.ReplaceAll(cat, \" \", \"_\"),","\t\t\"robot_url\":     WikiURL + strings.ReplaceAll(robot, \" \", \"_\"),","\t}","","\tjsonOutput, err := json.MarshalIndent(output, \"\", \"    \")","\tif err != nil {","\t\tprintJsonError(err)","\t\treturn","\t}","\tfmt.Println(string(jsonOutput)) //nolint:forbidigo","}"],"coverage":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,0,0,1,1,1,1,0,0,1,1,0,0,1,0,0,1,0,0,1,1,1,1,1,1,0,0,0,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,0,0,1,1,1,1,1,0,0,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,0,1,1,1,1,0,0,1,0,0,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0]}],"tree":{"name":".","type":"dir","children":[{"name":"internal","type":"dir","children":[{"name":"sidecarlogresults","type":"dir","children":[{"name":"sidecarlogresults.go","type":"file","fileId":0}]}]},{"name":"pkg","type":"dir","children":[{"name":"apis","type":"dir","children":[{"name":"config","type":"dir","children":[{"name":"resolver","type":"dir","children":[{"name":"feature_flags.go","type":"file","fileId":7},{"name":"store.go","type":"file","fileId":8}]},{"name":"testing","type":"dir","children":[{"name":"defaults.go","type":"file","fileId":11},{"name":"featureflags.go","type":"file","fileId":12}]},{"name":"default.go","type":"file","fileId":1},{"name":"events.go","type":"file","fileId":2},{"name":"feature_flags.go","type":"file","fileId":3},{"name":"featureflags_validation.go","type":"file","fileId":4},{"name":"metrics.go","type":"file","fileId":5},{"name":"metrics_tls.go","type":"file","fileId":6},{"name":"spire_config.go","type":"file","fileId":9},{"name":"store.go","type":"file","fileId":10},{"name":"tracing.go","type":"file","fileId":13},{"name":"wait_exponential_backoff.go","type":"file","fileId":14}]},{"name":"pipeline","type":"dir","children":[{"name":"errors","type":"dir","children":[{"name":"errors.go","type":"file","fileId":15}]},{"name":"internal","type":"dir","children":[{"name":"checksum","type":"dir","children":[{"name":"checksum.go","type":"file","fileId":17}]}]},{"name":"pod","type":"dir","children":[{"name":"affinity_assitant_template.go","type":"file","fileId":18},{"name":"template.go","type":"file","fileId":19}]},{"name":"v1","type":"dir","children":[{"name":"types","type":"dir","children":[{"name":"artifacts_types.go","type":"file","fileId":50},{"name":"param_types.go","type":"file","fileId":51},{"name":"result_types.go","type":"file","fileId":52},{"name":"resultsref.go","type":"file","fileId":53},{"name":"when_types.go","type":"file","fileId":54}]},{"name":"artifact_types.go","type":"file","fileId":20},{"name":"container_types.go","type":"file","fileId":21},{"name":"container_validation.go","type":"file","fileId":22},{"name":"matrix_types.go","type":"file","fileId":23},{"name":"merge.go","type":"file","fileId":24},{"name":"param_types.go","type":"file","fileId":25},{"name":"pipeline_conversion.go","type":"file","fileId":26},{"name":"pipeline_defaults.go","type":"file","fileId":27},{"name":"pipeline_types.go","type":"file","fileId":28},{"name":"pipeline_validation.go","type":"file","fileId":29},{"name":"pipelineref_validation.go","type":"file","fileId":30},{"name":"pipelinerun_conversion.go","type":"file","fileId":31},{"name":"pipelinerun_defaults.go","type":"file","fileId":32},{"name":"pipelinerun_types.go","type":"file","fileId":33},{"name":"pipelinerun_validation.go","type":"file","fileId":34},{"name":"register.go","type":"file","fileId":35},{"name":"result_defaults.go","type":"file","fileId":36},{"name":"result_types.go","type":"file","fileId":37},{"name":"result_validation.go","type":"file","fileId":38},{"name":"resultref.go","type":"file","fileId":39},{"name":"task_conversion.go","type":"file","fileId":40},{"name":"task_defaults.go","type":"file","fileId":41},{"name":"task_types.go","type":"file","fileId":42},{"name":"task_validation.go","type":"file","fileId":43},{"name":"taskref_types.go","type":"file","fileId":44},{"name":"taskref_validation.go","type":"file","fileId":45},{"name":"taskrun_conversion.go","type":"file","fileId":46},{"name":"taskrun_defaults.go","type":"file","fileId":47},{"name":"taskrun_types.go","type":"file","fileId":48},{"name":"taskrun_validation.go","type":"file","fileId":49},{"name":"when_types.go","type":"file","fileId":55},{"name":"when_validation.go","type":"file","fileId":56},{"name":"workspace_types.go","type":"file","fileId":57},{"name":"workspace_validation.go","type":"file","fileId":58}]},{"name":"v1alpha1","type":"dir","children":[{"name":"register.go","type":"file","fileId":59},{"name":"run_defaults.go","type":"file","fileId":60},{"name":"run_types.go","type":"file","fileId":61},{"name":"run_validation.go","type":"file","fileId":62},{"name":"stepaction_conversion.go","type":"file","fileId":63},{"name":"stepaction_defaults.go","type":"file","fileId":64},{"name":"stepaction_types.go","type":"file","fileId":65},{"name":"stepaction_validation.go","type":"file","fileId":66},{"name":"verificationpolicy_defaults.go","type":"file","fileId":67},{"name":"verificationpolicy_types.go","type":"file","fileId":68},{"name":"verificationpolicy_validation.go","type":"file","fileId":69}]},{"name":"v1beta1","type":"dir","children":[{"name":"container_conversion.go","type":"file","fileId":70},{"name":"container_types.go","type":"file","fileId":71},{"name":"container_validation.go","type":"file","fileId":72},{"name":"customrun_defaults.go","type":"file","fileId":73},{"name":"customrun_types.go","type":"file","fileId":74},{"name":"customrun_validation.go","type":"file","fileId":75},{"name":"matrix_types.go","type":"file","fileId":76},{"name":"merge.go","type":"file","fileId":77},{"name":"param_conversion.go","type":"file","fileId":78},{"name":"param_types.go","type":"file","fileId":79},{"name":"pipeline_conversion.go","type":"file","fileId":80},{"name":"pipeline_defaults.go","type":"file","fileId":81},{"name":"pipeline_types.go","type":"file","fileId":82},{"name":"pipeline_validation.go","type":"file","fileId":83},{"name":"pipelineref_conversion.go","type":"file","fileId":84},{"name":"pipelineref_validation.go","type":"file","fileId":85},{"name":"pipelinerun_conversion.go","type":"file","fileId":86},{"name":"pipelinerun_defaults.go","type":"file","fileId":87},{"name":"pipelinerun_types.go","type":"file","fileId":88},{"name":"pipelinerun_validation.go","type":"file","fileId":89},{"name":"provenance_conversion.go","type":"file","fileId":90},{"name":"register.go","type":"file","fileId":91},{"name":"resolver_conversion.go","type":"file","fileId":92},{"name":"result_conversion.go","type":"file","fileId":93},{"name":"result_defaults.go","type":"file","fileId":94},{"name":"result_types.go","type":"file","fileId":95},{"name":"result_validation.go","type":"file","fileId":96},{"name":"resultref.go","type":"file","fileId":97},{"name":"stepaction_conversion.go","type":"file","fileId":98},{"name":"stepaction_defaults.go","type":"file","fileId":99},{"name":"stepaction_types.go","type":"file","fileId":100},{"name":"stepaction_validation.go","type":"file","fileId":101},{"name":"task_conversion.go","type":"file","fileId":102},{"name":"task_defaults.go","type":"file","fileId":103},{"name":"task_types.go","type":"file","fileId":104},{"name":"task_validation.go","type":"file","fileId":105},{"name":"taskref_conversion.go","type":"file","fileId":106},{"name":"taskref_types.go","type":"file","fileId":107},{"name":"taskref_validation.go","type":"file","fileId":108},{"name":"taskrun_conversion.go","type":"file","fileId":109},{"name":"taskrun_defaults.go","type":"file","fileId":110},{"name":"taskrun_types.go","type":"file","fileId":111},{"name":"taskrun_validation.go","type":"file","fileId":112},{"name":"when_types.go","type":"file","fileId":113},{"name":"when_validation.go","type":"file","fileId":114},{"name":"workspace_conversion.go","type":"file","fileId":115},{"name":"workspace_types.go","type":"file","fileId":116},{"name":"workspace_validation.go","type":"file","fileId":117}]},{"name":"images.go","type":"file","fileId":16}]},{"name":"resolution","type":"dir","children":[{"name":"v1alpha1","type":"dir","children":[{"name":"register.go","type":"file","fileId":118},{"name":"resolution_request_conversion.go","type":"file","fileId":119},{"name":"resolution_request_defaults.go","type":"file","fileId":120},{"name":"resolution_request_lifecycle.go","type":"file","fileId":121},{"name":"resolution_request_types.go","type":"file","fileId":122},{"name":"resolution_request_validation.go","type":"file","fileId":123}]},{"name":"v1beta1","type":"dir","children":[{"name":"register.go","type":"file","fileId":124},{"name":"resolution_request_conversion.go","type":"file","fileId":125},{"name":"resolution_request_defaults.go","type":"file","fileId":126},{"name":"resolution_request_lifecycle.go","type":"file","fileId":127},{"name":"resolution_request_types.go","type":"file","fileId":128},{"name":"resolution_request_validation.go","type":"file","fileId":129}]}]},{"name":"resource","type":"dir","children":[{"name":"v1alpha1","type":"dir","children":[{"name":"register.go","type":"file","fileId":130}]}]},{"name":"run","type":"dir","children":[{"name":"v1alpha1","type":"dir","children":[{"name":"runstatus_types.go","type":"file","fileId":131}]},{"name":"v1beta1","type":"dir","children":[{"name":"customrunstatus_types.go","type":"file","fileId":132}]}]},{"name":"validate","type":"dir","children":[{"name":"metadata.go","type":"file","fileId":133}]},{"name":"version","type":"dir","children":[{"name":"conversion.go","type":"file","fileId":134}]}]},{"name":"container","type":"dir","children":[{"name":"container_replacements.go","type":"file","fileId":135},{"name":"sidecar_replacements.go","type":"file","fileId":136},{"name":"step_replacements.go","type":"file","fileId":137}]},{"name":"controller","type":"dir","children":[{"name":"errors.go","type":"file","fileId":138},{"name":"filter.go","type":"file","fileId":139}]},{"name":"credentials","type":"dir","children":[{"name":"dockercreds","type":"dir","children":[{"name":"creds.go","type":"file","fileId":140}]},{"name":"gitcreds","type":"dir","children":[{"name":"basic.go","type":"file","fileId":141},{"name":"creds.go","type":"file","fileId":142},{"name":"ssh.go","type":"file","fileId":143}]},{"name":"matcher","type":"dir","children":[{"name":"matcher.go","type":"file","fileId":144}]},{"name":"writer","type":"dir","children":[{"name":"writer.go","type":"file","fileId":145}]}]},{"name":"entrypoint","type":"dir","children":[{"name":"entrypointer.go","type":"file","fileId":146},{"name":"spire.go","type":"file","fileId":147}]},{"name":"internal","type":"dir","children":[{"name":"affinityassistant","type":"dir","children":[{"name":"affinityassistant_types.go","type":"file","fileId":148},{"name":"transformer.go","type":"file","fileId":149}]},{"name":"computeresources","type":"dir","children":[{"name":"compare","type":"dir","children":[{"name":"compare.go","type":"file","fileId":150}]},{"name":"limitrange","type":"dir","children":[{"name":"limitrange.go","type":"file","fileId":151}]},{"name":"tasklevel","type":"dir","children":[{"name":"tasklevel.go","type":"file","fileId":152}]},{"name":"transformer.go","type":"file","fileId":153}]},{"name":"defaultresourcerequirements","type":"dir","children":[{"name":"transformer.go","type":"file","fileId":154}]},{"name":"resolution","type":"dir","children":[{"name":"resolutionrequest.go","type":"file","fileId":155}]},{"name":"resultref","type":"dir","children":[{"name":"resultref.go","type":"file","fileId":156}]}]},{"name":"list","type":"dir","children":[{"name":"diff.go","type":"file","fileId":157}]},{"name":"names","type":"dir","children":[{"name":"generate.go","type":"file","fileId":158}]},{"name":"pipelinerunmetrics","type":"dir","children":[{"name":"fake","type":"dir","children":[{"name":"fake.go","type":"file","fileId":159}]},{"name":"injection.go","type":"file","fileId":160},{"name":"metrics.go","type":"file","fileId":161}]},{"name":"platforms","type":"dir","children":[{"name":"platforms.go","type":"file","fileId":162}]},{"name":"pod","type":"dir","children":[{"name":"creds_init.go","type":"file","fileId":163},{"name":"entrypoint.go","type":"file","fileId":164},{"name":"entrypoint_lookup.go","type":"file","fileId":165},{"name":"entrypoint_lookup_impl.go","type":"file","fileId":166},{"name":"pod.go","type":"file","fileId":167},{"name":"script.go","type":"file","fileId":168},{"name":"security_context_config.go","type":"file","fileId":169},{"name":"status.go","type":"file","fileId":170},{"name":"workingdir_init.go","type":"file","fileId":171}]},{"name":"reconciler","type":"dir","children":[{"name":"apiserver","type":"dir","children":[{"name":"apiserver.go","type":"file","fileId":172}]},{"name":"events","type":"dir","children":[{"name":"cache","type":"dir","children":[{"name":"cache.go","type":"file","fileId":173},{"name":"cacheclient.go","type":"file","fileId":174},{"name":"cachefakeclient.go","type":"file","fileId":175}]},{"name":"cloudevent","type":"dir","children":[{"name":"cloud_event_controller.go","type":"file","fileId":176},{"name":"cloudevent.go","type":"file","fileId":177},{"name":"cloudeventclient.go","type":"file","fileId":178},{"name":"cloudeventsfakeclient.go","type":"file","fileId":179}]},{"name":"k8sevent","type":"dir","children":[{"name":"event.go","type":"file","fileId":181},{"name":"events.go","type":"file","fileId":182}]},{"name":"event.go","type":"file","fileId":180}]},{"name":"notifications","type":"dir","children":[{"name":"customrun","type":"dir","children":[{"name":"controller.go","type":"file","fileId":183},{"name":"customrun.go","type":"file","fileId":184}]}]},{"name":"pipeline","type":"dir","children":[{"name":"dag","type":"dir","children":[{"name":"dag.go","type":"file","fileId":185}]}]},{"name":"pipelinerun","type":"dir","children":[{"name":"pipelinespec","type":"dir","children":[{"name":"pipelinespec.go","type":"file","fileId":190}]},{"name":"resources","type":"dir","children":[{"name":"apply.go","type":"file","fileId":191},{"name":"pipelineref.go","type":"file","fileId":192},{"name":"pipelinerunresolution.go","type":"file","fileId":193},{"name":"pipelinerunstate.go","type":"file","fileId":194},{"name":"resultrefresolution.go","type":"file","fileId":195},{"name":"validate_dependencies.go","type":"file","fileId":196},{"name":"validate_params.go","type":"file","fileId":197}]},{"name":"affinity_assistant.go","type":"file","fileId":186},{"name":"cancel.go","type":"file","fileId":187},{"name":"controller.go","type":"file","fileId":188},{"name":"pipelinerun.go","type":"file","fileId":189},{"name":"timeout.go","type":"file","fileId":198},{"name":"tracing.go","type":"file","fileId":199}]},{"name":"resolutionrequest","type":"dir","children":[{"name":"controller.go","type":"file","fileId":200},{"name":"resolutionrequest.go","type":"file","fileId":201}]},{"name":"taskrun","type":"dir","children":[{"name":"resources","type":"dir","children":[{"name":"apply.go","type":"file","fileId":204},{"name":"taskref.go","type":"file","fileId":205},{"name":"taskspec.go","type":"file","fileId":206},{"name":"validate_params.go","type":"file","fileId":207}]},{"name":"controller.go","type":"file","fileId":203},{"name":"taskrun.go","type":"file","fileId":208},{"name":"tracing.go","type":"file","fileId":209},{"name":"validate_taskrun.go","type":"file","fileId":210}]},{"name":"testing","type":"dir","children":[{"name":"configmap.go","type":"file","fileId":211},{"name":"factory.go","type":"file","fileId":212},{"name":"logger.go","type":"file","fileId":213},{"name":"status.go","type":"file","fileId":214}]},{"name":"volumeclaim","type":"dir","children":[{"name":"pvchandler.go","type":"file","fileId":215}]},{"name":"resources.go","type":"file","fileId":202}]},{"name":"remote","type":"dir","children":[{"name":"oci","type":"dir","children":[{"name":"resolver.go","type":"file","fileId":216}]},{"name":"resolution","type":"dir","children":[{"name":"error.go","type":"file","fileId":217},{"name":"request.go","type":"file","fileId":218},{"name":"resolver.go","type":"file","fileId":219}]}]},{"name":"remoteresolution","type":"dir","children":[{"name":"remote","type":"dir","children":[{"name":"resolution","type":"dir","children":[{"name":"request.go","type":"file","fileId":220},{"name":"resolver.go","type":"file","fileId":221}]}]},{"name":"resolver","type":"dir","children":[{"name":"bundle","type":"dir","children":[{"name":"resolver.go","type":"file","fileId":222}]},{"name":"cluster","type":"dir","children":[{"name":"resolver.go","type":"file","fileId":223}]},{"name":"framework","type":"dir","children":[{"name":"cache","type":"dir","children":[{"name":"annotated_resource.go","type":"file","fileId":224},{"name":"cache.go","type":"file","fileId":225},{"name":"clock.go","type":"file","fileId":226},{"name":"configstore.go","type":"file","fileId":227},{"name":"operations.go","type":"file","fileId":228},{"name":"setup.go","type":"file","fileId":229}]},{"name":"testing","type":"dir","children":[{"name":"fakecontroller.go","type":"file","fileId":233}]},{"name":"controller.go","type":"file","fileId":230},{"name":"fakeresolver.go","type":"file","fileId":231},{"name":"reconciler.go","type":"file","fileId":232}]},{"name":"git","type":"dir","children":[{"name":"resolver.go","type":"file","fileId":234}]},{"name":"http","type":"dir","children":[{"name":"resolver.go","type":"file","fileId":235}]},{"name":"hub","type":"dir","children":[{"name":"resolver.go","type":"file","fileId":236}]}]},{"name":"resource","type":"dir","children":[{"name":"crd_resource.go","type":"file","fileId":237},{"name":"request.go","type":"file","fileId":238}]}]},{"name":"resolution","type":"dir","children":[{"name":"common","type":"dir","children":[{"name":"context.go","type":"file","fileId":239},{"name":"errors.go","type":"file","fileId":240}]},{"name":"resolver","type":"dir","children":[{"name":"bundle","type":"dir","children":[{"name":"bundle.go","type":"file","fileId":241},{"name":"config.go","type":"file","fileId":242},{"name":"params.go","type":"file","fileId":243},{"name":"resolver.go","type":"file","fileId":244}]},{"name":"cluster","type":"dir","children":[{"name":"resolver.go","type":"file","fileId":245}]},{"name":"framework","type":"dir","children":[{"name":"testing","type":"dir","children":[{"name":"fakecontroller.go","type":"file","fileId":250},{"name":"featureflag.go","type":"file","fileId":251}]},{"name":"configstore.go","type":"file","fileId":246},{"name":"controller.go","type":"file","fileId":247},{"name":"fakeresolver.go","type":"file","fileId":248},{"name":"reconciler.go","type":"file","fileId":249}]},{"name":"git","type":"dir","children":[{"name":"config.go","type":"file","fileId":252},{"name":"repository.go","type":"file","fileId":253},{"name":"resolver.go","type":"file","fileId":254}]},{"name":"http","type":"dir","children":[{"name":"resolver.go","type":"file","fileId":255}]},{"name":"hub","type":"dir","children":[{"name":"resolver.go","type":"file","fileId":256}]}]},{"name":"resource","type":"dir","children":[{"name":"crd_resource.go","type":"file","fileId":257},{"name":"name.go","type":"file","fileId":258},{"name":"request.go","type":"file","fileId":259}]}]},{"name":"result","type":"dir","children":[{"name":"result.go","type":"file","fileId":260}]},{"name":"spire","type":"dir","children":[{"name":"config","type":"dir","children":[{"name":"config.go","type":"file","fileId":261}]},{"name":"controller.go","type":"file","fileId":262},{"name":"entrypointer.go","type":"file","fileId":263},{"name":"sign.go","type":"file","fileId":264},{"name":"spire_mock.go","type":"file","fileId":265},{"name":"verify.go","type":"file","fileId":266}]},{"name":"status","type":"dir","children":[{"name":"status.go","type":"file","fileId":267}]},{"name":"substitution","type":"dir","children":[{"name":"replacements.go","type":"file","fileId":268},{"name":"substitution.go","type":"file","fileId":269}]},{"name":"taskrunmetrics","type":"dir","children":[{"name":"fake","type":"dir","children":[{"name":"fake.go","type":"file","fileId":270}]},{"name":"injection.go","type":"file","fileId":271},{"name":"metrics.go","type":"file","fileId":272}]},{"name":"termination","type":"dir","children":[{"name":"parse.go","type":"file","fileId":273},{"name":"write.go","type":"file","fileId":274}]},{"name":"tracing","type":"dir","children":[{"name":"tracing.go","type":"file","fileId":275}]},{"name":"trustedresources","type":"dir","children":[{"name":"verifier","type":"dir","children":[{"name":"verifier.go","type":"file","fileId":276}]},{"name":"verify.go","type":"file","fileId":277}]},{"name":"workspace","type":"dir","children":[{"name":"apply.go","type":"file","fileId":278},{"name":"validate.go","type":"file","fileId":279}]}]},{"name":"tekton","type":"dir","children":[{"name":"release_names.go","type":"file","fileId":280}]}]},"summary":{"totalLines":29490,"coveredLines":24884,"percent":84.3811461512377}};
    </script>
    <script>
      window.COVERAGE_CONFIG = {"syntaxEnabled":true};
    </script>
    <script>
      (function() {
  'use strict';

  const data = window.COVERAGE_DATA;
  const config = window.COVERAGE_CONFIG || { syntaxEnabled: true };

  // State
  let currentFileId = null;
  let searchQuery = '';
  let contentSearchQuery = '';
  let matches = [];
  let currentMatchIndex = -1;
  let expandedDirs = new Set();
  let syntaxHighlightEnabled = config.syntaxEnabled;
  let sortMode = 'name'; // 'name' or 'coverage'
  let anchorLine = null;        // First line clicked (anchor for shift-select)
  let selectedRange = null;     // { start: N, end: M } or null

  // DOM elements
  const fileTree = document.getElementById('file-tree');
  const viewport = document.getElementById('viewport');
  const filePath = document.getElementById('file-path');
  const summary = document.getElementById('summary');
  const searchInput = document.getElementById('search-input');
  const contentSearch = document.getElementById('content-search');
  const matchInfo = document.getElementById('match-info');
  const prevMatch = document.getElementById('prev-match');
  const nextMatch = document.getElementById('next-match');
  const themeToggle = document.getElementById('theme-toggle');
  const syntaxToggle = document.getElementById('syntax-toggle');
  const helpModal = document.getElementById('help-modal');
  const closeHelp = document.getElementById('close-help');
  const helpToggle = document.getElementById('help-toggle');

  // Coverage cache: fileId -> percentage
  let coverageCache = new Map();

  function initCoverageCache() {
    data.files.forEach((file, idx) => {
      coverageCache.set(idx, calculateFileCoverage(idx));
    });
  }

  function calculateFileCoverage(fileId) {
    const file = data.files[fileId];
    let totalStatements = 0;
    let coveredStatements = 0;

    file.coverage.forEach(cov => {
      if (cov > 0) totalStatements++;
      if (cov === 2) coveredStatements++;
    });

    return totalStatements === 0 ? 0 : (coveredStatements / totalStatements) * 100;
  }

  function calculateDirectoryCoverage(node) {
    if (node.type === 'file') {
      return coverageCache.get(node.fileId) || 0;
    }

    let totalCoverage = 0;
    let fileCount = 0;

    node.children?.forEach(child => {
      const childCov = calculateDirectoryCoverage(child);
      totalCoverage += childCov;
      fileCount++;
    });

    return fileCount === 0 ? 0 : totalCoverage / fileCount;
  }

  function sortTreeNodes(node, mode) {
    if (!node.children || node.children.length === 0) return node;

    // Deep copy to avoid mutating original
    const sorted = { ...node };
    sorted.children = [...node.children].map(child => sortTreeNodes(child, mode));

    // Sort children
    sorted.children.sort((a, b) => {
      // Directories always first
      if (a.type !== b.type) return a.type === 'dir' ? -1 : 1;

      if (mode === 'coverage') {
        const aCov = calculateDirectoryCoverage(a);
        const bCov = calculateDirectoryCoverage(b);
        console.log('Sorting:', a.name, '('+aCov.toFixed(1)+'%) vs', b.name, '('+bCov.toFixed(1)+'%)', '=', bCov - aCov);
        // Descending: high coverage first
        return aCov !== bCov ? bCov - aCov : a.name.localeCompare(b.name);
      }

      return a.name.localeCompare(b.name);
    });

    return sorted;
  }

  // Initialize
  function init() {
    initCoverageCache();
    loadSortPreference();
    renderSummary();
    renderTree();
    setupEventListeners();
    loadTheme();
    loadSyntaxPreference();

    // Check for deep link hash first, otherwise select first file
    if (!navigateToHash() && data.files.length > 0) {
      selectFile(0);
    }

    // Listen for hash changes (browser back/forward)
    window.addEventListener('hashchange', navigateToHash);
  }

  // Deep linking: parse URL hash
  function parseHash() {
    const hash = window.location.hash.slice(1);
    if (!hash) return null;

    const match = hash.match(/^file-(\d+)(?::line-(\d+)(?:-(\d+))?)?$/);
    if (!match) return null;

    return {
      fileId: parseInt(match[1], 10),
      lineStart: match[2] ? parseInt(match[2], 10) : null,
      lineEnd: match[3] ? parseInt(match[3], 10) : null
    };
  }

  // Deep linking: navigate to hash location
  function navigateToHash() {
    const target = parseHash();
    if (!target) return false;

    if (target.fileId < 0 || target.fileId >= data.files.length) return false;

    selectFile(target.fileId);

    if (target.lineStart) {
      requestAnimationFrame(() => {
        const lineEnd = target.lineEnd || target.lineStart;
        anchorLine = target.lineStart;
        selectedRange = { start: target.lineStart, end: lineEnd };
        selectLineRange(target.lineStart, lineEnd);
        scrollToLine(target.lineStart);
      });
    }

    return true;
  }

  // Deep linking: scroll to and highlight a line
  function scrollToLine(lineNum) {
    const lineEl = document.querySelector('.code-line[data-line="' + lineNum + '"]');
    if (!lineEl) return;

    lineEl.scrollIntoView({ behavior: 'smooth', block: 'center' });
  }

  // Clear all selected lines
  function clearLineSelection() {
    document.querySelectorAll('.code-line.selected-line').forEach(el => {
      el.classList.remove('selected-line');
    });
  }

  // Select a range of lines (inclusive)
  function selectLineRange(start, end) {
    clearLineSelection();
    const minLine = Math.min(start, end);
    const maxLine = Math.max(start, end);
    for (let i = minLine; i <= maxLine; i++) {
      const lineEl = document.querySelector('.code-line[data-line="' + i + '"]');
      if (lineEl) {
        lineEl.classList.add('selected-line');
      }
    }
  }

  // Deep linking: update URL hash
  function updateHash(fileId, lineStart, lineEnd) {
    let hash = 'file-' + fileId;
    if (lineStart) {
      hash += ':line-' + lineStart;
      if (lineEnd && lineEnd !== lineStart) {
        // Normalise so start < end
        const minLine = Math.min(lineStart, lineEnd);
        const maxLine = Math.max(lineStart, lineEnd);
        hash = 'file-' + fileId + ':line-' + minLine + '-' + maxLine;
      }
    }
    history.replaceState(null, '', '#' + hash);
  }

  function renderSummary() {
    // Build summary safely using DOM methods
    summary.textContent = '';
    const span = document.createElement('span');
    span.className = 'percent';
    span.textContent = data.summary.percent.toFixed(1) + '%';
    summary.appendChild(span);
    summary.appendChild(document.createTextNode(
      ' coverage (' + data.summary.coveredLines + '/' + data.summary.totalLines + ' lines)'
    ));
  }

  function renderTree() {
    fileTree.textContent = '';
    // Auto-expand all top-level directories
    if (data.tree.children && data.tree.children.length > 0) {
      data.tree.children.forEach(child => {
        if (child.type === 'dir') {
          expandedDirs.add(getNodePath(child, 0));
        }
      });
    }
    const sortedTree = sortTreeNodes(data.tree, sortMode);
    renderNode(sortedTree, fileTree, 0);
  }

  function renderNode(node, container, depth) {
    if (node.name === '.' && node.type === 'dir') {
      // Root node, render children directly
      node.children.forEach(child => renderNode(child, container, depth));
      return;
    }

    const nodeEl = document.createElement('div');
    nodeEl.className = 'tree-node';
    nodeEl.dataset.name = node.name.toLowerCase();

    const item = document.createElement('div');
    item.className = 'tree-item';
    item.style.setProperty('--depth', depth);

    const icon = document.createElement('span');
    icon.className = 'icon';

    const name = document.createElement('span');
    name.className = 'name';
    name.textContent = node.name;

    if (node.type === 'dir') {
      const dirPath = getNodePath(node, depth);
      icon.textContent = expandedDirs.has(dirPath) ? '\u25BC' : '\u25B6';
      if (expandedDirs.has(dirPath)) {
        nodeEl.classList.add('expanded');
      }

      item.addEventListener('click', (e) => {
        e.stopPropagation();
        toggleDir(nodeEl, dirPath, icon);
      });

      item.appendChild(icon);
      item.appendChild(name);

      // Add coverage badge to all directories
      const badge = document.createElement('span');
      badge.className = 'coverage-badge';
      badge.textContent = calculateDirectoryCoverage(node).toFixed(1) + '%';
      item.appendChild(badge);

      nodeEl.appendChild(item);

      if (node.children && node.children.length > 0) {
        const children = document.createElement('div');
        children.className = 'tree-children';
        node.children.forEach(child => renderNode(child, children, depth + 1));
        nodeEl.appendChild(children);
      }
    } else {
      icon.textContent = '\uD83D\uDCC4';
      nodeEl.dataset.fileId = node.fileId;

      item.addEventListener('click', (e) => {
        e.stopPropagation();
        selectFile(node.fileId);
      });

      item.appendChild(icon);
      item.appendChild(name);

      // Add coverage badge to files
      const badge = document.createElement('span');
      badge.className = 'coverage-badge';
      badge.textContent = calculateDirectoryCoverage(node).toFixed(1) + '%';
      item.appendChild(badge);

      nodeEl.appendChild(item);
    }

    container.appendChild(nodeEl);
  }

  function getNodePath(node, depth) {
    return node.name + '_' + depth;
  }

  function toggleDir(nodeEl, path, icon) {
    if (nodeEl.classList.contains('expanded')) {
      nodeEl.classList.remove('expanded');
      expandedDirs.delete(path);
      icon.textContent = '\u25B6';
    } else {
      nodeEl.classList.add('expanded');
      expandedDirs.add(path);
      icon.textContent = '\u25BC';
    }
  }

  function selectFile(fileId) {
    currentFileId = fileId;
    matches = [];
    currentMatchIndex = -1;
    matchInfo.textContent = '';
    contentSearch.value = '';
    contentSearchQuery = '';
    anchorLine = null;
    selectedRange = null;

    // Update selection in tree
    document.querySelectorAll('.tree-item.selected').forEach(el => {
      el.classList.remove('selected');
    });
    const selected = document.querySelector('[data-file-id="' + fileId + '"] .tree-item');
    if (selected) {
      selected.classList.add('selected');
    }

    const file = data.files[fileId];
    if (!file) return;

    filePath.textContent = file.path;
    renderCode(file);

    // Update URL hash for deep linking
    updateHash(fileId, null);
  }

  function renderCode(file) {
    viewport.textContent = '';

    if (!file.lines || file.lines.length === 0) {
      const empty = document.createElement('div');
      empty.className = 'empty-state';
      const iconDiv = document.createElement('div');
      iconDiv.className = 'icon';
      iconDiv.textContent = '\uD83D\uDCED';
      const textDiv = document.createElement('div');
      textDiv.textContent = 'No content';
      empty.appendChild(iconDiv);
      empty.appendChild(textDiv);
      viewport.appendChild(empty);
      return;
    }

    const container = document.createElement('div');
    container.className = 'code-container';

    file.lines.forEach((line, idx) => {
      const lineEl = document.createElement('div');
      lineEl.className = 'code-line';
      lineEl.dataset.line = idx + 1;

      const cov = file.coverage[idx];
      if (cov === 2) {
        lineEl.classList.add('covered');
      } else if (cov === 1) {
        lineEl.classList.add('uncovered');
      }

      const gutter = document.createElement('div');
      gutter.className = 'gutter';

      const lineNum = document.createElement('div');
      lineNum.className = 'line-number';
      lineNum.textContent = idx + 1;
      lineNum.title = 'Click to select line, Shift+Click for range';

      // Add click handler for line number deep linking
      const lineNumber = idx + 1;
      lineNum.addEventListener('click', (e) => {
        e.stopPropagation();

        if (e.shiftKey && anchorLine !== null) {
          // Shift-click: select range from anchor to clicked line
          const start = Math.min(anchorLine, lineNumber);
          const end = Math.max(anchorLine, lineNumber);
          selectedRange = { start: start, end: end };
          selectLineRange(start, end);
          updateHash(currentFileId, start, end);
        } else {
          // Regular click: set anchor and select single line
          anchorLine = lineNumber;
          selectedRange = { start: lineNumber, end: lineNumber };
          selectLineRange(lineNumber, lineNumber);
          updateHash(currentFileId, lineNumber, null);
        }
      });

      const content = document.createElement('div');
      content.className = 'line-content';
      content.textContent = line || ' ';

      lineEl.appendChild(gutter);
      lineEl.appendChild(lineNum);
      lineEl.appendChild(content);
      container.appendChild(lineEl);
    });

    viewport.appendChild(container);

    // Apply syntax highlighting after rendering if enabled
    if (syntaxHighlightEnabled) {
      applySyntaxHighlighting();
    }
  }

  function setupEventListeners() {
    // File search
    let searchTimeout;
    searchInput.addEventListener('input', (e) => {
      clearTimeout(searchTimeout);
      searchTimeout = setTimeout(() => {
        searchQuery = e.target.value.toLowerCase();
        filterTree();
      }, 300);
    });

    // Content search
    let contentTimeout;
    contentSearch.addEventListener('input', (e) => {
      clearTimeout(contentTimeout);
      contentTimeout = setTimeout(() => {
        contentSearchQuery = e.target.value;
        searchInFile();
      }, 300);
    });

    contentSearch.addEventListener('keydown', (e) => {
      if (e.key === 'Enter') {
        if (e.shiftKey) {
          goToPrevMatch();
        } else {
          goToNextMatch();
        }
      }
    });

    prevMatch.addEventListener('click', goToPrevMatch);
    nextMatch.addEventListener('click', goToNextMatch);

    // Theme toggle
    themeToggle.addEventListener('click', toggleTheme);

    // Syntax toggle
    syntaxToggle.addEventListener('click', toggleSyntax);

    // Sort controls
    const sortButtons = document.querySelectorAll('.sort-btn');
    console.log('Found', sortButtons.length, 'sort buttons');
    sortButtons.forEach(btn => {
      console.log('Attaching click handler to button:', btn.dataset.sort);
      btn.addEventListener('click', () => {
        console.log('Sort button clicked:', btn.dataset.sort);
        changeSortMode(btn.dataset.sort);
      });
    });

    // Keyboard shortcuts
    document.addEventListener('keydown', (e) => {
      if ((e.ctrlKey || e.metaKey) && e.key === 'f' && currentFileId !== null) {
        e.preventDefault();
        contentSearch.focus();
      }
      if ((e.ctrlKey || e.metaKey) && e.key === 'p') {
        e.preventDefault();
        searchInput.focus();
      }
      // Help modal
      if (e.key === '?' && !e.ctrlKey && !e.metaKey) {
        e.preventDefault();
        showHelp();
      }
      if (e.key === 'Escape') {
        // Exit search if focused
        if (document.activeElement === searchInput) {
          searchInput.value = '';
          searchQuery = '';
          filterTree();
          searchInput.blur();
          viewport.focus();
          return;
        }
        if (document.activeElement === contentSearch) {
          contentSearch.value = '';
          contentSearchQuery = '';
          matchInfo.textContent = '';
          matches = [];
          currentMatchIndex = -1;
          if (currentFileId !== null) {
            renderCode(data.files[currentFileId]);
          }
          contentSearch.blur();
          viewport.focus();
          return;
        }
        hideHelp();
      }
    });

    closeHelp.addEventListener('click', hideHelp);
    helpToggle.addEventListener('click', showHelp);
    helpModal.addEventListener('click', (e) => {
      if (e.target === helpModal) hideHelp();
    });
  }

  function filterTree() {
    const nodes = document.querySelectorAll('.tree-node');

    if (!searchQuery) {
      nodes.forEach(n => n.classList.remove('hidden'));
      return;
    }

    nodes.forEach(node => {
      const name = node.dataset.name || '';
      const fileId = node.dataset.fileId;

      if (fileId !== undefined) {
        const file = data.files[parseInt(fileId)];
        const matchesQuery = file && file.path.toLowerCase().includes(searchQuery);
        node.classList.toggle('hidden', !matchesQuery);
      } else {
        const hasVisibleChild = Array.from(node.querySelectorAll('[data-file-id]')).some(f => {
          const fid = parseInt(f.dataset.fileId);
          const file = data.files[fid];
          return file && file.path.toLowerCase().includes(searchQuery);
        });
        node.classList.toggle('hidden', !hasVisibleChild);
        if (hasVisibleChild && searchQuery) {
          node.classList.add('expanded');
          const icon = node.querySelector('.icon');
          if (icon && icon.textContent === '\u25B6') {
            icon.textContent = '\u25BC';
          }
        }
      }
    });
  }

  function searchInFile() {
    matches = [];
    currentMatchIndex = -1;

    // Re-render code to clear highlights
    if (currentFileId !== null) {
      const file = data.files[currentFileId];
      if (file) {
        renderCode(file);
      }
    }

    if (!contentSearchQuery || currentFileId === null) {
      matchInfo.textContent = '';
      return;
    }

    const file = data.files[currentFileId];
    if (!file) return;

    const query = contentSearchQuery.toLowerCase();

    file.lines.forEach((line, idx) => {
      const text = line || '';
      const lowerText = text.toLowerCase();
      let pos = 0;
      let matchIndex;

      while ((matchIndex = lowerText.indexOf(query, pos)) !== -1) {
        matches.push({ line: idx, start: matchIndex, length: query.length });
        pos = matchIndex + 1;
      }
    });

    if (matches.length > 0) {
      highlightMatches();
      currentMatchIndex = 0;
      scrollToMatch(0);
      updateMatchInfo();
    } else {
      matchInfo.textContent = 'No matches';
    }
  }

  function highlightMatches() {
    const file = data.files[currentFileId];
    if (!file) return;

    const lineEls = document.querySelectorAll('.code-line');

    // Group matches by line
    const matchesByLine = {};
    matches.forEach((m, idx) => {
      if (!matchesByLine[m.line]) matchesByLine[m.line] = [];
      matchesByLine[m.line].push({ ...m, idx });
    });

    Object.keys(matchesByLine).forEach(lineIdx => {
      const lineEl = lineEls[parseInt(lineIdx)];
      if (!lineEl) return;

      const content = lineEl.querySelector('.line-content');
      if (!content) return;

      const text = file.lines[parseInt(lineIdx)] || '';
      const lineMatches = matchesByLine[lineIdx].sort((a, b) => a.start - b.start);

      // Build content using DOM nodes for safety
      content.textContent = '';
      let lastEnd = 0;

      lineMatches.forEach(m => {
        // Text before match
        if (m.start > lastEnd) {
          content.appendChild(document.createTextNode(text.substring(lastEnd, m.start)));
        }
        // Match span
        const span = document.createElement('span');
        span.className = 'match-highlight';
        span.dataset.matchIdx = m.idx;
        span.textContent = text.substring(m.start, m.start + m.length);
        content.appendChild(span);
        lastEnd = m.start + m.length;
      });

      // Text after last match
      if (lastEnd < text.length) {
        content.appendChild(document.createTextNode(text.substring(lastEnd)));
      }

      // Handle empty line
      if (content.childNodes.length === 0) {
        content.textContent = ' ';
      }
    });
  }

  function scrollToMatch(idx) {
    document.querySelectorAll('.current-match').forEach(el => {
      el.classList.remove('current-match');
    });

    const matchEl = document.querySelector('[data-match-idx="' + idx + '"]');
    if (matchEl) {
      matchEl.classList.add('current-match');
      matchEl.scrollIntoView({ behavior: 'smooth', block: 'center' });
    }
  }

  function updateMatchInfo() {
    if (matches.length === 0) {
      matchInfo.textContent = 'No matches';
    } else {
      matchInfo.textContent = (currentMatchIndex + 1) + '/' + matches.length;
    }
  }

  function goToNextMatch() {
    if (matches.length === 0) return;
    currentMatchIndex = (currentMatchIndex + 1) % matches.length;
    scrollToMatch(currentMatchIndex);
    updateMatchInfo();
  }

  function goToPrevMatch() {
    if (matches.length === 0) return;
    currentMatchIndex = (currentMatchIndex - 1 + matches.length) % matches.length;
    scrollToMatch(currentMatchIndex);
    updateMatchInfo();
  }

  function toggleTheme() {
    const body = document.body;
    const current = body.dataset.theme;
    const next = current === 'dark' ? 'light' : 'dark';
    body.dataset.theme = next;
    localStorage.setItem('coverage-theme', next);
  }

  function loadTheme() {
    const saved = localStorage.getItem('coverage-theme');
    if (saved) {
      document.body.dataset.theme = saved;
    }
  }

  function applySyntaxHighlighting() {
    if (!syntaxHighlightEnabled || currentFileId === null) return;
    if (typeof hljs === 'undefined') return;

    const file = data.files[currentFileId];
    if (!file) return;

    const lineEls = document.querySelectorAll('.code-line');

    lineEls.forEach((lineEl, idx) => {
      const cov = file.coverage[idx];
      // Only highlight lines with no coverage info
      if (cov !== 0) return;

      const content = lineEl.querySelector('.line-content');
      if (!content || !content.textContent.trim()) return;

      const text = content.textContent;

      // Use hljs.highlight() which returns result object
      const result = hljs.highlight(text, { language: 'go' });

      // Parse the highlighted HTML safely using DOMParser
      const parser = new DOMParser();
      const doc = parser.parseFromString('<div>' + result.value + '</div>', 'text/html');
      const wrapper = doc.body.firstChild;

      // Clear and append parsed nodes
      content.textContent = '';
      while (wrapper.firstChild) {
        content.appendChild(wrapper.firstChild);
      }
    });
  }

  function toggleSyntax() {
    syntaxHighlightEnabled = !syntaxHighlightEnabled;
    syntaxToggle.classList.toggle('active', syntaxHighlightEnabled);
    localStorage.setItem('coverage-syntax', syntaxHighlightEnabled ? 'on' : 'off');

    // Re-render current file
    if (currentFileId !== null) {
      const file = data.files[currentFileId];
      if (file) {
        renderCode(file);
      }
    }
  }

  function loadSyntaxPreference() {
    const saved = localStorage.getItem('coverage-syntax');
    if (saved !== null) {
      // User preference overrides default
      syntaxHighlightEnabled = saved === 'on';
    }
    // Update button state
    syntaxToggle.classList.toggle('active', syntaxHighlightEnabled);
  }

  function changeSortMode(mode) {
    if (sortMode === mode) return;

    console.log('Changing sort mode from', sortMode, 'to', mode);
    sortMode = mode;
    localStorage.setItem('coverage-sort-mode', mode);

    // Update button states
    document.querySelectorAll('.sort-btn').forEach(btn => {
      btn.classList.toggle('active', btn.dataset.sort === mode);
    });

    // Re-render tree
    renderTree();
  }

  function loadSortPreference() {
    const saved = localStorage.getItem('coverage-sort-mode');
    if (saved && (saved === 'name' || saved === 'coverage')) {
      sortMode = saved;
    }

    // Update button states
    document.querySelectorAll('.sort-btn').forEach(btn => {
      btn.classList.toggle('active', btn.dataset.sort === sortMode);
    });
  }

  function showHelp() {
    helpModal.classList.remove('hidden');
  }

  function hideHelp() {
    helpModal.classList.add('hidden');
  }

  // Start the app
  init();
})();

    </script>
  </body>
</html>
